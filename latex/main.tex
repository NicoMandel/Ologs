% IEEEAerospace2012.cls requires the following packages: times, rawfonts, oldfont, geometry
\documentclass[twocolumn,letterpaper]{IEEEAerospaceCLS}  % only supports two-column, letterpaper format

% The next line gives some packages you may find useful for your paper--these are not required though.
%\usepackage[]{graphicx,float,latexsym,amssymb,amsfonts,amsmath,amstext,times,psfig}
% NOTE: The .cls file is now compatible with amsmath!!!

\usepackage[]{graphicx}    % We use this package in this document
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    filecolor=black,      
    urlcolor=black,
    citecolor=black,
    draft,
}
\newcommand{\ignore}[1]{}  % {} empty inside = %% comment
\newcommand\todo[1]{\textbf{\textcolor{red}{#1}}}
\graphicspath{{imgs/}}

\begin{document}
\title{An ontology for UAV based  Semantic Navigation}

\author{%
    Nicolas Mandel\\
    Queensland University of Technology\\
    Australian Centre for Robotic Vision\\
    QUT Centre for Robotics\\
    nicolasjohann.mandel@hdr.qut.edu.au
    \and
    Michael Milford\\
    Queensland University of Technology\\
    Australian Centre for Robotic Vision\\
    QUT Centre for Robotics\\
    \and
    Felipe Gonzalez\\
    Queensland University of Technology\\
    Australian Centre for Robotic Vision\\
    QUT Centre for Robotics\\
    %%%% IMPORTANT: Use the correct copyright information--IEEE, Crown, or U.S. government. %%%%%
    \thanks{\footnotesize 978-1-7281-7436-5/21/$\$31.00$ \copyright2021 IEEE}              % This creates the copyright info that is the correct 2021 data.
    %\thanks{{U.S. Government work not protected by U.S. copyright}}         % Use this copyright notice only if you are employed by the U.S. Government.
    %\thanks{{978-1-7281-7436-5/21/$\$31.00$ \copyright2021 Crown}}          % Use this copyright notice only if you are employed by a crown government (e.g., Canada, UK, Australia).
    %\thanks{{978-1-7281-7436-5/21/$\$31.00$ \copyright2021 European Union}}    % Use this copyright notice is you are employed by the European Union.
}



\maketitle

\thispagestyle{plain}
\pagestyle{plain}



\maketitle

\thispagestyle{plain}
\pagestyle{plain}

\begin{abstract}
    Limitations in power, size and weight in UAVs have resulted in researchers exploring alternative navigation approaches to reduce the computational load onboard UAVs. In this work we present an ontology for semantic based navigation for UAVs. Contextual information is commonly used for navigation, with semantics at the frontier of contemporary robotic-based navigation research showing promising results. However, the connection between spatial and semantic information is not yet clear and formal definitions are limited in the literature. This paper aims to provide an ontology to link spatial and semantic relations through Ologs, an application of the mathematical field of category theory. Contemporary semantic concepts from natural language are fused with a spatial-semantic hierarchy in a mathematical framework. The framework is tested in simulations and its applicability verified with different scenarios. Results indicate that the defined spatial structure allows for improved UAV navigational capabilities. The presented ontology is mathematically sound and can be adapted to a number of semantic navigation use-cases in agriculture, search and rescue or industrial inspections.
\end{abstract}


\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction} \label{sec:Intro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Problem Introduction}

% \subsection{Why is this problem important}
Contemporary robotics places great emphasis on including semantic signals into the perception-understanding-control-pipeline. Semantic information has been included into the passive part of SLAM~\cite{cadena_past_2016,zhang_hierarchical_2019}, as well as into active path planning~\cite{koch_automatic_2019,alirezaie_exploiting_2017}. Kostavelis and Gasteratos define semantics as ''[...] related to the study between signs and the things to which they refer, that is their meaning.''~\cite{kostavelis_semantic_2015}. However, in terms of spatial occurrence, multiple levels of signals are possible, such as individual objects, regions or areas~\cite{kostavelis_semantic_2015}. These cause new problems for definining successful navigation, as highlighted by Anderson et al.~\cite{anderson_evaluation_2018}. Furthermore, recent advances in Computer Vision have produced a wide range of different sensors signals to be annotated with semantic information, such as pixel-level segmentation, object detection or scene classification~\cite{alom_history_2018}, which operate on different spatial levels.\\
The influence of these sensor signals on the level of names on conventional robotics algorithms, such as filters and path planners, is an active field of research~\cite{kostavelis_semantic_2015,cadena_past_2016,anderson_evaluation_2018}. UAVs are impacted by unique viewing angles, as well as risk-averse requirements and hard constraints on computational resources~\cite{mandel_method_2020,gonzalez_unmanned_2016}, which turn them into a special case of semantic based robotic navigation.
\begin{figure}
    \centering
    \includegraphics[width=3.25in]{Aerial13.png}\\
    \caption{\bf{An example of a UAV performing a semantic mapping task on an urban area, demonstrated by assigning colors to grid maps. The X denotes the UAV and its Field of View is denoted by a black square surrounding it.}}
    \label{fig:AerialImg}
\end{figure}
% \subsection{What do we propose for solving it}
In this paper we evaluate a selected subset of literature, which combines semantic signals with spatial information in robotics to demonstrate the state of the research. The literature is categorised with respect to different dimensions: robot type, spatial map and semantic map. In the second section the information from the literature is used to improve semantic mapping of a two-dimensional occupancy grid map and it is shown how parameters surrounding the quality of observations, overlap and field of view influence a Bayesian filter approach. The filter is supplemented through an informed prior and the effectiveness of the approach is demonstrated in numerical simulations. This research is directed towards enhancing the performance of a module which is tasked with extracting and evaluating the semantic information during UAV path planning in a navigational framework~\cite{mandel_towards_2020}. The final section of this work points to successful approaches from related fields dealing with semantic information, such as speech recognition and language, which could hold the potential to enhance the inclusion of semantic information, as demonstrated by Lienou et al.~\cite{lienou_semantic_2010}.
\section{Methodology} \label{sec:Met}
\subsection{Literature Taxonomy} \label{ssec:MetLit}
$26$ papers were selected for this research. The papers are sorted according to the following three dimensions and the methods employed in those papers are extracted:
\begin{enumerate}
    \item Robot Type
    \item Spatial Map
    \item Semantic Map
\end{enumerate}
A discussion on the results for the literature taxonomy is presented in section~\ref{ssec:ResLit} and illustrated by figure~\ref{fig:LitRes}. The information from the literature is used to derive an algorithm following the development pipeline as shown in figure~\ref{fig:DevProcess}. Following the proposal of an algorithm, numerical simulations are conducted to highlight the improved performance. The results from the numerical simulation are presented in section~\ref{ssec:ResSim} and conclusions for future developments and potential integration into higher level architectures are drawn in section~\ref{ssec:DiscSim}.
\subsection{Simulations} \label{ssec:MetSim}
\begin{figure}[h!]
    \centering
    \includegraphics[width=3.25in]{2-3DevelopmentCycle.png}\\
    \caption{\bf{A generic autonomy development cycle as proposed by Ladosz et al.~\protect\cite{ladosz_generic_2019}}}
    \label{fig:DevProcess}
\end{figure}
Numerical simulations are conducted to uncover influences of parameters of the mapping pipeline and differences between algorithms. Figure~\ref{fig:SimCase} shows the setup of the simulation. The task is to recreate a map from sequential, noisy semantic observations. The map is an evenly spaced 2D grid $M \times M$ defined by a one-hot vector of the true identity, $x_{i,j} = \{0,..., 1, ..., 0\}_K$, with $K$ indicating the number of classes. The probability of making an observation $z$ is given by $p(z\mid x)$. The pose is assumed to be known for the entire trajectory. At each time increment $t$ the UAV observes cells within its field of view $f$, receives a one-hot observation proportional to $p(z\mid x)$ and updates the posterior of each map cell given by Bayes' rule as:
\begin{equation} \label{eq:Bayes}
    p(x\mid z) = \frac{p(z\mid x) p(x)}{p(z)}
\end{equation}
which is equivalent to the performance of any given detector~\cite{alom_history_2018}.
\begin{figure*}[t]
    \centering
    \resizebox{\textwidth}{!}{
    \includegraphics[width=4in]{SimComp11.png}}
    \caption{\bf{
        Example of the different test environments. Colors are intended to represent different semantic classes according to table~\ref{tab:colors}. The top left corner shows the first simulation environment $s=1$, the bottom left corner an example path. The top centre shows the second environment $s=2$, the top right a transposed configuration, $t$, bottom centre a randomised configuration $r=1$ and bottom right a test configuration $c=1$ as defined in table~\ref{tab:params}.
    }}
    \label{fig:SimCase}
\end{figure*}
The UAV is following a conventional lawnmower pattern, where the stride in both dimensions is defined through a desired overlap $o$ and field of view $f$~\cite{shetty_implementation_2020}. Figure~\ref{fig:SimCase} shows a snapshot of the simulation at time $t=47$. The green cells in the figure indicate the cells that have already been observed, the red cells the current $f$ of the UAV, which is marked by the black $\times$. The blue cells denote the cells where the prior $p(x)$ has been predicted at $t_{-1}$, based on the posterior of the red cells.\\ 
Four algorithms are compared in parallel with the same sampled observations. In all cases, only the prior $p(x_{t=0})$ for each cell is predicted and all subsequent observations are incorporated according to equation~\ref{eq:Bayes}. In the baseline case (algorithm 1), the prior for each cell $p(x)$ is uniform over all classes $K$. In the other three cases, spatial correlation is incorporated into the prior. The prediction for the cells is made by extracting the next waypoint $t_{+1}$ and evaluating all cells that will be visible within the field-of-view $f$ at that timestep. In the second algorithm (algorithm 2), yet unobserved cells receive a prior which is a linear combination of the uniform prior and the posterior of the already observed cells. The posterior probability is weighted by a mixing parameter $\alpha \in [0, 1]$, as well as the ratio of number of observed cells divided by total cells and used as a prior for the yet unobseved cells.\\
The other two algorithms are based on assumptions drawn from the results of the literature taxonomy as detailed in section~\ref{ssec:ResLit}. Incorporating information in a hierarchical context has proven successful in related semantic fields, such as speech processing~\cite{fine_hierarchical_1998} and topic modelling~\cite{blei_latent_2003}. These approaches have been succesfully adapted to related domains, such as SLAM~\cite{zhang_hierarchical_2019}, or image annotation~\cite{fei-fei_bayesian_2005,lienou_semantic_2010}. Some algorithms have incorporated the semantic information succesfully for the purpose of navigation~\cite{koch_automatic_2019,chaplot_object_2020,wu_learning_2018,alirezaie_exploiting_2017}.\\
Two algorithms  that recalculate the prior based on hierarchical information are proposed: the prior is calculated according to an assumed distribution of ''areas'' -- $u$ -- groupings of cells. These groupings require the definition of $p(x\mid u)$ and $p(u)$, as well as the number of groupings -- usually smaller than $K$ -- analogous to topic modelling~\cite{blei_latent_2003}. In the third algorithm (algorithm 3), every map cell is assigned a fixed prior of $p(x_{t=0}) = p(x\mid u)p(u)$. In the fourth algorithm (algorithm 4) $p(u)$ is updated dynamically by using the observations of each cell within $f$, with a fixed $p(x\mid u)$, which leads to a new dynamically assigned $p(x)$.\\
Three variations of $p(u)$ and $p(x\mid u)$ are considered. The first is a manual version, where the mixture of ''objects'' in ''areas'' $p(x\mid u)$ is estimated by the user and the distribution of ''areas'' $p(u)$ in the map as well. In the second and third version, $p(x\mid u)$ and $p(u)$ are derived through Monte-Carlo simulations described in section~\ref{ssec:MetMC}. $K=5$ and $3$ are used for the simulations, because the small number allows for interpretability, visual simplicity and numerical stability when defining and evaluating simulation cases.\\
Robotics research is often constrained by the overlap of classes available in detection and simulation environments~\cite{chaplot_object_2020}, such that $5$ is a reasonable approximation for numerical research. The chosen classes are distributed according to different scales, with one class being dominant in the map, occupying over $70$\% of the cells in the majority of cases, while another class occupies less that $1$\%. Furthermore, the classes occupy different connected regions of the map, ranging from $1$ isolated cell to multiples of the field-of-view, which allows the investigation how different scales influence the performance.\\
The simulation cases can be transposed -- indicated by $t$ in figure~\ref{fig:SimCase}-- to evaluate the influence of the path planning direction on the predictive performance. The second simulation environment has further boolean parameters, that randomize the placement of objects in quadrants --$r$, as well as a parameter that mixes two quadrants -- $c$ -- to illustrate visual diversity and reduce uniformity of areas.\\
The simulation cases are displayed in figure~\ref{fig:SimCase} and table~\ref{tab:params} shows the parameters that have been varied.
\begin{table}[]
    \renewcommand{\arraystretch}{1.3}
    \caption{\bf Color indicators}
    \label{tab:colors}
    \centering
    \begin{tabular}{|r||l|}
        \hline
        \bfseries Color      & \bfseries Class Name    \\
        \hline \hline
        Red &  House\\
        \hline
        Gray  & Road         \\
        \hline
        Light Green     & Grass              \\
        \hline
        Dark Green & Tree           \\
        \hline
        Blue & Vehicle \\
        \hline
    \end{tabular}
\end{table}
\begin{table}[]
    \renewcommand{\arraystretch}{1.3}
    \caption{\bf Parameter variations for the simulations}
    \label{tab:params}
    \centering
    \begin{tabular}{|r||c|l|}
        \hline
        \bfseries Name      & \bfseries Symbol & \bfseries Values       \\
        \hline \hline
        Map Dimensions & $M$ & $48, 64$\\
        \hline
        Field of View  & $f$              & $1, 2$ \\
        \hline
        Overlap     & $o$              & $0.25, 0.5, 0.75$         \\
        \hline
        Accuracy & $p(z\mid x)$              & $0.6, 0.7, 0.8, 0.9, 0.95$        \\
        \hline
        Environment & $s$& $1, 2$ \\
        \hline
        Random & $r$ & $0, 1$ \\
        \hline
        Transpose & $t$ & $0, 1$  \\
        \hline
        Test & $c$ & $0, 1$  \\
        \hline
    \end{tabular}
\end{table}
The mixing parameter $\alpha$ is evaluated in a preliminary set of experiments, where $\alpha \in [0, 0.2, ..., 1]$ and therefore not included in table~\ref{tab:params}.
Figure~\ref{fig:SimCase} shows the basic variations for the simulation environments. The top left is the first environment, which is also used for the Monte-Carlo simulations detailed in section~\ref{ssec:MetMC} and excluded from the evaluation. The top centre shows the second environment, with the top right a transposed environment. The bottom left shows an example path, with the green colour indicating the already explored areas, the red the already seen fields and the blue the yet unexplored fields, which are predicted. The bottom centre shows a case where the placement of objects within their quadrants is randomised. The bottom right shows an environment with partial transpose, which convolutes the definition of an ''area'' as a section identifiable by its composition of objects. The colours are indicators of types of classes and can be interpreted as shown in table~\ref{tab:colors}, however, are not limited to the named classes.
\subsubsection{Monte-Carlo simulations} \label{ssec:MetMC}
$1000$ simulations with fixed $o=0.5$, $f=2$ and
\begin{equation} \nonumber
    p(z\mid x)=
    \begin{cases}
        0.8,~\text{for}~k=x \\
        \frac{1-0.8}{K-1},~\text{otherwise}
    \end{cases}
\end{equation}
are run on the first environment. $p(u)$ and $p(x\mid u)$ are sampled from a simplex and the performance of each algorithm as defined in section~\ref{ssec:MetEval} and $p(u)$ and $p(x\mid u)$ are saved if:
\begin{enumerate}
    \item The log-likelihood is smaller than the current smallest
    \item The difference between the predicted algorithm and the dynamic algorithm is bigger than the current biggest
\end{enumerate}
The final best results are used as parameters $p(u)$ and $p(x\mid u)$ for additional simulations as defined in section~\ref{ssec:MetSim}.
\subsubsection{Evaluation}\label{ssec:MetEval}
The reproduction quality of the posterior map for each individual state was evaluated with the sum over the log-likelihoods for each cell $m_{i,j}$, defined by:
\begin{equation} \label{eq:Entropy}
    H = - \sum_{i,j,k} p_{i,j,k}~ln(q_{i,j,k})
\end{equation}
is calculated, where $p$ represents the true state and $q$ the estimated map state.\\
For the comparison of different algorithms running with the same parameters, the log-likelihoods for each individual case are subtracted from another and the count of the positive and negative samples indicate the relative quality of the reproduction:
\begin{equation} \label{eq:eval}
    \frac{pos}{pos+neg} \in [0, 1]
\end{equation} If the value is below $50$\%, the algorithm performs worse than its compared basedline. This metric is chosen as a robust indicator, which is not affected by large variances for each simulation run caused by the different parameters. 
Only the second simulation cenivonment is included in the evaluation, since the first simulation environment was used to generate sample probability vectors, as described in section~\ref{ssec:MetMC}.
\section{Results} \label{sec:Res}
\subsection{Literature Taxonomy} \label{ssec:ResLit}
\begin{figure*}
    \centering
    \resizebox{\textwidth}{!}{
    \includegraphics[width=4in]{Lit-11.png}}
    \caption{\bf{
        Categorization of the reviewed literature. The y-axis represents the level of the semantic information, whether objects, areas or a hierarchical combination were used. The x-axis represents the spatial information, ranging from image space over topological associations to metric space. The colors represent the type of robot used in the research, with blue denoting UAVs, orange denoting ground robots and green generic research.
    }}
    \label{fig:LitRes}
\end{figure*}
Figure~\ref{fig:LitRes} shows the results of generating a taxonomic representation of the literature. The reviewed literature extends to a selection from 1995 to 2020 and has been classified according to the spatial and semantic maps that were used, as well as the robot type employed in the research. It should be noted that in most cases image space was used to extract semantic information, however, the map retainment is considered as the defining factor for the spatial map. The majority  of research considered in this work is employing a hybrid approach on either the semantic level or the spatial level. A smaller portion considers non-hybrid information and is placed in the corners of the figure.  
\subsubsection{Generic Research} \label{sssec:ResLitHist}
$5$ research efforts considered as ''generic'' from as early as 1995  have been included in the taxonomy of this paper.\\
Chown and colleagues for example~\cite{chown_prototypes_1995} researched the "what" and "where" subsystems of the human cognition and their learning over time. They captured the influence of landmark recognition, recreation of consistent Euclidean maps, as well as the importance of gateways, representing transitions between regions. Suenderhauf et al.~\cite{sunderhauf_meaningful_2017} associated point-clouds in SLAM with labels propagated through a modern neural network. Yang et al.~\cite{yang_visual_2018} used scene priors derived from vector representations of class names to enhance a reinforcement learning module which relies on visual cues in indoor environments. Crespo et al.~\cite{crespo_reasoning_2018} generalised the implementation of a knowledgebase-system developed by Tenorth et al.~\cite{tenorth_knowrob-map_2010} to a database implementation and improved the speed significantly. In 2018,Wu et al.~\cite{wu_learning_2018} used reinforcement learning to train an agent to recognise a room and infer whether one room type is directly or indirectly accessible from another room using a Bernoulli distribution.
\subsubsection{Ground Robots} \label{sssec:ResLitCont}
$8$ research efforts from a timespan between 2000 and 2020 have been considered in this taxonomy. Contemporary image processing techniques have accelerated semantic spatial research through significant improvements in reliability and robustness of classification and localisation in image space~\cite{alom_history_2018}.\\
Kuipers~\cite{kuipers_spatial_2000} connected places, defined as 0D ''points'', through 1D ''paths'' with 2D ''regions'' in topological maps. The proposed maps had a sensory and control level, a causal level, a topological level and a metrical level, all of which were connnected hierarchically. Together with his colleagues, Kuipers~\cite{kuipers_local_2004} also conducted experiments where local metric room representations were linked through topological constraints.~\todo{This is not yet in the graphic. INCLUDE!}. Galindo et al.~\cite{galindo_robot_2008} connected a spatial hierarchical representation consisting of areas and objects with a terminological box and connected between these two in a deterministic manner to enable inference and path planning. Borkowski et al.~\cite{borkowski_towards_2010} assigned a hierarchical place taxomony based on house representations from architecture to a metric map and performed path-planning within this map while considering semantic constraints. Tenorth~\cite{tenorth_knowrob-map_2010} built a topological representation of abstract objects and locations and associates these in a hierarchical fashion to enhance task planning by incorporating the relations of objects. Krishnan and Krishna~\cite{krishnan_visual_2010} constructed a hierarchical semantical-topological and explored the semantic nodes before proceeding to the next. Zhang et al.~\cite{zhang_hierarchical_2019} used a hierarchical topic model to improve the performance of a SLAM system by actively integrating the object association problem into a hierarchical dirichlet process.\\
Chaplot et al.~\cite{chaplot_object_2020} won the 2020 CVPR challenge to navigate to an object goal by learning a semantic-metric map from visual cues and training a policy to generate frontier-based goals. Their research also highlighted that other RL policies were outperformed by frontier-based methods and were unable to generalize to the real-world.\\
\subsubsection{UAVs} \label{sssec:ResLitUAV}
$13$ UAV-based research efforts from $2013$ onwards have been included in this taxonomy, which present a variety of approaches of including semantic information. A substantial amount of literature is concerned with passive acquisition of semantic information: 
Le Saux and Sanfourche~\cite{saux_rapid_2013}, Sheppard and Rahnemoonfar~\cite{sheppard_real-time_2017}, Christie et al.~\cite{christie_semantics_2016} and Kyrkou et al.~\cite{kyrkou_dronet:_2018}, classified top-down images taken from a UAV. Cavaliere et al.~\cite{cavaliere_towards_2016,cavaliere_towards_2018} associated ''tracks'' coming from images with ''places'' from geospatial information to describe relations between them in a relational manner, as detailed in~\cite{landsiedel_review_2017}. The individual items were structured hierarchically to distinguish between different type of tracks, such as vehicles and humans on the first level and cars, motorcycles and trucks on the second level. Drouilly et al.~\cite{drouilly_semantic_2015} developed a metric to evaluate the semantic quality of a path through an environment depending on the distribution of objects and the observation quality.\\
Semantic information has also been employed in activa navigation. Maturana et al.~\cite{maturana_looking_2017} annotated a 2.5D map with detection of cars and approached the cars. Maravall et al.~\cite{maravall_navigation_2017} used the image entropy to navigate through a topological map to semantically salient places. Alirezaie~\cite{alirezaie_exploiting_2017} developed a RRT implementation that discards semantically inadmissible points through geospatial information associated with the waypoints and significantly improved planning time for longer distances. Dang et al.~\cite{dang_autonomous_2018} employed an object detector on top of a voxel grid to detect humans and bicycles. Koch et al.~\cite{koch_automatic_2019} respected semantic constraints during the path planning step for 3D reconstruction using UAVs while maintaining the quality of the reconstruction.
Toudeshki et al.~\cite{toudeshki_robust_2018} combined a visual teach-and-repeat approach with an object detector to funnel the UAV to follow a path.
\subsubsection{Summary} \label{sssec:ResLitSum}
Fusing semantic information with spatial information for navigation, mapping or task-planning has been an active field of research for the past decades. A majority of research fuses information into hybrid models, either on the semantic or on the spatial axis. This is demonstrated by the centralised cluster as shown in figure~\ref{fig:LitRes}. UAV research is more spread out than other approaches in this figure.
\subsection{Simulations} \label{ssec:ResSim}
Figure~\ref{fig:Res} displays the results of the numerical simulations evaluated on the second simulation environment, $s=2$. Preliminary experiments showed that the second algorithm, which predicts yet unobserved cells with a mixture of $\alpha = 0.5$ always outperformed the weakest baseline and largely outperformed the second, hierarchical baseline. Therefore, results are presented which compare the hierarchical dynamic prediction of $p(x)$ through $p(u)$ and $p(x\mid u)$ with the prediction through the mixture component of $\alpha = 0.5$. A total of $1975$ simulation cases are included in this evaluation. The height of the bar indicates the percentage of outperformance, as indicated by equation~\ref{eq:eval}. A value below the threshold of $50$ \% indicates a worse performance.
\begin{figure*}
    \centering
    \resizebox{\textwidth}{!}{
    \includegraphics[width=4in]{Results-10.png}}
    \caption{\bf{
        Relative amount of simulations where the entropy for dynamically updated priors was lower than for linear mixing. Each row represents a different parameter as described in table~\ref{tab:params}. The black vertical line indicates the $50$ threshold. Values lower than the threshold indicate a worse performance.
    }}
    \label{fig:Res}
\end{figure*}
% go from nondescript to descript here!
The bars for \emph{Dim} and \emph{Fov} indicate that neither the dimensions of the map $M$, nor an extended field of view $f$ lead to an improvement of one algorithm over the other. \emph{Transp} and \emph{Test} -- $t$ and $c$ respectively -- also do not significantly influence the result.\\
The decreasing bars for the ''accuracy''-parameter in figure~\ref{fig:Res} indicate that the influence of the prior diminishes when the detection accuracy improves, which is aligned with the intuition of Bayesian filtering, as the detections converge to the true state. The increasing performance with increasing overlap $o$ -- which is running in parallel for both axes -- show that the additional observations benefit the hierarchical algorithm more than a linear mixing. The higher value for the \emph{Rand} parameter show that even in a randomized setting, the hierarchical prediction can lead to increased performance. The low value for \emph{Ptu} case 0 shows that a handcrafted detection parameter performs significantly worse, however, the high values for 1 and 2 indicate that with the right parameters for $p(u)$ and $p(x\mid u)$, the performance can increase significantly.
\begin{figure*}
    \centering
    \resizebox{\textwidth}{!}{
    \includegraphics[width=4in]{SampRes-10.png}}
    \caption{\bf{
        Example reproductions from the different algorithms. 
    }}
    \label{fig:SampRes}
\end{figure*}
Figure~\ref{fig:SampRes} shows a selected reproduction of an example case with the entropy value of the map as calculated by equation~\ref{eq:Entropy} in the header. A simple Bayesian approach, shown in the top right corner, has a high entropy, which is highlighted through the noise in the reproduced map. While the hierarchical static prediction already performs better, both approaches of dynamic prediction perform better than the static approaches.
\section{Discussion} \label{sec:Disc}
This work has categorized $26$ papers with respect to spatial map, semantic map and robot type. Furthermore, an algorithm has been derived according to the development pipeline shown in figure~\ref{fig:DevProcess} and the algorithm has been tested in numerical simulations.
\subsection{Taxonomy} \label{ssec:DiscLit}
The taxonomy of $26$ papers, even though not exhaustive, highlights significant factors that influence the synergy between semantic and spatial information. Not targeting robotics and therefore not included in the taxonomy, however considered relevant for semantic information is the work by Harnad, which discusses the association of sensory inputs with symbolic systems and intricate representations~\cite{harnad_symbol_1990}. Kostavelis and Gasteratos have completed an extensive literature review of semantic mapping for mobile robotics~\cite{kostavelis_semantic_2015} and Landsiedel et al.~\cite{landsiedel_review_2017} have reviewed spatial relations in robotics. However, the taxonomy highlights the dimensions of semantic and spatial information with respect to the robot type to drive the development of an algorithm and point at trends.\\
The clustering of UAV-based semantic research in the corners of figure~\ref{fig:LitRes} indicates that mixing hierarchical information for UAVs is not an easy feat. While enormous datasets and challenges along with unified metrics have driven computer vision research~\cite{alom_history_2018,corke_what_2020} and are starting to show the benefits in navigation~\cite{anderson_evaluation_2018,chaplot_object_2020}, UAVs are facing additional challenges.
On the one hand the viewpoint of UAVs compared to generalised image datasets is unique, with oblique and top-down viewing points decreasing the accuracy of detectors~\cite{richardwebster_psyphy:_2019}. On the other hand, UAVs face additional obstacles with safety considerations, as well as reduced computational capabilities~\cite{boroujerdian_mavbench_2018,mandel_method_2020}. Furthermore, increasingly complex architectures and differing quality requirements can cause difficulties in deploying algorithms~\cite{cervera_try_2019,malatova_how_2020}. 
Semantic research generally benefits from unified metrics~\cite{anderson_evaluation_2018}, simulation environments and challenges~\cite{chaplot_object_2020,yang_visual_2018}. The driving force of standardised environments and challenges~\cite{corke_what_2020} can also be seen in the UAV community, as exhibited by the development of autonomous racing algorithms~\cite{moon_challenges_2019}.\\
Chown et al.~\cite{chown_prototypes_1995} emphasize the importance of ''gateways'' as transitions between regions, which arise naturally in manmade houses and have been used in many research efforts for ground-based vechicles~\cite{kuipers_local_2004,wu_learning_2018,krishnan_visual_2010}, however, may be difficult to define for UAVs. Where an area ends and another begins may be ambiguous for large outdoor environments, which are usually covered by UAVs~\cite{vanegas_novel_2018,shetty_implementation_2020}, whereas rooms often provide a natural separation in indoor environments. Furthermore, definitions of semantic area, region, or scene, if representing a spatial extent, could not be identified from the literature and the borders may be fluid between all of these defintions depending on the task and research field.
\subsection{Simulations} \label{ssec:DiscSim}
The results of the simulations in section~\ref{ssec:ResSim} indicate that incorporating hierarchical information into a mapping pipeline can be beneficial, but is largely dependant on detection. In this research, important hardware parameters such as flying velocity and battery charge~\cite{boroujerdian_mavbench_2018} have been omitted for simplicity. Furthermore, the simulation environment is a reduced, hand-designed version, because no standardised simulation environment for semantic mapping for UAVs could be identified. The simplicity has been attempted to be counteracted through the consideration of parameters $c$, $t$ and $r$ to increase the diversity of test cases.   
The reliance on detection parameters is demonstrated through the significant drop in performance for \emph{Ptu} as seen in figure~\ref{fig:Res} and the convergence of the performance with increasing accuracy. With perfect detectors the filtering approach would not be necessary, however, despite increasing performance~\cite{alom_history_2018}, unique viewpoints~\cite{richardwebster_psyphy:_2019} and computational constraints~\cite{krishnan_sky_2020} decrease the quality of detections. The hierarchical approach proposed in this research is largely dependant on the parameters $p(u)$ and $p(x\mid u)$, as clearly demonstrated by figure~\ref{fig:Res}, which could be learned from data with an appropriate generative model.
\section{Future Work} \label{sec:Fut}
To learn the parameters of the hierarchical model would require a formalised definition of the generative probabilistic model. Semantics, as the study of signs and the things to which they refer~\cite{kostavelis_semantic_2015}, has profound roots in language. Computer scientists working with language have put large efforts into attempting to model spoken and written language. Spoken language has employed hierarchical models of language based on the Markov assumption to separate spoken words~\cite{fine_hierarchical_1998,murphy_dynamic_2002}, which have been translated to alternative purposes, such as motion prediction~\cite{li_layered_2015} and recognition~\cite{oliver_layered_2002,aarno_layered_2006}. Natural Language Processing has put significant efforts into into classifying words into topics and documents (which are considered mixtures of topics) for classification and proposition~\cite{blei_latent_2003,hofmann_unsupervised_2001}, which has been adapted for the task of scene anotation in computer vision~\cite{bosch_scene_2006,fei-fei_bayesian_2005} and on satellite images~\cite{lienou_semantic_2010}.\\
Learning the parameters from data analogous to these models would enable the model to be extended further, either to incorporate location uncertainty or to be embedded into higher-level frameworks for semantic navigation~\cite{mandel_towards_2020,vanegas_uncertainty_2016}.\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\acknowledgments
This research was conducted by the Australian Research Council project number CE140100016, and supported by the QUT Centre for Robotics and ARC grant FT140101229. The authors acknowledge continued support from the Queensland University of Technology (QUT) through the Centre for Robotics. N. M. acknowledges M. Xu for his support during the development of this work


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{IEEEtran}
\bibliography{references}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\thebiography
%% This biostyle allows you to insert your photo size 1in X 1.25in
\begin{biographywithpic}{Nicolas Mandel}{Nico_Headshot_resized.png}
    received the BSc in Sports and Technology from the Otto-von-Guericke University Magdeburg and the MSc in Biomedical Engineering Sciences from the University of Applied Sciences Technikum Vienna after writing his thesis about mechanical modelling of cardiovascular treatments at the University of Cape Town. He is currently pursuing his PhD with the Australian Centre of Excellence for Robotic Vision at Queensland University of Technology, Brisbane, focussing on employing semantics for UAV navigation.
\end{biographywithpic}

\begin{biographywithpic}{Michael Milford}{Milford_2019_resized.png}
    received the Ph.D. in Electrical Engineering and the Bachelor of Mechanical and Space Engineering from the University of Queensland (UQ), Brisbane, Australia. He is currently a Professor of Robotics, Australian Research Council Future Fellow, Chief Investigator for the Australian Centre of Excellence for Robotic Vision and Deputy Director of the QUT Centre for Robotics at Queensland University of Technology, Brisbane, Australia. His research models the neural mechanisms in the brain underlying tasks like navigation and perception to develop new technologies in challenging application domains such as all-weather, anytime positioning for autonomous vehicles.
\end{biographywithpic}

\begin{biographywithpic}{Felipe Gonzalez}{Felipe_resized.jpg}
    is an Associate Professor (UAV) in the Science and Engineering Faculty, QUT and the QUT UAV Remote Sensing Group.  He holds a BEng(Mech) and a PhD from the University of Sydney.  His research explores bioinspired  optimization,  uncertainty  based UAV path planning and UAV for environmental  monitoring.   He  currently  leads three  CRC  Plant  Biosecurity  projects evaluating  Unmanned  Aerial  Systems  for  Deployment  in Plant Biosecurity.  Felipe is a Chartered Professional Engineer and member of professional organizations including the RAeS,IEEE and AIAA
\end{biographywithpic}



\end{document}
