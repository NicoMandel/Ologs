
@misc{noauthor_friendly_2018,
	title = {A friendly introduction to {Bayes} {Theorem} and {Hidden} {Markov} {Models}},
	url = {https://www.youtube.com/watch?v=kqSzLo9fenk&t=388s},
	abstract = {Announcement: New Book by Luis Serrano! Grokking Machine Learning. bit.ly/grokkingML

A friendly introduction to Bayes Theorem and Hidden Markov Models, with simple examples. No background knowledge needed, except basic probability.
Accompanying notebook:
https://github.com/luisguiserrano/hmm},
	urldate = {2020-10-05},
	month = mar,
	year = {2018}
}

@misc{noauthor_how_nodate,
	title = {How to import other {Python} files?},
	url = {https://stackoverflow.com/questions/2349991/how-to-import-other-python-files},
	urldate = {2020-10-02},
	journal = {Stack Overflow}
}

@misc{noauthor_univers_2015,
	title = {Univers. {Newcastle} {Stephan} {Chalup}},
	url = {https://www.newcastle.edu.au/profile/stephan-chalup#career},
	language = {en},
	urldate = {2020-10-02},
	month = jan,
	year = {2015},
	note = {Last Modified: 2017-10-19 09:15:25}
}

@inproceedings{wang_spatial_2008,
	title = {Spatial {Latent} {Dirichlet} {Allocation}},
	url = {http://papers.nips.cc/paper/3278-spatial-latent-dirichlet-allocation.pdf},
	urldate = {2020-09-29},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 20},
	publisher = {Curran Associates, Inc.},
	author = {Wang, Xiaogang and Grimson, Eric},
	editor = {Platt, J. C. and Koller, D. and Singer, Y. and Roweis, S. T.},
	year = {2008},
	pages = {1577--1584}
}

@misc{tu_dirichlet-multinomial_nodate,
	title = {The {Dirichlet}-{Multinomial} and {Dirichlet}-{Categoricalmodels} for {Bayesian} inference},
	url = {http://people.csail.mit.edu/stephentu/writeups/dirichlet-conjugate-prior.pdf},
	urldate = {2020-09-29},
	author = {Tu, Stephen}
}

@misc{calogicacom_dice_2019,
	title = {Dice, {Polls} \& {Dirichlet} {Multinomials}},
	url = {https://towardsdatascience.com/calogica-com-dice-polls-dirichlet-multinomials-eca987e6ec3f},
	abstract = {A few applications of Bayesian Statistics and the Dirichlet Multinomial distribution using probabilistic programming.},
	language = {en},
	urldate = {2020-09-29},
	journal = {Medium},
	author = {calogica.com, Claus Herther @},
	month = jan,
	year = {2019}
}

@book{gelman_bayesian_2013,
	edition = {3rd edition},
	title = {Bayesian {Data} {Analysis}, {Third} {Edition}, 3rd {Edition}},
	url = {http://www.stat.columbia.edu/~gelman/book/},
	abstract = {Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors—all leaders in the statistics community—introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition  Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book’s web page.},
	language = {eng},
	publisher = {CRC Press},
	author = {Gelman, Andrew},
	collaborator = {Carlin, John and Stern, Hal and Dunson, David and Vehtari, Aki and Rubin, Donald},
	year = {2013},
	keywords = {Electronic books}
}

@article{lienou_semantic_2010,
	title = {Semantic {Annotation} of {Satellite} {Images} {Using} {Latent} {Dirichlet} {Allocation}},
	volume = {7},
	issn = {1558-0571},
	doi = {10.1109/LGRS.2009.2023536},
	abstract = {In this letter, we are interested in the annotation of large satellite images, using semantic concepts defined by the user. This annotation task combines a step of supervised classification of patches of the large image and the integration of the spatial information between these patches. Given a training set of images for each concept, learning is based on the latent Dirichlet allocation (LDA) model. This hierarchical model represents each item of a collection as a random mixture of latent topics, where each topic is characterized by a distribution over words. The LDA-based image representation is obtained using simple features extracted from image words. We then exploit the capability of the LDA model to assign probabilities to unseen images, in order to classify the patches of the large image into the semantic concepts, using the maximum-likelihood method. We conduct experiments on panchromatic QuickBird images with 60-cm resolution. Taking into account the spatial information between the patches shows to improve the annotation performance.},
	number = {1},
	journal = {IEEE Geoscience and Remote Sensing Letters},
	author = {Lienou, Marie and Maitre, Henri and Datcu, Mihai},
	month = jan,
	year = {2010},
	note = {Conference Name: IEEE Geoscience and Remote Sensing Letters},
	keywords = {Data mining, Earth, Feature extraction, Image analysis, Image representation, Indexing, Large-image annotation, Layout, Linear discriminant analysis, Satellites, Spatial resolution, geophysical image processing, hierarchical model, large-image annotation, latent Dirichlet allocation (LDA), latent Dirichlet allocation model, maximum-likelihood method, panchromatic QuickBird images, random mixture, remote sensing, satellite images, semantic annotation, spatial information, visual databases},
	pages = {28--32}
}

@inproceedings{monay_plsa-based_2004,
	address = {New York, NY, USA},
	series = {{MULTIMEDIA} '04},
	title = {{PLSA}-based image auto-annotation: constraining the latent space},
	isbn = {978-1-58113-893-1},
	shorttitle = {{PLSA}-based image auto-annotation},
	url = {https://doi.org/10.1145/1027527.1027608},
	doi = {10.1145/1027527.1027608},
	abstract = {We address the problem of unsupervised image auto-annotation with probabilistic latent space models. Unlike most previous works, which build latent space representations assuming equal relevance for the text and visual modalities, we propose a new way of modeling multi-modal co-occurrences, constraining the definition of the latent space to ensure its consistency in semantic terms (words), while retaining the ability to jointly model visual information. The concept is implemented by a linked pair of Probabilistic Latent Semantic Analysis (PLSA) models. On a 16000-image collection, we show with extensive experiments that our approach significantly outperforms previous joint models.},
	urldate = {2020-09-27},
	booktitle = {Proceedings of the 12th annual {ACM} international conference on {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Monay, Florent and Gatica-Perez, Daniel},
	month = oct,
	year = {2004},
	keywords = {PLSA, automatic annotation of images, semantic indexing},
	pages = {348--351}
}

@inproceedings{bosch_scene_2006,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Scene {Classification} {Via} {pLSA}},
	isbn = {978-3-540-33839-0},
	doi = {10.1007/11744085_40},
	abstract = {Given a set of images of scenes containing multiple object categories (e.g. grass, roads, buildings) our objective is to discover these objects in each image in an unsupervised manner, and to use this object distribution to perform scene classification. We achieve this discovery using probabilistic Latent Semantic Analysis (pLSA), a generative model from the statistical text literature, here applied to a bag of visual words representation for each image. The scene classification on the object distribution is carried out by a k-nearest neighbour classifier.We investigate the classification performance under changes in the visual vocabulary and number of latent topics learnt, and develop a novel vocabulary using colour SIFT descriptors. Classification performance is compared to the supervised approaches of Vogel \& Schiele [19] and Oliva \& Torralba [11], and the semi-supervised approach of Fei Fei \& Perona [3] using their own datasets and testing protocols. In all cases the combination of (unsupervised) pLSA followed by (supervised) nearest neighbour classification achieves superior results. We show applications of this method to image retrieval with relevance feedback and to scene classification in videos.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2006},
	publisher = {Springer},
	author = {Bosch, Anna and Zisserman, Andrew and Muñoz, Xavier},
	editor = {Leonardis, Aleš and Bischof, Horst and Pinz, Axel},
	year = {2006},
	pages = {517--530}
}

@article{hofmann_unsupervised_2001,
	title = {Unsupervised {Learning} by {Probabilistic} {Latent} {Semantic} {Analysis}},
	volume = {42},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1007617005950},
	doi = {10.1023/A:1007617005950},
	abstract = {This paper presents a novel statistical method for factor analysis of binary and count data which is closely related to a technique known as Latent Semantic Analysis. In contrast to the latter method which stems from linear algebra and performs a Singular Value Decomposition of co-occurrence tables, the proposed technique uses a generative latent class model to perform a probabilistic mixture decomposition. This results in a more principled approach with a solid foundation in statistical inference. More precisely, we propose to make use of a temperature controlled version of the Expectation Maximization algorithm for model fitting, which has shown excellent performance in practice. Probabilistic Latent Semantic Analysis has many applications, most prominently in information retrieval, natural language processing, machine learning from text, and in related areas. The paper presents perplexity results for different types of text and linguistic data collections and discusses an application in automated document indexing. The experiments indicate substantial and consistent improvements of the probabilistic method over standard Latent Semantic Analysis.},
	language = {en},
	number = {1},
	urldate = {2020-09-28},
	journal = {Machine Learning},
	author = {Hofmann, Thomas},
	month = jan,
	year = {2001},
	pages = {177--196}
}

@inproceedings{fei-fei_bayesian_2005,
	title = {A {Bayesian} hierarchical model for learning natural scene categories},
	volume = {2},
	doi = {10.1109/CVPR.2005.16},
	abstract = {We propose a novel approach to learn and recognize natural scene categories. Unlike previous work, it does not require experts to annotate the training set. We represent the image of a scene by a collection of local regions, denoted as codewords obtained by unsupervised learning. Each region is represented as part of a "theme". In previous work, such themes were learnt from hand-annotations of experts, while our method learns the theme distributions as well as the codewords distribution over the themes without supervision. We report satisfactory categorization performances on a large set of 13 categories of complex scenes.},
	booktitle = {2005 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR}'05)},
	author = {Fei-Fei, L. and Perona, P.},
	month = jun,
	year = {2005},
	note = {ISSN: 1063-6919},
	keywords = {Animals, Bayesian hierarchical model, Bayesian methods, Cities and towns, Dictionaries, Frequency, Histograms, Humans, Layout, Unsupervised learning, Vehicles, belief networks, codeword distribution, image classification, image representation, learning natural scene category, natural scenes, training set, unsupervised learning},
	pages = {524--531 vol. 2}
}

@inproceedings{hofmann_probabilistic_1999,
	address = {New York, NY, USA},
	series = {{SIGIR} '99},
	title = {Probabilistic latent semantic indexing},
	isbn = {978-1-58113-096-6},
	url = {https://doi.org/10.1145/312624.312649},
	doi = {10.1145/312624.312649},
	urldate = {2020-09-24},
	booktitle = {Proceedings of the 22nd annual international {ACM} {SIGIR} conference on {Research} and development in information retrieval},
	publisher = {Association for Computing Machinery},
	author = {Hofmann, Thomas},
	month = aug,
	year = {1999},
	pages = {50--57}
}

@article{blei_latent_2003,
	title = {Latent dirichlet allocation},
	volume = {3},
	issn = {1532-4435},
	url = {https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf},
	doi = {10.1162/jmlr.2003.3.4-5.993},
	abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
	number = {null},
	journal = {The Journal of Machine Learning Research},
	author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
	month = mar,
	year = {2003},
	pages = {993--1022}
}

@misc{noauthor_singular_nodate,
	title = {Singular {Value} {Decomposition} ({SVD}) and {Image} {Compression}},
	url = {https://www.youtube.com/watch?v=DG7YTlGnCEo},
	abstract = {Github repo: http://www.github.com/luisguiserrano/...

Grokking Machine Learning Book:
https://www.manning.com/books/grokkin...
40\% discount promo code: serranoyt

In this video, we learn a very useful matrix trick called singular value decomposition (SVD), in which we express a matrix as a product of two rotation matrices and one scaling matrix.
We also show a very interesting application to image compression.

Similar videos:
Principal component analysis (PCA): https://www.youtube.com/watch?v=g-Hb2...
Matrix factorization and Netflix recommendations: https://www.youtube.com/watch?v=ZspR5...

Introduction: (0:00)
Transformations: (0:50)
A puzzle: (1:27)
A harder puzzle: (2:21)
Linear transformations: (3:50)
Dimensionality reduction: (10:50)
Image compression: (23:57)},
	urldate = {2020-09-24}
}

@misc{noauthor_scientific_nodate,
	title = {Scientific {Writing} and {Publishing}},
	url = {https://masterclasses.nature.com/online-course-in-scientific-writing-and-publishing/16507840},
	abstract = {Learn how to publish a great research paper with our online course in Scientific Writing and Publishing. Taught by Nature journal editors.},
	language = {en},
	urldate = {2020-09-23},
	journal = {Nature Masterclasses}
}

@misc{noauthor_short_2017,
	title = {A {Short} {Introduction} to {Entropy}, {Cross}-{Entropy} and {KL}-{Divergence}},
	url = {https://www.youtube.com/watch?v=ErfnhcEV1O8},
	abstract = {Entropy, Cross-Entropy and KL-Divergence are often used in Machine Learning, in particular for training classifiers. In this short video, you will understand where they come from and why we use them in ML.

Paper:
- "A mathematical theory of communication", Claude E. Shannon, 1948, http://pubman.mpdl.mpg.de/pubman/item...

Errata:
* At 5:05, the sign is reversed on the second line, it should read: "Entropy = -0.35 log2(0.35) - ... - 0.01 log2(0.01) = 2.23 bits"

The painting on the first slide is by Annie Clavel, a great French artist currently living in Los Angeles. The painting is reproduced with her kind authorization.  Please visit her website: http://www.annieclavel.com/.},
	urldate = {2020-09-21},
	month = nov,
	year = {2017}
}

@misc{noauthor_introduction_2017,
	title = {Introduction to {Dirichlet} {Processes} and their use},
	url = {https://www.youtube.com/watch?v=Incr_IWWHaQ},
	abstract = {Wray Buntine - Professor, Monash University, Melbourne, Australia

Assuming the attendee has knowledge of the Poisson, Gamma, multinomial and Dirichlet distributions, this talk will present the basic ideas and theory to understand and use the Dirichlet process and its close relatives, the Pitman-Yor process and the gamma process.  We will first look at some motivating examples.  Then we will look at the non-hierarchical versions of the processes, which are basically infinite parameter vectors.  These have a number of handy properties and have simple, elegant marginal and posterior inference.  Finally, we will look at the hierarchical versions of these processes.  These are fundamentally different.  To understand the hierarchical version we will briefly review some aspects of stochastic process theory and additive distributions.  The hierarchical versions becomes Dirichlet and Gamma distributions (the process part disappears) but the techniques developed for the non-hierarchical process models can be borrowed to develop good algorithms, since the Dirichlet and Gamma are challenging when placed hierarchically.},
	urldate = {2020-09-21},
	month = oct,
	year = {2017}
}

@misc{august_31_dirichlet_nodate,
	title = {The {Dirichlet} process for dummies (i.e., biologists, like me)},
	url = {http://phyletica.org/dirichlet-process/},
	abstract = {An accessible introduction to how the Dirichlet process works and why it's useful.},
	language = {en},
	urldate = {2020-09-21},
	journal = {phyletica},
	author = {August 31, The Dirichlet process for dummieswas published on and {2015.}}
}

@article{carmichael_research_2015,
	title = {The {Research} {Is} {Clear}: {Long} {Hours} {Backfire} for {People} and for {Companies}},
	issn = {0017-8012},
	shorttitle = {The {Research} {Is} {Clear}},
	url = {https://hbr.org/2015/08/the-research-is-clear-long-hours-backfire-for-people-and-for-companies},
	abstract = {The high cost of overwork.},
	urldate = {2020-09-20},
	journal = {Harvard Business Review},
	author = {Carmichael, Sarah Green},
	month = aug,
	year = {2015},
	note = {Section: Organizational culture},
	keywords = {Organizational culture, Stress, Time management, Work-life balance}
}

@misc{johnson_bayesian_nodate,
	title = {Bayesian {Inference} for {Dirichlet}-{Multinomials}},
	url = {http://web.science.mq.edu.au/~mjohnson/papers/Johnson-IPAM11-extras.pdf},
	abstract = {Alternative Link:
http://users.cecs.anu.edu.au/{\textasciitilde}ssanner/MLSS2010/Johnson1.pdf},
	author = {Johnson, M}
}

@misc{noauthor_topic_2018,
	title = {Topic {Modelling} {In} {Python} {Using} {Latent} {Semantic} {Analysis}},
	url = {https://www.analyticsvidhya.com/blog/2018/10/stepwise-guide-topic-modeling-latent-semantic-analysis/},
	abstract = {Latent Semantic Analysis is a Topic Modeling technique. This article gives an intuitive understanding of Topic Modeling along with Python implementation.},
	urldate = {2020-09-18},
	journal = {Analytics Vidhya},
	month = oct,
	year = {2018}
}

@misc{noauthor_natural_2019,
	title = {Natural {Language} {Processing} ({Part} 5): {Topic} {Modeling} with {Latent} {Dirichlet} {Allocation} in {Python}},
	shorttitle = {Natural {Language} {Processing} ({Part} 5)},
	url = {https://www.youtube.com/watch?v=NYkbqzTlW3w},
	abstract = {This six-part video series goes through an end-to-end Natural Language Processing (NLP) project in Python to compare stand up comedy routines.

- Natural Language Processing (Part 1): Introduction to NLP \&amp; Data Science
- Natural Language Processing (Part 2): Data Cleaning \&amp; Text Pre-Processing in Python
- Natural Language Processing (Part 3): Exploratory Data Analysis \&amp; Word Clouds in Python
- Natural Language Processing (Part 4): Sentiment Analysis with TextBlob in Python
- Natural Language Processing (Part 5): Topic Modeling with Latent Dirichlet Allocation in Python
- Natural Language Processing (Part 6): Text Generation with Markov Chains in Python

All of the supporting Python code can be found here: https://github.com/adashofdata/nlp-in...},
	urldate = {2020-09-18},
	month = jan,
	year = {2019}
}

@misc{noauthor_latent_2016,
	title = {Latent {Dirichlet} {Allocation} ({Part} 1 of 2)},
	url = {https://www.youtube.com/watch?v=T05t-SqKArY},
	abstract = {Latent Dirichlet Allocation is a powerful machine learning technique used to sort documents by topic. Learn all about it in this video!

This is part 1 of a 2 video series.
Video 2: https://www.youtube.com/watch?v=BaM1u...

For information on my book "Grokking Machine Learning": https://www.manning.com/books/grokkin...
Discount code (40\%): serranoyt},
	urldate = {2020-09-18},
	month = jul,
	year = {2016}
}

@misc{noauthor_cs231n_nodate,
	title = {{CS231n} {Convolutional} {Neural} {Networks} for {Visual} {Recognition}},
	url = {https://cs231n.github.io/},
	urldate = {2020-09-17}
}

@book{arnold_mathematical_1978,
	address = {New York},
	series = {Graduate {Texts} in {Mathematics}},
	title = {Mathematical {Methods} of {Classical} {Mechanics}},
	isbn = {978-1-4757-1693-1},
	url = {https://www.springer.com/gp/book/9781475716931},
	abstract = {Many different mathematical methods and concepts are used in classical mechanics: differential equations and phase ftows, smooth mappings and manifolds, Lie groups and Lie algebras, symplectic geometry and ergodic theory. Many modern mathematical theories arose from problems in mechanics and only later acquired that axiomatic-abstract form which makes them so hard to study. In this book we construct the mathematical apparatus of classical mechanics from the very beginning; thus, the reader is not assumed to have any previous knowledge beyond standard courses in analysis (differential and integral calculus, differential equations), geometry (vector spaces, vectors) and linear algebra (linear operators, quadratic forms). With the help of this apparatus, we examine all the basic problems in dynamics, including the theory of oscillations, the theory of rigid body motion, and the hamiltonian formalism. The author has tried to show the geometric, qualitative aspect of phenomena. In this respect the book is closer to courses in theoretical mechanics for theoretical physicists than to traditional courses in theoretical mechanics as taught by mathematicians.},
	language = {en},
	urldate = {2020-09-17},
	publisher = {Springer-Verlag},
	author = {Arnold, V. I.},
	year = {1978},
	doi = {10.1007/978-1-4757-1693-1}
}

@misc{noauthor_lda_2016,
	title = {{LDA} {Topic} {Models}},
	url = {https://www.youtube.com/watch?v=3mHy4OSyRf0&t=1058s},
	abstract = {LDA Topic Models is a powerful tool for extracting meaning from text. In this video I talk about the idea behind the LDA itself, why does it work, what are the free tools and frameworks that can be used, what LDA parameters are tuneable, what do they mean in terms of your specific use case and what to look for when you evaluate it.},
	urldate = {2020-09-17},
	month = jul,
	year = {2016}
}

@misc{noauthor_prof_2017,
	title = {Prof. {David} {Blei} - {Probabilistic} {Topic} {Models} and {User} {Behavior}},
	url = {https://www.youtube.com/watch?v=FkckgwMHP2s&t=1086s},
	abstract = {David Blei, Professor of Statistics and Computer Science at Columbia University, delivered a lecture entitled 'Probabilistic Topic Models and User Behavior' on Friday 27th January 2017 at the University of Edinburgh.},
	urldate = {2020-09-17},
	month = feb,
	year = {2017}
}

@misc{noauthor_visualizing_nodate,
	title = {Visualizing {Dirichlet} {Distributions} with {Matplotlib}},
	url = {http://blog.bogatron.net/blog/2014/02/02/visualizing-dirichlet-distributions/},
	urldate = {2020-09-17}
}

@misc{noauthor_topic_nodate,
	title = {Topic {Modeling} {Explained}: {LDA} to {Bayesian} {Inference} {\textbar} {TDK} {Technologies}},
	url = {https://www.tdktech.com/tech-talks/topic-modeling-explained-lda-to-bayesian-inference},
	urldate = {2020-09-17}
}

@misc{tedunderwood_topic_2012,
	title = {Topic modeling made just simple enough.},
	url = {https://tedunderwood.com/2012/04/07/topic-modeling-made-just-simple-enough/},
	abstract = {Right now, humanists often have to take topic modeling on faith. There are several good posts out there that introduce the principle of the thing (by Matt Jockers, for instance, and Scott Weingart)…},
	language = {en},
	urldate = {2020-09-17},
	journal = {The Stone and the Shell},
	author = {{tedunderwood}},
	month = apr,
	year = {2012}
}

@misc{tomar_topic_2019,
	title = {Topic modeling using {Latent} {Dirichlet} {Allocation}({LDA}) and {Gibbs} {Sampling} explained!},
	url = {https://medium.com/analytics-vidhya/topic-modeling-using-lda-and-gibbs-sampling-explained-49d49b3d1045},
	abstract = {How Topic Modelling works and how to implement it using LDA and Gibbs Sampling},
	language = {en},
	urldate = {2020-09-17},
	journal = {Medium},
	author = {Tomar, Ankur},
	month = jul,
	year = {2019}
}

@misc{noauthor_beginners_2016,
	title = {Beginners {Guide} to {Topic} {Modeling} in {Python} and {Feature} {Selection}},
	url = {https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/},
	abstract = {A practical guide to perform topic modeling in python. Which are the various ways to improve the results such as frequency filter, POS tag and LDA},
	urldate = {2020-09-17},
	journal = {Analytics Vidhya},
	month = aug,
	year = {2016}
}

@misc{noauthor_tutorial_2014,
	title = {Tutorial on {Dirichlet} {Distribution} by {Max} {Sklar}},
	url = {https://www.youtube.com/watch?v=6k7IzONQOzM},
	abstract = {WANT TO EXPERIENCE A TALK LIKE THIS LIVE?
Barcelona: https://www.datacouncil.ai/barcelona
New York City: https://www.datacouncil.ai/new-york-city
San Francisco: https://www.datacouncil.ai/san-francisco
Singapore: https://www.datacouncil.ai/singapore


More info and tutorial on Dirichlet distribution here: http://www.hakkalabs.co/articles/the-...

FOLLOW DATA COUNCIL:
Twitter: https://twitter.com/DataCouncilAI 
LinkedIn: https://www.linkedin.com/company/data... 
Facebook: https://www.facebook.com/datacouncilai},
	urldate = {2020-09-17},
	month = jan,
	year = {2014}
}

@misc{hakka_labs_digging_nodate,
	type = {Technology},
	title = {Digging into the {Dirichlet} {Distribution} by {Max} {Sklar}},
	url = {https://www.slideshare.net/g33ktalk/machine-learning-meetup-12182013},
	abstract = {When it comes to recommendation systems and natural language processing, data},
	urldate = {2020-09-17},
	author = {Hakka Labs}
}

@article{woolston_pandemic_2020,
	title = {Pandemic darkens postdocs’ work and career hopes},
	volume = {585},
	copyright = {2020 Nature},
	url = {https://www.nature.com/articles/d41586-020-02548-2},
	doi = {10.1038/d41586-020-02548-2},
	abstract = {Nature’s survey of this key segment of the scientific workforce paints a gloomy picture of job-loss fears, interrupted research and anxiety about the future.},
	language = {en},
	number = {7824},
	urldate = {2020-09-13},
	journal = {Nature},
	author = {Woolston, Chris},
	month = sep,
	year = {2020},
	note = {Number: 7824
Publisher: Nature Publishing Group},
	pages = {309--312}
}

@article{shetty_implementation_2020,
	title = {Implementation of {Survivor} {Detection} {Strategies} {Using} {Drones}},
	url = {http://arxiv.org/abs/2003.12559},
	abstract = {Survivors stranded during floods tend to seek refuge on dry land. It is important to search for these survivors and help them reach safety as quickly as possible. The terrain in such situations however, is heavily damaged and restricts the movement of emergency personnel towards these survivors. Therefore, it is advantageous to utilize Unmanned Aerial Vehicles (UAVs) in cooperation with on-ground first responders to aid search and rescue efforts. In this article we demonstrate an implementation and improvement of the weight-based path planning algorithm using an off-the-shelf UAV. The coordinates of the survivor and their heading is reported by an on-ground observer to the UAV to generate a weighted map of the surroundings for exploration. Each coordinate in the map is assigned a weight which dictates the priority of exploration. These waypoints are then sorted on the basis of their weights to arrive at an ordered list for exploration by the UAV. We developed the model in MATLAB, followed by prototyping on Robot Operating System (ROS) using a 3DR Iris quadcopter. We tested the model on an off-the-shelf UAV by utilizing the MAVROS and MAVLINK capabilities of ROS. During the implementation of the algorithm on the UAV, several additional factors such as unreliable GPS signals and limited field of view which could effect the performance of the model were in effect, despite which the algorithm performed fairly well. We compared our model with conventional algorithms described in the literature, and showed that our implementation outperforms them.},
	urldate = {2020-09-10},
	journal = {arXiv:2003.12559 [cs, eess]},
	author = {Shetty, Sarthak J. and Ravichandran, Rahul and Tony, Lima Agnel and Abhinay, N. Sai and Das, Kaushik and Ghose, Debasish},
	month = apr,
	year = {2020},
	note = {arXiv: 2003.12559},
	keywords = {Computer Science - Robotics, Electrical Engineering and Systems Science - Systems and Control}
}

@misc{carattino_step_nodate,
	title = {Step by {Step} {Guide} to {Building} a {GUI}},
	url = {/blog/step-by-step-guide-to-building-a-gui/},
	abstract = {Using PyQt to build a GUI for your webcam},
	language = {en},
	urldate = {2020-09-10},
	journal = {Python For The Lab},
	author = {Carattino, Aquiles}
}

@misc{noauthor_mcmc_nodate,
	title = {{MCMC} sampling for dummies — {While} {My} {MCMC} {Gently} {Samples}},
	url = {https://twiecki.io/blog/2015/11/10/mcmc-sampling/},
	urldate = {2020-09-10}
}

@misc{noauthor_hierarchical_nodate,
	title = {Hierarchical {Bayesian} {Neural} {Networks} with {Informative} {Priors} — {While} {My} {MCMC} {Gently} {Samples}},
	url = {https://twiecki.io/blog/2018/08/13/hierarchical_bayesian_neural_network/},
	urldate = {2020-09-10}
}

@misc{than_1_todo_2020,
	title = {{TODO} {Group}: {Why} {Open} {Source} matters to your enterprise},
	shorttitle = {{TODO} {Group}},
	url = {https://www.linuxfoundation.org/blog/2020/09/why-open-source-matters-to-your-enterprise/},
	abstract = {This paper, published by the European Chapter of the TODO Group, aims to provide a balanced and quick overview of the business pros and cons of using open source software.},
	language = {en-US},
	urldate = {2020-09-09},
	journal = {The Linux Foundation},
	author = {Than 1, More and Members, 000 and Software, Is the World’s Leading Home for Collaboration on Open Source and St, Open and {ards} and Data, Open and Linux, open hardware Linux Foundation’s projects are critical to the world’s infrastructure including and {Kubernetes} and {Node.js} and practices, more The Linux Foundation’s methodology focuses on leveraging best and Contributors, Addressing the Needs of and {users} and information, solution providers to create sustainable models for open collaboration For more and Linuxfoundation.org, Please Visit Us at},
	month = sep,
	year = {2020}
}

@misc{noauthor_caffe_nodate,
	title = {Caffe in a {Day} {Tutorial}},
	url = {https://docs.google.com/presentation/d/1HxGdeq8MPktHaPb-rlmYYQ723iWzq9ur6Gjo71YiG0Y/edit#slide=id.g1190c3d925_10_47}
}

@misc{noauthor_3d_nodate,
	title = {{3D} {Geometry} and {Vision}},
	url = {https://3dgv.github.io/},
	abstract = {3D geometry and Vision seminar},
	language = {en-US},
	urldate = {2020-09-04},
	journal = {3dgv.github.io}
}

@misc{noauthor_cs_nodate,
	title = {{CS} 228 - {Probabilistic} {Graphical} {Models}},
	url = {https://cs.stanford.edu/~ermon/cs228/index.html},
	urldate = {2020-09-03}
}

@book{koller_probabilistic_2009,
	address = {Cambridge, MA},
	series = {Adaptive computation and machine learning.},
	title = {Probabilistic graphical models: principles and techniques},
	isbn = {978-0-262-01319-2},
	shorttitle = {Probabilistic graphical models},
	language = {eng},
	publisher = {MIT Press},
	author = {Koller, Daphne},
	collaborator = {Friedman, Nir},
	year = {2009},
	keywords = {Bayesian statistical decision theory, Graphic methods, Graphical modeling (Statistics)}
}

@misc{mishra_debugging_nodate,
	title = {Debugging {ROS} {C}++ nodes with {VS} {Code}},
	url = {http://www.lib4dev.in/info/MrGnomes/VS_Code_ROS/i19793},
	abstract = {Awesome libraries for developers},
	urldate = {2020-09-03},
	author = {Mishra, Amit}
}

@inproceedings{suenderhauf_continuous_2015,
	title = {Continuous factor graphs for holistic scene understanding},
	url = {https://eprints.qut.edu.au/109683/},
	abstract = {We propose a novel mathematical formulation for the holistic scene understanding problem and transform it from the discrete into the continuous domain. The problem can then be modeled with a nonlinear continuous factor graph, and the MAP solution is found via least squares optimization. We evaluate our method on the realistic NYU2 dataset.},
	language = {en},
	urldate = {2020-04-09},
	publisher = {unpublished},
	author = {Suenderhauf, Niko and Upcroft, Ben and Milford, Michael},
	month = jun,
	year = {2015},
	pages = {2}
}

@phdthesis{murphy_dynamic_2002,
	address = {Berkeley, CA},
	type = {{PhD} {Thesis}},
	title = {Dynamic {Bayesian} {Networks}: {Representation}, {Inference} and {Learning}},
	url = {https://www.cs.ubc.ca/~murphyk/Thesis/thesis.pdf},
	abstract = {Modellingsequentialdatais importantin many areasofscienceandengineering.HiddenMarkov models(HMMs)andKalmanfiltermodels(KFMs)arepopularforthisbecausethey aresimpleandflexible.Forexample,HMMshave beenusedforspeechrecognitionandbio-sequenceanalysis,andKFMshave beenusedforproblemsrangingfromtrackingplanesandmissilestopredictingtheeconomy.  However, HMMsandKFMsarelimitedintheir“expressive power”.DynamicBayesianNetworks(DBNs)generalizeHMMsbyallowingthestatespacetoberepresentedinfactoredform,insteadofasa singlediscreterandomvariable.DBNsgeneralizeKFMsbyallowingarbitraryprobabilitydistributions,notjust(unimodal)linear-Gaussian.Inthisthesis,I willdiscusshow torepresentmany differentkindsofmodelsasDBNs,how toperformexactandapproximateinferenceinDBNs,andhow tolearnDBNmodelsfromsequentialdata.Inparticular, themainnoveltechnicalcontributionsofthisthesisareasfollows:a wayofrepresentingHierarchicalHMMsasDBNs,whichenablesinferencetobedoneinO(T)timeinsteadofO(T3), whereTis thelengthofthesequence;anexactsmoothingalgorithmthattakesO(logT)spaceinsteadofO(T);a simplewayofusingthejunctiontreealgorithmforonlineinferenceinDBNs;newcomplexityboundsonexactonlineinferenceinDBNs;a newdeterministicapproximateinferencealgorithmcalledfactoredfrontier;ananalysisoftherelationshipbetweentheBKalgorithmandloopy beliefpropagation;a wayofapplyingRao-BlackwellisedparticlefilteringtoDBNsingeneral,andtheSLAM(simultaneouslocalizationandmapping)probleminparticular;a wayofextendingthestructuralEMalgorithmtoDBNs;anda varietyofdifferentapplicationsofDBNs.However, perhapsthemainvalueofthethesisis itscatholicpresentationofthefieldofsequentialdatamodelling},
	language = {en},
	urldate = {2020-03-09},
	school = {University of California, Berkeley},
	author = {Murphy, Kevin},
	year = {2002}
}

@inproceedings{lucas_iterative_1981,
	title = {An iterative image registration technique with an application to stereo vision},
	abstract = {Image registration finds a variety of applications in computer vision. Unfortunately, traditional image registration techniques tend to be costly. We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration. Our technique is faster because it examines far fewer potential matches between the images than existing techniques. Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing. We show show our technique can be adapted for use in a stereo vision system. 2. The registration problem The translational image registration problem can be characterized as follows: We are given functions F(x) and G(x) which give the respective pixel values at each location x in two images, where x is a vector. We wish to find the disparity vector h which minimizes some measure of the difference between F(x + h) and G(x), for x in some region of interest R. (See figure 1). 1.},
	booktitle = {In {IJCAI81}},
	author = {Lucas, Bruce D. and Kanade, Takeo},
	year = {1981},
	pages = {674--679}
}

@inproceedings{sturm_plane-based_1999,
	title = {On {Plane}-{Based} {Camera} {Calibration}: {A} {General} {Algorithm}, {Singularities}, {Applications}},
	shorttitle = {On {Plane}-{Based} {Camera} {Calibration}},
	abstract = {We present a general algorithm for plane-based calibration that can deal with arbitrary numbers of views and calibration  planes. The algorithm can simultaneously calibrate different views from a camera with variable intrinsic parameters  and it is easy to incorporate known values of intrinsic parameters. For some minimal cases, we describe all singularities,  naming the parameters that can not be estimated. Experimental results of our method are shown that exhibit the singularities  while revealing good performance in non-singular conditions. Several applications of plane-based 3D geometry  inference are discussed as well.  1 Introduction  The motivations for considering planes for calibrating cameras are mainly twofold. First, concerning calibration in its own right, planar calibration patterns are cheap and easy to produce, a laser printer output for example is absolutely sufficient for applications where highest accuracy is not demanded. Second, planar surface patches are probably ...},
	author = {Sturm, Peter F. and Maybank, Stephen J.},
	year = {1999},
	pages = {432--437}
}

@misc{noauthor_sports_nodate,
	title = {Sports {Data} - {Sports} {AI}, {Technology}, {Data} {Feeds}},
	url = {https://www.statsperform.com/},
	abstract = {Stats Perform harnesses the true power of sports data by leveraging advancements in artificial intelligence to generate the industry’s richest insights.},
	language = {en-US},
	urldate = {2020-09-02},
	journal = {Stats Perform}
}

@article{sharma_automated_2017,
	title = {Automated {Top} {View} {Registration} of {Broadcast} {Football} {Videos}},
	url = {http://arxiv.org/abs/1703.01437},
	abstract = {In this paper, we propose a novel method to register football broadcast video frames on the static top view model of the playing surface. The proposed method is fully automatic in contrast to the current state of the art which requires manual initialization of point correspondences between the image and the static model. Automatic registration using existing approaches has been difficult due to the lack of sufficient point correspondences. We investigate an alternate approach exploiting the edge information from the line markings on the field. We formulate the registration problem as a nearest neighbour search over a synthetically generated dictionary of edge map and homography pairs. The synthetic dictionary generation allows us to exhaustively cover a wide variety of camera angles and positions and reduce this problem to a minimal per-frame edge map matching procedure. We show that the per-frame results can be improved in videos using an optimization framework for temporal camera stabilization. We demonstrate the efficacy of our approach by presenting extensive results on a dataset collected from matches of football World Cup 2014.},
	urldate = {2020-09-02},
	journal = {arXiv:1703.01437 [cs]},
	author = {Sharma, Rahul Anand and Bhat, Bharath and Gandhi, Vineet and Jawahar, C. V.},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.01437},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@inproceedings{chen_sports_2019,
	title = {Sports {Camera} {Calibration} via {Synthetic} {Data}},
	doi = {10.1109/CVPRW.2019.00305},
	abstract = {Calibrating sports cameras is important for autonomous broadcasting and sports analysis. Here we propose a highly automatic method for calibrating sports cameras from a single image using synthetic data. First, we develop a novel camera pose engine that generates camera poses by randomly sampling camera parameters. The camera pose engine has only three significant free parameters so that it can effectively generate diverse camera poses and corresponding edge (i.e. field marking) images. Then, we learn compact feature descriptors via a siamese network from paired edge images and build a feature-pose database. After that, we use a novel GAN (generative adversarial network) model to detect field markings in real images. Finally, we query an initial camera pose from the feature-pose database and refine camera poses using truncated distance images. We evaluate our method on both synthetic and real data. Our method not only demonstrates the robustness on the synthetic data but also achieves state-of-the-art accuracy on a standard soccer dataset and very high performance on a volleyball dataset.},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	author = {Chen, Jianhui and Little, James J.},
	month = jun,
	year = {2019},
	note = {ISSN: 2160-7516},
	keywords = {Calibration, Cameras, Feature extraction, GAN model, Gallium nitride, Image edge detection, Robot vision systems, automatic method, autonomous broadcasting, calibration, camera pose engine, cameras, diverse camera, feature extraction, feature-pose database, field marking detection, generative adversarial network, image sampling, image sensors, learning (artificial intelligence), neural nets, novel GAN model, object detection, paired edge images, pose estimation, random sampling camera parameters, sport, sports analysis, sports camera calibration, synthetic data, truncated distance images, volleyball dataset},
	pages = {2497--2504}
}

@inproceedings{chen_two-point_2018,
	title = {A {Two}-{Point} {Method} for {PTZ} {Camera} {Calibration} in {Sports}},
	doi = {10.1109/WACV.2018.00038},
	abstract = {Calibrating narrow field of view soccer cameras is challenging because there are very few field markings in the image. Unlike previous solutions, we propose a two-point method, which requires only two point correspondences given the prior knowledge of base location and orientation of a pan-tilt-zoom (PTZ) camera. We deploy this new calibration method to annotate pan-tilt-zoom data from soccer videos. The collected data are used as references for new images. We also propose a fast random forest method to predict pan-tilt angles without image-to-image feature matching, leading to an efficient calibration method for new images. We demonstrate our system on synthetic data and two real soccer datasets. Our two-point approach achieves superior performance over the state-of-the-art method.},
	booktitle = {2018 {IEEE} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})},
	author = {Chen, Jianhui and Zhu, Fangrui and Little, James J.},
	month = mar,
	year = {2018},
	keywords = {Broadcasting, Calibration, Cameras, Games, PTZ camera calibration, Prediction algorithms, Robustness, Training, calibration, fast random forest method, feature extraction, image matching, image sensors, image-to-image feature, pan-tilt-zoom data, soccer cameras, soccer datasets, soccer videos, sport, state-of-the-art method, two-point method, video cameras},
	pages = {287--295}
}

@inproceedings{cheshire_player_nodate,
	address = {Stanford},
	title = {Player  {Tracking}  and  {Analysis}  of  {Basketball}  {Plays}},
	abstract = {We developed an algorithm that tracks the move-ments  of  ten  different  players  from  a  video  of  a  basketballgame. With their position tracked, we then proceed to map theposition  of  these  players  onto  an  image  of  a  basketball  court.The  purpose  of  tracking  player  is  to  provide  the  maximumamount of information to basketball coaches and organizations,so that they can better design mechanisms of defense and attack.Overall,  our  model  has  a  high  degree  of  identification  andtracking  of  the  players  in  the  court.},
	booktitle = {Stanford class work},
	author = {Cheshire, Evan and Halasz, Cibele and Perin, Jose K}
}

@article{lu_learning_2013,
	title = {Learning to {Track} and {Identify} {Players} from {Broadcast} {Sports} {Videos}},
	volume = {35},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2012.242},
	abstract = {Tracking and identifying players in sports videos filmed with a single pan-tilt-zoom camera has many applications, but it is also a challenging problem. This paper introduces a system that tackles this difficult task. The system possesses the ability to detect and track multiple players, estimates the homography between video frames and the court, and identifies the players. The identification system combines three weak visual cues, and exploits both temporal and mutual exclusion constraints in a Conditional Random Field (CRF). In addition, we propose a novel Linear Programming (LP) Relaxation algorithm for predicting the best player identification in a video clip. In order to reduce the number of labeled training data required to learn the identification system, we make use of weakly supervised learning with the assistance of play-by-play texts. Experiments show promising results in tracking, homography estimation, and identification. Moreover, weakly supervised learning with play-by-play texts greatly reduces the number of labeled training examples required. The identification system can achieve similar accuracies by using merely 200 labels in weakly supervised learning, while a strongly supervised approach needs a least 20,000 labels.},
	number = {7},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Lu, Wei-Lwun and Ting, Jo-Anne and Little, James J. and Murphy, Kevin P.},
	month = jul,
	year = {2013},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Artificial Intelligence, Athletes, CRF, Cameras, Feature extraction, Humans, Image Processing, Computer-Assisted, Image color analysis, LP relaxation algorithm, Pattern Recognition, Automated, Sports, Sports video analysis, Supervised learning, Vectors, Video Recording, Videos, Visualization, broadcast sports video, conditional random field, homography estimation, identification, identification system, labeled training data, learning (artificial intelligence), linear programming, mutual exclusion constraint, object detection, object tracking, play-by-play text, player detection, player identification, player tracking, random processes, relaxation theory, single pan-tilt-zoom camera, sport, supervised learning, temporal exclusion constraint, tracking, video cameras, video clip, video frame, video signal processing, visual cue, weakly supervised learning},
	pages = {1704--1716}
}

@misc{noauthor_open_nodate,
	title = {Open {Source} {Sports} {Video} {Analysis} using {Maching} {Learning} - {DEV}},
	url = {https://dev.to/stephan007/open-source-sports-video-analysis-using-maching-learning-2ag4},
	urldate = {2020-09-02}
}

@misc{noauthor_operator_nodate,
	title = {Operator overloading},
	url = {https://www.pythoninformer.com/python-language/magic-methods/operator-overload/},
	abstract = {definition of magic methods and which can be overloaded. 
does not contain imul and so forth, which would be used for *= and such.},
	urldate = {2020-09-01}
}

@misc{noauthor_python_nodate,
	title = {Python {Implementation} of {Viterbi} {Algorithm}},
	url = {https://stackoverflow.com/questions/9729968/python-implementation-of-viterbi-algorithm},
	urldate = {2020-08-28},
	journal = {Stack Overflow}
}

@misc{noauthor_protontypesawesome-robotic-tooling_2020,
	title = {protontypes/awesome-robotic-tooling},
	copyright = {Unlicense License         ,                 Unlicense License},
	url = {https://github.com/protontypes/awesome-robotic-tooling},
	abstract = {Free tools for professional robotic development in C++ and Python with a touch of ROS, autonomous driving and aerospace},
	urldate = {2020-08-27},
	publisher = {protontypes},
	month = aug,
	year = {2020},
	note = {original-date: 2019-10-24T15:32:17Z},
	keywords = {aerospace, artificial-intelligence, automotive, autonomous-driving, awesome, awesome-list, cplusplus, cpp, lidar, machine-learning, mapping, point-cloud, python, robot, robotic, robotics, ros, ros2, self-driving-car, slam}
}

@misc{sakai_pythonrobotics_nodate,
	title = {{PythonRobotics} - {GitHub} - {Path} {Planning} {Algorithms}},
	url = {https://github.com/AtsushiSakai/PythonRobotics},
	abstract = {Python sample codes for robotics algorithms. Contribute to AtsushiSakai/PythonRobotics development by creating an account on GitHub.},
	language = {en},
	urldate = {2020-08-27},
	journal = {GitHub},
	author = {Sakai, Atsushi}
}

@inproceedings{malatova_how_2020,
	address = {Seoul, South Korea},
	title = {How do you {Architect} your {Robots}? {State} of the {Practice} and {Guidelines} for {ROS}-based {Systems}},
	volume = {42},
	shorttitle = {How do you {Architect} your {Robots}?},
	url = {https://conf.researchr.org/details/icse-2020/icse-2020-Software-Engineering-in-Practice/9/How-do-you-Architect-your-Robots-State-of-the-Practice-and-Guidelines-for-ROS-based-},
	doi = {https://doi.org/10.1145/3377813.3381358},
	abstract = {The Robot Operating System (ROS) is the de-facto standard for robotic software. If on one hand ROS is helping roboticists, e.g., by providing a standardized communication platform, on the other hand ROS-based systems are getting larger and more complex and could benefit from good software architecture practices. This paper presents an observational study aimed at (i) unveiling the state of the practice for architecture of ROS-based systems and (ii) providing guidance to roboticists about how to properly architect ROS-based systems. To achieve these goals, we (i) build a dataset of 335 GitHub repositories containing real open-source ROS-based systems, (ii) mine the repositories for extracting the state of the practice about how roboticists are architecting them, and (iii) synthesize a catalog of 49 evidence-based guidelines for architecting ROS-based systems. The guidelines have been validated by 77 roboticists working on real-world open-source ROS-based systems.},
	language = {en},
	urldate = {2020-08-27},
	booktitle = {{ICSE2020} - {Software} {Engineering} in {Practice}},
	publisher = {ACM},
	author = {Malatova, Ivano and Lewis, Grace and Schmerl, Bradley and Lago, Patricia and Garlan, David},
	year = {2020}
}

@book{russell_artificial_2016,
	address = {Harlow, United Kingdom, UNITED KINGDOM},
	title = {Artificial {Intelligence}: {A} {Modern} {Approach}, {Global} {Edition}},
	isbn = {978-1-292-15397-1},
	shorttitle = {Artificial {Intelligence}},
	url = {http://ebookcentral.proquest.com/lib/qut/detail.action?docID=5495855},
	urldate = {2020-08-26},
	publisher = {Pearson Education Limited},
	author = {Russell, Stuart and Norvig, Peter},
	year = {2016},
	keywords = {Artificial intelligence.}
}

@article{mandel_method_2020,
	title = {A {Method} for {Evaluating} and {Selecting} {Suitable} {Hardware} for {Deployment} of {Embedded} {System} on {UAVs}},
	volume = {20},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/20/16/4420},
	doi = {10.3390/s20164420},
	abstract = {The use of UAVs for remote sensing is increasing. In this paper, we demonstrate a method for evaluating and selecting suitable hardware to be used for deployment of algorithms for UAV-based remote sensing under considerations of Size, Weight, Power, and Computational constraints. These constraints hinder the deployment of rapidly evolving computer vision and robotics algorithms on UAVs, because they require intricate knowledge about the system and architecture to allow for effective implementation. We propose integrating computational monitoring techniques\&mdash;profiling\&mdash;with an industry standard specifying software quality\&mdash;ISO 25000\&mdash;and fusing both in a decision-making model\&mdash;the analytic hierarchy process\&mdash;to provide an informed decision basis for deploying embedded systems in the context of UAV-based remote sensing. One software package is combined in three software\&ndash;hardware alternatives, which are profiled in hardware-in-the-loop simulations. Three objectives are used as inputs for the decision-making process. A Monte Carlo simulation provides insights into which decision-making parameters lead to which preferred alternative. Results indicate that local weights significantly influence the preference of an alternative. The approach enables relating complex parameters, leading to informed decisions about which hardware is deemed suitable for deployment in which case.},
	language = {en},
	number = {16},
	urldate = {2020-08-26},
	journal = {Sensors},
	author = {Mandel, Nicolas and Milford, Michael and Gonzalez, Felipe},
	month = jan,
	year = {2020},
	note = {Number: 16
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {UAV, computer architecture, decision making, navigation, semantics},
	pages = {4420}
}

@inproceedings{mandel_towards_2020,
	title = {Towards {Simulating} {Semantic} {Onboard} {UAV} {Navigation}},
	doi = {10.1109/AERO47225.2020.9172771},
	abstract = {In recent years the field of robotic navigation has increasingly harnessed semantic information in order to facilitate the planning and execution of robotic tasks. The use of semantic information focuses on employing representations more understandable by humans to accomplish tasks with robustness against environmental change, limiting memory requirements and improving scalability. Contemporary computer vision algorithms extracting semantic information have continuously improved their performance on benchmark datasets, however, most computations are expensive, limiting their use for robotic platforms constrained by size, weight and power such as unmanned aerial vehicles (UAVs), Recent advances have demonstrated the potential for navigation systems based on semantic information to be included into real-time operation of UAVs. This paper describes the development of a processing pipeline to incorporate the use of semantic information into a UAV navigation system. A navigation framework that uses the Robot Operating System (ROS) and semantic information is being developed, with simulations as a primary evaluation mechanism, preceeding deployment on hardware. The proposed system takes inputs from RGB images generated on-board the UAV and processes them in real-time to generate a semantic representation of its environment. The UAV executes subsequent actions autonomously by reasoning about the semantic content of the environment in order to accomplish a goal. Results from simulation indicated that the system is capable of extracting semantic information from camera images alone and infer plausible motion inputs for the flight controller to execute. The results also show that the system is capable of processing data in real-time and is able to enhance navigational capabilities to drive UAVs towards a higher level of autonomy.},
	booktitle = {2020 {IEEE} {Aerospace} {Conference}},
	author = {Mandel, Nicolas and Alvarez, Fernando Vanegas and Milford, Michael and Gonzalez, Felipe},
	month = mar,
	year = {2020},
	note = {ISSN: 1095-323X},
	pages = {1--15}
}

@misc{desai_complete_2020,
	title = {From a complete newbie to passing the {TensorFlow} {Developer} {Certificate} {Exam}},
	url = {https://towardsdatascience.com/from-a-complete-newbie-to-passing-the-tensorflow-developer-certificate-exam-d919e1e5a0f3},
	abstract = {My journey from learning Python to passing the TensorFlow Developers Exam in less than 5 months.},
	language = {en},
	urldate = {2020-08-26},
	journal = {Medium},
	author = {Desai, Harsheev},
	month = aug,
	year = {2020}
}

@inproceedings{thede_second-order_1999,
	address = {College Park, Maryland, USA},
	title = {A {Second}-{Order} {Hidden} {Markov} {Model} for {Part}-of-{Speech} {Tagging}},
	url = {https://www.aclweb.org/anthology/P99-1023},
	doi = {10.3115/1034678.1034712},
	urldate = {2020-08-26},
	booktitle = {Proceedings of the 37th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Thede, Scott M. and Harper, Mary P.},
	month = jun,
	year = {1999},
	pages = {175--182}
}

@article{sung-hyun_log-viterbi_2018,
	title = {Log-{Viterbi} algorithm applied on second-order hidden {Markov} model for human activity recognition},
	volume = {14},
	issn = {1550-1477},
	url = {https://doi.org/10.1177/1550147718772541},
	doi = {10.1177/1550147718772541},
	abstract = {Recognition of human activities is getting into the limelight among researchers in the field of pervasive computing, ambient intelligence, robotic, and monitoring such as assistive living, elderly care, and health care. Many platforms, models, and algorithms have been developed and implemented to recognize the human activities. However, existing approaches suffer from low-activity accuracy and high time complexity. Therefore, we proposed probabilistic log-Viterbi algorithm on second-order hidden Markov model that facilitates our algorithm by reducing the time complexity with increased accuracy. Second-order hidden Markov model is efficient relevance between previous two activities, current activity, and current observation that incorporate more information into recognition procedure. The log-Viterbi algorithm converts the products of a large number of probabilities into additions and finds the most likely activity from observation sequence under given model. Therefore, this approach maximizes the probability of activity recognition with improved accuracy and reduced time complexity. We compared our proposed algorithm among other famous probabilistic models such as Naïve Bayes, condition random field, hidden Markov model, and hidden semi-Markov model using three datasets in the smart home environment. The recognition possibility of our proposed method is significantly better in accuracy and time complexity than early proposed method. Moreover, this improved algorithm for activity recognition is much effective for almost all the dynamic environments such as assistive living, elderly care, healthcare applications, and home automation.},
	language = {en},
	number = {4},
	urldate = {2020-08-26},
	journal = {International Journal of Distributed Sensor Networks},
	author = {Sung-Hyun, Yang and Thapa, Keshav and Kabir, M Humayun and Hee-Chan, Lee},
	month = apr,
	year = {2018},
	note = {Publisher: SAGE Publications},
	pages = {1550147718772541}
}

@misc{unknown_markov_nodate,
	type = {Presentation},
	title = {Markov {Chain} {Modelling}},
	url = {https://sequenceanalysis.github.io/slides/analyzing_sequential_user_behavior_part3.pdf},
	urldate = {2020-08-26},
	author = {Unknown}
}

@article{salnikov_using_2016,
	title = {Using higher-order {Markov} models to reveal flow-based communities in networks},
	volume = {6},
	issn = {2045-2322},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4814833/},
	doi = {10.1038/srep23194},
	abstract = {Complex systems made of interacting elements are commonly abstracted as networks, in which nodes are associated with dynamic state variables, whose evolution is driven by interactions mediated by the edges. Markov processes have been the prevailing paradigm to model such a network-based dynamics, for instance in the form of random walks or other types of diffusions. Despite the success of this modelling perspective for numerous applications, it represents an over-simplification of several real-world systems. Importantly, simple Markov models lack memory in their dynamics, an assumption often not realistic in practice. Here, we explore possibilities to enrich the system description by means of second-order Markov models, exploiting empirical pathway information. We focus on the problem of community detection and show that standard network algorithms can be generalized in order to extract novel temporal information about the system under investigation. We also apply our methodology to temporal networks, where we can uncover communities shaped by the temporal correlations in the system. Finally, we discuss relations of the framework of second order Markov processes and the recently proposed formalism of using non-backtracking matrices for community detection.},
	urldate = {2020-08-26},
	journal = {Scientific Reports},
	author = {Salnikov, Vsevolod and Schaub, Michael T. and Lambiotte, Renaud},
	month = mar,
	year = {2016},
	pmid = {27029508},
	pmcid = {PMC4814833}
}

@misc{gales_theory_1993,
	title = {The {Theory} of {Segmental} {Hidden} {Markov} {Models}},
	url = {https://www.researchgate.net/profile/Steve_Young3/publication/240338881_The_Theory_of_Segmental_Hidden_Markov_Models/links/0f31753bec86f2d7a2000000/The-Theory-of-Segmental-Hidden-Markov-Models.pdf},
	language = {en},
	urldate = {2020-08-26},
	publisher = {Cambridge University Engineering Department},
	author = {Gales, M and Young, S},
	month = jun,
	year = {1993}
}

@article{foreman_generalisation_1992,
	title = {Generalisation of the {Viterbi} algorithm},
	volume = {4},
	issn = {1471-678X},
	url = {https://academic.oup.com/imaman/article/4/4/351/665110},
	doi = {10.1093/imaman/4.4.351},
	abstract = {Abstract.  The Viterbi algorithm, derived using dynamic programming techniques, is a maximum a posteriori (MAP) decoding method which was developed in the elect},
	language = {en},
	number = {4},
	urldate = {2020-08-26},
	journal = {IMA Journal of Management Mathematics},
	author = {Foreman, Lindsey A.},
	month = jan,
	year = {1992},
	note = {Publisher: Oxford Academic},
	pages = {351--367}
}

@misc{noauthor_viterbi_2020,
	title = {Viterbi algorithm},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Viterbi_algorithm&oldid=970298562},
	abstract = {The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states—called the Viterbi path—that results in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMM).
The algorithm has found universal application in decoding the convolutional codes used in both CDMA and GSM digital cellular, dial-up modems, satellite, deep-space communications, and 802.11 wireless LANs. It is now also commonly used in speech recognition, speech synthesis, diarization, keyword spotting, computational linguistics, and bioinformatics. For example, in speech-to-text (speech recognition), the acoustic signal is treated as the observed sequence of events, and a string of text is considered to be the "hidden cause" of the acoustic signal. The Viterbi algorithm finds the most likely string of text given the acoustic signal.},
	language = {en},
	urldate = {2020-08-26},
	journal = {Wikipedia},
	month = jul,
	year = {2020},
	note = {Page Version ID: 970298562}
}

@inproceedings{heller_infinite_2009,
	title = {Infinite {Hierarchical} {Hidden} {Markov} {Models}},
	url = {http://proceedings.mlr.press/v5/heller09a.html},
	abstract = {In this paper we present the Infinite Hierarchical Hidden Markov Model (IHHMM), a nonparametric generalization of Hierarchical Hidden Markov Models (HHMMs). HHMMs have been used for modeling sequen...},
	language = {en},
	urldate = {2020-08-26},
	booktitle = {Artificial {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Heller, Katherine and Teh, Yee Whye and Gorur, Dilan},
	month = apr,
	year = {2009},
	note = {ISSN: 1938-7228},
	pages = {224--231}
}

@article{karaman_hierarchical_2014,
	title = {Hierarchical {Hidden} {Markov} {Model} in detecting activities of daily living in wearable videos for studies of dementia},
	volume = {69},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-012-1117-x},
	doi = {10.1007/s11042-012-1117-x},
	abstract = {This paper presents a method for indexing activities of daily living in videos acquired from wearable cameras. It addresses the problematic of analyzing the complex multimedia data acquired from wearable devices, which has been recently a growing concern due to the increasing amount of this kind of multimedia data. In the context of dementia diagnosis by doctors, patient activities are recorded in the environment of their home using a lightweight wearable device, to be later visualized by the medical practitioners. The recording mode poses great challenges since the video data consists in a single sequence shot where strong motion and sharp lighting changes often appear. Because of the length of the recordings, tools for an efficient navigation in terms of activities of interest are crucial. Our work introduces a video structuring approach that combines automatic motion based segmentation of the video and activity recognition by a hierarchical two-level Hidden Markov Model. We define a multi-modal description space over visual and audio features, including mid-level features such as motion, location, speech and noise detections. We show their complementarities globally as well as for specific activities. Experiments on real data obtained from the recording of several patients at home show the difficulty of the task and the promising results of the proposed approach.},
	language = {en},
	number = {3},
	urldate = {2020-08-26},
	journal = {Multimedia Tools and Applications},
	author = {Karaman, Svebor and Benois-Pineau, Jenny and Dovgalecs, Vladislavs and Mégret, Rémi and Pinquier, Julien and André-Obrecht, Régine and Gaëstel, Yann and Dartigues, Jean-François},
	month = apr,
	year = {2014},
	pages = {743--771}
}

@article{ivanov_recognition_2000,
	title = {Recognition of visual activities and interactions by stochastic parsing},
	volume = {22},
	issn = {1939-3539},
	doi = {10.1109/34.868686},
	abstract = {This paper describes a probabilistic syntactic approach to the detection and recognition of temporally extended activities and interactions between multiple agents. The fundamental idea is to divide the recognition problem into two levels. The lower level detections are performed using standard independent probabilistic event detectors to propose candidate detections of low-level features. The outputs of these detectors provide the input stream for a stochastic context-free grammar parsing mechanism. The grammar and parser provide longer range temporal constraints, disambiguate uncertain low-level detections, and allow the inclusion of a priori knowledge about the structure of temporal events in a given domain. We develop a real-time system and demonstrate the approach in several experiments on gesture recognition and in video surveillance. In the surveillance application, we show how the system correctly interprets activities of multiple interacting objects.},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Ivanov, Y.A. and Bobick, A.F.},
	month = aug,
	year = {2000},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Computer Society, Computer vision, Detectors, Event detection, Handwriting recognition, Hidden Markov models, Pattern recognition, Stochastic processes, Stochastic systems, Video surveillance, computer vision, context-free grammar, context-free grammars, gesture recognition, multi-agent systems, multiple agent systems, parsing, probabilistic syntactic pattern recognition, stochastic parsing, stochastic processes, surveillance, video surveillance, visual activity recognition},
	pages = {852--872}
}

@inproceedings{kijak_hmm_2003,
	title = {{HMM} based structuring of tennis videos using visual and audio cues},
	volume = {3},
	doi = {10.1109/ICME.2003.1221310},
	abstract = {This paper focuses on the use of hidden Markov models (HMMs) for structure analysis of videos, and demonstrates how they can be efficiently applied to merge audio and visual cues. Our approach is validated in the particular domain of tennis videos. The basic temporal unit is the video shot. Visual features describe the audio events within a video shot. The video structure parsing relies on the analysis of the temporal interleaving of video shots, with respect to prior information about tennis content and editing rules. As a result, typical tennis scenes are identified. In addition, each shot is assigned to a level in the hierarchy described in terms of point, game and set.},
	booktitle = {2003 {International} {Conference} on {Multimedia} and {Expo}. {ICME} '03. {Proceedings} ({Cat}. {No}.{03TH8698})},
	author = {Kijak, E. and Gravier, G. and Gros, P. and Oisel, L. and Bimbot, F.},
	month = jul,
	year = {2003},
	keywords = {Broadcasting, Data mining, Games, HMM based structuring, Hidden Markov models, Interleaved codes, Layout, Multimedia communication, Research and development, Streaming media, Videos, audio cues, audio features, audio signal processing, hidden Markov models, image classification, image segmentation, multimedia systems, sport, tennis videos, video signal processing, video structure analysis, video structure parsing, visual cues, visual features},
	pages = {III--309}
}

@article{rabiner_tutorial_1989,
	title = {A tutorial on hidden {Markov} models and selected applications in speech recognition},
	volume = {77},
	issn = {1558-2256},
	doi = {10.1109/5.18626},
	abstract = {This tutorial provides an overview of the basic theory of hidden Markov models (HMMs) as originated by L.E. Baum and T. Petrie (1966) and gives practical details on methods of implementation of the theory along with a description of selected applications of the theory to distinct problems in speech recognition. Results from a number of original sources are combined to provide a single source of acquiring the background required to pursue further this area of research. The author first reviews the theory of discrete Markov chains and shows how the concept of hidden states, where the observation is a probabilistic function of the state, can be used effectively. The theory is illustrated with two simple examples, namely coin-tossing, and the classic balls-in-urns system. Three fundamental problems of HMMs are noted and several practical techniques for solving these problems are given. The various types of HMMs that have been studied, including ergodic as well as left-right models, are described.{\textless}{\textgreater}},
	number = {2},
	journal = {Proceedings of the IEEE},
	author = {Rabiner, L.R.},
	month = feb,
	year = {1989},
	note = {Conference Name: Proceedings of the IEEE},
	keywords = {Hidden Markov models, Markov processes, Speech recognition, Tutorial, balls-in-urns system, coin-tossing, discrete Markov chains, ergodic models, hidden Markov models, hidden states, left-right models, probabilistic function, speech recognition},
	pages = {257--286}
}

@article{fine_hierarchical_1998,
	title = {The {Hierarchical} {Hidden} {Markov} {Model}: {Analysis} and {Applications}},
	volume = {32},
	issn = {1573-0565},
	shorttitle = {The {Hierarchical} {Hidden} {Markov} {Model}},
	url = {https://doi.org/10.1023/A:1007469218079},
	doi = {10.1023/A:1007469218079},
	abstract = {We introduce, analyze and demonstrate a recursive hierarchical generalization of the widely used hidden Markov models, which we name Hierarchical Hidden Markov Models (HHMM). Our model is motivated by the complex multi-scale structure which appears in many natural sequences, particularly in language, handwriting and speech. We seek a systematic unsupervised approach to the modeling of such structures. By extending the standard Baum-Welch (forward-backward) algorithm, we derive an efficient procedure for estimating the model parameters from unlabeled data. We then use the trained model for automatic hierarchical parsing of observation sequences. We describe two applications of our model and its parameter estimation procedure. In the first application we show how to construct hierarchical models of natural English text. In these models different levels of the hierarchy correspond to structures on different length scales in the text. In the second application we demonstrate how HHMMs can be used to automatically identify repeated strokes that represent combination of letters in cursive handwriting.},
	language = {en},
	number = {1},
	urldate = {2020-08-26},
	journal = {Machine Learning},
	author = {Fine, Shai and Singer, Yoram and Tishby, Naftali},
	month = jul,
	year = {1998},
	pages = {41--62}
}

@misc{noauthor_cuda_2014,
	title = {{CUDA} {Pro} {Tip}: {Occupancy} {API} {Simplifies} {Launch} {Configuration}},
	shorttitle = {{CUDA} {Pro} {Tip}},
	url = {https://developer.nvidia.com/blog/cuda-pro-tip-occupancy-api-simplifies-launch-configuration/},
	abstract = {CUDA 6.5 includes several new runtime functions to assist in configuring kernel launches to achieve maximum GPU occupancy.},
	language = {en-US},
	urldate = {2020-08-25},
	journal = {NVIDIA Developer Blog},
	month = jul,
	year = {2014}
}

@book{davis_representations_1990,
	title = {Representations of {Commonsense} {Knowledge}},
	isbn = {978-1-4832-2113-7},
	url = {http://ebookcentral.proquest.com/lib/qut/detail.action?docID=2056902},
	urldate = {2020-08-23},
	publisher = {Elsevier Science \& Technology},
	author = {Davis, Ernest and Brachman, Ronald J.},
	year = {1990},
	keywords = {Artificial intelligence., Commonsense reasoning., Intelligent agents (Computer software).}
}

@article{marcus_next_2020,
	title = {The {Next} {Decade} in {AI}: {Four} {Steps} {Towards} {Robust} {Artificial} {Intelligence}},
	shorttitle = {The {Next} {Decade} in {AI}},
	url = {http://arxiv.org/abs/2002.06177},
	abstract = {Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.},
	urldate = {2020-08-23},
	journal = {arXiv:2002.06177 [cs]},
	author = {Marcus, Gary},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.06177},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, I.2, I.2.6}
}

@misc{noauthor_gpt-3_nodate,
	title = {{GPT}-3, {Bloviator}: {OpenAI}’s language generator has no idea what it’s talking about},
	shorttitle = {{GPT}-3, {Bloviator}},
	url = {https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/},
	abstract = {Since OpenAI first described its new AI language-generating system called GPT-3 in May, hundreds of media outlets (including MIT Technology Review) have written about the system and its capabilities. Twitter has been abuzz about its power and potential. The New York Times published an op-ed about it. Later this year, OpenAI will begin charging companies…},
	language = {en},
	urldate = {2020-08-23},
	journal = {MIT Technology Review}
}

@misc{noauthor_nvidia_nodate,
	title = {{NVIDIA} {Research}: {Graduate} {Fellows} \& {Fellowship} {Opportunities}},
	shorttitle = {{NVIDIA} {Research}},
	url = {https://www.nvidia.com/en-us/research/graduate-fellowships/},
	abstract = {Our fellowship program is an ideal introduction of NVIDIA to the future leaders of our industry.},
	language = {en-us},
	urldate = {2020-08-23},
	journal = {NVIDIA}
}

@inproceedings{costa_first-order_2008,
	address = {Florida},
	title = {A {First}-{Order} {Bayesian} {Tool} for {Probabilistic} {Ontologies}},
	url = {https://www.aaai.org/Library/FLAIRS/2008/flairs08-142.php},
	abstract = {One of the major weaknesses of current research on the Semantic Web (SW) is the lack of proper means to represent and reason with uncertainty. A number of recent efforts from the SW community, the W3C, and others have recently emerged to address this gap. Such efforts have the positive side effect of bringing together two fields of research that have been apart for historical reasons, the artificial intelligence and the SW communities. One example of the potential research gains of this convergence is the current development of Probabilistic OWL (PR-OWL), an extension of the OWL Web Ontology Language that provides a framework to build probabilistic ontologies, thus enabling proper representation and reasoning with uncertainty within the SW context. PR-OWL is based on Multi-Entity Bayesian Networks (MEBN), a first-order probabilistic logic that combines the representational power of first-order logic (FOL) and Bayesian Networks (BN). However, PR-OWL and MEBN are still in development, lacking a software tool that implements their underlying concepts. The development of UnBBayes-MEBN, an open source, Java-based application that is currently in alpha phase (public release March 08), addresses this gap by providing both a GUI for building probabilistic ontologies and a reasoner based on the PR-OWL/MEBN framework. This work focuses on the major challenges of UnBBayes-MEBN implementation, describes the features already implemented, and provides an overview of the major algorithms, mainly the one used for building a Situation Specific Bayesian Network (SSBN) from a MEBN Theory.},
	urldate = {2020-08-19},
	booktitle = {Proceedings of the {Twenty}-{First} {International} {FLAIRS} {Conference}},
	publisher = {AAAI},
	author = {Costa, P. and Ladeira, M and Carvalho, R and Laskey, K and Santos, L and Matsumoto, S},
	month = feb,
	year = {2008}
}

@inproceedings{arora_randomized_2017,
	title = {Randomized algorithm for informative path planning with budget constraints},
	doi = {10.1109/ICRA.2017.7989582},
	abstract = {Maximizing information gathered within a budget is a relevant problem for information gathering tasks for robots with cost or operating time constraints. This problem is also known as the informative path planning (IPP) problem or correlated orienteering. It can be formalized as that of finding budgeted routes in a graph such that the reward collected by the route is maximized, where the reward at nodes can be dependent. Unfortunately, the problem is NP-Hard and the state of the art methods are too slow to even present an approximate solution online. Here we present Randomized Anytime Orienteering (RAOr) algorithm that provides near optimal solutions while demonstrably converging to an efficient solution in runtimes that allows the solver to be run online. The key idea of our approach is to pose orienteering as a combination of a Constraint Satisfaction Problem and a Traveling Salesman Problem. This formulation allows us to restrict the search space to routes that incur minimum distance to visit a set of selected nodes, and rapidly search this space using random sampling. The paper provides the analysis of asymptotic near-optimality, convergence rates for RAOr algorithms, and present strategies to improve anytime performance of the algorithm. Our experimental results suggest an improvement by an order of magnitude over the state of the art methods in relevant simulation and in real world scenarios.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Arora, Sankalp and Scherer, Sebastian},
	month = may,
	year = {2017},
	keywords = {Algorithm design and analysis, Approximation algorithms, IPP problem, NP-hard problem, RAOr algorithm, Robot sensing systems, Space exploration, Traveling salesman problems, budget constraints, computational complexity, constraint satisfaction problem, correlated orienteering, cost constraints, information gathering task, informative path planning, operating time constraints, path planning, randomised algorithms, randomized algorithm, randomized anytime orienteering algorithm, traveling salesman problem},
	pages = {4997--5004}
}

@article{xu_probabilistic_2020,
	title = {Probabilistic {Visual} {Place} {Recognition} for {Hierarchical} {Localization}},
	author = {Xu, Ming and Suenderhauf, Niko and Milford, M.},
	year = {2020}
}

@article{penicka_physical_2019,
	title = {Physical {Orienteering} {Problem} for {Unmanned} {Aerial} {Vehicle} {Data} {Collection} {Planning} in {Environments} {With} {Obstacles}},
	volume = {4},
	issn = {2377-3766},
	doi = {10.1109/LRA.2019.2923949},
	abstract = {This letter concerns a variant of the orienteering problem (OP) that arises from multi-goal data collection scenarios where a robot with a limited travel budget is requested to visit given target locations in an environment with obstacles. We call the introduced OP variant the physical OP (POP). The POP sets out to determine a feasible, collision-free, path that maximizes collected reward from a subset of the target locations and does not exceed the given travel budget. The problem combines motion planning and combinatorial optimization to visit multiple target locations. The proposed solution to the POP is based on the variable neighborhood search (VNS) method combined with the asymptotically optimal sampling-based probabilistic roadmap (PRM*) method. The VNS-PRM* uses initial low-dense roadmap that is continuously expanded during the VNSbased POP optimization to shorten paths of the promising solutions and, thus, allows maximizing the sum of the collected rewards. The computational results support the feasibility of the proposed approach by a fast determination of high-quality solutions. Moreover, an experimental verification demonstrates the applicability of the proposed VNS-PRM* approach for data collection planning for an unmanned aerial vehicle in an urban-like environment with obstacles.},
	number = {3},
	journal = {IEEE Robotics and Automation Letters},
	author = {Pěnička, Robert and Faigl, Jan and Saska, Martin},
	month = jul,
	year = {2019},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Aerial Systems: Applications, Data collection, Motion and Path Planning, Optimization, Path planning, Planning, Robots, Routing, Unmanned aerial vehicles, VNS-PRM* approach, VNS-based POP optimization, asymptotically optimal sampling-based probabilistic roadmap method, autonomous aerial vehicles, collision avoidance, combinatorial optimization, high-quality solutions, mobile robots, motion planning, multi-robot systems, multigoal data collection scenarios, multiple target locations, optimisation, physical OP, physical orienteering problem, probability, remotely operated vehicles, search problems, target locations, travel budget, unmanned aerial vehicle data collection planning, variable neighborhood search method},
	pages = {3005--3012}
}

@incollection{borkowski_towards_2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Towards {Semantic} {Navigation} in {Mobile} {Robotics}},
	isbn = {978-3-642-17322-6},
	url = {https://doi.org/10.1007/978-3-642-17322-6_30},
	abstract = {Nowadays mobile robots find application in many areas of production, public transport, security and defense, exploration of space, etc. In order to make further progress in this domain of engineering, a significant barrier has to be broken: robots must be able to understand the meaning of surrounding world. Until now, mobile robots have only perceived geometrical features of the environment. Rapid progress in sensory devices (video cameras, laser range finders, microwave radars) and sufficient computational power available on-board makes it possible to develop robot controllers that possess certain knowledge about the area of application and which are able to reason at a semantic level.The first part of the paper deals with mobile robots dedicated to operate inside buildings. A concept of the semantic navigation based upon hypergraphs is introduced. Then it is shown how semantic information, useful for mobile robots, can be extracted from the digital documentation of a building.In the second part of the paper we report the latest results on extracting semantic features from the raw data supplied by laser scanners. The aim of this research is to develop a system that will enable a mobile robot to operate in a building with ability to recognise and identify objects of certain classes. Data processing techniques involved in this system include a 3D-model of the environment updated on-line, rule-based and feature-based classifiers of objects, a path planner utilizing cellular networks and other advanced tools. Experiments carried out under real-life conditions validate the proposed solutions.},
	language = {en},
	urldate = {2020-08-13},
	booktitle = {Graph {Transformations} and {Model}-{Driven} {Engineering}: {Essays} {Dedicated} to {Manfred} {Nagl} on the {Occasion} of his 65th {Birthday}},
	publisher = {Springer},
	author = {Borkowski, Adam and Siemiatkowska, Barbara and Szklarski, Jacek},
	editor = {Engels, Gregor and Lewerentz, Claus and Schäfer, Wilhelm and Schürr, Andy and Westfechtel, Bernhard},
	year = {2010},
	doi = {10.1007/978-3-642-17322-6_30},
	keywords = {Building Information Modeling, Cellular Neural Network, Mobile Robot, Path Planning, Point Cloud},
	pages = {719--748}
}

@misc{herrero_jupyterlab-ros_2020,
	title = {{JupyterLab}-{ROS}},
	url = {https://blog.jupyter.org/jupyterlab-ros-3dc9dab7f421},
	abstract = {Building a cloud robotics development platform using JupyterLab and ROS},
	language = {en},
	urldate = {2020-08-12},
	journal = {Medium},
	author = {Herrero, Carlos},
	month = aug,
	year = {2020}
}

@misc{noauthor_computer_nodate,
	title = {Computer {Science} {PhD} --help},
	url = {https://phdadvice.carrd.co},
	abstract = {the greatest hits},
	language = {en},
	urldate = {2020-08-12},
	journal = {Computer Science PhD --help}
}

@article{satsangi_exploiting_2018,
	title = {Exploiting submodular value functions for scaling up active perception},
	volume = {42},
	issn = {1573-7527},
	url = {https://doi.org/10.1007/s10514-017-9666-5},
	doi = {10.1007/s10514-017-9666-5},
	abstract = {In active perception tasks, an agent aims to select sensory actions that reduce its uncertainty about one or more hidden variables. For example, a mobile robot takes sensory actions to efficiently navigate in a new environment. While partially observable Markov decision processes (POMDPs) provide a natural model for such problems, reward functions that directly penalize uncertainty in the agent’s belief can remove the piecewise-linear and convex (PWLC) property of the value function required by most POMDP planners. Furthermore, as the number of sensors available to the agent grows, the computational cost of POMDP planning grows exponentially with it, making POMDP planning infeasible with traditional methods. In this article, we address a twofold challenge of modeling and planning for active perception tasks. We analyze \$\${\textbackslash}rho \$\$ρPOMDP and POMDP-IR, two frameworks for modeling active perception tasks, that restore the PWLC property of the value function. We show the mathematical equivalence of these two frameworks by showing that given a \$\${\textbackslash}rho \$\$ρPOMDP along with a policy, they can be reduced to a POMDP-IR and an equivalent policy (and vice-versa). We prove that the value function for the given \$\${\textbackslash}rho \$\$ρPOMDP (and the given policy) and the reduced POMDP-IR (and the reduced policy) is the same. To efficiently plan for active perception tasks, we identify and exploit the independence properties of POMDP-IR to reduce the computational cost of solving POMDP-IR (and \$\${\textbackslash}rho \$\$ρPOMDP). We propose greedy point-based value iteration (PBVI), a new POMDP planning method that uses greedy maximization to greatly improve scalability in the action space of an active perception POMDP. Furthermore, we show that, under certain conditions, including submodularity, the value function computed using greedy PBVI is guaranteed to have bounded error with respect to the optimal value function. We establish the conditions under which the value function of an active perception POMDP is guaranteed to be submodular. Finally, we present a detailed empirical analysis on a dataset collected from a multi-camera tracking system employed in a shopping mall. Our method achieves similar performance to existing methods but at a fraction of the computational cost leading to better scalability for solving active perception tasks.},
	language = {en},
	number = {2},
	urldate = {2020-08-12},
	journal = {Autonomous Robots},
	author = {Satsangi, Yash and Whiteson, Shimon and Oliehoek, Frans A. and Spaan, Matthijs T. J.},
	month = feb,
	year = {2018},
	pages = {209--233}
}

@book{doucet_tutorial_2011,
	title = {A tutorial on particle filtering and smoothing: fifteen years later},
	shorttitle = {A tutorial on particle filtering and smoothing},
	abstract = {Optimal estimation problems for non-linear non-Gaussian state-space models do not typically admit analytic solutions. Since their introduction in 1993, particle filtering methods have become a very popular class of algorithms to solve these estimation problems numerically in an online manner, i.e. recursively as observations become available, and are now routinely used in fields as diverse as computer vision, econometrics, robotics and navigation. The objective of this tutorial is to provide a complete, up-to-date survey of this field as of 2008. Basic and advanced particle methods for filtering as well as smoothing are presented.},
	author = {Doucet, Arnaud and Johansen, Adam M.},
	year = {2011}
}

@inproceedings{marjanovic_engineers_2016,
	title = {An engineer's guide to particle filtering on matrix {Lie} groups},
	doi = {10.1109/ICASSP.2016.7472422},
	abstract = {In many important engineering applications the state dynamics of a system are modelled by Stochastic Differential Equations (SDEs) evolving in non-Euclidean spaces such as matrix Lie groups. Due to the advances in computing power, the problem of state estimation can be efficiently addressed by the particle filtering method. This requires dealing with both the geometry and the stochastics of the problem. However, the very few papers that properly deal with either are in the mathematics literature and not accessible. The engineering literature is also small but plagued with problems. With this in mind, we give a direct accessible derivation of the particle filter algorithm for state estimation in matrix Lie groups. We do not rely on differential geometry or advanced stochastic calculus. Simulation examples are provided.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Marjanovic, Goran and Solo, Victor},
	month = mar,
	year = {2016},
	note = {ISSN: 2379-190X},
	keywords = {Filtering, Geometry, Heuristic algorithms, Lie groups, Manifolds, Mathematical model, Particle filter, SDEs, State estimation, Stochastic processes, advanced stochastic calculus, differential equations, differential geometry, engineer guide, matrix Lie group integrators, matrix Lie groups, matrix algebra, nonEuclidean spaces, particle filtering (numerical methods), particle filtering method, sequential Monte Carlo methods, state estimation, state estimation problem, stochastic differential equations},
	pages = {3969--3973}
}

@inproceedings{krishnan_visual_2010,
	title = {A visual exploration algorithm using semantic cues that constructs image based hybrid maps},
	doi = {10.1109/IROS.2010.5649870},
	abstract = {A vision based exploration algorithm that invokes semantic cues for constructing a hybrid map of images - a combination of semantic and topological maps is presented in this paper. At the top level the map is a graph of semantic constructs. Each node in the graph is a semantic construct or label such as a room or a corridor, the edge represented by a transition region such as a doorway that links the two semantic constructs. Each semantic node embeds within it a topological graph that constitutes the map at the middle level. The topological graph is a set of nodes, each node representing an image of the higher semantic construct. At the low level the topological graph embeds metric values and relations, where each node embeds the pose of the robot from which the image was taken and any two nodes in the graph are related by a transformation consisting of a rotation and translation. The exploration algorithm explores a semantic construct completely before moving or branching onto a new construct. Within each semantic construct it uses a local feature based exploration algorithm that uses a combination of local and global decisions to decide the next best place to move. During the process of exploring a semantic construct it identifies transition regions that serve as gateways to move from that construct to another. The exploration is deemed complete when all transition regions are marked visited. Loop detection happens at transition regions and graph relaxation techniques are used to close loops when detected to obtain a consistent metric embedding of the robot poses. Semantic constructs are labeled using a visual bag of words (VBOW) representation with a probabilistic SVM classifier.},
	booktitle = {2010 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Krishnan, Aravindhan K and Krishna, K Madhava},
	month = oct,
	year = {2010},
	note = {ISSN: 2153-0866},
	keywords = {Logic gates, Measurement, Probabilistic logic, Robot sensing systems, SLAM (robots), SVM classifier, Semantics, Support vector machines, edge detection, edge representation, feature extraction, graph theory, hybrid maps, image reconstruction, image representation, local feature based exploration algorithm, loop detection, mobile robots, pose estimation, robot poses, robot vision, semantic construct, semantic cues, support vector machines, topological graph, topological maps, visual exploration algorithm},
	pages = {1316--1321}
}

@misc{noauthor_category_2014,
	title = {Category {Theory} for {Programmers}: {The} {Preface}},
	shorttitle = {Category {Theory} for {Programmers}},
	url = {https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/},
	abstract = {Table of Contents Part One Category: The Essence of Composition Types and Functions Categories Great and Small Kleisli Categories Products and Coproducts Simple Algebraic Data Types Functors Functo…},
	language = {en},
	urldate = {2020-08-09},
	journal = {Bartosz Milewski's Programming Cafe},
	month = oct,
	year = {2014}
}

@book{simmonds_mastering_2017,
	address = {Birmingham},
	edition = {2nd edition},
	title = {Mastering {Embedded} {Linux} {Programming} - {Second} {Edition}},
	isbn = {978-1-78728-328-2},
	abstract = {Master the techniques needed to build great, efficient embedded devices on Linux About This Book Discover how to build and configure reliable embedded Linux devices This book has been updated to include Linux 4.9 and Yocto Project 2.2 (Morty) This comprehensive guide covers the remote update of devices in the field and power management Who This Book Is For If you are an engineer who wishes to understand and use Linux in embedded devices, this book is for you. It is also for Linux developers and system programmers who are familiar with embedded systems and want to learn and program the best in class devices. It is appropriate for students studying embedded techniques, for developers implementing embedded Linux devices, and engineers supporting existing Linux devices. What You Will Learn Evaluate the Board Support Packages offered by most manufacturers of a system on chip or embedded module Use Buildroot and the Yocto Project to create embedded Linux systems quickly and efficiently Update IoT devices in the field without compromising security Reduce the power budget of devices to make batteries last longer Interact with the hardware without having to write kernel device drivers Debug devices remotely using GDB, and see how to measure the performance of the systems using powerful tools such as perk, ftrace, and valgrind Find out how to configure Linux as a real-time operating system In Detail Embedded Linux runs many of the devices we use every day, from smart TVs to WiFi routers, test equipment to industrial controllers - all of them have Linux at their heart. Linux is a core technology in the implementation of the inter-connected world of the Internet of Things. The comprehensive guide shows you the technologies and techniques required to build Linux into embedded systems. You will begin by learning about the fundamental elements that underpin all embedded Linux projects: the toolchain, the bootloader, the kernel, and the root filesystem. You’ll see how to create each of these elements from scratch, and how to automate the process using Buildroot and the Yocto Project. Moving on, you’ll find out how to implement an effective storage strategy for flash memory chips, and how to install updates to the device remotely once it is deployed. You’ll also get to know the key aspects of writing code for embedded Linux, such as how to access hardware from applications, the implications of writing multi-threaded code, and techniques to manage memory in an ...},
	language = {eng},
	publisher = {Packt Publishing},
	author = {Simmonds, Chris},
	collaborator = {Safari, an O’Reilly Media Company},
	year = {2017},
	keywords = {Electronic books}
}

@misc{noauthor_how_2015,
	title = {How to undo (almost) anything with {Git}},
	url = {https://github.blog/2015-06-08-how-to-undo-almost-anything-with-git/},
	abstract = {One of the most useful features of any version control system is the ability to “undo” your mistakes. In Git, “undo” can mean many slightly different things. When you make a new commit, Git stores},
	language = {en-US},
	urldate = {2020-08-05},
	journal = {The GitHub Blog},
	month = jun,
	year = {2015},
	note = {Library Catalog: github.blog}
}

@misc{passos_writing_2018,
	title = {Writing {LaTeX} {Documents} {In} {Visual} {Studio} {Code} {With} {LaTeX} {Workshop}},
	url = {https://medium.com/@rcpassos/writing-latex-documents-in-visual-studio-code-with-latex-workshop-d9af6a6b2815},
	abstract = {If you want to write LaTeX on your machine, VS Code is a great option for you! Installing all the necessary packages is a simple process…},
	language = {en},
	urldate = {2020-08-05},
	journal = {Medium},
	author = {Passos, Rafael "Auyer"},
	month = nov,
	year = {2018},
	note = {Library Catalog: medium.com}
}

@article{bourmaud_continuous-discrete_2015,
	title = {Continuous-{Discrete} {Extended} {Kalman} {Filter} on {Matrix} {Lie} {Groups} {Using} {Concentrated} {Gaussian} {Distributions}},
	volume = {51},
	issn = {1573-7683},
	url = {https://doi.org/10.1007/s10851-014-0517-0},
	doi = {10.1007/s10851-014-0517-0},
	abstract = {In this paper we generalize the continuous-discrete extended Kalman filter (CD-EKF) to the case where the state and the observations evolve on connected unimodular matrix Lie groups. We propose a new assumed density filter called continuous-discrete extended Kalman filter on Lie groups (CD-LG-EKF). It is built upon a geometrically meaningful modeling of the concentrated Gaussian distribution on Lie groups. Such a distribution is parametrized by a mean and a covariance matrix defined on the Lie group and in its associated Lie algebra respectively. Our formalism yields tractable equations for both non-linear continuous time propagation and discrete update of the distribution parameters under the assumption that the posterior distribution of the state is a concentrated Gaussian. As a side effect, we contribute to the derivation of the first and second order differential of the matrix Lie group logarithm using left connection. We also show that the CD-LG-EKF reduces to the usual CD-EKF if the state and the observations evolve on Euclidean spaces. Our approach leads to a systematic methodology for the design of filters, which is illustrated by the application to a camera pose filtering problem with observations on Lie group. In this application, the CD-LG-EKF significantly outperforms two constrained non-linear filters (one based on a linearization technique and the other on the unscented transform) applied on the embedding space of the Lie group.},
	language = {en},
	number = {1},
	urldate = {2020-08-05},
	journal = {Journal of Mathematical Imaging and Vision},
	author = {Bourmaud, Guillaume and Mégret, Rémi and Arnaudon, Marc and Giremus, Audrey},
	month = jan,
	year = {2015},
	pages = {209--228}
}
@inproceedings{marjanovic_engineers_2016,
	title = {An engineer's guide to particle filtering on matrix {Lie} groups},
	doi = {10.1109/ICASSP.2016.7472422},
	abstract = {In many important engineering applications the state dynamics of a system are modelled by Stochastic Differential Equations (SDEs) evolving in non-Euclidean spaces such as matrix Lie groups. Due to the advances in computing power, the problem of state estimation can be efficiently addressed by the particle filtering method. This requires dealing with both the geometry and the stochastics of the problem. However, the very few papers that properly deal with either are in the mathematics literature and not accessible. The engineering literature is also small but plagued with problems. With this in mind, we give a direct accessible derivation of the particle filter algorithm for state estimation in matrix Lie groups. We do not rely on differential geometry or advanced stochastic calculus. Simulation examples are provided.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Marjanovic, Goran and Solo, Victor},
	month = mar,
	year = {2016},
	note = {ISSN: 2379-190X},
	keywords = {Filtering, Geometry, Heuristic algorithms, Lie groups, Manifolds, Mathematical model, Particle filter, SDEs, State estimation, Stochastic processes, advanced stochastic calculus, differential equations, differential geometry, engineer guide, matrix Lie group integrators, matrix Lie groups, matrix algebra, nonEuclidean spaces, particle filtering (numerical methods), particle filtering method, sequential Monte Carlo methods, state estimation, state estimation problem, stochastic differential equations},
	pages = {3969--3973}
}

@patent{andriluka_united_2015,
	title = {United {States} {Patent}: 9058663 - {Modeling} human-human interactions for monocular {3D} pose estimation},
	shorttitle = {United {States} {Patent}},
	url = {http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&Sect2=HITOFF&d=PALL&p=1&u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&r=1&f=G&l=50&s1=9058663.PN.&OS=PN/9058663},
	abstract = {Techniques are disclosed for the automatic recovery of two dimensional
     (2D) and three dimensional (3D) poses of multiple subjects interacting
     with one another, as depicted in a sequence of 2D images. As part of
     recovering 2D and 3D pose estimates, a pose recovery tool may account for
     constraints on positions of body parts of the first and second person
     resulting from the correlated activity. That is, individual subjects in
     the video are treated as mutual context for one another.},
	assignee = {Disney Enterprises, Inc.},
	number = {9058663},
	urldate = {2020-08-04},
	author = {Andriluka, Mykhaylo and DE and Sigal, Leonid},
	month = jun,
	year = {2015},
	note = {Library Catalog: Patents - USPTO}
}

@inproceedings{johnson_clustered_2010,
	address = {Aberystwyth},
	title = {Clustered {Pose} and {Nonlinear} {Appearance} {Models} for {Human} {Pose} {Estimation}},
	isbn = {978-1-901725-40-7},
	url = {http://www.bmva.org/bmvc/2010/conference/paper12/index.html},
	doi = {10.5244/C.24.12},
	language = {en},
	urldate = {2020-08-04},
	booktitle = {Procedings of the {British} {Machine} {Vision} {Conference} 2010},
	publisher = {British Machine Vision Association},
	author = {Johnson, Sam and Everingham, Mark},
	year = {2010},
	pages = {12.1--12.11}
}

@inproceedings{andriluka_monocular_2010,
	title = {Monocular {3D} pose estimation and tracking by detection},
	doi = {10.1109/CVPR.2010.5540156},
	abstract = {Automatic recovery of 3D human pose from monocular image sequences is a challenging and important research topic with numerous applications. Although current methods are able to recover 3D pose for a single person in controlled environments, they are severely challenged by real-world scenarios, such as crowded street scenes. To address this problem, we propose a three-stage process building on a number of recent advances. The first stage obtains an initial estimate of the 2D articulation and viewpoint of the person from single frames. The second stage allows early data association across frames based on tracking-by-detection. These two stages successfully accumulate the available 2D image evidence into robust estimates of 2D limb positions over short image sequences (= tracklets). The third and final stage uses those tracklet-based estimates as robust image observations to reliably recover 3D pose. We demonstrate state-of-the-art performance on the HumanEva II benchmark, and also show the applicability of our approach to articulated 3D tracking in realistic street conditions.},
	booktitle = {2010 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Andriluka, Mykhaylo and Roth, Stefan and Schiele, Bernt},
	month = jun,
	year = {2010},
	note = {ISSN: 1063-6919},
	keywords = {2D articulation estimation, 2D image evidence, 2D limb position, 3D human pose, Biological system modeling, Cameras, Computer science, Hidden Markov models, Humans, Hybrid power systems, Image sequences, Layout, Motion estimation, Robustness, articulated 3D tracking, crowded street scene, data association, detection tracking, image sequences, monocular 3D pose estimation, monocular image sequence, object detection, optical tracking, pose estimation, three-stage process building, tracking-by-detection, tracklet-based estimates, viewpoint estimation},
	pages = {623--630}
}

@article{bogo_keep_2016,
	title = {Keep it {SMPL}: {Automatic} {Estimation} of {3D} {Human} {Pose} and {Shape} from a {Single} {Image}},
	shorttitle = {Keep it {SMPL}},
	url = {http://arxiv.org/abs/1607.08128},
	abstract = {We describe the first method to automatically estimate the 3D pose of the human body as well as its 3D shape from a single unconstrained image. We estimate a full 3D mesh and show that 2D joints alone carry a surprising amount of information about body shape. The problem is challenging because of the complexity of the human body, articulation, occlusion, clothing, lighting, and the inherent ambiguity in inferring 3D from 2D. To solve this, we first use a recently published CNN-based method, DeepCut, to predict (bottom-up) the 2D body joint locations. We then fit (top-down) a recently published statistical body shape model, called SMPL, to the 2D joints. We do so by minimizing an objective function that penalizes the error between the projected 3D model joints and detected 2D joints. Because SMPL captures correlations in human shape across the population, we are able to robustly fit it to very little data. We further leverage the 3D model to prevent solutions that cause interpenetration. We evaluate our method, SMPLify, on the Leeds Sports, HumanEva, and Human3.6M datasets, showing superior pose accuracy with respect to the state of the art.},
	urldate = {2020-08-04},
	journal = {arXiv:1607.08128 [cs]},
	author = {Bogo, Federica and Kanazawa, Angjoo and Lassner, Christoph and Gehler, Peter and Romero, Javier and Black, Michael J.},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.08128},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{mehta_vnect_2017,
	title = {{VNect}: {Real}-time {3D} {Human} {Pose} {Estimation} with a {Single} {RGB} {Camera}},
	volume = {36},
	issn = {0730-0301, 1557-7368},
	shorttitle = {{VNect}},
	url = {http://arxiv.org/abs/1705.01583},
	doi = {10.1145/3072959.3073596},
	abstract = {We present the first real-time method to capture the full global 3D skeletal pose of a human in a stable, temporally consistent manner using a single RGB camera. Our method combines a new convolutional neural network (CNN) based pose regressor with kinematic skeleton fitting. Our novel fully-convolutional pose formulation regresses 2D and 3D joint positions jointly in real time and does not require tightly cropped input frames. A real-time kinematic skeleton fitting method uses the CNN output to yield temporally stable 3D global pose reconstructions on the basis of a coherent kinematic skeleton. This makes our approach the first monocular RGB method usable in real-time applications such as 3D character control---thus far, the only monocular methods for such applications employed specialized RGB-D cameras. Our method's accuracy is quantitatively on par with the best offline 3D monocular RGB pose estimation methods. Our results are qualitatively comparable to, and sometimes better than, results from monocular RGB-D approaches, such as the Kinect. However, we show that our approach is more broadly applicable than RGB-D solutions, i.e. it works for outdoor scenes, community videos, and low quality commodity RGB cameras.},
	number = {4},
	urldate = {2020-08-04},
	journal = {ACM Transactions on Graphics},
	author = {Mehta, Dushyant and Sridhar, Srinath and Sotnychenko, Oleksandr and Rhodin, Helge and Shafiei, Mohammad and Seidel, Hans-Peter and Xu, Weipeng and Casas, Dan and Theobalt, Christian},
	month = jul,
	year = {2017},
	note = {arXiv: 1705.01583},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics},
	pages = {1--14}
}

@article{tome_lifting_2017,
	title = {Lifting from the {Deep}: {Convolutional} {3D} {Pose} {Estimation} from a {Single} {Image}},
	shorttitle = {Lifting from the {Deep}},
	url = {http://arxiv.org/abs/1701.00295},
	doi = {10.1109/CVPR.2017.603},
	abstract = {We propose a unified formulation for the problem of 3D human pose estimation from a single raw RGB image that reasons jointly about 2D joint estimation and 3D pose reconstruction to improve both tasks. We take an integrated approach that fuses probabilistic knowledge of 3D human pose with a multi-stage CNN architecture and uses the knowledge of plausible 3D landmark locations to refine the search for better 2D locations. The entire process is trained end-to-end, is extremely efficient and obtains state- of-the-art results on Human3.6M outperforming previous approaches both on 2D and 3D errors.},
	urldate = {2020-08-04},
	journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	author = {Tome, Denis and Russell, Chris and Agapito, Lourdes},
	month = jul,
	year = {2017},
	note = {arXiv: 1701.00295},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {5689--5698}
}

@article{talib_systematic_2020,
	title = {A systematic literature review on hardware implementation of artificial intelligence algorithms},
	issn = {1573-0484},
	url = {https://doi.org/10.1007/s11227-020-03325-8},
	doi = {10.1007/s11227-020-03325-8},
	abstract = {Artificial intelligence (AI) and machine learning (ML) tools play a significant role in the recent evolution of smart systems. AI solutions are pushing towards a significant shift in many fields such as healthcare, autonomous airplanes and vehicles, security, marketing customer profiling and other diverse areas. One of the main challenges hindering the AI potential is the demand for high-performance computation resources. Recently, hardware accelerators are developed in order to provide the needed computational power for the AI and ML tools. In the literature, hardware accelerators are built using FPGAs, GPUs and ASICs to accelerate computationally intensive tasks. These accelerators provide high-performance hardware while preserving the required accuracy. In this work, we present a systematic literature review that focuses on exploring the available hardware accelerators for the AI and ML tools. More than 169 different research papers published between the years 2009 and 2019 are studied and analysed.},
	language = {en},
	urldate = {2020-08-04},
	journal = {The Journal of Supercomputing},
	author = {Talib, Manar Abu and Majzoub, Sohaib and Nasir, Qassim and Jamal, Dina},
	month = may,
	year = {2020}
}

@misc{tenenbaum_rss_2020,
	title = {{RSS} 2020, {Keynote} + {Q}\&{A}: {Josh} {Tenenbaum}},
	volume = {RSS 2020},
	shorttitle = {{RSS} 2020, {Keynote} + {Q}\&{A}},
	url = {https://www.youtube.com/watch?time_continue=911&v=D9xVj7oLVh4&feature=emb_logo},
	abstract = {It's all in your head: Intuitive physics, planning, and problem-solving in brains, minds and machines

I will overview what we know about the human mind's internal models of the physical world, including how these models arise over evolution and developmental learning, how they are implemented in neural circuitry, and how they are used to support planning and rapid trial-and-error problem-solving in tool use and other physical reasoning tasks. I will also discuss prospects for building more human-like physical common sense in robots and other AI systems.},
	language = {en},
	urldate = {2020-08-03},
	collaborator = {Tenenbaum, Josh},
	month = jul,
	year = {2020}
}

@misc{noauthor_probabilistic_nodate,
	title = {Probabilistic {Models} of {Cognition} - 2nd {Edition}},
	url = {http://probmods.org/},
	urldate = {2020-08-02}
}

@article{bochkovskiy_yolov4_2020,
	title = {{YOLOv4}: {Optimal} {Speed} and {Accuracy} of {Object} {Detection}},
	shorttitle = {{YOLOv4}},
	url = {http://arxiv.org/abs/2004.10934},
	abstract = {There are a huge number of features which are said to improve Convolutional Neural Network (CNN) accuracy. Practical testing of combinations of such features on large datasets, and theoretical justification of the result, is required. Some features operate on certain models exclusively and for certain problems exclusively, or only for small-scale datasets; while some features, such as batch-normalization and residual-connections, are applicable to the majority of models, tasks, and datasets. We assume that such universal features include Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT) and Mish-activation. We use new features: WRC, CSP, CmBN, SAT, Mish activation, Mosaic data augmentation, CmBN, DropBlock regularization, and CIoU loss, and combine some of them to achieve state-of-the-art results: 43.5\% AP (65.7\% AP50) for the MS COCO dataset at a realtime speed of {\textasciitilde}65 FPS on Tesla V100. Source code is at https://github.com/AlexeyAB/darknet},
	urldate = {2020-08-02},
	journal = {arXiv:2004.10934 [cs, eess]},
	author = {Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
	month = apr,
	year = {2020},
	note = {arXiv: 2004.10934},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing}
}

@misc{noauthor_deep_nodate,
	title = {Deep {Learning} based {Human} {Pose} {Estimation} using {OpenCV} ( {C}++ / {Python} )},
	url = {https://www.learnopencv.com/deep-learning-based-human-pose-estimation-using-opencv-cpp-python/},
	abstract = {In this tutorial, we will discuss how to use a Deep Neural Net model for performing Human Pose Estimation in OpenCV. We will explain in detail how to use a pre-trained Caffe model that won the COCO keypoints challenge in 2016 in your own application. We will briefly go over the architecture to get an […]},
	language = {en-US},
	urldate = {2020-08-02},
	note = {Library Catalog: www.learnopencv.com}
}

@misc{noauthor_multi-person_nodate,
	title = {Multi-{Person} {Pose} {Estimation} in {OpenCV} using {OpenPose}},
	url = {https://www.learnopencv.com/multi-person-pose-estimation-in-opencv-using-openpose/},
	abstract = {In our previous post, we used the OpenPose model to perform Human Pose Estimation for a single person. In this post, we will discuss how to perform multi-person pose estimation. When there are multiple people in a photo, pose estimation produces multiple independent keypoints. We need to figure out which set of keypoints belong to […]},
	language = {en-US},
	urldate = {2020-08-02},
	note = {Library Catalog: www.learnopencv.com}
}

@misc{noauthor_pose_nodate,
	title = {Pose {Detection} comparison : {wrnchAI} vs {OpenPose}},
	shorttitle = {Pose {Detection} comparison},
	url = {https://www.learnopencv.com/pose-detection-comparison-wrnchai-vs-openpose/},
	abstract = {In our previous posts, we discussed how to perform Body and Hand pose estimation using the OpenPose library. Recently, as part of our consulting business, we got a chance to try the state-of-the-art pose-estimation system ( wrnchAI ) built by wrnch and compare it’s performance with OpenPose. We evaluated the Human Body Pose Estimation systems […]},
	language = {en-US},
	urldate = {2020-08-02},
	note = {Library Catalog: www.learnopencv.com}
}

@misc{noauthor_introducing_nodate,
	title = {Introducing {OAK}: {Spatial} {AI} {Powered} by {OpenCV}},
	url = {https://opencv.org/introducing-oak-spatial-ai-powered-by-opencv/},
	urldate = {2020-08-02}
}

@misc{noauthor_about_nodate,
	title = {About this project — pybind11 2.5.0 documentation},
	url = {https://pybind11.readthedocs.io/en/stable/intro.html},
	urldate = {2020-08-02}
}

@misc{noauthor_opencv_nodate,
	title = {{OpenCV} {AI} {Kit}},
	url = {https://www.kickstarter.com/projects/opencv/opencv-ai-kit},
	abstract = {A tiny, powerful, open source Spatial AI system},
	language = {en},
	urldate = {2020-08-02},
	journal = {Kickstarter},
	note = {Library Catalog: www.kickstarter.com}
}

@misc{noauthor_fundamentals_nodate,
	title = {Fundamentals of {Peak} {Performance}},
	url = {https://ssg.padlet.org/spld/fundamentalspeakperformance},
	abstract = {Start to build the best version of yourself.},
	language = {en},
	urldate = {2020-07-31},
	journal = {Padlet},
	note = {Library Catalog: ssg.padlet.org}
}

@misc{noauthor_openai_2019,
	title = {{OpenAI} {Plays} {Hide} and {Seek}…and {Breaks} {The} {Game}! 🤖},
	url = {https://www.youtube.com/watch?v=Lu56xVlZ40M},
	abstract = {❤️ Check out Weights \&amp; Biases here and sign up for a free demo: https://www.wandb.com/papers

Their blog post is available here: https://www.wandb.com/articles/better...

📝 The paper "Emergent Tool Use from Multi-Agent Interaction" is available here:
https://openai.com/blog/emergent-tool...

❤️ Watch these videos in early access on our Patreon page or join us here on YouTube: 
- https://www.patreon.com/TwoMinutePapers
- https://www.youtube.com/channel/UCbfY...

\&nbsp;🙏 We would like to thank our generous Patreon supporters who make Two Minute Papers possible:
Alex Haro, Andrew Melnychuk, Angelos Evripiotis, Anthony Vdovitchenko, Brian Gilman, Bryan Learn, Christian Ahlin, Claudio Fernandes, Daniel Hasegan, Dennis Abts, Eric Haddad, Eric Martel, Evan Breznyik, Geronimo Moralez, James Watt, Javier Bustamante, John De Witt, Kaiesh Vohra, Kasia Hayden, Kjartan Olason, Levente Szabo, Lorin Atzberger, Lukas Biewald, Marcin Dukaczewski, Marten Rauschenberg, Matthias Jost,, Maurits van Mastrigt, Michael Albrecht, Michael Jensen, Nader Shakerin, Owen Campbell-Moore, Owen Skarpness, Raul Araújo da Silva, Rob Rowe, Robin Graham, Ryan Monsurate, Shawn Azman, Steef, Steve Messina, Sunil Kim, Taras Bobrovytsky, Thomas Krcmar, Torsten Reil.
https://www.patreon.com/TwoMinutePapers

Splash screen/thumbnail design: Felícia Fehér - http://felicia.hu

Károly Zsolnai-Fehér's links:
Instagram: https://www.instagram.com/twominutepa...
Twitter: https://twitter.com/twominutepapers
Web: https://cg.tuwien.ac.at/{\textasciitilde}zsolnai/

\#OpenAI},
	urldate = {2020-07-30},
	month = oct,
	year = {2019}
}

@misc{noauthor_map_2017,
	title = {The {Map} of {Physics}},
	url = {https://www.youtube.com/watch?v=ZihywtixUYo},
	abstract = {Everything we know about physics - and a few things we don't - in a simple map.

If you are interested in buying a print you can buy it as a poster here: 
North America: store.dftba.com/products/map-of-physi...
Everywhere else: http://www.redbubble.com/people/domin...
French version: https://www.redbubble.com/people/domi...
Spanish Version: https://www.redbubble.com/people/domi...

Or on a load of other objects: http://www.redbubble.com/people/domin...

Also you can download a digital version here: https://www.flickr.com/photos/9586967...

I made the music, which you can find on my Soundcloud if you'd like to get lost in some cosmic jam. https://soundcloud.com/dominicwalliman

Errata and clarifications.

I endeavour to be as accurate as possible in my videos, but I am human and definitely don’t know everything, so there are sometimes mistakes. Also, due to the nature of my videos, there are bound to be oversimplifications. Some of these are intentional because I don’t have time to go into full detail, but sometimes they are unintentional and here is where I clear them up.

1. “Isaac Newton invented calculus.” Actually there is controversy over who invented calculus first Isaac Newton or Gottfried Leibniz. Regardless of who it was I have used Leibniz’s mathematical notation here and so he definitely deserves credit. I did’t know about all this so thanks to those who pointed it out. https://en.wikipedia.org/wiki/Leibniz...
2. “Maxwell derived the laws of electromagnetism.” This is a simplification as Maxwell’s work was built on the backs of other scientists like Hans Christian Ørsted, André-Marie Ampère and Michael Faraday who discovered induction and saw that electricity and magnetism were part of the same thing. But it was Maxwell who worked out all the maths and brought electricity and magnetism together into a unified theory. https://en.wikipedia.org/wiki/Electro...
3. “Entropy is a measure of order and disorder”. This is also a simplification and this does a good job of explaining it better https://en.wikipedia.org/wiki/Entropy
4. Einstein and Quantum physics: I made it sound like quantum physics was built by people other than Einstein, but this couldn’t be further from the truth. Einstein got a Nobel prize for his work on the photoelectric effect which was a key result to show the particle-like nature of light. Funnily enough he never got a nobel prize for his work on Relativity!

Also, if you enjoyed this video, you will probably like my science books, available in all good books shops around the work and is printed in 16 languages. Links are below or just search for Professor Astro Cat. They are fun children's books aimed at the age range 7-12. But they are also a hit with adults who want good explanations of science. The books have won awards and the app won a Webby.

Frontiers of Space: http://nobrow.net/shop/professor-astr...
Atomic Adventure: http://nobrow.net/shop/professor-astr...
Intergalactic Activity Book: http://nobrow.net/shop/professor-astr...
Solar System App: http://www.minilabstudios.com/apps/pr...

Find me on twitter, instagram, and my website:
http://dominicwalliman.com
https://twitter.com/DominicWalliman
https://www.instagram.com/dominicwall...
https://www.facebook.com/dominicwalliman},
	urldate = {2020-07-30},
	month = feb,
	year = {2017}
}

@article{noauthor_quiet_2020,
	title = {The {Quiet} {Crisis} of {PhDs} and {COVID}-19: {Reaching} the financial tipping point.},
	shorttitle = {The {Quiet} {Crisis} of {PhDs} and {COVID}-19},
	url = {https://www.researchsquare.com/article/rs-36330/v2},
	doi = {10.21203/rs.3.rs-36330/v2},
	abstract = {Before the COVID-19 crisis, existing high levels of financial concerns amongst PhD students increased their vulnerability to disruptive events. Impacts from the pandemic have increased their financial stress to the point that may result in many being forced to exit research studies. An exodus ...},
	language = {en},
	urldate = {2020-07-29},
	month = jul,
	year = {2020}
}

@misc{noauthor_where_nodate,
	title = {Where to look for \#altac {PhDs} at universities},
	url = {https://docs.google.com/document/d/1Ovc1sJ6b825LdQT1lEU29Em1cICfH0MHtUfrvmBvnvg/edit?fbclid=IwAR26tFMsaEQWAWyzWhJvMXYKALWSY2kr1Jv4JKs1poINXA3HBbX2c6wWHmI&usp=embed_facebook},
	abstract = {Jennifer Polk, 15 July 2020  Where to look for PhDs working in higher / postsecondary education beyond postdocs, the tenure-track, or adjunct positions. This list isn’t exhaustive and every uni is organized differently:  student affairs (academic advisors, learning strategists career educators, c...},
	language = {de},
	urldate = {2020-07-29},
	journal = {Google Docs},
	note = {Library Catalog: docs.google.com}
}

@misc{noauthor_postgraduate_nodate,
	type = {general},
	title = {Postgraduate career advice - {HiQ}},
	copyright = {Copyright Queensland University of Technology 2016},
	url = {https://qutvirtual4.qut.edu.au/group/student/jobs-and-careers/postgraduate-career-advice?fbclid=IwAR3nytFAKXTT0f1xHYDwK1XkklUaof2IEOmPYj8KBaBLCDPzBqPH0DnTj1I},
	abstract = {How to balance your PhD research and teaching, develop a teaching philosophy and find academic work.},
	language = {en},
	urldate = {2020-07-29},
	note = {Library Catalog: qutvirtual4.qut.edu.au
Publisher: Queensland University of Technology}
}

@misc{noauthor_using_2013,
	title = {Using {Shared} {Memory} in {CUDA} {C}/{C}++},
	url = {https://developer.nvidia.com/blog/using-shared-memory-cuda-cc/},
	abstract = {This post provides a detailed introduction to Shared Memory in CUDA C/C++, including static and dynamic allocation, thread synchronization, and performance.},
	language = {en-US},
	urldate = {2020-07-28},
	journal = {NVIDIA Developer Blog},
	month = jan,
	year = {2013},
	note = {Library Catalog: developer.nvidia.com}
}

@article{spivak_ologs_2012,
	title = {Ologs: a categorical framework for knowledge representation},
	volume = {7},
	issn = {1932-6203},
	shorttitle = {Ologs},
	url = {http://arxiv.org/abs/1102.1889},
	doi = {10.1371/journal.pone.0024274},
	abstract = {In this paper we introduce the olog, or ontology log, a category-theoretic model for knowledge representation (KR). Grounded in formal mathematics, ologs can be rigorously formulated and cross-compared in ways that other KR models (such as semantic networks) cannot. An olog is similar to a relational database schema; in fact an olog can serve as a data repository if desired. Unlike database schemas, which are generally difficult to create or modify, ologs are designed to be user-friendly enough that authoring or reconfiguring an olog is a matter of course rather than a difficult chore. It is hoped that learning to author ologs is much simpler than learning a database definition language, despite their similarity. We describe ologs carefully and illustrate with many examples. As an application we show that any primitive recursive function can be described by an olog. We also show that ologs can be aligned or connected together into a larger network using functors. The various methods of information flow and institutions can then be used to integrate local and global world-views. We finish by providing several different avenues for future research.},
	number = {1},
	urldate = {2020-07-27},
	journal = {PLoS ONE},
	author = {Spivak, David I. and Kent, Robert E.},
	month = jan,
	year = {2012},
	note = {arXiv: 1102.1889},
	keywords = {00-01, 18-01, 68P20, 68T30, Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science, H.2.1, H.5.2, Mathematics - Category Theory},
	pages = {e24274}
}

@misc{noauthor_getting_2020,
	title = {Getting started as a contributor on {PX4} — {PX4} {Developer} {Summit} {Virtual} 2020},
	url = {https://www.youtube.com/watch?v=m2o_0z0Pyy4&feature=youtu.be},
	abstract = {The PX4 Developer Summit is the annual flagship conference hosted by Dronecode for the drone development community. https://bit.ly/2YXe4Rd

Title: Getting started as a contributor on PX4

Summary: PX4 is a big subject, sometimes it can be daunting to even begin looking at how to get started. We are going to present an overview of: the ways people can contribute to the project, how they can get started, and where they can go to drill deeper into particular areas of interest. While this content is directed at getting volunteers spun up efficiently, hopefully it will be of use to anyone getting started with PX4. This presentation includes a pdf file with important reference content and details which were omitted from the video, attendees are encouraged to refer to that pdf for additional information.

https://sched.co/cjOg},
	urldate = {2020-07-27},
	month = jul,
	year = {2020}
}

@misc{noauthor_advanced_nodate,
	title = {Advanced {Lectures} - {QUT} {Centre} for {Robotics} - {QUT} {Wiki}},
	url = {https://wiki.qut.edu.au/display/cyphy/Advanced+Lectures},
	urldate = {2020-07-27}
}

@misc{wicht_use_2012,
	title = {Use {CMake} to easily compiles {Latex} documents into {PDF}},
	url = {https://baptiste-wicht.com/posts/2012/09/cmake-compile-latex-documents.html},
	abstract = {Everyone who compiles Latex documents by hand knows that it is not a panacea. You have to compile the file several times to handle the references. Moreover, if you have a glossary or an index, you hav},
	language = {en},
	urldate = {2020-07-27},
	journal = {Blog blog("Baptiste Wicht");},
	author = {Wicht, Baptiste},
	month = sep,
	year = {2012},
	note = {Library Catalog: baptiste-wicht.com}
}

@article{wu_learning_2018,
	title = {Learning and {Planning} with a {Semantic} {Model}},
	url = {http://arxiv.org/abs/1809.10842},
	abstract = {Building deep reinforcement learning agents that can generalize and adapt to unseen environments remains a fundamental challenge for AI. This paper describes progresses on this challenge in the context of man-made environments, which are visually diverse but contain intrinsic semantic regularities. We propose a hybrid model-based and model-free approach, LEArning and Planning with Semantics (LEAPS), consisting of a multi-target sub-policy that acts on visual inputs, and a Bayesian model over semantic structures. When placed in an unseen environment, the agent plans with the semantic model to make high-level decisions, proposes the next sub-target for the sub-policy to execute, and updates the semantic model based on new observations. We perform experiments in visual navigation tasks using House3D, a 3D environment that contains diverse human-designed indoor scenes with real-world objects. LEAPS outperforms strong baselines that do not explicitly plan using the semantic content.},
	urldate = {2020-07-24},
	journal = {arXiv:1809.10842 [cs, stat]},
	author = {Wu, Yi and Wu, Yuxin and Tamar, Aviv and Russell, Stuart and Gkioxari, Georgia and Tian, Yuandong},
	month = sep,
	year = {2018},
	note = {arXiv: 1809.10842},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{fuentes-pacheco_visual_2015,
	title = {Visual simultaneous localization and mapping: a survey},
	volume = {43},
	issn = {1573-7462},
	shorttitle = {Visual simultaneous localization and mapping},
	url = {https://doi.org/10.1007/s10462-012-9365-8},
	doi = {10.1007/s10462-012-9365-8},
	abstract = {Visual SLAM (simultaneous localization and mapping) refers to the problem of using images, as the only source of external information, in order to establish the position of a robot, a vehicle, or a moving camera in an environment, and at the same time, construct a representation of the explored zone. SLAM is an essential task for the autonomy of a robot. Nowadays, the problem of SLAM is considered solved when range sensors such as lasers or sonar are used to built 2D maps of small static environments. However SLAM for dynamic, complex and large scale environments, using vision as the sole external sensor, is an active area of research. The computer vision techniques employed in visual SLAM, such as detection, description and matching of salient features, image recognition and retrieval, among others, are still susceptible of improvement. The objective of this article is to provide new researchers in the field of visual SLAM a brief and comprehensible review of the state-of-the-art.},
	language = {en},
	number = {1},
	urldate = {2020-07-24},
	journal = {Artificial Intelligence Review},
	author = {Fuentes-Pacheco, Jorge and Ruiz-Ascencio, José and Rendón-Mancha, Juan Manuel},
	month = jan,
	year = {2015},
	pages = {55--81}
}

@inproceedings{chaplot_learning_2019,
	title = {Learning {To} {Explore} {Using} {Active} {Neural} {SLAM}},
	url = {https://openreview.net/forum?id=HklXn1BKDH},
	abstract = {This work presents a modular and hierarchical approach to learn policies for exploring 3D environments, called `Active Neural SLAM'. Our approach leverages the strengths of both classical and...},
	urldate = {2020-07-23},
	author = {Chaplot, Devendra Singh and Gandhi, Dhiraj and Gupta, Saurabh and Gupta, Abhinav and Salakhutdinov, Ruslan},
	month = sep,
	year = {2019}
}

@article{chaplot_object_2020,
	title = {Object {Goal} {Navigation} using {Goal}-{Oriented} {Semantic} {Exploration}},
	url = {http://arxiv.org/abs/2007.00643},
	abstract = {This work studies the problem of object goal navigation which involves navigating to an instance of the given object category in unseen environments. End-to-end learning-based navigation methods struggle at this task as they are ineffective at exploration and long-term planning. We propose a modular system called, `Goal-Oriented Semantic Exploration' which builds an episodic semantic map and uses it to explore the environment efficiently based on the goal object category. Empirical results in visually realistic simulation environments show that the proposed model outperforms a wide range of baselines including end-to-end learning-based methods as well as modular map-based methods and led to the winning entry of the CVPR-2020 Habitat ObjectNav Challenge. Ablation analysis indicates that the proposed model learns semantic priors of the relative arrangement of objects in a scene, and uses them to explore efficiently. Domain-agnostic module design allow us to transfer our model to a mobile robot platform and achieve similar performance for object goal navigation in the real-world.},
	urldate = {2020-07-22},
	journal = {arXiv:2007.00643 [cs]},
	author = {Chaplot, Devendra Singh and Gandhi, Dhiraj and Gupta, Abhinav and Salakhutdinov, Ruslan},
	month = jul,
	year = {2020},
	note = {arXiv: 2007.00643},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Robotics}
}

@article{chaplot_semantic_2020,
	title = {Semantic {Curiosity} for {Active} {Visual} {Learning}},
	url = {http://arxiv.org/abs/2006.09367},
	abstract = {In this paper, we study the task of embodied interactive learning for object detection. Given a set of environments (and some labeling budget), our goal is to learn an object detector by having an agent select what data to obtain labels for. How should an exploration policy decide which trajectory should be labeled? One possibility is to use a trained object detector's failure cases as an external reward. However, this will require labeling millions of frames required for training RL policies, which is infeasible. Instead, we explore a self-supervised approach for training our exploration policy by introducing a notion of semantic curiosity. Our semantic curiosity policy is based on a simple observation -- the detection outputs should be consistent. Therefore, our semantic curiosity rewards trajectories with inconsistent labeling behavior and encourages the exploration policy to explore such areas. The exploration policy trained via semantic curiosity generalizes to novel scenes and helps train an object detector that outperforms baselines trained with other possible alternatives such as random exploration, prediction-error curiosity, and coverage-maximizing exploration.},
	urldate = {2020-07-22},
	journal = {arXiv:2006.09367 [cs]},
	author = {Chaplot, Devendra Singh and Jiang, Helen and Gupta, Saurabh and Gupta, Abhinav},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.09367},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning}
}

@misc{noauthor_rep_nodate,
	title = {{REP} 147 -- {A} {Standard} interface for {Aerial} {Vehicles} ({ROS}.org)},
	url = {https://www.ros.org/reps/rep-0147.html},
	urldate = {2020-07-22}
}

@inproceedings{kuipers_local_2004,
	title = {Local metrical and global topological maps in the hybrid spatial semantic hierarchy},
	volume = {5},
	doi = {10.1109/ROBOT.2004.1302485},
	abstract = {Topological and metrical methods for representing spatial knowledge have complementary strengths. We present a hybrid extension to the spatial semantic hierarchy that combines their strengths and avoids their weaknesses. Metrical SLAM methods are used to build local maps of small-scale space within the sensory horizon of the agent, while topological methods are used to represent the structure of large-scale space. We describe how a local perceptual map is analyzed to identify a local topology description and is abstracted to a topological place. The map building method creates a set of topological map hypotheses that are consistent with travel experience. The set of maps is guaranteed under reasonable assumptions to include the correct map. We demonstrate the method on a real environment with multiple nested large-scale loops.},
	booktitle = {{IEEE} {International} {Conference} on {Robotics} and {Automation}, 2004. {Proceedings}. {ICRA} '04. 2004},
	author = {Kuipers, B. and Modayil, J. and Beeson, P. and MacMahon, M. and Savelli, F.},
	month = apr,
	year = {2004},
	note = {ISSN: 1050-4729},
	keywords = {Buildings, Extraterrestrial measurements, Intelligent robots, Large-scale systems, Mobile robots, Robot kinematics, Simultaneous localization and mapping, Space exploration, Spatial resolution, Topology, global topological maps, hybrid spatial semantic hierarchy, large-scale space, local metrical maps, local perceptual map, path planning, robots, semantic networks, simultaneous localization and mapping, spatial knowledge representation, structural ambiguity, topology},
	pages = {4845--4851 Vol.5}
}

@incollection{chen_estimating_2001,
	address = {Boston, MA},
	title = {Estimating data for multicriteria decision making problems: optimization {techniquesBi}-objective assignment problem; {Decision} support systems with multiple criteria; {Financial} applications of multicriteria analysis; {Fuzzy} multi-objective linear programming; {Multi}-objective combinatorial optimization; {Multi}-objective integer linear programming; {Multi}-objective optimization and decision support systems; {Multi}-objective optimization: {Interaction} of design and control; {Multi}-objective optimization: {Interactive} methods for preference value functions; {Multi}-objective optimization: {Lagrange} duality; {Multi}-objective optimization: {Pareto} optimal solutions, properties; {Multicriteria} sorting methods; {Multiple} objective programming support; {Outranking} methods; {Portfolio} selection and multicriteria analysis; {Preference} disaggregation; {Preference} disaggregation approach: {Basic} features, examples from financial decision making; {Preference} {modelingESTIMATING} {DATA} {FOR} {MULTICRITERIA} {DECISION} {MAKING} {PROBLEMS}: {OPTIMIZATION} {TECHNIQUES}},
	isbn = {978-0-306-48332-5},
	shorttitle = {Estimating data for multicriteria decision making problems},
	url = {https://doi.org/10.1007/0-306-48332-7_123},
	language = {en},
	urldate = {2020-07-21},
	booktitle = {Encyclopedia of {Optimization}},
	publisher = {Springer US},
	author = {Chen, Qing and Triantaphyllou, Evangelos},
	year = {2001},
	doi = {10.1007/0-306-48332-7_123},
	keywords = {90C29, AHP, MCDM, analytic hierarchy process, consistent judgment matrix, data elicitation, eigenvalue, eigenvector, incomplete judgments, least squares problem, multicriteria decision making, pairwise comparisons, scale},
	pages = {567--576}
}

@article{huo_new_2011,
	title = {New parametric prioritization methods for an analytical hierarchy process based on a pairwise comparison matrix},
	volume = {54},
	issn = {0895-7177},
	url = {http://www.sciencedirect.com/science/article/pii/S0895717711004031},
	doi = {10.1016/j.mcm.2011.06.062},
	abstract = {In this paper, new parametric prioritization methods (PPMs) to determine a family of priority vectors in an analytical hierarchy process (AHP) are proposed, pointing out the logical relation of elements in the comparative matrix. The scales and consistency cannot determine the priorities, but only the order of the alternatives. To derive the priorities of alternatives, a series of theorems and mathematical programming models is given based on a pairwise comparison matrix. This refers to parameters θ,α,β, by which there exists a family of priorities for the same judgment matrix. The discrimination of alternatives can be easily improved when using the proposed priority method by modifying the values of the parameters. Some false cognitions about how to determine the priority of an analytical hierarchy process are rectified. One should not elicit priority vectors from the judgment matrix; the information is incomplete, and the parameters must be considered. Finally, the meanings of parameters are explained in practical applications and an approach for determining the values of the parameters is proposed. Examples are also used to illustrate the features and applicability of the new approach in an AHP.},
	language = {en},
	number = {11},
	urldate = {2020-07-21},
	journal = {Mathematical and Computer Modelling},
	author = {Huo, Liang-an and Lan, Jibin and Wang, Zhongxing},
	month = dec,
	year = {2011},
	keywords = {Analytic hierarchy process (AHP), Consistency, Judgment matrix, Parametric prioritization method (PPM), Priority},
	pages = {2736--2749}
}

@inproceedings{carr_point-less_2012,
	title = {Point-less calibration: {Camera} parameters from gradient-based alignment to edge images},
	shorttitle = {Point-less calibration},
	doi = {10.1109/WACV.2012.6163012},
	abstract = {Point-based targets, such as checkerboards, are often not practical for outdoor camera calibration, as cameras are usually at significant heights requiring extremely large calibration patterns on the ground. Fortunately, it is possible to make use of existing non-point landmarks in the scene by formulating camera calibration in terms of image alignment. In this paper, we simultaneously estimate the camera intrinsic, extrinsic and lens distortion parameters directly by aligning to a planar schematic of the scene. For cameras with square pixels and known principal point, finding the parameters to such an image warp is equivalent to calibrating the camera. Overhead schematics of many environments resemble edge images. Edge images are difficult to align using image-based algorithms because both the image and its gradient are sparse. We employ a `long range' gradient which enables informative parameter updates at each iteration while maintaining a precise alignment measure. As a result, we are able to calibrate our camera models robustly using regular gradient-based image alignment, given an initial ground to image homography estimate.},
	booktitle = {2012 {IEEE} {Workshop} on the {Applications} of {Computer} {Vision} ({WACV})},
	author = {Carr, Peter and Sheikh, Yaser and Matthews, Iain},
	month = jan,
	year = {2012},
	note = {ISSN: 1550-5790},
	keywords = {Calibration, Cameras, Feature extraction, Image edge detection, Lenses, Optimization, Three dimensional displays, calibration patterns, camera extrinsic, camera intrinsic, camera parameters, edge detection, edge images, estimation theory, gradient based alignment, gradient methods, image alignment, image based algorithms, image homography estimation, image sensors, lens distortion parameters, outdoor camera calibration, overhead schematics, point based targets, point less calibration},
	pages = {377--384}
}

@misc{noauthor_intel_nodate,
	title = {Intel will use multi-camera, {3D} athlete tracking in the 2020 {Olympics}},
	url = {https://www.engadget.com/2019-09-11-intel-olympics-2020-3d-athlete-tracking.html},
	abstract = {Intel plans to bring 3D athlete tracking (3DAT) to the 2020 Olympics. Today, the company announced that its 3DAT system will use four cameras to film athletes in the 100-meter and other sprinting events. Algorithms will then analyze the biomechanics of the athletes' movements and broadcast those as visual overlays available during replays.},
	language = {en},
	urldate = {2020-07-19},
	journal = {Engadget},
	note = {Library Catalog: www.engadget.com}
}

@inproceedings{rematas_soccer_2018,
	title = {Soccer on {Your} {Tabletop}},
	url = {https://openaccess.thecvf.com/content_cvpr_2018/html/Rematas_Soccer_on_Your_CVPR_2018_paper.html},
	urldate = {2020-07-19},
	author = {Rematas, Konstantinos and Kemelmacher-Shlizerman, Ira and Curless, Brian and Seitz, Steve},
	year = {2018},
	pages = {4738--4747}
}

@misc{noauthor_wrnch_nodate,
	title = {wrnch},
	url = {https://wrnch.ai/},
	language = {en-US},
	urldate = {2020-07-19},
	note = {Library Catalog: wrnch.ai}
}

@misc{gudnason_estimating_2020,
	title = {Estimating {3D} {Poses} of {Athletes} at {Live} {Sporting} {Events} {\textbar} {The} {New} {York} {Times} - {Research} \& {Development}},
	url = {https://rd.nytimes.com/projects/estimating-3d-poses-of-athletes-at-live-sporting-events},
	abstract = {We’re using computer vision and burst photography from multiple cameras to uncover new insights about athletic performances.},
	language = {en},
	urldate = {2020-07-19},
	author = {Gudnason, Amelia Pisapia, Anna, Dan Oved},
	month = jun,
	year = {2020},
	note = {Library Catalog: rd.nytimes.com}
}

@incollection{doring_what_2011,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Physics}},
	title = {“{What} is a {Thing}?”: {Topos} {Theory} in the {Foundations} of {Physics}},
	isbn = {978-3-642-12821-9},
	shorttitle = {“{What} is a {Thing}?},
	url = {https://doi.org/10.1007/978-3-642-12821-9_13},
	abstract = {The goal of this article is to summarise the first steps in developing a fundamentally new way of constructing theories of physics. The motivation comes from a desire to address certain deep issues that arise when contemplating quantum theories of space and time. In doing so we provide a new answer to Heidegger’s timeless question “What is a thing?”.Our basic contention is that constructing a theory of physics is equivalent to finding a representation in a topos of a certain formal language that is attached to the system. Classical physics uses the topos of sets. Other theories involve a different topos. For the types of theory discussed in this article, a key goal is to represent any physical quantity A with an arrow 𝐴˘𝜙:𝛴𝜙→𝜙A˘ϕ:Σϕ→Rϕ{\textbackslash}breve\{A\}\_{\textbackslash}phi:{\textbackslash}varSigma\_{\textbackslash}phi{\textbackslash}rightarrow\{{\textbackslash}cal R\}\_{\textbackslash}phi where Σ φ and 𝜙Rϕ\{{\textbackslash}cal R\}\_{\textbackslash}phi are two special objects (the “state object” and “quantity-value object”) in the appropriate topos,τ φ .We discuss two different types of language that can be attached to a system, S. The first, (𝑆)PL(S){\textbackslash}mathcal\{PL\}(S), is a propositional language; the second, (𝑆)L(S){\textbackslash}mathcal\{L\}(\{S\}), is a higher-order, typed language. Both languages provide deductive systems with an intuitionistic logic. With the aid of (𝑆)PL(S){\textbackslash}mathcal\{PL\}(S) we expand and develop some of the earlier work1 on topos theory and quantum physics. A key step is a process we term “daseinisation” by which a projection operator is mapped to a sub-object of the spectral presheaf 𝛴⎯⎯⎯Σ\_\{{\textbackslash}underline\{{\textbackslash}varSigma\}\}—the topos quantum analogue of a classical state space. The topos concerned is 𝐒𝐞𝐭𝐬()opSetsV(H)op{\textbackslash}textbf\{Sets\}\{{\textbackslash}cal V\}(\{{\textbackslash}cal H\}){\textasciicircum}\{{\textbackslash}textrm\{op\}\}: the category of contravariant set-valued functors on the category (partially ordered set) ()V(H)\{{\textbackslash}cal V\}(\{{\textbackslash}cal H\}) of commutative sub-algebras of the algebra of bounded operators on the quantum Hilbert space H\{{\textbackslash}cal H\}.There are two types of daseinisation, called “outer” and “inner”: they involve approximating a projection operator by projectors that are, respectively, larger and smaller in the lattice of projectors on H\{{\textbackslash}cal H\}.We then introduce the more sophisticated language (𝑆)L(S){\textbackslash}mathcal\{L\}(\{S\}) and use it to study “truth objects” and “pseudo-states” in the topos. These objects play the role of states: a necessary development as the spectral presheaf has no global elements, and hence there are no microstates in the sense of classical physics.One of the main mathematical achievements is finding a topos representation for self-adjoint operators. This involves showing that, for any bounded, self-adjoint operator 𝐴̂ A{\textasciicircum}\{{\textbackslash}hat A\}, there is a corresponding arrow 𝛿˘𝑜(𝐴̂ ):𝛴⎯⎯⎯→ℝ⪰⎯⎯⎯⎯⎯δ˘o(A{\textasciicircum}):Σ\_→R⪰\_\{{\textbackslash}breve\{{\textbackslash}delta\}{\textasciicircum}o({\textbackslash}hat\{A\})\}:\{{\textbackslash}underline\{{\textbackslash}varSigma\}\}{\textbackslash}rightarrow\{{\textbackslash}underline\{\{{\textbackslash}mathbb\{R\}\}{\textasciicircum}\{{\textbackslash}succeq\}\}\} where ℝ⪰⎯⎯⎯⎯⎯R⪰\_\{{\textbackslash}underline\{\{{\textbackslash}mathbb\{R\}\}{\textasciicircum}\{{\textbackslash}succeq\}\}\} is the quantity-value object for this theory. The construction of 𝛿˘𝑜(𝐴̂ )δ˘o(A{\textasciicircum})\{{\textbackslash}breve\{{\textbackslash}delta\}{\textasciicircum}o({\textbackslash}hat\{A\})\} is an extension of the daseinisation of projection operators.The object ℝ⪰⎯⎯⎯⎯⎯R⪰\_\{{\textbackslash}underline\{\{{\textbackslash}mathbb\{R\}\}{\textasciicircum}\{{\textbackslash}succeq\}\}\} can serve as the quantity-value object if only outer daseinisation of self-adjoint operators is used in the construction of arrows 𝛿˘𝑜(𝐴̂ ):𝛴⎯⎯⎯→ℝ⪰⎯⎯⎯⎯⎯δ˘o(A{\textasciicircum}):Σ\_→R⪰\_\{{\textbackslash}breve\{{\textbackslash}delta\}{\textasciicircum}o({\textbackslash}hat\{A\})\}:\{{\textbackslash}underline\{{\textbackslash}varSigma\}\}{\textbackslash}rightarrow\{{\textbackslash}underline\{\{{\textbackslash}mathbb\{R\}\}{\textasciicircum}\{{\textbackslash}succeq\}\}\}. If both inner and outer daseinisation are used, then a related presheaf ℝ↔⎯⎯⎯⎯⎯⎯R↔\_\{{\textbackslash}underline\{{\textbackslash}mathbb\{R\}{\textasciicircum}\{{\textbackslash}leftrightarrow\}\}\} is the appropriate choice. Moreover, in order to enhance the applicability of the quantity-value object, one can consider a topos analogue of the Grothendieck extension of a monoid to a group, applied to ℝ⪰⎯⎯⎯⎯⎯R⪰\_\{{\textbackslash}underline\{\{{\textbackslash}mathbb\{R\}\}{\textasciicircum}\{{\textbackslash}succeq\}\}\} (resp. ℝ↔⎯⎯⎯⎯⎯⎯R↔\_\{{\textbackslash}underline\{{\textbackslash}mathbb\{R\}{\textasciicircum}\{{\textbackslash}leftrightarrow\}\}\}). The resulting object, 𝑘(ℝ⪰⎯⎯⎯⎯⎯)k(R⪰\_)\{k(\{{\textbackslash}underline\{\{{\textbackslash}mathbb\{R\}\}{\textasciicircum}\{{\textbackslash}succeq\}\}\})\} (resp. 𝑘(ℝ↔⎯⎯⎯⎯⎯⎯)k(R↔\_)k(\{{\textbackslash}underline\{{\textbackslash}mathbb\{R\}{\textasciicircum}\{{\textbackslash}leftrightarrow\}\}\})), is an abelian group-object in τ φ .Finally we turn to considering a collection of systems: in particular, we are interested in the relation between the topos representation of a composite system, and the representations of its constituents. Our approach to these matters is to construct a category of systems and to find coherent topos representations of the entire category.},
	language = {en},
	urldate = {2020-07-15},
	booktitle = {New {Structures} for {Physics}},
	publisher = {Springer},
	author = {Döring, A. and Isham, C.},
	editor = {Coecke, Bob},
	year = {2011},
	doi = {10.1007/978-3-642-12821-9_13},
	pages = {753--937}
}

@misc{noauthor_how_nodate,
	title = {How to {Write} a {Git} {Commit} {Message}},
	url = {https://chris.beams.io/posts/git-commit/},
	urldate = {2020-07-14}
}

@misc{noauthor_qcr_nodate,
	title = {{QCR} {Seminar} {CloudStor} {Recordings}},
	url = {https://cloudstor.aarnet.edu.au/plus/s/2ePcF5JqSiXjIYD},
	abstract = {Robotics\_Seminars is publicly shared},
	language = {en\_GB},
	urldate = {2020-07-14},
	journal = {CloudStor},
	note = {Library Catalog: cloudstor.aarnet.edu.au}
}

@misc{suenderhauf_good_nodate,
	title = {Good {Citizens} of {Robotics}},
	url = {https://sites.google.com/view/rss20-gcr},
	abstract = {How to build a career
How to make videos
How to do a presentation},
	language = {de},
	urldate = {2020-07-14},
	journal = {Good  Citizens of Robotics},
	author = {Suenderhauf, Niko},
	note = {Library Catalog: sites.google.com}
}

@article{chown_prototypes_1995,
	title = {Prototypes, {Location}, and {Associative} {Networks} ({PLAN}): {Towards} a {Unified} {Theory} of {Cognitive} {Mapping}},
	volume = {19},
	copyright = {© 1995 Cognitive Science Society, Inc.},
	issn = {1551-6709},
	shorttitle = {Prototypes, {Location}, and {Associative} {Networks} ({PLAN})},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog1901_1},
	doi = {10.1207/s15516709cog1901_1},
	abstract = {An integrated representation of large-scale space, or cognitive map, colled PLAN, is presented that attempts to address a broader spectrum of issues than has been previously attempted in a single model. Rather than examining way-finding as a process separate from the rest of cognition, one or the fundamental goals of this work is to examine how the wayfinding process is integrated into general cognition. One result of this approach is that the model is “heads-up,” or scene-based, because it takes advantage of the properties of the human visual system and, particularly, the visual system's split into two pathways. The emphasis on the human location or “where” system is new to cognitive mapping and is port of an attempt to synthesize prototype theory, associative networks and location together in a connectionist system. Not all of PLAN is new, however. Many of its parts have analogues in one or another preexisting theory. What makes PLAN unique is integrating the various components into a coherent whole, and the capacity of this resulting system to speak to a wide range of constraints. Our approach emphasizes adaptiveness; thus, our focus on such issues as ease of use and efficiency of learning. The result is a model that has a stronger relationship both to the environment, and to the ways that humans interact with it, compared with previous models. The resulting model is examined in some detail and compared to other systems.},
	language = {en},
	number = {1},
	urldate = {2020-07-13},
	journal = {Cognitive Science},
	author = {Chown, Eric and Kaplan, Stephen and Kortenkamp, David},
	year = {1995},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1207/s15516709cog1901\_1},
	pages = {1--51}
}

@article{saaty_analytic_1987,
	title = {The analytic hierarchy process—what it is and how it is used},
	volume = {9},
	issn = {0270-0255},
	url = {http://www.sciencedirect.com/science/article/pii/0270025587904738},
	doi = {https://doi.org/10.1016/0270-0255(87)90473-8},
	abstract = {Here we introduce the Analytic Hierarchy Process as a method of measurement with ratio scales and illustrate it with two examples. We then give the axioms and some of the central theoretical underpinnings of the theory. Finally, we discuss some of the ideas relating to this process and its ramifications. In this paper we give special emphasis to departure from consistency and its measurement and to the use of absolute and relative measurement, providing examples and justification for rank preservation and reversal in relative measurement.},
	number = {3},
	urldate = {2019-04-17},
	journal = {Mathematical Modelling},
	author = {Saaty, R. W.},
	month = jan,
	year = {1987},
	pages = {161--176}
}

@misc{noauthor_category_2014,
	title = {Category {Theory} for {Programmers}: {The} {Preface}},
	shorttitle = {Category {Theory} for {Programmers}},
	url = {https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/},
	abstract = {Table of Contents Part One Types and Functions Kleisli Categories Simple Algebraic Data Types Functoriality Natural Transformations Part Two Limits and Colimits Representable Functors Yoneda Embedd…},
	language = {en},
	urldate = {2020-07-09},
	journal = {Bartosz Milewski's Programming Cafe},
	month = oct,
	year = {2014},
	note = {Library Catalog: bartoszmilewski.com}
}

@misc{noauthor_pdf_nodate,
	title = {[{PDF}] {IMPLEMENTING} {GENETIC} {ALGORITHMS} {TO} {CUDA} {ENVIRONMENT} {USING} {DATA} {PARALLELIZATION} {\textbar} {Semantic} {Scholar}},
	url = {https://www.semanticscholar.org/paper/IMPLEMENTING-GENETIC-ALGORITHMS-TO-CUDA-ENVIRONMENT-Oiso-Matsumura/54eab0dacade262eecf3a84241f5c2f88b79febe},
	urldate = {2020-07-07}
}

@inproceedings{tornatis_hybrid_2002,
	title = {Hybrid simultaneous localization and map building: closing the loop with multi-hypotheses tracking},
	volume = {3},
	shorttitle = {Hybrid simultaneous localization and map building},
	doi = {10.1109/ROBOT.2002.1013648},
	abstract = {In this paper simultaneous localization and map building is performed with a hybrid, metric-topological,approach. A global topological map connects local metric maps, allowing a compact environment model, which does not require global metric consistency and permits both precision and robustness. However, the most important innovation of the approach is the way how loops in the environment are handled by map building using the information of the multi hypotheses topological localization. The method uses data from a 360/spl deg/ laser scanner to extract comers and openings for the topological approach and infinite lines for the metric method. This hybrid approach has been tested in a 50 /spl times/ 25 m/sup 2/ portion of the institute building with a fully autonomous robot. The performances of the whole system are proven empirically by comparing maps generated by independent explorations, testing the localization capabilities, making relocation experiments and showing how the technique for closing the loop works.},
	booktitle = {Proceedings 2002 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({Cat}. {No}.{02CH37292})},
	author = {Tornatis, N. and Nourbakhsh, I. and Siegwart, R.},
	month = may,
	year = {2002},
	keywords = {Data mining, Grid computing, Kalman filter, Kalman filters, Orbital robotics, Performance evaluation, Robots, Robustness, Switches, System testing, Technological innovation, Tracking loops, global topological map, localization, map building, mobile robot, mobile robots, multiple hypotheses tracking, navigation, path planning, position control, topology},
	pages = {2749--2754 vol.3}
}

@article{thrun_learning_1998,
	title = {Learning metric-topological maps for indoor mobile robot navigation},
	volume = {99},
	issn = {0004-3702},
	url = {http://www.sciencedirect.com/science/article/pii/S0004370297000787},
	doi = {10.1016/S0004-3702(97)00078-7},
	abstract = {Autonomous robots must be able to learn and maintain models of their environments. Research on mobile robot navigation has produced two major paradigms for mapping indoor environments: grid-based and topological. While grid-based methods produce accurate metric maps, their complexity often prohibits efficient planning and problem solving in large-scale indoor environments. Topological maps, on the other hand, can be used much more efficiently, yet accurate and consistent topological maps are often difficult to learn and maintain in large-scale environments, particularly if momentary sensor data is highly ambiguous. This paper describes an approach that integrates both paradigms: grid-based and topological. Grid-based maps are learned using artificial neural networks and naive Bayesian integration. Topological maps are generated on top of the grid-based maps, by partitioning the latter into coherent regions. By combining both paradigms, the approach presented here gains advantages from both worlds: accuracy/consistency and efficiency. The paper gives results for autonomous exploration, mapping and operation of a mobile robot in populated multi-room environments.},
	language = {en},
	number = {1},
	urldate = {2020-07-06},
	journal = {Artificial Intelligence},
	author = {Thrun, Sebastian},
	month = feb,
	year = {1998},
	keywords = {Autonomous robots, Exploration, Mobile robots, Neural networks, Occupancy grids, Path planning, Planning, Robot mapping, Topological maps},
	pages = {21--71}
}

@article{tomatis_hybrid_2003,
	series = {Best {Papers} of the {Eurobot} '01 {Workshop}},
	title = {Hybrid simultaneous localization and map building: a natural integration of topological and metric},
	volume = {44},
	issn = {0921-8890},
	shorttitle = {Hybrid simultaneous localization and map building},
	url = {http://www.sciencedirect.com/science/article/pii/S092188900300006X},
	doi = {10.1016/S0921-8890(03)00006-X},
	abstract = {In this paper the metric and topological paradigms are integrated in a hybrid system for both localization and map building. A global topological map connects local metric maps, allowing a compact environment model, which does not require global metric consistency and permits both precision and robustness. Furthermore, the approach handles loops in the environment during automatic mapping by means of the information of the multimodal topological localization. The system uses a 360° laser scanner to extract corners and openings for the topological approach and lines for the metric method. This hybrid approach has been tested in a 50m×25m portion of the institute building with the fully autonomous robot Donald Duck. Experiments are of four types: maps created by a complete exploration of the environment are compared to estimate their quality; test missions are randomly generated in order to evaluate the efficiency of the approach for both the localization and relocation; the fourth type of experiments shows the practicability of the approach for closing the loop.},
	language = {en},
	number = {1},
	urldate = {2020-07-06},
	journal = {Robotics and Autonomous Systems},
	author = {Tomatis, Nicola and Nourbakhsh, Illah and Siegwart, Roland},
	month = jul,
	year = {2003},
	keywords = {Hybrid (metric–topological), Kalman filtering, Mobile robot navigation, POMDP},
	pages = {3--14}
}

@article{spivak_functorial_2013,
	title = {Functorial {Data} {Migration}},
	url = {http://arxiv.org/abs/1009.1166},
	abstract = {In this paper we present a simple database definition language: that of categories and functors. A database schema is a small category and an instance is a set-valued functor on it. We show that morphisms of schemas induce three "data migration functors", which translate instances from one schema to the other in canonical ways. These functors parameterize projections, unions, and joins over all tables simultaneously and can be used in place of conjunctive and disjunctive queries. We also show how to connect a database and a functional programming language by introducing a functorial connection between the schema and the category of types for that language. We begin the paper with a multitude of examples to motivate the definitions, and near the end we provide a dictionary whereby one can translate database concepts into category-theoretic concepts and vice-versa.},
	urldate = {2020-07-05},
	journal = {arXiv:1009.1166 [cs, math]},
	author = {Spivak, David I.},
	month = feb,
	year = {2013},
	note = {arXiv: 1009.1166},
	keywords = {18A99, 94A99, 68P15, Computer Science - Databases, H.2.1, H.5.2, Mathematics - Category Theory}
}

@misc{seif_heres_2019,
	title = {Here’s how to use {CuPy} to make {Numpy} {700X} faster},
	url = {https://towardsdatascience.com/heres-how-to-use-cupy-to-make-numpy-700x-faster-4b920dda1f56},
	abstract = {It’s time for some GPU power!},
	language = {en},
	urldate = {2020-07-02},
	journal = {Medium},
	author = {Seif, George},
	month = nov,
	year = {2019},
	note = {Library Catalog: towardsdatascience.com}
}

@misc{noauthor_cupycupy_2020,
	title = {cupy/cupy},
	copyright = {MIT License         ,                 MIT License},
	url = {https://github.com/cupy/cupy},
	abstract = {NumPy-like API accelerated with CUDA. Contribute to cupy/cupy development by creating an account on GitHub.},
	urldate = {2020-07-02},
	publisher = {CuPy},
	month = jul,
	year = {2020},
	note = {original-date: 2016-11-01T09:54:45Z},
	keywords = {cublas, cuda, cudnn, cupy, curand, cusolver, cusparse, cutensor, gpu, nccl, numpy, nvrtc, nvtx, python, scipy}
}

@misc{noauthor_numpy_nodate,
	title = {From numpy to xtensor — xtensor documentation},
	url = {https://xtensor.readthedocs.io/en/latest/numpy.html},
	urldate = {2020-07-02}
}

@misc{pilger_dpilger26numcpp_2020,
	title = {dpilger26/{NumCpp}},
	copyright = {MIT License         ,                 MIT License},
	url = {https://github.com/dpilger26/NumCpp},
	abstract = {C++ implementation of the Python Numpy library. Contribute to dpilger26/NumCpp development by creating an account on GitHub.},
	urldate = {2020-07-02},
	author = {Pilger, David},
	month = jul,
	year = {2020},
	note = {original-date: 2018-02-07T06:14:23Z},
	keywords = {algorithms, c-plus-plus, cpp, data-structures, mathematical-functions, numerical-analysis, numpy, python, scientific-computing}
}

@misc{noauthor_first_nodate,
	title = {First steps — pybind11 2.5.dev1 documentation},
	url = {https://pybind11.readthedocs.io/en/latest/basics.html},
	urldate = {2020-07-02}
}

@misc{python_python_nodate,
	title = {Python {Bindings}: {Calling} {C} or {C}++ {From} {Python} – {Real} {Python}},
	shorttitle = {Python {Bindings}},
	url = {https://realpython.com/python-bindings-overview/},
	abstract = {What are Python bindings? Should you use ctypes, CFFI, or a different tool? In this step-by-step tutorial, you'll get an overview of some of the options you can use to call C or C++ code from Python.},
	language = {en},
	urldate = {2020-07-02},
	author = {Python, Real},
	note = {Library Catalog: realpython.com}
}

@article{ma_design_1993,
	title = {Design and experiments for a coupled tendon-driven manipulator},
	volume = {13},
	issn = {1941-000X},
	doi = {10.1109/37.184790},
	abstract = {The authors describe the operation of a tendon-driven manipulator, the CT ARM-I, which has a tendon traction force transmission mechanism in which the pair of tendons that drive a joint are pulled from base actuators via pulleys mounted on the base-side joints. The mechanism makes the most of the coupled drive function of the tendon traction forces and thus enables the lightweight manipulator to exhibit enormous payload capability. The manipulator has a solid structure and is inexpensive to manufacture because of its mechanical simplicity. Experiments demonstrate that the CT ARM-I has an active compliance arm and offers payload capability superior to that of conventional manipulators.{\textless}{\textgreater}},
	number = {1},
	journal = {IEEE Control Systems Magazine},
	author = {Ma, S. and Hirose, S. and Yoshinada, H.},
	month = feb,
	year = {1993},
	note = {Conference Name: IEEE Control Systems Magazine},
	keywords = {Actuators, Arm, CT ARM-I, Manipulators, Manufacturing, Optical coupling, Payloads, Pulleys, Service robots, Tendons, Wires, active compliance arm, actuators, compliance control, control system synthesis, coupled tendon-driven manipulator, force control, manipulators, robots, tendon traction force transmission mechanism},
	pages = {30--36}
}

@misc{noauthor_lecture_2020,
	title = {Lecture 20 - {RL} {Debugging} and {Diagnostics} {\textbar} {Stanford} {CS229}: {Machine} {Learning} ({Autumn} 2018)},
	shorttitle = {Lecture 20 - {RL} {Debugging} and {Diagnostics} {\textbar} {Stanford} {CS229}},
	url = {https://www.youtube.com/watch?v=pLhPQynL0tY&feature=youtu.be},
	abstract = {Take an adapted version of this course as part of the Stanford Artificial Intelligence Professional Program. Learn more at: https://stanford.io/3bhmLce

Andrew Ng 
Adjunct Professor of Computer Science
https://www.andrewng.org/
 
To follow along with the course schedule and syllabus, visit: 
http://cs229.stanford.edu/syllabus-au... 
 
To get the latest news on Stanford’s upcoming professional programs in Artificial Intelligence, visit: 
http://learn.stanford.edu/AI.html
 
To view all online courses and programs offered by Stanford, visit: http://online.stanford.edu},
	urldate = {2020-06-29},
	month = apr,
	year = {2020}
}

@misc{noauthor_motion_nodate,
	title = {Motion {Strategy} {Library}},
	url = {http://lavalle.pl/msl/},
	urldate = {2020-06-24}
}

@misc{noauthor_how_2015,
	title = {How {Much} {Power} {Is} {Needed} {To} {Hover} ?},
	url = {https://justdrones.com.au/how-much-power-is-needed-to-hover/},
	abstract = {This article is a theoretical venture that aims to answer a series of practical questions, such as: – given a certain electrical setup that can generate a certain power, what is the maximum thrust that we can achieve ? – can a human-powered aircraft be built ? – can I […]},
	language = {en-AU},
	urldate = {2020-06-18},
	journal = {Just Drones},
	month = oct,
	year = {2015},
	note = {Library Catalog: justdrones.com.au
Section: Web}
}

@misc{australia_review_2017,
	type = {Text},
	title = {Review the {IP} background: due diligence},
	shorttitle = {Review the {IP} background},
	url = {https://www.ipaustralia.gov.au/understanding-ip/commercialise-your-ip/review-ip-background-due-diligence},
	abstract = {If a person or organisation (a business ‘entity’) believes they own IP or have an opportunity to source IP from others, a comprehensive appraisal of the viability of commercialising that IP should be made before committing to its commercialisation.},
	language = {en},
	urldate = {2020-06-14},
	author = {Australia, I. P.},
	month = apr,
	year = {2017},
	note = {Library Catalog: www.ipaustralia.gov.au
Publisher: IP Australia}
}

@inproceedings{cesic_full_2016,
	title = {Full body human motion estimation on lie groups using {3D} marker position measurements},
	doi = {10.1109/HUMANOIDS.2016.7803369},
	abstract = {This paper proposes a new algorithm for full body human motion estimation using 3D marker position measurements. The joints are represented with Lie group members, including special orthogonal groups SO(2) and SO(3), and a special euclidean group SE(3). We employ the Lie Group Extended Kalman Filter (LG-EKF) for stochastic inference on groups, thus explicitly accounting for the non-euclidean geometry of the state space, and provide the derivation of the LG-EKF recursion for articulated motion estimation. We evaluate the performance of the proposed algorithm in both simulation and on real-world motion capture data, comparing it with the Euler angles based EKF. The results show that the proposed filter significantly outperforms the Euler angles based EKF, since it estimates human motion more accurately and is not affected by gimbal lock.},
	booktitle = {2016 {IEEE}-{RAS} 16th {International} {Conference} on {Humanoid} {Robots} ({Humanoids})},
	author = {Ćesić, Josip and Joukov, Vladimir and Petrović, Ivan and Kulić, Dana},
	month = nov,
	year = {2016},
	note = {ISSN: 2164-0580},
	keywords = {3D marker position measurements, Algebra, Kalman filters, Kinematics, LG-EKF, Lie group extended Kalman filter, Lie groups, Manifolds, Motion estimation, Position measurement, Stochastic processes, Three-dimensional displays, control engineering computing, full body human motion estimation, gimbal lock, motion estimation, nonlinear filters, position measurement, robotics, robots, special euclidean group, special orthogonal group, stochastic inference},
	pages = {826--833}
}

@inproceedings{carpentier_kinematics-dynamics_2015,
	title = {A kinematics-dynamics based estimator of the center of mass position for anthropomorphic system — {A} complementary filtering approach},
	doi = {10.1109/HUMANOIDS.2015.7363493},
	abstract = {This paper presents an original approach to simply and efficiently estimate the center of mass position of a free-floating base system, like a humanoid robot or a human body. This approach relies on the theory of complementary filtering, which is a popular technique in aerial robotics, but rarely implemented in humanoid robotics. The main idea consists in merging input measurements like the zero-moment point position, the contact forces, etc. which are then filtered according to their reliability in their respective spectral bandwidth. We validate this approach in simulation by (i) comparing the estimated center of mass trajectory with its real value and (ii) showing that the complementary filter offers on average a least reconstruction error than the classic Kalman filter.},
	booktitle = {2015 {IEEE}-{RAS} 15th {International} {Conference} on {Humanoid} {Robots} ({Humanoids})},
	author = {Carpentier, Justin and Benallegue, Mehdi and Mansard, Nicolas and Laumond, Jean-Paul},
	month = nov,
	year = {2015},
	keywords = {Estimation, Force measurement, Frequency-domain analysis, Noise measurement, Position measurement, Robots, Trajectory, aerial robotics, aerospace robotics, anthropomorphic system, center of mass position, complementary filtering approach, contact forces, filtering theory, force measurement, free-floating base system, human body, humanoid robot, humanoid robots, input measurements, kinematics-dynamics based estimator, position measurement, robot dynamics, robot kinematics, zero-moment point position},
	pages = {1121--1126}
}

@article{jia-ching_cheng_capture_1999,
	title = {Capture and representation of human walking in live video sequences},
	volume = {1},
	issn = {1941-0077},
	doi = {10.1109/6046.766736},
	abstract = {Extracting human representations from video has vast applications. In this paper, we present a knowledge-based framework to capture metarepresentations for real-life video with human walkers. The system models the human body as an articulated object and the human walking as a cyclic activity with highly correlated temporal patterns. We extract for each of the body parts its motion, shape, and texture. Once available, this structural information can be used to manipulate or synthesize the original video sequence, or animate the walker with a different motion in a new synthesized video.},
	number = {2},
	journal = {IEEE Transactions on Multimedia},
	author = {Jia-Ching Cheng and Moura, J.M.F.},
	month = jun,
	year = {1999},
	note = {Conference Name: IEEE Transactions on Multimedia},
	keywords = {Animation, Biological system modeling, Cameras, Collaboration, Data mining, Humans, Legged locomotion, Shape, Video sequences, Videoconference, human representations, human walking, image motion analysis, image sequences, knowledge-based framework, live video sequences, metarepresentations, real-life video, temporal patterns, video sequence, virtual reality},
	pages = {144--156}
}

@incollection{koritnik_simple_2010,
	title = {A {Simple} {Kinematic} {Model} of a {Human} {Body} for {Virtual} {Environments}},
	abstract = {We developed a simple kinematic model of a human body for real-time visualization applications in graphical virtual environments.
For practical reasons a reduced number of active markers in optical measurements were employed to assess the values of joint
variables, which caused computational issues in the configurations of the model that involved kinematic singularities. A method
of handling the singularities by using simple algorithms is presented, enabling smooth and natural-appearing movements of
the virtual figure without significantly affecting the natural ranges of human-like motion. The applicability of the model
is demonstrated by a virtual mirror – a virtual reality application for real-time visualization of body movements enabling
a visual feedback – which is useful in medical and performance studies.

Key wordsHuman modelling-virtual environment-kinematic singularity-motion visualization},
	author = {Koritnik, Tomaz and Bajd, Tadej and Munih, Marko},
	month = jan,
	year = {2010},
	doi = {10.1007/978-90-481-9262-5_43},
	pages = {401--408}
}

@misc{noauthor_sample_nodate,
	title = {Sample research budget template {\textbar} {Better} {Thesis}},
	url = {http://betterthesis.dk/sample-research-budget-template},
	urldate = {2020-06-11}
}

@misc{noauthor_roles_nodate,
	title = {Roles {Involved} in {Research} {Financial} {Management} {\textbar} {UNSW} {Finance}},
	url = {https://www.fin.unsw.edu.au/roles-involved-research-financial-management},
	urldate = {2020-06-11}
}

@misc{tasmania_budget_2014,
	type = {Standard {Page}},
	title = {Budget {Preparation} - {Research} {Division}},
	copyright = {http://www.utas.edu.au/copyright-statement/},
	url = {https://www.utas.edu.au/research-admin/research-funding/finding-and-applying-for-funding/budget-preparation},
	abstract = {University of Tasmania web page},
	language = {en-AU},
	urldate = {2020-06-11},
	journal = {Research Division - University of Tasmania, Australia},
	author = {Tasmania, University of},
	month = dec,
	year = {2014},
	note = {Last Modified: 2018-05-23
Library Catalog: www.utas.edu.au
Publisher: The University of Tasmania}
}

@misc{noauthor_but_nodate,
	title = {But what is the {Fourier} {Transform}?  {A} visual introduction.},
	shorttitle = {But what is the {Fourier} {Transform}?},
	url = {https://www.youtube.com/watch?v=spUNpyF58BY},
	abstract = {An animated introduction to the Fourier Transform.
Home page: https://www.3blue1brown.com/
Brought to you by you: http://3b1b.co/fourier-thanks

Follow-on video about the uncertainty principle: https://youtu.be/MBnnXbOM5S4

Interactive made by a viewer inspired by this video:
https://prajwalsouza.github.io/Experi...

Also, take a look at this Jupyter notebook implementing this idea in a way you can play with:
https://github.com/thatSaneKid/fourie...

------------------
Animations largely made using manim, a scrappy open-source python library.  https://github.com/3b1b/manim

If you want to check it out, I feel compelled to warn you that it's not the most well-documented tool, and has many other quirks you might expect in a library someone wrote with only their own use in mind.

Music by Vincent Rubinetti.
Download the music on Bandcamp:
https://vincerubinetti.bandcamp.com/a...

Stream the music on Spotify:
https://open.spotify.com/album/1dVyjw...

If you want to contribute translated subtitles or to help review those that have already been made by others and need approval, you can click the gear icon in the video and go to subtitles/cc, then "add subtitles/cc".  I really appreciate those who do this, as it helps make the lessons accessible to more people.
------------------

3blue1brown is a channel about animating math, in all senses of the word animate.  And you know the drill with YouTube, if you want to stay posted on new videos, subscribe, and click the bell to receive notifications (if you're into that).

If you are new to this channel and want to see more, a good place to start is this playlist: http://3b1b.co/recommended

Various social media stuffs:
Website: https://www.3blue1brown.com
Twitter: https://twitter.com/3Blue1Brown
Patreon: https://patreon.com/3blue1brown
Facebook: https://www.facebook.com/3blue1brown
Reddit: https://www.reddit.com/r/3Blue1Brown},
	urldate = {2020-06-11}
}

@book{brand_petersen_matrix_2012,
	title = {The {Matrix} {Cookbook}},
	url = {https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf},
	abstract = {Collection of Formulae and all that rubbish},
	language = {en},
	author = {Brand Petersen, K and Syskind Pedersen, M},
	month = nov,
	year = {2012}
}

@misc{noauthor_sample_nodate-1,
	title = {Sample budgets and justifications},
	url = {https://www.southalabama.edu/departments/research/resources/sampleresearchbudg.pdf},
	author = {, Alabama}
}

@misc{noauthor_health_nodate,
	title = {Health {Research} {AUS} sample budget},
	url = {http://www.health.gov.on.ca/en/pro/ministry/research/docs/hsrf_target_research_budget_example.pdf}
}

@misc{noauthor_detailed_nodate,
	title = {Detailed sample {Timeline}},
	url = {https://www.theigc.org/wp-content/uploads/2016/12/IGC-Project-Budget-Template-Sample.pdf}
}

@misc{noauthor_checklist_nodate,
	title = {Checklist for {Proposal} {Budget} {Items} {\textbar} {ORSP}},
	url = {https://orsp.umich.edu/checklist-proposal-budget-items},
	urldate = {2020-06-10}
}

@misc{noauthor_budget_nodate,
	title = {Budget and {Cost} {Resources} {\textbar} {ORSP}},
	url = {https://orsp.umich.edu/develop-proposal/budget-and-cost-resources},
	urldate = {2020-06-10}
}

@misc{noauthor_research_nodate,
	title = {Research {Proposals} - {Budget} {\textbar} {ORSP}},
	url = {https://orsp.umich.edu/research-proposals-budget},
	urldate = {2020-06-10}
}

@misc{odonnell_constructing_2011,
	title = {Constructing your budget},
	url = {https://researchwhisperer.org/2011/12/13/budget/},
	abstract = {How to build a budget. For an nice, tasty budget, you will need the following ingredients: accurate information about staffing, travel, equipment and consumables and any other fiddly bits.},
	language = {en},
	urldate = {2020-06-10},
	journal = {The Research Whisperer},
	author = {O'Donnell, Jonathan},
	month = dec,
	year = {2011},
	note = {Library Catalog: researchwhisperer.org}
}

@misc{odonnell_how_2014,
	title = {How to make a simple research budget},
	url = {https://researchwhisperer.org/2014/10/07/simple-research-budget/},
	abstract = {Every research project needs a budget*. If you are applying for funding, you must say what you are planning to spend that funding on. More than that, you need to show how spending that money will h…},
	language = {en},
	urldate = {2020-06-10},
	journal = {The Research Whisperer},
	author = {O'Donnell, Jonathan},
	month = oct,
	year = {2014},
	note = {Library Catalog: researchwhisperer.org}
}

@article{fletcher_ten_2012,
	title = {Ten {Simple} {Rules} {To} {Commercialize} {Scientific} {Research}},
	volume = {8},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002712},
	doi = {10.1371/journal.pcbi.1002712},
	language = {en},
	number = {9},
	urldate = {2020-06-10},
	journal = {PLOS Computational Biology},
	author = {Fletcher, Anthony C. and Bourne, Philip E.},
	month = sep,
	year = {2012},
	note = {Publisher: Public Library of Science},
	keywords = {Drug research and development, Finance, Intellectual property, Marketing, Monoclonal antibodies, Peer review, Research design, Scientists},
	pages = {e1002712}
}

@misc{noauthor_logistische_nodate,
	title = {Logistische {Differentialgleichung} lösen (als separierbare {DGL}) {\textbar} {Trennung} der {Veränderlichen}},
	url = {https://www.youtube.com/watch?v=QRzQkE83uGE&list=PLvBnQVOJXCUF8rDSyRkI-lbb1BYKOWkzK&index=7},
	abstract = {Jede Gleichung, in der eine Ableitung enthalten ist, heißt "Differentialgleichung" (DGL). Mit diesen Gleichungen werden z.B. in den Natur- und Wirtschaftswissenschaften Änderungsverhalten ausgedrückt. Die Logistische Differentialgleichung beschreibt dabei Wachstumsprozesse mit einer natürlichen Obergrenze, wie bei der Population von Menschen, der Ausbreitung von Gerüchten oder dem Lebenszyklus eines Produktes am Markt. Wie die logistische DGL mit Trennung der Veränderlichen gelöst werden kann, erfährst du in diesem Video!

Sei dabei, wenn es los geht. Ich öffne meine eigene Online Plattform. Mit Kursen, individuellem Support und allem, was du benötigst um deine Prüfung zu bestehen.

--------------------------------------------------------------------------------------------------------------------------
\#WERBUNG. Für Kurse, welche ich selbst erstellt habe 🤓

Statistik- und Wahrscheinlichkeitsrechnung
https://www.udemy.com/course/statisti...

Differentialrechnung 
https://www.udemy.com/course/differen...

Integralrechnung 
https://www.udemy.com/course/integral...

Grenzwerte von Funktionen 
https://www.udemy.com/course/grenzwer...

Extremwertrechnung
https://www.udemy.com/course/extremwe...

Funktionen mit mehreren Variablen
https://www.udemy.com/course/funktion...

Mehrdimensionale Integralrechnung 
https://www.udemy.com/course/mehrdime...

Folgen, Reihen und Differenzengleichungen
https://www.udemy.com/course/folgen-r...

Mathe 1 Crashkurs (erstellt für HU Berlin)
https://champcademy.teachable.com/p/m...

.
Falls du mich unterstützen möchtest, kannst du dies unter folgenden Link gern tun:
https://www.patreon.com/mathepeter

✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄

Diesen Taschenrechner und Tafelwerk nutze ich. 
Es handelt sich hierbei um Affiliate Links. Für jeden Kauf bekomme ich eine kleine Provision. Für dich bleibt der Preis gleich:

Mein Taschenrechner
https://amzn.to/2RbhKKj

Mein Tafelwerk
https://amzn.to/2WdVUtd
--------------------------------------------------------------------------------------------------------------------------

Inhalt:
0:00 Was dich erwartet
0:34 Schritt 1: y'=dy/dx
1:30 Schritt 2: Trennung der Veränderlichen
3:07 Nebenrechnung: Partialbruchzerlegung
8:37 Schritt 3: Integrieren
11:10 Nach der Funktion umstellen
19:17 \#WERBUNG

♥♥♥                 ♜♞♝♛♚♝♞♜              ♥♥♥
                        ♟♟♟♟♟♟♟♟
---------------------------------------------------------------------
Willst du mir eine Kaffeepause spendieren?
https://www.patreon.com/mathepeter
---------------------------------------------------------------------
                        ♙♙♙♙♙♙♙♙   
♥♥♥                 ♖♘♗♕♔♗♘♖              ♥♥♥


Warum MathePeter: 
Vielen von euch fällt Mathe während des Studiums oder der Ausbildung nicht leicht. Ihr müsst sogar eine Prüfung in Mathe schreiben. Ehrlich gesagt gibt es auch Schöneres im Leben als sich auf eine Matheprüfung vorzubereiten. Während meiner Zeit als Tutor an der Uni habe ich gemerkt, dass Mathe lernen auch einfacher geht. Auf diesem Kanal erarbeiten wir gemeinsam die Basics für eure Prüfung. Dieser Kanal dient auch als Ergänzung für online und offline Nachhilfe. Mathe lernen so einfach wie möglich ist das Ziel. In Zukunft kommen Crashkurse, Videos und Videokurse. Ich freue mich auf euch! Schreibt mir einfach eine Nachricht. 

\#MathePeter},
	urldate = {2020-06-04}
}

@misc{noauthor_karush_nodate,
	title = {Karush {Kuhn} {Tucker} {Bedingungen} ({KKT}) {\textbar} {Notwendiges} oder hinreichendes {Kriterium} für {Extrema}},
	url = {https://www.youtube.com/watch?v=adBmzj01CSs&list=PLvBnQVOJXCUHXNc8W34jImeAnpGfcKRle&index=2&t=0s},
	urldate = {2020-06-04}
}

@misc{noauthor_lagrange_nodate,
	title = {Lagrange {Verfahren} {REMAKE} {\textbar} {Extrema} mit "=" {Nebenbedingungen} inkl. {Tipps}\&{Tricks}},
	url = {https://www.youtube.com/watch?v=p8N8cG9L5bA},
	abstract = {Mit dem Lagrange Verfahren berechnest du Extrema und Sattelpunkte von Funktionen unter "=" Nebenbedingungen. Diese Schritt-für-Schritt-Anleitung führt dich einfach und schnell durch jede Extremwertaufgabe mit Gleichungsnebenbedingungen. Wie das funktioniert, mit welchen Tricks du arbeiten kannst und was es mit dem Lagrange Multiplikator auf sich hat, erfährst du in diesem Video!

Als Dank für die 100.000 Aufrufe des Originalvideos
( https://youtu.be/RnlZ-kwUL1E ) gibts dieses Remake in stark überarbeiteter Form. Vielen Dank für eure Unterstützung!

Sei dabei, wenn es los geht. Ich öffne meine eigene Online Plattform. Mit Kursen, individuellem Support und allem, was du benötigst um deine Prüfung zu bestehen.

--------------------------------------------------------------------------------------------------------------------------
\#WERBUNG. Für Kurse, welche ich selbst erstellt habe 🤓

Statistik- und Wahrscheinlichkeitsrechnung
https://www.udemy.com/course/statisti...

Differentialrechnung 
https://www.udemy.com/course/differen...

Integralrechnung 
https://www.udemy.com/course/integral...

Grenzwerte von Funktionen 
https://www.udemy.com/course/grenzwer...

Extremwertrechnung
https://www.udemy.com/course/extremwe...

Funktionen mit mehreren Variablen
https://www.udemy.com/course/funktion...

Mehrdimensionale Integralrechnung 
https://www.udemy.com/course/mehrdime...

Folgen, Reihen und Differenzengleichungen
https://www.udemy.com/course/folgen-r...

Mathe 1 Crashkurs (erstellt für HU Berlin)
https://champcademy.teachable.com/p/m...

.
Falls du mich unterstützen möchtest, kannst du dies unter folgenden Link gern tun:
https://www.patreon.com/mathepeter

✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄

Diesen Taschenrechner und Tafelwerk nutze ich. 
Es handelt sich hierbei um Affiliate Links. Für jeden Kauf bekomme ich eine kleine Provision. Für dich bleibt der Preis gleich:

Mein Taschenrechner
https://amzn.to/2RbhKKj

Mein Tafelwerk
https://amzn.to/2WdVUtd
--------------------------------------------------------------------------------------------------------------------------

Inhalt:
0:00 Was dich erwartet
0:20 Schritt 1: Lagrangefunktion aufstellen
2:18 Schritt 2: Gradient der Lagrangefunktion Null setzen
4:31 Schritt 3: Lambda eliminieren mit dem Additionsverfahren
7:06 Trick: Determinantenmethode (Schritt 1+2+3 in 60 Sekunden)
8:23 Schritt 4: Gleichungssystem lösen
12:48 Rangbedingung
14:23 Art der kritischen Punkte
15:25 Bedeutung der Lagrange Multiplikatoren
16:33 \#WERBUNG

♥♥♥                 ♜♞♝♛♚♝♞♜              ♥♥♥
                        ♟♟♟♟♟♟♟♟
---------------------------------------------------------------------
Willst du mir eine Kaffeepause spendieren?
https://www.patreon.com/mathepeter
---------------------------------------------------------------------
                        ♙♙♙♙♙♙♙♙   
♥♥♥                 ♖♘♗♕♔♗♘♖              ♥♥♥


Warum MathePeter: 
Vielen von euch fällt Mathe während des Studiums oder der Ausbildung nicht leicht. Ihr müsst sogar eine Prüfung in Mathe schreiben. Ehrlich gesagt gibt es auch Schöneres im Leben als sich auf eine Matheprüfung vorzubereiten. Während meiner Zeit als Tutor an der Uni habe ich gemerkt, dass Mathe lernen auch einfacher geht. Auf diesem Kanal erarbeiten wir gemeinsam die Basics für eure Prüfung. Dieser Kanal dient auch als Ergänzung für online und offline Nachhilfe. Mathe lernen so einfach wie möglich ist das Ziel. In Zukunft kommen Crashkurse, Videos und Videokurse. Ich freue mich auf euch! Schreibt mir einfach eine Nachricht. 

\#MathePeter},
	urldate = {2020-06-04}
}

@misc{noauthor_lagrange-methode_nodate,
	title = {Lagrange-{Methode} {Einfach} {Erklärt}! + {Beispiel}},
	url = {https://www.youtube.com/watch?v=RnlZ-kwUL1E},
	abstract = {Mit der Lagrange-Methode berechnest du Extrema von Funktionen unter Gleichungsnebenbedingungen. Diese Schritt-für-Schritt-Anleitung führt dich einfach und schnell durch jede Extremwertaufgabe von Funktionen mit mehreren Variablen.
NEU: Der einfachste und schnellste Weg Lagrange-Aufgaben zu lösen: https://youtu.be/p6\_TRegg6Uw

Sei dabei, wenn es los geht. Ich öffne meine eigene Online Plattform. Mit Kursen, individuellem Support und allem, was du benötigst um deine Prüfung zu bestehen.

--------------------------------------------------------------------------------------------------------------------------
\#WERBUNG. Für Kurse, welche ich selbst erstellt habe 🤓

Statistik- und Wahrscheinlichkeitsrechnung
https://www.udemy.com/course/statisti...

Differentialrechnung 
https://www.udemy.com/course/differen...

Integralrechnung 
https://www.udemy.com/course/integral...

Grenzwerte von Funktionen 
https://www.udemy.com/course/grenzwer...

Extremwertrechnung
https://www.udemy.com/course/extremwe...

Funktionen mit mehreren Variablen
https://www.udemy.com/course/funktion...

Mehrdimensionale Integralrechnung 
https://www.udemy.com/course/mehrdime...

Folgen, Reihen und Differenzengleichungen
https://www.udemy.com/course/folgen-r...

Mathe 1 Crashkurs (erstellt für HU Berlin)
https://champcademy.teachable.com/p/m...

.
Falls du mich unterstützen möchtest, kannst du dies unter folgenden Link gern tun:
https://www.patreon.com/mathepeter

✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄

Diesen Taschenrechner und Tafelwerk nutze ich. 
Es handelt sich hierbei um Affiliate Links. Für jeden Kauf bekomme ich eine kleine Provision. Für dich bleibt der Preis gleich:

Mein Taschenrechner
https://amzn.to/2RbhKKj

Mein Tafelwerk
https://amzn.to/2WdVUtd
--------------------------------------------------------------------------------------------------------------------------
Inhalt:
0:15 Wann benutzt man die Lagrange-Methode?
0:45 Schritt 1: Lagrangefunktion aufstellen
2:13 Schritt 2: Alle ersten Ableitungen = 0
3:46 Schritt 3: Lambda eliminieren
5:59 Schritt 4: Gleichungssystem lösen
8:44 Zusammenfassung

♥♥♥                 ♜♞♝♛♚♝♞♜              ♥♥♥
                        ♟♟♟♟♟♟♟♟
---------------------------------------------------------------------
Willst du mir eine Kaffeepause spendieren?
https://www.patreon.com/mathepeter
---------------------------------------------------------------------
                        ♙♙♙♙♙♙♙♙   
♥♥♥                 ♖♘♗♕♔♗♘♖              ♥♥♥


Verwandte Videos:
Extrema unter Ungleichungsnebenbedingungen (Übersicht) - https://youtu.be/Gpi8GTTbyx0
Extrema mehrerer Variablen 1/2: Notwendig - https://youtu.be/j3zed7Khku8
Extrema mehrerer Variablen 2/2: Hinreichend - https://youtu.be/NVAacS3WpDg
Grundfunktionen ableiten - https://youtu.be/cdXtfQQr9j8
Polynome (Potenzregel, Summenregel, Faktorregel) - https://youtu.be/ByJQOHlaXqQ
Brüche ableiten (Trick) - https://youtu.be/xMfS-VNV-Q4
Gradient+Steilster Anstieg - https://youtu.be/5wE5SVhe01w
Extrema \&amp; Wendepunkte 1/2 - https://youtu.be/hwGuLogK0QY
Extrema \&amp; Wendepunkte 2/2 - https://youtu.be/6PGU2c\_5tAI
Extrema \&amp; Wendepunkte - Beispiel - https://youtu.be/BjSJMxqyRRU
Höhenlinien - https://youtu.be/AwuHwunMrWU

Warum MathePeter: 
Vielen von euch fällt Mathe während des Studiums oder der Ausbildung nicht leicht. Ihr müsst sogar eine Prüfung in Mathe schreiben. Ehrlich gesagt gibt es auch Schöneres im Leben als sich auf eine Matheprüfung vorzubereiten. Während meiner Zeit als Tutor an der Uni habe ich gemerkt, dass Mathe lernen auch einfacher geht. Auf diesem Kanal erarbeiten wir gemeinsam die Basics für eure Prüfung. Dieser Kanal dient auch als Ergänzung für online und offline Nachhilfe. Mathe lernen so einfach wie möglich ist das Ziel. In Zukunft kommen Crashkurse, Videos und Videokurse. Ich freue mich auf euch! Schreibt mir einfach eine Nachricht. 

\#MathePeter},
	urldate = {2020-06-04}
}

@misc{noauthor_mathepeter_nodate,
	title = {{MathePeter} - {YouTube}},
	url = {https://www.youtube.com/channel/UCHTK6ZEUvS5nDzesP7ZGGSg},
	urldate = {2020-06-04}
}

@misc{noauthor_integralsatz_nodate,
	title = {Integralsatz von {Gauß}},
	url = {https://www.youtube.com/watch?v=T41IHNRNjhw&fbclid=IwAR1SM0clsQhinZSrtWs83EnQMxrh3Wfk9pfPCc-XarDUaPlzhqgX83HoP-8},
	abstract = {Der (klassische) Integralsatz von Gauß besagt, dass jeglicher Fluss durch einen Körper durch die geschlossene Oberfläche des Körpers erfolgen muss. Wie du den Integralsatz praktisch in Rechenaufgaben anwenden kannst, zeige ich dir in diesem Video!

Sei dabei, wenn es los geht. Ich öffne meine eigene Online Plattform. Mit Kursen, individuellem Support und allem, was du benötigst um deine Prüfung zu bestehen.

--------------------------------------------------------------------------------------------------------------------------
\#WERBUNG. Für Kurse, welche ich selbst erstellt habe 🤓

Statistik- und Wahrscheinlichkeitsrechnung
https://www.udemy.com/course/statisti...

Differentialrechnung 
https://www.udemy.com/course/differen...

Integralrechnung 
https://www.udemy.com/course/integral...

Grenzwerte von Funktionen 
https://www.udemy.com/course/grenzwer...

Extremwertrechnung
https://www.udemy.com/course/extremwe...

Funktionen mit mehreren Variablen
https://www.udemy.com/course/funktion...

Mehrdimensionale Integralrechnung 
https://www.udemy.com/course/mehrdime...

Folgen, Reihen und Differenzengleichungen
https://www.udemy.com/course/folgen-r...

Mathe 1 Crashkurs (erstellt für HU Berlin)
https://champcademy.teachable.com/p/m...
Falls du mich unterstützen möchtest, kannst du dies unter folgenden Link gern tun:
https://www.patreon.com/mathepeter

✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄✄

Diesen Taschenrechner und Tafelwerk nutze ich. 
Es handelt sich hierbei um Affiliate Links. Für jeden Kauf bekomme ich eine kleine Provision. Für dich bleibt der Preis gleich:

Mein Taschenrechner
https://amzn.to/2RbhKKj

Mein Tafelwerk
https://amzn.to/2WdVUtd
--------------------------------------------------------------------------------------------------------------------------
Inhalt:
0:00 Allgemeiner Satz von Gauß + Voraussetzungen
1:30 Häufigste Anwendung 2D und 3D (klassisch)
2:42 Praktische Anwendung im 3D
4:52 Praktische Anwendung im 2D (Ebener Satz von Gauß)
5:58 Zusammenfassung + Merkregeln

♥♥♥                 ♜♞♝♛♚♝♞♜              ♥♥♥
                        ♟♟♟♟♟♟♟♟
---------------------------------------------------------------------
Willst du mir eine Kaffeepause spendieren?
https://www.patreon.com/mathepeter
---------------------------------------------------------------------
                        ♙♙♙♙♙♙♙♙   
♥♥♥                 ♖♘♗♕♔♗♘♖              ♥♥♥


Warum MathePeter: 
Vielen von euch fällt Mathe während des Studiums oder der Ausbildung nicht leicht. Ihr müsst sogar eine Prüfung in Mathe schreiben. Ehrlich gesagt gibt es auch schöneres im Leben als sich auf eine Matheprüfung vorzubereiten. Während meiner Zeit als Tutor an der Uni habe ich gemerkt das Mathe lernen auch einfacher geht. Auf diesem Kanal erarbeiten wir gemeinsam die Basics für eure Prüfung. Dieser Kanal dient auch als Ergänzung für online und offline Nachhilfe. Mathe lernen so einfach wie möglich ist das Ziel. In Zukunft kommen Crashkurse, Videos und Videokurse. ich freue mich auf euch! Schreibt mir einfach eine Nachricht. 

\#MathePeter},
	urldate = {2020-06-04}
}

@article{suarez_benchmarks_2020,
	title = {Benchmarks for {Aerial} {Manipulation}},
	volume = {5},
	issn = {2377-3766},
	doi = {10.1109/LRA.2020.2972870},
	abstract = {This letter is devoted to benchmarks for aerial manipulation robots (drones equipped with robotic arms), which are demonstrating their potential to conduct tasks involving physical interactions with objects or the environment in high altitude workspaces, being a cost effective solution for example in inspection and maintenance operations. Thus, the letter deals with different methods and criteria to evaluate and compare the performance of aerial manipulators. This is not an easy task, taking into account the wide variety of designs, morphologies and implementations that can be found in recent works. In order to cope with this problem, this letter analyzes the capabilities and functionalities of several aerial manipulation prototypes (aerial platform + manipulator), identifying a set of relevant metrics and criteria. A number of benchmarks are defined to evaluate the performance of the aerial manipulator in terms of accuracy, execution time, manipulation capability, or impact response. Experimental results carried out with a compliant joint aerial manipulator in test-bench and in indoor-outdoor testbeds illustrate some of the benchmarks.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Suarez, Alejandro and Vega, Victor M. and Fernandez, Manuel and Heredia, Guillermo and Ollero, Anibal},
	month = apr,
	year = {2020},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Aerial systems, Benchmark testing, Manipulators, Morphology, Prototypes, Task analysis, Trajectory, aerial manipulation robots, autonomous aerial vehicles, compliant joint aerial manipulator, force control, helicopters, high altitude workspaces, manipulation capability, manipulator dynamics, mechanics and control, mobile robots, position control, robotic arms},
	pages = {2650--2657}
}

@inproceedings{morton_development_2016,
	title = {Development of a robust framework for an outdoor mobile manipulation {UAV}},
	doi = {10.1109/AERO.2016.7500576},
	abstract = {There is a growing interest to autonomously collect or manipulate objects in remote or unknown environments, such as mountains, gullies, bush-land, or rough terrain. There are several limitations of conventional methods using manned or remotely controlled aircraft. The capability of small Unmanned Aerial Vehicles (UAV) used in parallel with robotic manipulators could overcome some of these limitations. By enabling the autonomous exploration of both naturally hazardous environments, or areas which are biologically, chemically, or radioactively contaminated, it is possible to collect samples and data from such environments without directly exposing personnel to such risks. This paper covers the design, integration, and initial testing of a framework for outdoor mobile manipulation UAV. The framework is designed to allow further integration and testing of complex control theories, with the capability to operate outdoors in unknown environments. The results obtained act as a reference for the effectiveness of the integrated sensors and low-level control methods used for the preliminary testing, as well as identifying the key technologies needed for the development of an outdoor capable system.},
	booktitle = {2016 {IEEE} {Aerospace} {Conference}},
	author = {Morton, Kye and Toro, Luis Felipe Gonzalez},
	month = mar,
	year = {2016},
	keywords = {Control theory, Manipulator dynamics, Mobile communication, Robustness, Stability analysis, Testing, aircraft, autonomous aerial vehicles, naturally hazardous environments, outdoor capable system, outdoor mobile manipulation UAV, remotely controlled aircraft, robotic manipulators, robust control, robust framework, unmanned aerial vehicles},
	pages = {1--8}
}

@misc{knapp_quality_2019,
	address = {ROScon},
	title = {Quality of {Service} for {ROS2} {Communications}},
	url = {https://roscon.ros.org/2019/talks/roscon2019_qos.pdf},
	language = {en},
	author = {Knapp, Emerson},
	month = nov,
	year = {2019}
}

@misc{noauthor_open_nodate,
	title = {The {Open} {Motion} {Planning} {Library}},
	url = {https://ompl.kavrakilab.org/},
	urldate = {2020-06-01}
}

@misc{noauthor_20_nodate,
	title = {The 20 {Minute} {Business} {Plan}: {Business} {Model} {Canvas} {Made} {Easy}},
	shorttitle = {The 20 {Minute} {Business} {Plan}},
	url = {https://www.alexandercowan.com/business-model-canvas-templates/},
	abstract = {Save time, improve discussions, think more deeply about the business- what's not to like about the Canvas? This tutorial walks through it in 10 steps.},
	language = {en-US},
	urldate = {2020-06-01},
	journal = {Alex Cowan},
	note = {Library Catalog: www.alexandercowan.com
Section: Venture Management}
}

@misc{noauthor_how_nodate-1,
	title = {How to {Write} a {Business} {Plan} {\textbar} {How} to {Write} a {Business} {Plan}},
	url = {https://www.opencolleges.edu.au/careers/how-write-business-plan},
	urldate = {2020-06-01}
}

@misc{employment_swot_2011,
	type = {Collection; {Text}},
	title = {{SWOT} analysis},
	url = {https://www.business.qld.gov.au/starting-business/planning/market-customer-research/swot-analysis},
	abstract = {Get an overview of the SWOT analysis business tool, including what it involves, the benefits of using one, and how to conduct one for your business.},
	language = {en-AU},
	urldate = {2020-06-01},
	author = {Employment, Small Business {and} Training},
	month = jul,
	year = {2011},
	note = {Last Modified: 2019-01-02
Library Catalog: www.business.qld.gov.au
Publisher: corporateName=The State of Queensland;}
}

@article{grijs_ten_2015,
	title = {Ten {Simple} {Rules} for {Establishing} {International} {Research} {Collaborations}},
	volume = {11},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004311},
	doi = {10.1371/journal.pcbi.1004311},
	language = {en},
	number = {10},
	urldate = {2020-06-01},
	journal = {PLOS Computational Biology},
	author = {Grijs, Richard de},
	month = oct,
	year = {2015},
	note = {Publisher: Public Library of Science},
	keywords = {Culture, Geographic distribution, Government funding of science, Intellectual property, Language, Research grants, Research integrity, Scientists},
	pages = {e1004311}
}

@misc{noauthor_how_nodate-2,
	title = {How to find international collaborators for your research {\textbar} {British} {Council}},
	url = {https://www.britishcouncil.org/voices-magazine/how-to-find-international-collaborators-for-your-research},
	abstract = {Sandy Sparks, Learning and Development Consultant at the University of Warwick, gives her best advice for finding and maintaining a collaboration.},
	language = {en},
	urldate = {2020-06-01},
	note = {Library Catalog: www.britishcouncil.org}
}

@article{qiu_unrealcv_2016,
	title = {{UnrealCV}: {Connecting} {Computer} {Vision} to {Unreal} {Engine}},
	shorttitle = {{UnrealCV}},
	url = {https://arxiv.org/abs/1609.01326v1},
	abstract = {Computer graphics can not only generate synthetic images and ground truth but
it also offers the possibility of constructing virtual worlds in which: (i) an
agent can perceive, navigate, and take actions guided by AI algorithms, (ii)
properties of the worlds can be modified (e.g., material and reflectance),
(iii) physical simulations can be performed, and (iv) algorithms can be learnt
and evaluated. But creating realistic virtual worlds is not easy. The game
industry, however, has spent a lot of effort creating 3D worlds, which a player
can interact with. So researchers can build on these resources to create
virtual worlds, provided we can access and modify the internal data structures
of the games. To enable this we created an open-source plugin UnrealCV
(http://unrealcv.github.io) for a popular game engine Unreal Engine 4 (UE4). We
show two applications: (i) a proof of concept image dataset, and (ii) linking
Caffe with the virtual world to test deep network algorithms.},
	language = {en},
	urldate = {2020-06-01},
	author = {Qiu, Weichao and Yuille, Alan},
	month = sep,
	year = {2016}
}
@misc{noauthor_multiple_nodate,
	title = {Multiple {View} {Geometry} - {Lecture} 1 ({Prof}. {Daniel} {Cremers})},
	url = {https://www.youtube.com/watch?v=RDkwklFGMfo&list=PLTBdjV_4f-EJn6udZ34tht9EVIW7lbeo4&index=1},
	abstract = {Lecturer: Prof. Dr. Daniel Cremers, TU München

Topics covered:
- A short review of Linear Algebra

Lecture slides: https://vision.in.tum.de/teaching/onl...},
	urldate = {2020-05-28}
}

@misc{noauthor_multiple_nodate-1,
	title = {Multiple {Subplots} {\textbar} {Python} {Data} {Science} {Handbook}},
	url = {https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html},
	urldate = {2020-05-28}
}

@misc{noauthor_234_nodate,
	title = {2.3.4 {Numeric} {Types} -- int, float, long, complex},
	url = {https://docs.python.org/2.4/lib/typesnumeric.html},
	urldate = {2020-05-28}
}

@book{lee_global_2017,
	title = {Global {Formulations} of {Lagrangian} and {Hamiltonian} {Dynamics} on {Manifolds}: {A} {Geometric} {Approach} to {Modeling} and {Analysis}},
	isbn = {978-3-319-56953-6},
	shorttitle = {Global {Formulations} of {Lagrangian} and {Hamiltonian} {Dynamics} on {Manifolds}},
	abstract = {This book provides an accessible introduction to the variational formulation of Lagrangian and Hamiltonian mechanics, with a novel emphasis on global descriptions of the dynamics, which is a significant conceptual departure from more traditional approaches based on the use of local coordinates on the configuration manifold. In particular, we introduce a general methodology for obtaining globally valid equations of motion on configuration manifolds that are Lie groups, homogeneous spaces, and embedded manifolds, thereby avoiding the difficulties associated with coordinate singularities. The material is presented in an approachable fashion by considering concrete configuration manifolds of increasing complexity, which then motivates and naturally leads to the more general formulation that follows. Understanding of the material is enhanced by numerous in-depth examples throughout the book, culminating in non-trivial applications involving multi-body systems. This book is written for a general audience of mathematicians, engineers, and physicists with a basic knowledge of mechanics. Some basic background in differential geometry is helpful, but not essential, as the relevant concepts are introduced in the book, thereby making the material accessible to a broad audience, and suitable for either self-study or as the basis for a graduate course in applied mathematics, engineering, or physics.},
	language = {en},
	publisher = {Springer},
	author = {Lee, Taeyoung and Leok, Melvin and McClamroch, N. Harris},
	month = aug,
	year = {2017},
	note = {Google-Books-ID: 0fwwDwAAQBAJ},
	keywords = {Language Arts \& Disciplines / Library \& Information Science / General, Mathematics / Counting \& Numeration, Mathematics / Linear \& Nonlinear Programming, Mathematics / Mathematical Analysis, Mathematics / Numerical Analysis, Science / Mechanics / Dynamics, Science / System Theory, Technology \& Engineering / Mechanical}
}

@phdthesis{gammulle_deep_2019,
	type = {phd},
	title = {Deep learning for human action understanding},
	url = {https://eprints.qut.edu.au/135199/},
	abstract = {This thesis addresses the problem of understanding human behaviour in videos in multiple problem settings including, recognition, segmentation, and prediction. Considering the complex nature of human behaviour, we propose to capture both short-term and long-term context in the given videos and propose novel multitask learning-based approaches to solve the action prediction task, as well as an adversarially-trained approach to action recognition. We demonstrate the efficacy of these techniques by applying them to multiple real-world human behaviour understanding settings including, security surveillance, sports action recognition, group activity recognition and recognition of cooking activities.},
	language = {en},
	urldate = {2020-05-27},
	school = {Queensland University of Technology},
	author = {Gammulle, Pranali Harshala},
	year = {2019}
}

@inproceedings{boroujerdian_why_2018,
	title = {Why {Compute} {Matters} for {UAV} {Energy} {Efficiency}?},
	volume = {6},
	author = {Boroujerdian, Behzad and Genc, Hasan and Krishnan, Srivatsan and Faust, Aleksandra and Reddi, Vijay Janapa},
	year = {2018},
	note = {Issue: 6}
}

@article{krishnan_air_2019,
	title = {Air {Learning}: {An} {AI} {Research} {Platform} for {Algorithm}-{Hardware} {Benchmarking} of {Autonomous} {Aerial} {Robots}},
	shorttitle = {Air {Learning}},
	url = {http://arxiv.org/abs/1906.00421},
	abstract = {We introduce Air Learning, an AI research platform for benchmarking algorithm-hardware performance and energy efficiency trade-offs. We focus in particular on deep reinforcement learning (RL) interactions in autonomous unmanned aerial vehicles (UAVs). Equipped with a random environment generator, AirLearning exposes a UAV to a diverse set of challenging scenarios. Users can specify a task, train different RL policies and evaluate their performance and energy efficiency on a variety of hardware platforms. To show how Air Learning can be used, we seed it with Deep Q Networks (DQN) and Proximal Policy Optimization (PPO) to solve a point-to-point obstacle avoidance task in three different environments, generated using our configurable environment generator. We train the two algorithms using curriculum learning and non-curriculum-learning. Air Learning assesses the trained policies' performance, under a variety of quality-of-flight (QoF) metrics, such as the energy consumed, endurance and the average trajectory length, on resource-constrained embedded platforms like a Ras-Pi. We find that the trajectories on an embedded Ras-Pi are vastly different from those predicted on a high-end desktop system, resulting in up to 79.43\% longer trajectories in one of the environments. To understand the source of such differences, we use Air Learning to artificially degrade desktop performance to mimic what happens on a low-end embedded system. QoF metrics with hardware-in-the-loop characterize those differences and expose how the choice of onboard compute affects the aerial robot's performance. We also conduct reliability studies to demonstrate how Air Learning can help understand how sensor failures affect the learned policies. All put together, Air Learning enables a broad class of RL studies on UAVs. More information and code for Air Learning can be found here: http://bit.ly/2JNAVb6.},
	urldate = {2020-05-27},
	journal = {arXiv:1906.00421 [cs]},
	author = {Krishnan, Srivatsan and Borojerdian, Behzad and Fu, William and Faust, Aleksandra and Reddi, Vijay Janapa},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.00421},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics}
}

@inproceedings{boroujerdian_mavbench_2018,
	title = {{MAVBench}: {Micro} {Aerial} {Vehicle} {Benchmarking}},
	shorttitle = {{MAVBench}},
	doi = {10.1109/MICRO.2018.00077},
	abstract = {Unmanned Aerial Vehicles (UAVs) are getting closer to becoming ubiquitous in everyday life. Among them, Micro Aerial Vehicles (MAVs) have seen an outburst of attention recently, specifically in the area with a demand for autonomy. A key challenge standing in the way of making MAVs autonomous is that researchers lack the comprehensive understanding of how performance, power, and computational bottlenecks affect MAV applications. MAVs must operate under a stringent power budget, which severely limits their flight endurance time. As such, there is a need for new tools, benchmarks, and methodologies to foster the systematic development of autonomous MAVs. In this paper, we introduce the MAVBench' framework which consists of a closed-loop simulator and an end-to-end application benchmark suite. A closed-loop simulation platform is needed to probe and understand the intra-system (application data flow) and inter-system (system and environment) interactions in MAV applications to pinpoint bottlenecks and identify opportunities for hardware and software co-design and optimization. In addition to the simulator, MAVBench provides a benchmark suite, the first of its kind, consisting of a variety of MAV applications designed to enable computer architects to perform characterization and develop future aerial computing systems. Using our open source, end-to-end experimental platform, we uncover a hidden, and thus far unexpected compute to total system energy relationship in MAVs. Furthermore, we explore the role of compute by presenting three case studies targeting performance, energy and reliability. These studies confirm that an efficient system design can improve MAV's battery consumption by up to 1.8X.},
	booktitle = {2018 51st {Annual} {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture} ({MICRO})},
	author = {Boroujerdian, Behzad and Genc, Hasan and Krishnan, Srivatsan and Cui, Wenzhi and Faust, Aleksandra and Reddi, Vijay},
	month = oct,
	year = {2018},
	keywords = {Aerial computing, Batteries, Benchmark, Benchmark testing, Drones, FAA, Hardware, Kernel, MAVBench framework, Rotors, aerial computing systems, autonomous MAVs, autonomous aerial vehicles, battery consumption, battery powered vehicles, closed loop systems, closed-loop simulation platform, micro aerial vehicles, microaerial vehicle benchmarking, mobile robots, robotics, simuator, total system energy relationship, unmanned aerial vehicles},
	pages = {894--907}
}

@misc{noauthor_jetson_2019,
	title = {Jetson {Nano}: {Deep} {Learning} {Inference} {Benchmarks}},
	shorttitle = {Jetson {Nano}},
	url = {https://developer.nvidia.com/embedded/jetson-nano-dl-inference-benchmarks},
	abstract = {Jetson Nano can run a wide variety of advanced networks, including the full native versions of popular ML frameworks like TensorFlow, PyTorch, Caffe/Caffe2, Keras, MXNet, and others. These networks can be used to build autonomous machines and complex AI systems by implementing robust capabilities such as image recognition, object detection and localization, pose estimation, semantic segmentation, video enhancement, and intelligent analytics. To run the following benchmarks on your Jetson Nano, please see the instructions here.},
	language = {en},
	urldate = {2020-05-26},
	journal = {NVIDIA Developer},
	month = apr,
	year = {2019},
	note = {Library Catalog: developer.nvidia.com}
}

@misc{noauthor_how_2015,
	title = {How to choose the right motor for your multicopter drone},
	url = {https://www.dronetrest.com/t/how-to-choose-the-right-motor-for-your-multicopter-drone/568},
	abstract = {This small guide is to help you choose the right motor for your quadcopter or other multirotor. To help you with this decision, it would be desirable to have several test statistics at your disposal which can be found in the thrust data tables. Luckily, reputable manufacturers will have carried out these necessary tests so you don’t have to and these will provide you with the needed information. An example of one such thrust data table for a MT1806 is given below:    If you are totally unfamil...},
	language = {en},
	urldate = {2020-05-26},
	journal = {DroneTrest},
	month = oct,
	year = {2015},
	note = {Library Catalog: www.dronetrest.com}
}

@misc{noauthor_payload_2019,
	title = {Payload capability of {DJI} {F450}},
	url = {https://discuss.ardupilot.org/t/payload-capability-of-dji-f450/49840},
	abstract = {Hi!  I am new to drones but I have read a lot of literature on the working and selection of components for custom made drones. I had a question particular to this drone kit: DJI F450. I wish to attach a roughly  1 kg or less payload (in addition to the drone’s own weight; including the frame,batteries and other components). I’ll be using 2210/920 kV DJI motors with 10’’ propellers. What max payload can this configuration for this drone kit allow me to carry?  If this is not possible, then can so...},
	language = {en-US},
	urldate = {2020-05-26},
	journal = {ArduPilot Discourse},
	month = dec,
	year = {2019},
	note = {Library Catalog: discuss.ardupilot.org}
}

@misc{noauthor_thrust_nodate,
	title = {Thrust to {Weight} {Ratios} {\textbar} {A} {Drone} {Design} {Foundation}},
	url = {https://www.youtube.com/watch?v=KgTN_VuKORs},
	abstract = {Learn what the heck thrust to weight ratios are (TWR or TW), and why they are important to drone design. 

In the drone designing process, the first step should be determining a target thrust to weight (TW) ratio that is desirable for the type of drone you want to build. 

You will want different TW ratios for different types of drones.},
	urldate = {2020-05-26}
}

@misc{reid_multirotor_2017,
	title = {Multirotor {Motor} {Guide}},
	url = {https://www.rotordronepro.com/guide-multirotor-motors/},
	abstract = {It’s easy to pick the right multirotor motors for your quadcopter when you understand the basics. Here are some guidelines to follow to choose the most effective powerplants. Where to Start? Decide on Motor Size First First answer these two questions: What’s your quadcopter’s total weight? What’s the size of the frame? The aggregate weight of your quadcopter …},
	language = {en-US},
	urldate = {2020-05-26},
	journal = {RotorDrone},
	author = {Reid, John},
	month = feb,
	year = {2017},
	note = {Library Catalog: www.rotordronepro.com
Section: Drone Sports}
}

@misc{noauthor_drone_nodate,
	title = {Drone {Thrust} {Testing}},
	url = {https://www.halfchrome.com/drone-thrust-testing/},
	abstract = {At Half Chrome, we strive to provide real quantitative metrics to back up our opinions about the drones that we test. We do careful comparisons of camera quality on our camera page. We even crash our drones to see how they hold up. Admittedly, we don’t always try to crash. Our latest quantitative metric is …  Drone Thrust Testing Read More »},
	language = {en-US},
	urldate = {2020-05-26},
	journal = {Half Chrome Drones},
	note = {Library Catalog: www.halfchrome.com}
}

@misc{noauthor_stanford_nodate,
	title = {Stanford {Robotics} {Lab}},
	url = {https://cs.stanford.edu/groups/manips/},
	abstract = {Human Centered Robotics Research},
	urldate = {2020-05-26}
}

@misc{mazzarol_is_nodate,
	title = {Is commercialising {Australia}’s research an insurmountable challenge?},
	url = {http://theconversation.com/is-commercialising-australias-research-an-insurmountable-challenge-26276},
	abstract = {Universities play a key role in a country’s national innovation system (NIS). As I discussed in a previous article, Australia’s universities perform well by international benchmarks. The level of Australia’s…},
	language = {en},
	urldate = {2020-05-26},
	journal = {The Conversation},
	author = {Mazzarol, Tim},
	note = {Library Catalog: theconversation.com}
}

@misc{mazzarol_boosting_nodate,
	title = {Boosting commercialisation of research poses a big challenge for universities},
	url = {http://theconversation.com/boosting-commercialisation-of-research-poses-a-big-challenge-for-universities-42410},
	abstract = {The government has proposed changes to how Australia's publicly funded research agencies are supported and how their performance is managed to boost the commercialisation of research.},
	language = {en},
	urldate = {2020-05-26},
	journal = {The Conversation},
	author = {Mazzarol, Tim},
	note = {Library Catalog: theconversation.com}
}

@misc{noauthor_making_2018,
	title = {Making academics compete for funding does not lead to better science},
	url = {https://sciencenordic.com/academia-forskerzonen-researcher-zone/making-academics-compete-for-funding-does-not-lead-to-better-science/1458549},
	abstract = {New study challenges accepted science policy that more competitive funding and powerful top-down university management is the best way to boost the quality of science produced.},
	language = {no},
	urldate = {2020-05-25},
	month = sep,
	year = {2018},
	note = {Library Catalog: sciencenordic.com
Section: society and culture}
}

@article{sandstrom_funding_2018,
	title = {Funding, evaluation, and the performance of national research systems},
	volume = {12},
	issn = {1751-1577},
	url = {http://www.sciencedirect.com/science/article/pii/S1751157717302882},
	doi = {10.1016/j.joi.2018.01.007},
	abstract = {Understanding the quality of science systems requires international comparative studies, which are difficult because of the lack of comparable data especially about inputs in research. In this study, we deploy an approach based on change instead of on levels of inputs and outputs: an approach that to a large extent eliminates the problem of measurement differences between countries. We firstly show that there are large differences in efficiency between national science systems, defined as the increase in output (highly cited papers) per percentage increase in input (funding). We then discuss our findings using popular explanations of performance differences: differences in funding systems (performance related or not), differences in the level of competition, differences in the level of university autonomy, and differences in the level of academic freedom. Interestingly, the available data do not support these common explanations. What the data suggest is that efficient systems are characterized by a well-developed ex post evaluation system combined with considerably high institutional funding and relatively low university autonomy (meaning a high autonomy of professionals). On the other hand, the less efficient systems have a strong ex ante control, either through a high level of so-called competitive project funding, or through strong power of the university management. Another conclusion is that more and better data are needed.},
	language = {en},
	number = {1},
	urldate = {2020-05-25},
	journal = {Journal of Informetrics},
	author = {Sandström, Ulf and Van den Besselaar, Peter},
	month = feb,
	year = {2018},
	keywords = {Bibliometrics, Citations, Input-output studies, Performance-based funding, Research efficiency, Research policy},
	pages = {365--384}
}

@misc{noauthor_dantardunizar-profiling-ros-pkg_nodate,
	title = {dantard/unizar-profiling-ros-pkg},
	url = {https://github.com/dantard/unizar-profiling-ros-pkg},
	abstract = {The ros profiling package. Contribute to dantard/unizar-profiling-ros-pkg development by creating an account on GitHub.},
	language = {en},
	urldate = {2020-05-25},
	journal = {GitHub},
	note = {Library Catalog: github.com}
}

@article{subramanian_review_2012,
	title = {A review of applications of {Analytic} {Hierarchy} {Process} in operations management},
	volume = {138},
	issn = {0925-5273},
	url = {http://www.sciencedirect.com/science/article/pii/S0925527312001442},
	doi = {10.1016/j.ijpe.2012.03.036},
	abstract = {The purpose of this paper is to review the literature on the applications of the Analytic Hierarchy Process (AHP) in operations management and suggest possible gaps from the point of view of researchers and practitioners. This paper systematically categorises the published literature from 1990 to 2009 in 291 peer reviewed journals articles (searched via Emerald, Ingenta, MetaPress, ProQuest, and ScienceDirect) and then reviews and analyses them methodologically. Our analysis has revealed that a significant number of AHP applications are found when problems require considerations of both quantitative and qualitative factors (e.g., socioeconomic operations decisions). AHP has been largely applied to macro (complex and real) and people (managerial–subjective) oriented problems. The most addressed decision themes are product and process design and, managing the supply chain. A majority of AHP applications are application or case study oriented and only a few papers aimed at contributing to AHP modelling before applying to practical problems. Our review has found that significant research gap exists in the application of AHP in the areas of forecasting, layout of facilities and managing stocks. This paper presents a comprehensive listing of AHP applications in operations management and develops a framework for identifying the decision areas that have better research gaps to be studied by future researchers.},
	language = {en},
	number = {2},
	urldate = {2020-05-22},
	journal = {International Journal of Production Economics},
	author = {Subramanian, Nachiappan and Ramanathan, Ramakrishnan},
	month = aug,
	year = {2012},
	keywords = {Analytic Hierarchy Process, Operations management, Review},
	pages = {215--241}
}

@inproceedings{galvez_serna_review_2020,
	title = {A review of current approaches for {UAV} autonomous mission planning for {Mars} biosignatures detection},
	copyright = {IEEE},
	isbn = {978-1-72812-734-7},
	url = {https://eprints.qut.edu.au/198852/},
	abstract = {Autonomous mission planning for unmanned aerial vehicles (UAVs) aims to leverage the capabilities of UAVs equipped with on-board sensors to accomplish a wide range of applications, including planetary exploration where greater science yields can be achieved at lower costs over shorter time periods. A significant body of research has already been performed with the aim of improving the autonomy of UAV missions, particularly in the areas of navigation and target identification. In this work, we review current approaches to drone navigation and exploration for planetary missions, with a focus on Mars and the main autonomy levels/techniques employed to achieve these levels. Recognising the importance of astrobiology in Mars exploration, we highlight progress in the area of autonomous biosignature detection capabilities trialed on Earth, and discuss the objectives and challenges in relation to future missions to Mars. Finally, we indicate currently available software tools and future work to improve autonomous mission planning capabilities.},
	language = {en},
	urldate = {2020-05-22},
	booktitle = {{IEEE} {Aerospace} {Conference} 2020},
	publisher = {IEEE},
	author = {Galvez Serna, Julian and Vanegas Alvarez, Fernando and Gonzalez, Felipe and Flannery, David},
	month = mar,
	year = {2020}
}

@misc{brooks_rosprofiler_2014,
	title = {rosprofiler - {ROS} {Wiki}},
	url = {http://wiki.ros.org/rosprofiler},
	language = {en},
	urldate = {2020-05-21},
	author = {Brooks, D},
	month = aug,
	year = {2014}
}

@inproceedings{forouher_data_2014,
	title = {Data {Flow} {Analysis} in {ROS}},
	abstract = {This paper presents an enhancement to the Robot Operating System (ROS), which provides statistics about the data flow between nodes inside the ROS framework. These statistics measurements include message frequency, transportation delay and other metrics on connections between ROS nodes. We enhanced an existing ROS tool, which displays connections between nodes, so that it also displays these measurements. On this basis, we further present a change detection mechanism, using these measurements to detect errors and provide an overall robot health status.},
	booktitle = {{ISR}/{Robotik} 2014; 41st {International} {Symposium} on {Robotics}},
	author = {Forouher, Dariush and Hartmann, Jan and Maehle, Erik},
	month = jun,
	year = {2014},
	pages = {1--6}
}

@incollection{bihlmaier_advanced_2016,
	address = {Cham},
	series = {Studies in {Computational} {Intelligence}},
	title = {Advanced {ROS} {Network} {Introspection} ({ARNI})},
	isbn = {978-3-319-26054-9},
	url = {https://doi.org/10.1007/978-3-319-26054-9_25},
	abstract = {This tutorial chapter gives an introduction to Advanced ROS Network Introspection (ARNI), which was released as a solution for monitoring large ROS-based robotic installations. In the spirit of infrastructure monitoring (like Nagios), we generate metadata about all hosts, nodes, topics and connections, in order to monitor and specify the state of distributed robot software based on ROS. ARNI provides a more in-depth view of what is going on within the ROS computation graph out of the box. Any existing ROS node and host can be introspected without prior modification or recompilation. This extends from live network properties to host and node specific ones by running an additional node on each host of the ROS network. Furthermore, it is possible to define reference values for the state of all ROS components based on their metadata attributes. Subsequently, ARNI provides a mechanism to take countermeasures on detection of a violated specification. All features are modular and can be used without modifying existing ROS software. ARNI was written for ROS Indigo and this tutorial has been tested on Ubuntu Trusty (14.04). A link to the source code repository together with complementary information is available at http://wiki.ros.org/arni.},
	language = {en},
	urldate = {2020-05-19},
	booktitle = {Robot {Operating} {System} ({ROS}): {The} {Complete} {Reference} ({Volume} 1)},
	publisher = {Springer International Publishing},
	author = {Bihlmaier, Andreas and Hadlich, Matthias and Wörn, Heinz},
	editor = {Koubaa, Anis},
	year = {2016},
	doi = {10.1007/978-3-319-26054-9_25},
	keywords = {Introspection, Monitoring, Reliability, Safety},
	pages = {651--670}
}

@misc{goh_analytic_nodate,
	title = {Analytic hierarchy process for robot selection - {QUT} {Library}},
	url = {https://qut.primo.exlibrisgroup.com/discovery/fulldisplay?docid=wos000071151100007&context=PC&vid=61QUT_INST:61QUT&lang=en&search_scope=MyInst_and_CI&adaptor=Primo%20Central&tab=Everything&query=any,contains,analytic%20hierarchy%20process%20robotics&facet=rtype,exclude,reviews&facet=rtype,exclude,newspaper_articles&offset=0},
	urldate = {2020-05-19},
	author = {Goh, Ch}
}

@article{ataei_monte_2013,
	title = {Monte {Carlo} {Analytic} {Hierarchy} {Process} ({MAHP}) approach to selection of optimum mining method},
	volume = {23},
	issn = {2095-2686},
	url = {http://www.sciencedirect.com/science/article/pii/S209526861300116X},
	doi = {10.1016/j.ijmst.2013.07.017},
	abstract = {One of the most critical and complicated steps in mine design is a selection of suitable mining method based upon geological, geotechnical, geographical, safety and economical parameters. The aim of this study is developing a Monte Carlo simulation to selection the optimum mining method by using effective and major criteria and at the same time, taking subjective judgments of decision makers into consideration. Proposed approach is based on the combination of Monte Carlo simulation with conventional Analytic Hierarchy Process (AHP). Monte Carlo simulation is used to determine the confidence level of each alternative’s score, is calculated by AHP, with the respect to the variance of decision makers’ opinion. The proposed method is applied for Jajarm Bauxite Mine in Iran and eventually the most appropriate mining methods for this mine are ranked.},
	language = {en},
	number = {4},
	urldate = {2020-05-19},
	journal = {International Journal of Mining Science and Technology},
	author = {Ataei, Mohammad and Shahsavany, Hashem and Mikaeil, Reza},
	month = jul,
	year = {2013},
	keywords = {AHP, Mining method selection, Monte Carlo simulation, Multi-criteria decision making},
	pages = {573--578}
}

@article{muhlbacher_analytic_2013,
	title = {Der {Analytic} {Hierarchy} {Process} ({AHP}): {Eine} {Methode} zur {Entscheidungsunterstützung} im {Gesundheitswesen}},
	volume = {11},
	issn = {1868-677X},
	shorttitle = {Der {Analytic} {Hierarchy} {Process} ({AHP})},
	url = {https://doi.org/10.1007/s40275-014-0011-8},
	doi = {10.1007/s40275-014-0011-8},
	abstract = {Regulatory decision bodies and clinical decision-makers have to decide on the approval, pricing and individualized treatment of patients. This decision is based on the assessment of the risk-benefit or cost-benefit ratios. The assessment of benefits often relies on multiple patient-relevant endpoints. Thereby the results of the clinical effects can be contrary. The more endpoints and the more heterogeneous the results, the more complex is the decision-making. The Analytic Hierarchy Process (AHP) is proposed to solve this problem by weighting multiple decision criteria.},
	language = {de},
	number = {2},
	urldate = {2020-05-19},
	journal = {PharmacoEconomics German Research Articles},
	author = {Mühlbacher, Axel C. and Kaczynski, Anika},
	month = oct,
	year = {2013},
	pages = {119--132}
}

@article{dahri_monte_2017,
	title = {Monte {Carlo} simulation-aided analytical hierarchy process ({AHP}) for flood susceptibility mapping in {Gabes} {Basin} (southeastern {Tunisia})},
	volume = {76},
	issn = {1866-6299},
	url = {https://doi.org/10.1007/s12665-017-6619-4},
	doi = {10.1007/s12665-017-6619-4},
	abstract = {Flash floods are among the most severe hazards which have disastrous environmental, human, and economic impacts. This study is interested in the characterization of flood hazard in Gabes Catchment (southeastern Tunisia), considered as an important step for flood management in the region. Analytical hierarchy process (AHP) and geographic information system are applied to delineate and characterize flood areas. A spatial database was developed based on geological map, digital elevation model, land use, and rainfall data in order to evaluate the different factors susceptible to affect flood analysis. However, the uncertainties that are associated with AHP techniques may significantly impact the results. Flood susceptibility is analyzed as a function of weights using Monte Carlo (MC) simulation and Global sensitivity analysis. AHP and MC–AHP models gave similar results. However, compared to AHP approach, MC–AHP confidence intervals (95\%) of the overall scores had small overlaps. Results obtained were validated by remote sensing data for the zones that showed very high flood hazard during the extreme rainfall event of June 2014 that hit the study basin.},
	language = {en},
	number = {7},
	urldate = {2020-05-19},
	journal = {Environmental Earth Sciences},
	author = {Dahri, Noura and Abida, Habib},
	month = apr,
	year = {2017},
	pages = {302}
}

@misc{noauthor_quantopian_2020,
	title = {Quantopian},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Quantopian&oldid=952114203},
	abstract = {Quantopian is a Boston-based company that aims to create a crowd-sourced hedge fund by letting freelance quantitative analysts develop, test, and use trading algorithms to buy and sell securities.. Its primary competitors are other open source trading platforms mainly Numerai, QuantConnect, \& WorldQuant.},
	language = {en},
	urldate = {2020-05-17},
	journal = {Wikipedia},
	month = apr,
	year = {2020},
	note = {Page Version ID: 952114203}
}

@misc{noauthor_free_nodate,
	title = {Free {Stock} {API} and {Financial} {Statements} {API} - {FMP} {API}},
	url = {https://financialmodelingprep.com/developer/docs},
	abstract = {This documentation includes a financial statements API, a free stock API and a historical quotes API. Find all companies financial reports, company stock prices in Real-time.},
	urldate = {2020-05-16},
	journal = {Financial Modeling Prep},
	note = {Library Catalog: financialmodelingprep.com}
}

@misc{noauthor_income_nodate,
	title = {Income {Statement}, {Balance} {Sheet} and {Cashflows} are coming up as an empty dataframe · {Issue} \#191 · ranaroussi/yfinance},
	url = {https://github.com/ranaroussi/yfinance/issues/191},
	abstract = {Income Statement, Balance Sheet and Cashflows are coming up as an empty data frame. This is because variable url in base.py is being updated to /quote//holders in line 283 and when fetching the fin...},
	language = {en},
	urldate = {2020-05-10},
	journal = {GitHub},
	note = {Library Catalog: github.com}
}

@misc{noauthor_models_nodate,
	title = {Models — investpy 0.9.14 documentation},
	url = {https://investpy.readthedocs.io/models.html},
	urldate = {2020-05-10}
}

@misc{manu_codingfun_python_2020,
	title = {Python {Stock} {Analysis} — {Balance} {Sheet} {Trend} {Analysis}},
	url = {https://towardsdatascience.com/python-stock-analysis-balance-sheet-trend-analysis-18e6eb63cdc},
	abstract = {I used to have plenty of Excel templates pre-build in Excel in order to analyse stocks of any company of my interest. My old process was…},
	language = {en},
	urldate = {2020-05-10},
	journal = {Medium},
	author = {Manu (CodingFun), Jose},
	month = jan,
	year = {2020},
	note = {Library Catalog: towardsdatascience.com}
}

@misc{noauthor_reading_nodate,
	title = {Reading {Financial} {Statements} into {Python} {Pandas} - {Episode} 4},
	url = {https://www.youtube.com/watch?v=IKznctrWlrM},
	abstract = {How to Read Financial Statements (income statement) into Python Pandas from SimFin data for Value Investing Stock Analysis Series, Episode 4

Source Code: https://github.com/taewookim/YouTube/...},
	urldate = {2020-05-10}
}

@misc{noauthor_ralgotrading_nodate,
	title = {r/algotrading - {Tradestation} web api vs. {IB} {API}},
	url = {https://www.reddit.com/r/algotrading/comments/3y3fih/tradestation_web_api_vs_ib_api/},
	abstract = {12 votes and 9 comments so far on Reddit},
	language = {en-US},
	urldate = {2020-05-10},
	journal = {reddit},
	note = {Library Catalog: www.reddit.com}
}

@misc{noauthor_ralgotrading_nodate-1,
	title = {r/algotrading - {Tradestation} {API}},
	url = {https://www.reddit.com/r/algotrading/comments/9hczek/tradestation_api/},
	abstract = {3 votes and 2 comments so far on Reddit},
	language = {en-US},
	urldate = {2020-05-10},
	journal = {reddit},
	note = {Library Catalog: www.reddit.com}
}

@inproceedings{sikang_liu_high_2016,
	title = {High speed navigation for quadrotors with limited onboard sensing},
	doi = {10.1109/ICRA.2016.7487284},
	abstract = {We address the problem of high speed autonomous navigation of quadrotor micro aerial vehicles with limited onboard sensing and computation. In particular, we propose a dual range planning horizon method to safely and quickly navigate quadrotors to specified goal locations in previously unknown and unstructured environments. In each planning epoch, a short-range planner uses a local map to generate a new trajectory. At the same time, a safe stopping policy is found. This allows the robot to come to an emergency halt when necessary. Our algorithm guarantees collision avoidance and demonstrates important advances in real-time planning. First, our novel short range planning method allows us to generate and re-plan trajectories that are dynamically feasible, comply with state and input constraints, and avoid obstacles in real-time. Further, previous planning algorithms abstract away the obstacle detection problem by assuming the instantaneous availability of geometric information about the environment. In contrast, our method addresses the challenge of using the raw sensor data to form a map and navigate in real-time. Finally, in addition to simulation examples, we provide physical experiments that demonstrate the entire algorithmic pipeline from obstacle detection to trajectory execution.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Sikang Liu and Watterson, Michael and Tang, Sarah and Kumar, Vijay},
	month = may,
	year = {2016},
	keywords = {Collision avoidance, Navigation, Planning, Real-time systems, Robot sensing systems, Trajectory, autonomous aerial vehicles, dual range planning horizon method, geometric information, helicopters, high speed autonomous navigation, obstacle detection, path planning, quadrotor microaerial vehicles, short-range planner, stopping policy, trajectory control, trajectory execution, trajectory generation, trajectory planning},
	pages = {1484--1491}
}

@article{nielsen_neural_2015,
	title = {Neural {Networks} and {Deep} {Learning}},
	url = {http://neuralnetworksanddeeplearning.com},
	language = {en},
	urldate = {2020-05-07},
	author = {Nielsen, Michael A.},
	year = {2015},
	note = {Publisher: Determination Press}
}

@book{klaas_machine_2019,
	edition = {1st edition},
	title = {Machine {Learning} for {Finance}},
	abstract = {A guide to advances in machine learning for financial professionals, with working Python code Key Features Explore advances in machine learning and how to put them to work in financial industries Clear explanation and expert discussion of how machine learning works, with an emphasis on financial applications Deep coverage of advanced machine learning approaches including neural networks, GANs, and reinforcement learning Book Description Machine Learning for Finance explores new advances in machine learning and shows how they can be applied across the financial sector, including in insurance, transactions, and lending. It explains the concepts and algorithms behind the main machine learning techniques and provides example Python code for implementing the models yourself. The book is based on Jannes Klaas' experience of running machine learning training courses for financial professionals. Rather than providing ready-made financial algorithms, the book focuses on the advanced ML concepts and ideas that can be applied in a wide variety of ways. The book shows how machine learning works on structured data, text, images, and time series. It includes coverage of generative adversarial learning, reinforcement learning, debugging, and launching machine learning products. It discusses how to fight bias in machine learning and ends with an exploration of Bayesian inference and probabilistic programming. What you will learn Apply machine learning to structured data, natural language, photographs, and written text How machine learning can detect fraud, forecast financial trends, analyze customer sentiments, and more Implement heuristic baselines, time series, generative models, and reinforcement learning in Python, scikit-learn, Keras, and TensorFlow Dig deep into neural networks, examine uses of GANs and reinforcement learning Debug machine learning applications and prepare them for launch Address bias and privacy concerns in machine learning Who this book is for This book is ideal for readers who understand math and Python, and want to adopt machine learning in financial applications. The book assumes college-level knowledge of math and statistics. Downloading the example code for this ebook: You can download the example code files for this ebook on GitHub at the following link: https://github.com/PacktPublishing/Machine-Learning-for-Finance . If you require support please email: customercarepackt.com},
	language = {eng},
	publisher = {Packt Publishing},
	author = {Klaas, Jannes},
	collaborator = {Safari, an O’Reilly Media Company},
	year = {2019},
	keywords = {Electronic books}
}

@misc{sentdex_python_nodate,
	title = {Python {Programming} for {Finance}},
	url = {https://pythonprogramming.net/getting-stock-prices-python-programming-for-finance/},
	urldate = {2020-05-07},
	author = {SentDex, Harrison}
}

@article{tardioli_pound_2019,
	title = {Pound: {A} multi-master {ROS} node for reducing delay and jitter in wireless multi-robot networks},
	volume = {111},
	issn = {0921-8890},
	shorttitle = {Pound},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889017309144},
	doi = {10.1016/j.robot.2018.10.009},
	abstract = {The Robot Operating System (ROS) is a popular and widely used software framework for building robotics systems. With the growth of its popularity, it has started to be used in multi-robot systems as well. However, the TCP connections that the platform relies on for connecting the so-called ROS nodes presents several issues regarding limited-bandwidth, delays, and jitter, when used in wireless multi-hop networks. In this paper, we present a thorough analysis of the problem and propose a new ROS node called Pound to improve the wireless communication performance by reducing delay and jitter in data exchanges, especially in multi-hop networks. Pound allows the use of multiple ROS masters (roscores), features data compression, and importantly, introduces a priority scheme that allows favoring more important flows over less important ones. We compare Pound to the state-of-the-art solutions through extensive experiments and show that it performs equally well, or better in all the test cases, including a control-over-network example.},
	language = {en},
	urldate = {2020-05-07},
	journal = {Robotics and Autonomous Systems},
	author = {Tardioli, Danilo and Parasuraman, Ramviyas and Ögren, Petter},
	month = jan,
	year = {2019},
	keywords = {Delay, Jitter, Multi-robot systems, Robot operating system, Wireless multi-hop networks},
	pages = {73--87}
}

@misc{noauthor_linux_nodate,
	title = {Linux {Users} and {Groups}},
	url = {https://www.linode.com/docs/tools-reference/linux-users-and-groups/},
	abstract = {An introduction to the principal concepts and use of the users and groups system in Linux systems.},
	language = {en},
	urldate = {2020-05-07},
	journal = {Linode Guides \& Tutorials},
	note = {Library Catalog: www.linode.com}
}

@inproceedings{chao_efficient_2010,
	title = {Efficient parallelized particle filter design on {CUDA}},
	doi = {10.1109/SIPS.2010.5624805},
	abstract = {Particle filtering is widely used in numerous nonlinear applications which require reconfigurability, fast prototyping, and online parallel signal processing. The emerging computing platform, CUDA, may be regarded as the most appealing platform for such implementation. However, there are not yet literatures exploring how to utilize CUDA for particle filters. This parer aims to provide two design techniques, A) finite-redraw importance-maximizing (FRIM) prior editing and B) localized resampling, for efficient implementation of particle filters on CUDA, which can be verified to reduce global operations and provide significant speedup. The modifications on algorithm and architectural mapping are evaluated with conceptual and quantitative analysis. From the classic bearings-only tracking experiments, the proposed design is 5.73 times faster than the direct implementation on GeForce 9400m.},
	booktitle = {2010 {IEEE} {Workshop} {On} {Signal} {Processing} {Systems}},
	author = {Chao, Min-An and Chu, Chun-Yuan and Chao, Chih-Hao and Wu, An-Yeu},
	month = oct,
	year = {2010},
	note = {ISSN: 2162-3570},
	keywords = {Accuracy, Atmospheric measurements, CUDA, Computer architecture, Degradation, GPGPU, GeForce 9400m, Graphics processing unit, Instruction sets, Particle filter, Particle measurements, finite redraw importance maximizing, online parallel signal processing, parallel processing, parallelized particle filter design, particle filtering (numerical methods), signal processing},
	pages = {299--304}
}

@misc{michaelwillett_particle_2020,
	title = {Particle {Filter} {SLAM} with {CUDA}},
	url = {https://github.com/michaelwillett/CUDA-Particle-Filter},
	abstract = {Contribute to michaelwillett/CUDA-Particle-Filter development by creating an account on GitHub.},
	urldate = {2020-05-07},
	author = {michaelwillett},
	month = apr,
	year = {2020},
	note = {original-date: 2016-11-09T16:48:14Z}
}

@article{williams_roofline_2009,
	title = {Roofline: an insightful visual performance model for multicore architectures},
	volume = {52},
	issn = {0001-0782},
	shorttitle = {Roofline},
	url = {http://doi.org/10.1145/1498765.1498785},
	doi = {10.1145/1498765.1498785},
	abstract = {The Roofline model offers insight on how to improve the performance of software and hardware.},
	number = {4},
	urldate = {2020-05-06},
	journal = {Communications of the ACM},
	author = {Williams, Samuel and Waterman, Andrew and Patterson, David},
	month = apr,
	year = {2009},
	pages = {65--76}
}

@article{krishnan_sky_2020,
	title = {The {Sky} {Is} {Not} the {Limit}: {A} {Visual} {Performance} {Model} for {Cyber}-{Physical} {Co}-{Design} in {Autonomous} {Machines}},
	volume = {19},
	issn = {1556-6064},
	shorttitle = {The {Sky} {Is} {Not} the {Limit}},
	doi = {10.1109/LCA.2020.2981022},
	abstract = {We introduce the “Formula-1” (F-1) roofline model to understand the role of computing in aerial autonomous machines. The model provides insights by exploiting the fundamental relationships between various components in an aerial robot, such as sensor framerate, compute performance, and body dynamics (physics). F-1 serves as a tool that can aid computer and cyber-physical system architects to understand the optimal design (or selection) of various components in the development of autonomous machines.},
	number = {1},
	journal = {IEEE Computer Architecture Letters},
	author = {Krishnan, Srivatsan and Wan, Zishen and Bhardwaj, Kshitij and Whatmough, Paul and Faust, Aleksandra and Wei, Gu-Yeon and Brooks, David and Reddi, Vijay Janapa},
	month = jan,
	year = {2020},
	note = {Conference Name: IEEE Computer Architecture Letters},
	keywords = {Acceleration, Computational modeling, Cyber-physical system, Heuristic algorithms, Robot sensing systems, Unmanned aerial vehicles, Visualization, aerial autonomous machines, performance model, robot learning, system architecture},
	pages = {38--42}
}

@misc{tatan_12_2019,
	title = {In 12 minutes: {Stocks} {Analysis} with {Pandas} and {Scikit}-{Learn}},
	shorttitle = {In 12 minutes},
	url = {https://towardsdatascience.com/in-12-minutes-stocks-analysis-with-pandas-and-scikit-learn-a8d8a7b50ee7},
	abstract = {Analyse, Visualize and Predict stocks prices quickly with Python},
	language = {en},
	urldate = {2020-05-06},
	journal = {Medium},
	author = {Tatan, Vincent},
	month = may,
	year = {2019},
	note = {Library Catalog: towardsdatascience.com}
}

@misc{noauthor_peoplenet_nodate,
	title = {{PeopleNet} {\textbar} {NVIDIA} {NGC}},
	url = {https://ngc.nvidia.com/catalog/models/nvidia:tlt_peoplenet/version},
	urldate = {2020-05-05}
}

@article{cohen_perfect_2017,
	title = {The perfect wave},
	volume = {358},
	copyright = {Copyright © 2017 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/358/6364/711},
	doi = {10.1126/science.358.6364.711},
	abstract = {A scientist and a surfer team up to convert a landlocked lake into The Endless Summer dream
A scientist and a surfer team up to convert a landlocked lake into The Endless Summer dream},
	language = {en},
	number = {6364},
	urldate = {2020-05-05},
	journal = {Science},
	author = {Cohen, Jon},
	month = nov,
	year = {2017},
	pmid = {29123046},
	note = {Publisher: American Association for the Advancement of Science
Section: Feature},
	pages = {711--713}
}

@misc{noauthor_power_2019,
	title = {Power supply considerations for {Jetson} {Nano} {Developer} {Kit}},
	url = {https://forums.developer.nvidia.com/t/power-supply-considerations-for-jetson-nano-developer-kit/71637},
	abstract = {Out of the box, the Jetson Nano Developer Kit is configured to accept power via the Micro-USB connector. You’ll need to power the developer kit with a good quality power supply that can deliver 5V⎓2A at the developer kit’s Micro-USB port. Not every power supply rated at “5V⎓2A” will actually do this.  The power supply will need to consistently deliver ≥4.75V to avoid brownout condition.  Note that some USB cables can lead to additional voltage droop.  See the Jetson Nano Supported Components Lis...},
	language = {en-US},
	urldate = {2020-05-01},
	journal = {NVIDIA Developer Forums},
	month = mar,
	year = {2019},
	note = {Library Catalog: forums.developer.nvidia.com}
}

@article{kawaharazuka_musculoskeletal_2020,
	title = {Musculoskeletal {AutoEncoder}: {A} {Unified} {Online} {Acquisition} {Method} of {Intersensory} {Networks} for {State} {Estimation}, {Control}, and {Simulation} of {Musculoskeletal} {Humanoids}},
	volume = {5},
	issn = {2377-3766},
	shorttitle = {Musculoskeletal {AutoEncoder}},
	doi = {10.1109/LRA.2020.2972841},
	abstract = {While the musculoskeletal humanoid has various biomimetic benefits, the modeling of its complex structure is difficult, and many learning-based systems have been developed so far. There are various methods, such as control methods using acquired relationships between joints and muscles represented by a data table or neural network, and state estimation methods using Extended Kalman Filter or table search. In this letter, we construct a Musculoskeletal AutoEncoder representing the relationship among joint angles, muscle tensions, and muscle lengths, and propose a unified method of state estimation, control, and simulation of musculoskeletal humanoids using it. By updating the Musculoskeletal AutoEncoder online using the actual robot sensor information, we can continuously conduct more accurate state estimation, control, and simulation than before the online learning. We conducted several experiments using the musculoskeletal humanoid Musashi, and verified the effectiveness of this study.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Kawaharazuka, Kento and Tsuzuki, Kei and Onitsuka, Moritaka and Asano, Yuki and Okada, Kei and Kawasaki, Koji and Inaba, Masayuki},
	month = apr,
	year = {2020},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Biomimetics, Humanoid robots, Muscles, Robot sensing systems, State estimation, Training, biomimetic benefits, biomimetics, humanoid robots, intersensory networks, joint angles, learning (artificial intelligence), learning-based systems, mobile robots, muscle, muscle lengths, muscle tensions, musculoskeletal autoencoder, musculoskeletal humanoid Musashi, musculoskeletal humanoids, online learning, robot sensor information, sensors, state estimation, state estimation methods, tendon/wire mechanism, unified online acquisition method},
	pages = {2411--2418}
}

@article{schmid_efficient_2020,
	title = {An {Efficient} {Sampling}-{Based} {Method} for {Online} {Informative} {Path} {Planning} in {Unknown} {Environments}},
	volume = {5},
	issn = {2377-3766},
	doi = {10.1109/LRA.2020.2969191},
	abstract = {The ability to plan informative paths online is essential to robot autonomy. In particular, sampling-based approaches are often used as they are capable of using arbitrary information gain formulations. However, they are prone to local minima, resulting in sub-optimal trajectories, and sometimes do not reach global coverage. In this letter, we present a new RRT*-inspired online informative path planning algorithm. Our method continuously expands a single tree of candidate trajectories and rewires nodes to maintain the tree and refine intermediate paths. This allows the algorithm to achieve global coverage and maximize the utility of a path in a global context, using a single objective function. We demonstrate the algorithm's capabilities in the applications of autonomous indoor exploration as well as accurate Truncated Signed Distance Field (TSDF)-based 3D reconstruction on-board a Micro Aerial Vehicle (MAV). We study the impact of commonly used information gain and cost formulations in these scenarios and propose a novel TSDF-based 3D reconstruction gain and cost-utility formulation. Detailed evaluation in realistic simulation environments show that our approach outperforms sampling-based state of the art methods in these tasks. Experiments on a real MAV demonstrate the ability of our method to robustly plan in real-time, exploring an indoor environment with on-board sensing and computation. We make our framework available for future research.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Schmid, Lukas and Pantic, Michael and Khanna, Raghav and Ott, Lionel and Siegwart, Roland and Nieto, Juan},
	month = apr,
	year = {2020},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Linear programming, Motion and path planning, Planning, Robots, Surface reconstruction, TSDF-based 3D reconstruction gain, Three-dimensional displays, Trajectory, aerial systems, aircraft control, arbitrary information gain formulations, autonomous aerial vehicles, autonomous indoor exploration, cost formulations, cost-utility formulation, global coverage, image reconstruction, indoor environment, information gain, informative paths, local minima, mobile robots, online informative path planning, optimisation, path planning, perception and autonomy, reactive and sensor-based planning, realistic simulation environments, robot autonomy, robot vision, robustly plan, sampling methods, sampling-based approaches, single objective function, suboptimal trajectories, truncated signed distance field-based 3D reconstruction on-board},
	pages = {1500--1507}
}

@article{druon_visual_2020,
	title = {Visual {Object} {Search} by {Learning} {Spatial} {Context}},
	volume = {5},
	issn = {2377-3766},
	doi = {10.1109/LRA.2020.2967677},
	abstract = {We present a visual navigation approach that uses context information to navigate an agent to find and reach a target object. To learn context from the objects present in the scene, we transform visual information into an intermediate representation called context grid which essentially represents how much the object at the location is semantically similar to the target object. As this representation can encode the target object and other objects together, it allows us to navigate an agent in a human-inspired way: the agent will go to the likely place by seeing surrounding context objects in the beginning when the target is not visible and, once the target object comes into sight, it will reach the target quickly. Since context grid does not directly contain visual or semantic feature values that change according to introductions of new objects, such as new instances of the same object with different appearance or an object from a slightly different class, our navigation model generalizes well to unseen scenes/objects. Experimental results show that our approach outperforms previous approaches in navigating in unseen scenes, especially for broad scenes. We also evaluated human performances in the target-driven navigation task and compared with machine learning based navigation approaches including this work.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Druon, Raphael and Yoshiyasu, Yusuke and Kanezaki, Asako and Watt, Alassane},
	month = apr,
	year = {2020},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Deep learning in robotics and automation, Feature extraction, Navigation, Search problems, Semantics, Task analysis, Three-dimensional displays, Visualization, autonomous agents, context grid, context information, learning (artificial intelligence), mobile robots, navigation, object detection, robot vision, semantic feature values, spatial context, surrounding context objects, target object, target-driven navigation task, visual feature values, visual information, visual navigation approach, visual object search, visual-based navigation},
	pages = {1279--1286}
}

@book{thrun_probabilistic_2005,
	address = {Cambridge, Mass},
	series = {Intelligent robotics and autonomous agents.},
	title = {Probabilistic robotics},
	isbn = {978-0-262-20162-9},
	url = {http://probabilistic-robotics.org/},
	abstract = {"Probabilistic robotics is a new and growing area in robotics, concerned with perception and control in the face of uncertainty. Building on the field of mathematical statistics, probabilistic robotics endows robots with a new level of robustness in real-world situations." "Probabilistic Robotics introduces the reader to a wealth of techniques and algorithms in the field. All algorithms are based on a single overarching mathematical foundation. Each chapter provides example implementations in pseudo code, detailed mathematical derivations, discussions from a practitioner's perspective, and extensive lists of exercises and class projects. The book's Web site, http://www.probabilistic-robotics.org, has additional material." "The book is relevant for anyone involved in robotic software development and scientific research. It will also be of interest to applied statisticians and engineers dealing with real-world sensor data."--BOOK JACKET., Probabilistic robotics is a new and growing area in robotics, concerned with perception and control in the face of uncertainty. Building on the field of mathematical statistics, probabilistic robotics endows robots with a new level of robustness in real-world situations.},
	language = {eng},
	publisher = {MIT Press},
	author = {Thrun, Sebastian},
	collaborator = {Burgard, Wolfram and Fox, Dieter},
	year = {2005},
	keywords = {Artificial intelligence, Probabilities, Robotics}
}

@misc{noauthor_stefan_nodate,
	title = {Stefan {Hrabar} - {CEO} and {Co}-{Founder} - {Emesent} {\textbar} {LinkedIn}},
	url = {https://au.linkedin.com/in/stefanhrabar},
	abstract = {View Stefan Hrabar’s profile on LinkedIn, the world's largest professional community. Stefan has 3 jobs listed on their profile. See the complete profile on LinkedIn and discover Stefan’s connections and jobs at similar companies.},
	language = {en},
	urldate = {2020-04-29},
	note = {Library Catalog: au.linkedin.com}
}

@misc{seita_ingredients_nodate,
	title = {The {Ingredients} of {Real} {World} {Robotic} {Reinforcement} {Learning}},
	url = {http://bair.berkeley.edu/blog/2020/04/27/ingredients/},
	abstract = {The BAIR Blog},
	urldate = {2020-04-29},
	journal = {The Berkeley Artificial Intelligence Research Blog},
	author = {Seita, Daniel},
	note = {Library Catalog: bair.berkeley.edu}
}

@misc{noauthor_principles_2017,
	title = {Principles, {Statistical} and {Computational} {Tools} for {Reproducible} {Science}},
	url = {https://online-learning.harvard.edu/course/principles-statistical-and-computational-tools-reproducible-science},
	abstract = {Learn skills and tools that support data science and reproducible research, to ensure you can trust your own research results, reproduce them yourself, and communicate them to others.},
	language = {en},
	urldate = {2020-04-28},
	journal = {Harvard Online Courses},
	month = oct,
	year = {2017},
	note = {Library Catalog: online-learning.harvard.edu}
}

@misc{koplik_persistent_2019,
	title = {Persistent {Homology}: {A} {Non}-{Mathy} {Introduction} with {Examples}},
	shorttitle = {Persistent {Homology}},
	url = {https://towardsdatascience.com/persistent-homology-with-examples-1974d4b9c3d0},
	abstract = {Using Topological Data Analysis (TDA) Tools in Data Science},
	language = {en},
	urldate = {2020-04-27},
	journal = {Medium},
	author = {Koplik, Gary},
	month = oct,
	year = {2019},
	note = {Library Catalog: towardsdatascience.com}
}

@misc{noauthor_speeding_2020,
	title = {Speeding {Up} {Deep} {Learning} {Inference} {Using} {TensorRT}},
	url = {https://devblogs.nvidia.com/speeding-up-deep-learning-inference-using-tensorrt/},
	abstract = {This is an updated version of How to Speed Up Deep Learning Inference Using TensorRT. This version starts from a PyTorch model instead of the ONNX model, upgrades the sample application to use…},
	language = {en-US},
	urldate = {2020-04-26},
	journal = {NVIDIA Developer Blog},
	month = apr,
	year = {2020},
	note = {Library Catalog: devblogs.nvidia.com}
}

@misc{noauthor_portfolio_nodate,
	title = {Portfolio {Performance}},
	url = {https://www.portfolio-performance.info/},
	abstract = {Portfolio Performance ist ein Open Source Programm zur Berechnung der Performance eines Gesamtportfolios anhand von True-Time Weighted Rate of Return und internem Zinsfuß.},
	language = {de},
	urldate = {2020-04-22},
	note = {Library Catalog: www.portfolio-performance.info}
}

@misc{noauthor_visualization_nodate,
	title = {Visualization with {Seaborn} {\textbar} {Python} {Data} {Science} {Handbook}},
	url = {https://jakevdp.github.io/PythonDataScienceHandbook/04.14-visualization-with-seaborn.html},
	urldate = {2020-04-22}
}

@misc{noauthor_how_nodate,
	title = {How to change directory permissions in {Linux}},
	url = {https://www.pluralsight.com/blog/it-ops/linux-file-permissions},
	abstract = {Learn how to change directory permissions in Linux for individuals, groups, and everyone, using both letter and number codes.},
	language = {en},
	urldate = {2020-04-22},
	note = {Library Catalog: www.pluralsight.com}
}

@misc{noauthor_git_nodate,
	title = {Git - {Tagging}},
	url = {https://git-scm.com/book/en/v2/Git-Basics-Tagging},
	urldate = {2020-04-21}
}

@article{cervera_roslab_2019,
	title = {{ROSLab}: {Sharing} {ROS} {Code} {Interactively} {With} {Docker} and {JupyterLab}},
	volume = {26},
	issn = {1558-223X},
	shorttitle = {{ROSLab}},
	doi = {10.1109/MRA.2019.2916286},
	abstract = {The success of the Robot Operating System (ROS) and the advance of open source ideas have radically changed and improved the experience of sharing software among members of the robotics community. Yet the lack of a suitable workflow for continuous integration and verification in robotics represents a significant obstacle to developing software that can be run by independent users for testing and reusing purposes.},
	number = {3},
	journal = {IEEE Robotics Automation Magazine},
	author = {Cervera, Enric and Del Pobil, Angel P.},
	month = sep,
	year = {2019},
	note = {Conference Name: IEEE Robotics Automation Magazine},
	keywords = {Automation, Documentation, Kinetic theory, Libraries, Robots, Software, Testing},
	pages = {64--69}
}

@misc{opencv_latest_2020,
	type = {Blog},
	title = {Latest {Trends} of {Object} {Detection}: {From} {CornerNet} to {CenterNet} {Explained}. {Part} {I}: {CornerNet}},
	url = {https://opencv.org/latest-trends-of-object-detection-from-cornernet-to-centernet-explained-part-i-cornernet/},
	urldate = {2020-04-21},
	journal = {OpenCV Blog},
	author = {OpenCV},
	month = sep,
	year = {2020}
}

@misc{noauthor_key_nodate,
	title = {Key {Papers} in {Deep} {RL} — {Spinning} {Up} documentation},
	url = {https://spinningup.openai.com/en/latest/spinningup/keypapers.html},
	urldate = {2020-04-21}
}

@article{brewin_comparison_2020,
	title = {Comparison of {Two} {Methods} for {Measuring} {Sea} {Surface} {Temperature} {When} {Surfing}},
	volume = {1},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2673-1924/1/1/2},
	doi = {10.3390/oceans1010002},
	abstract = {Nearshore coastal waters are among the most dynamic regions on the planet and difficult to sample from conventional oceanographic platforms. It has been suggested that environmental sampling of the nearshore could be improved by mobilising vast numbers of citizens who partake in marine recreational sports, like surfing. In this paper, we compared two approaches for measuring sea surface temperature (SST), an Essential Climate Variable, when surfing. One technique involved attaching a commercially-available miniature temperature logger (Onset UTBI-001 TidbiT v2) to the leash of the surfboard (tether connecting surfer and surfboard) and the second, attaching a surfboard fin (Smartfin) that contained an environmental sensor package. Between July 2017 and July 2018, 148 surfing sessions took place, 90 in the southwest UK and 58 in San Diego, California, USA. During these sessions, both Smartfin and leash sensors were deployed simultaneously. On the leash, two TidbiT v2 sensors were attached, one with (denoted LP) and one without (denoted LU) a protective boot, designed to shield the sensor from sunlight. The median temperature from each technique, during each surfing session, was extracted and compared along with independent water temperature data from a nearby pier and benthic logger, and matched with photosynthetically available radiation (PAR) data from satellite observations (used as a proxy for solar radiation during each surf). Results indicate a mean difference (   \&delta;   ) of 0.13 \&deg;C and mean absolute difference (   ϵ   ) of 0.14 \&deg;C between Smartfin and LU, and a    \&delta;    of 0.04 \&deg;C and an    ϵ    of 0.06 \&deg;C between Smartfin and LP. For UK measurements, we observed better agreement between methods (    \&delta; = 0.07     \&deg;C and     ϵ = 0.08     \&deg;C between Smartfin and LU, and     \&delta; = 0.00     \&deg;C and     ϵ = 0.03     \&deg;C between Smartfin and LP) when compared with measurements in San Diego (    \&delta; = 0.22     \&deg;C and     ϵ = 0.23     \&deg;C between Smartfin and LU, and     \&delta; = 0.08     \&deg;C and     ϵ = 0.11     \&deg;C between Smartfin and LP). Surfing SST data were found to agree well, in general, with independent temperature data from a nearby pier and benthic logger. Differences in SST between leash and Smartfin were found to correlate with PAR, both for the unprotected (LU) and protected (LP) TidbiT v2 sensors, explaining the regional differences in the comparison (PAR generally higher during US surfing sessions than UK sessions). Considering that the Smartfin is sheltered from ambient light by the surfboard, unlike the leash, results indicate the leash TidbiT v2 sensors warm with exposure to sunlight biasing the SST data positively, a result consistent with published tests on similar sensors in shallow waters. We matched all LU data collected prior to this study with satellite PAR products and corrected for solar heating. Results highlight the need to design temperature sensor packages that minimise exposure from solar heating when towed in the surface ocean.},
	language = {en},
	number = {1},
	urldate = {2020-04-20},
	journal = {Oceans},
	author = {Brewin, Robert J. W. and Cyronak, Tyler and Bresnahan, Philip J. and Andersson, Andreas J. and Richard, Jon and Hammond, Katherine and Billson, Oliver and de Mora, Lee and Jackson, Thomas and Smale, Dan and Dall’Olmo, Giorgio},
	month = mar,
	year = {2020},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {citizen science, coastal, ocean temperature, surfers},
	pages = {6--26}
}

@misc{noauthor_droid_nodate,
	title = {Droid {Cam} - using {Android} {Phone} as a webcam for {Zoom}},
	url = {http://www.dev47apps.com/droidcam/linuxx/},
	abstract = {Android Apps},
	language = {en-US},
	urldate = {2020-04-20},
	note = {Library Catalog: www.dev47apps.com}
}

@misc{noauthor_cs294-158-sp20_nodate,
	title = {{CS294}-158-{SP20} {Deep} {Unsupervised} {Learning} {Spring} 2020},
	url = {https://sites.google.com/view/berkeley-cs294-158-sp20/home},
	language = {de},
	urldate = {2020-04-19}
}

@misc{h_free_2020,
	title = {Free {Stock} {Data} for {Python} {Using} {Yahoo} {Finance} {API}},
	url = {https://towardsdatascience.com/free-stock-data-for-python-using-yahoo-finance-api-9dafd96cad2e},
	abstract = {In this post, I’m going to explore the use of integrating with the Yahoo Finance API via Python code.},
	language = {en},
	urldate = {2020-04-10},
	journal = {Medium},
	author = {H, Barney},
	month = mar,
	year = {2020},
	note = {Library Catalog: towardsdatascience.com}
}

@misc{aroussi_ranaroussiyfinance_2020,
	title = {ranaroussi/yfinance},
	copyright = {Apache-2.0},
	url = {https://github.com/ranaroussi/yfinance},
	abstract = {Yahoo! Finance market data downloader (+faster Pandas Datareader)},
	urldate = {2020-04-10},
	author = {Aroussi, Ran},
	month = apr,
	year = {2020},
	note = {original-date: 2017-05-21T10:16:15Z},
	keywords = {financial-data, fix-yahoo-finance, market-data, pandas, python, stock-data, yahoo-finance, yahoo-finance-api}
}

@misc{aroussi_reliably_nodate,
	title = {Reliably download historical market data from {Yahoo}! {Finance} with {Python}},
	url = {https://aroussi.com/post/python-yahoo-finance},
	abstract = {Ever since Yahoo! Finance decommissioned their historical data API, Python developers looked for a reliable workaround. As a result, my library, yfinance, gained momentum and was downloaded over 100,000 acording to PyPi.},
	language = {en},
	urldate = {2020-04-10},
	journal = {Ran Aroussi (Official Website)},
	author = {Aroussi, Ran},
	note = {Library Catalog: aroussi.com}
}

@misc{noauthor_press_nodate,
	title = {Press {Releases} : {DOCOMO} to {Pursue} {Collaboration} with {Skydio}, {U}.{S}. {Manufacturer} of {Autonomous} {Drones} {Capable} of {Flying} without {GPS} {Guidance}},
	shorttitle = {Press {Releases}},
	url = {https://www.nttdocomo.co.jp/english/info/media_center/pr/2020/0122_00.html},
	abstract = {TOKYO, JAPAN, January 22, 2020 --- NTT DOCOMO, INC. announced today that it has agreed to pursue collaboration on the development of drone solutions and the sales of drones in Japan and Southeast Asia with Skydio, Inc., a US-based drone manufacturer with particular expertise in the field of AI-based autonomous flying and collision avoidance. The collaboration aims at accelerating the development of industrial drone market in the territory.},
	language = {en},
	urldate = {2020-04-09},
	journal = {NTT DOCOMO Home},
	note = {Library Catalog: www.nttdocomo.co.jp}
}

@misc{chen_basketball_2020,
	title = {Basketball {GAN} - {Generate} {Ghosting} {Defensive} {Strategies} given an offensive {Sketch}},
	url = {https://github.com/chychen/BasketballGAN},
	abstract = {Basketball coaches often sketch plays on a whiteboard to help players get the ball through the net. A new AI model predicts how opponents would respond to these tactics.},
	urldate = {2020-04-09},
	author = {Chen, Jay},
	month = mar,
	year = {2020},
	note = {original-date: 2019-09-16T01:13:02Z},
	keywords = {acmmm2019, ai, basketball, deep-learning, gan, human-computer-interaction, sport}
}

@misc{noauthor_git_nodate-1,
	title = {Git {Book} - {Basic} branching and {Merging}},
	url = {https://git-scm.com/book/en/v2/Git-Branching-Basic-Branching-and-Merging},
	urldate = {2020-04-07}
}

@misc{noauthor_control_nodate,
	title = {Control {Bootcamp} - {YouTube}},
	url = {https://www.youtube.com/playlist?list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m},
	urldate = {2020-04-06}
}

@article{stone_evaluation_2016,
	title = {Evaluation of {Emerging} {Energy}-{Efficient} {Heterogeneous} {Computing} {Platforms} for {Biomolecular} and {Cellular} {Simulation} {Workloads}},
	volume = {2016},
	issn = {2164-7062},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4978513/},
	doi = {10.1109/IPDPSW.2016.130},
	abstract = {Many of the continuing scientific advances achieved through computational biology are predicated on the availability of ongoing increases in computational power required for detailed simulation and analysis of cellular processes on biologically-relevant timescales. A critical challenge facing the development of future exascale supercomputer systems is the development of new computing hardware and associated scientific applications that dramatically improve upon the energy efficiency of existing solutions, while providing increased simulation, analysis, and visualization performance. Mobile computing platforms have recently become powerful enough to support interactive molecular visualization tasks that were previously only possible on laptops and workstations, creating future opportunities for their convenient use for meetings, remote collaboration, and as head mounted displays for immersive stereoscopic viewing. We describe early experiences adapting several biomolecular simulation and analysis applications for emerging heterogeneous computing platforms that combine power-efficient system-on-chip multi-core CPUs with high-performance massively parallel GPUs. We present low-cost power monitoring instrumentation that provides sufficient temporal resolution to evaluate the power consumption of individual CPU algorithms and GPU kernels. We compare the performance and energy efficiency of scientific applications running on emerging platforms with results obtained on traditional platforms, identify hardware and algorithmic performance bottlenecks that affect the usability of these platforms, and describe avenues for improving both the hardware and applications in pursuit of the needs of molecular modeling tasks on mobile devices and future exascale computers.},
	urldate = {2020-04-03},
	journal = {IEEE International Symposium on Parallel \& Distributed Processing, Workshops and Phd Forum : [proceedings]. IEEE International Symposium on Parallel \& Distributed Processing, Workshops and Phd Forum},
	author = {Stone, John E. and Hallock, Michael J. and Phillips, James C. and Peterson, Joseph R. and Luthey-Schulten, Zaida and Schulten, Klaus},
	month = may,
	year = {2016},
	pmid = {27516922},
	pmcid = {PMC4978513},
	pages = {89--100}
}

@article{mendez_sedar_2019,
	title = {{SeDAR}: {Reading} {Floorplans} {Like} a {Human}—{Using} {Deep} {Learning} to {Enable} {Human}-{Inspired} {Localisation}},
	issn = {1573-1405},
	shorttitle = {{SeDAR}},
	url = {https://doi.org/10.1007/s11263-019-01239-4},
	doi = {10.1007/s11263-019-01239-4},
	abstract = {The use of human-level semantic information to aid robotic tasks has recently become an important area for both Computer Vision and Robotics. This has been enabled by advances in Deep Learning that allow consistent and robust semantic understanding. Leveraging this semantic vision of the world has allowed human-level understanding to naturally emerge from many different approaches. Particularly, the use of semantic information to aid in localisation and reconstruction has been at the forefront of both fields. Like robots, humans also require the ability to localise within a structure. To aid this, humans have designed high-level semantic maps of our structures called floorplans. We are extremely good at localising in them, even with limited access to the depth information used by robots. This is because we focus on the distribution of semantic elements, rather than geometric ones. Evidence of this is that humans are normally able to localise in a floorplan that has not been scaled properly. In order to grant this ability to robots, it is necessary to use localisation approaches that leverage the same semantic information humans use. In this paper, we present a novel method for semantically enabled global localisation. Our approach relies on the semantic labels present in the floorplan. Deep Learning is leveraged to extract semantic labels from RGB images, which are compared to the floorplan for localisation. While our approach is able to use range measurements if available, we demonstrate that they are unnecessary as we can achieve results comparable to state-of-the-art without them.},
	language = {en},
	urldate = {2020-04-02},
	journal = {International Journal of Computer Vision},
	author = {Mendez, Oscar and Hadfield, Simon and Pugeault, Nicolas and Bowden, Richard},
	month = sep,
	year = {2019}
}

@article{dai_curriculum_2019,
	title = {Curriculum {Model} {Adaptation} with {Synthetic} and {Real} {Data} for {Semantic} {Foggy} {Scene} {Understanding}},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-019-01182-4},
	doi = {10.1007/s11263-019-01182-4},
	abstract = {This work addresses the problem of semantic scene understanding under fog. Although marked progress has been made in semantic scene understanding, it is mainly concentrated on clear-weather scenes. Extending semantic segmentation methods to adverse weather conditions such as fog is crucial for outdoor applications. In this paper, we propose a novel method, named Curriculum Model Adaptation (CMAda), which gradually adapts a semantic segmentation model from light synthetic fog to dense real fog in multiple steps, using both labeled synthetic foggy data and unlabeled real foggy data. The method is based on the fact that the results of semantic segmentation in moderately adverse conditions (light fog) can be bootstrapped to solve the same problem in highly adverse conditions (dense fog). CMAda is extensible to other adverse conditions and provides a new paradigm for learning with synthetic data and unlabeled real data. In addition, we present four other main stand-alone contributions: (1) a novel method to add synthetic fog to real, clear-weather scenes using semantic input; (2) a new fog density estimator; (3) a novel fog densification method for real foggy scenes without known depth; and (4) the Foggy Zurich dataset comprising 3808 real foggy images, with pixel-level semantic annotations for 40 images with dense fog. Our experiments show that (1) our fog simulation and fog density estimator outperform their state-of-the-art counterparts with respect to the task of semantic foggy scene understanding (SFSU); (2) CMAda improves the performance of state-of-the-art models for SFSU significantly, benefiting both from our synthetic and real foggy data. The foggy datasets and code are publicly available.},
	language = {en},
	urldate = {2020-04-02},
	journal = {International Journal of Computer Vision},
	author = {Dai, Dengxin and Sakaridis, Christos and Hecker, Simon and Van Gool, Luc},
	month = may,
	year = {2019}
}

@article{grard_deep_2020,
	title = {Deep {Multicameral} {Decoding} for {Localizing} {Unoccluded} {Object} {Instances} from a {Single} {RGB} {Image}},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-020-01323-0},
	doi = {10.1007/s11263-020-01323-0},
	abstract = {Occlusion-aware instance-sensitive segmentation is a complex task generally split into region-based segmentations, by approximating instances as their bounding box. We address the showcase scenario of dense homogeneous layouts in which this approximation does not hold. In this scenario, outlining unoccluded instances by decoding a deep encoder becomes difficult, due to the translation invariance of convolutional layers and the lack of complexity in the decoder. We therefore propose a multicameral design composed of subtask-specific lightweight decoder and encoder–decoder units, coupled in cascade to encourage subtask-specific feature reuse and enforce a learning path within the decoding process. Furthermore, the state-of-the-art datasets for occlusion-aware instance segmentation contain real images with few instances and occlusions mostly due to objects occluding the background, unlike dense object layouts. We thus also introduce a synthetic dataset of dense homogeneous object layouts, namely Mikado, which extensibly contains more instances and inter-instance occlusions per image than these public datasets. Our extensive experiments on Mikado and public datasets show that ordinal multiscale units within the decoding process prove more effective than state-of-the-art design patterns for capturing position-sensitive representations. We also show that Mikado is plausible with respect to real-world problems, in the sense that it enables the learning of performance-enhancing representations transferable to real images, while drastically reducing the need of hand-made annotations for finetuning. The proposed dataset will be made publicly available.},
	language = {en},
	urldate = {2020-04-02},
	journal = {International Journal of Computer Vision},
	author = {Grard, Matthieu and Dellandréa, Emmanuel and Chen, Liming},
	month = mar,
	year = {2020}
}

@article{valada_self-supervised_2019,
	title = {Self-{Supervised} {Model} {Adaptation} for {Multimodal} {Semantic} {Segmentation}},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-019-01188-y},
	doi = {10.1007/s11263-019-01188-y},
	abstract = {Learning to reliably perceive and understand the scene is an integral enabler for robots to operate in the real-world. This problem is inherently challenging due to the multitude of object types as well as appearance changes caused by varying illumination and weather conditions. Leveraging complementary modalities can enable learning of semantically richer representations that are resilient to such perturbations. Despite the tremendous progress in recent years, most multimodal convolutional neural network approaches directly concatenate feature maps from individual modality streams rendering the model incapable of focusing only on the relevant complementary information for fusion. To address this limitation, we propose a mutimodal semantic segmentation framework that dynamically adapts the fusion of modality-specific features while being sensitive to the object category, spatial location and scene context in a self-supervised manner. Specifically, we propose an architecture consisting of two modality-specific encoder streams that fuse intermediate encoder representations into a single decoder using our proposed self-supervised model adaptation fusion mechanism which optimally combines complementary features. As intermediate representations are not aligned across modalities, we introduce an attention scheme for better correlation. In addition, we propose a computationally efficient unimodal segmentation architecture termed AdapNet++ that incorporates a new encoder with multiscale residual units and an efficient atrous spatial pyramid pooling that has a larger effective receptive field with more than \$\$10{\textbackslash},{\textbackslash}times \$\$10× fewer parameters, complemented with a strong decoder with a multi-resolution supervision scheme that recovers high-resolution details. Comprehensive empirical evaluations on Cityscapes, Synthia, SUN RGB-D, ScanNet and Freiburg Forest benchmarks demonstrate that both our unimodal and multimodal architectures achieve state-of-the-art performance while simultaneously being efficient in terms of parameters and inference time as well as demonstrating substantial robustness in adverse perceptual conditions.},
	language = {en},
	urldate = {2020-04-02},
	journal = {International Journal of Computer Vision},
	author = {Valada, Abhinav and Mohan, Rohit and Burgard, Wolfram},
	month = jul,
	year = {2019}
}

@article{rosu_semi-supervised_2019,
	title = {Semi-supervised {Semantic} {Mapping} {Through} {Label} {Propagation} with {Semantic} {Texture} {Meshes}},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-019-01187-z},
	doi = {10.1007/s11263-019-01187-z},
	abstract = {Scene understanding is an important capability for robots acting in unstructured environments. While most SLAM approaches provide a geometrical representation of the scene, a semantic map is necessary for more complex interactions with the surroundings. Current methods treat the semantic map as part of the geometry which limits scalability and accuracy. We propose to represent the semantic map as a geometrical mesh and a semantic texture coupled at independent resolution. The key idea is that in many environments the geometry can be greatly simplified without loosing fidelity, while semantic information can be stored at a higher resolution, independent of the mesh. We construct a mesh from depth sensors to represent the scene geometry and fuse information into the semantic texture from segmentations of individual RGB views of the scene. Making the semantics persistent in a global mesh enables us to enforce temporal and spatial consistency of the individual view predictions. For this, we propose an efficient method of establishing consensus between individual segmentations by iteratively retraining semantic segmentation with the information stored within the map and using the retrained segmentation to re-fuse the semantics. We demonstrate the accuracy and scalability of our approach by reconstructing semantic maps of scenes from NYUv2 and a scene spanning large buildings.},
	language = {en},
	urldate = {2020-04-02},
	journal = {International Journal of Computer Vision},
	author = {Rosu, Radu Alexandru and Quenzel, Jan and Behnke, Sven},
	month = jun,
	year = {2019}
}

@article{stutz_learning_2018,
	title = {Learning {3D} {Shape} {Completion} {Under} {Weak} {Supervision}},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-018-1126-y},
	doi = {10.1007/s11263-018-1126-y},
	abstract = {We address the problem of 3D shape completion from sparse and noisy point clouds, a fundamental problem in computer vision and robotics. Recent approaches are either data-driven or learning-based: Data-driven approaches rely on a shape model whose parameters are optimized to fit the observations; Learning-based approaches, in contrast, avoid the expensive optimization step by learning to directly predict complete shapes from incomplete observations in a fully-supervised setting. However, full supervision is often not available in practice. In this work, we propose a weakly-supervised learning-based approach to 3D shape completion which neither requires slow optimization nor direct supervision. While we also learn a shape prior on synthetic data, we amortize, i.e., learn, maximum likelihood fitting using deep neural networks resulting in efficient shape completion without sacrificing accuracy. On synthetic benchmarks based on ShapeNet (Chang et al. Shapenet: an information-rich 3d model repository, 2015. arXiv:1512.03012) and ModelNet (Wu et al., in: Proceedings of IEEE conference on computer vision and pattern recognition (CVPR), 2015) as well as on real robotics data from KITTI (Geiger et al., in: Proceedings of IEEE conference on computer vision and pattern recognition (CVPR), 2012) and Kinect (Yang et al., 3d object dense reconstruction from a single depth view, 2018. arXiv:1802.00411), we demonstrate that the proposed amortized maximum likelihood approach is able to compete with the fully supervised baseline of Dai et al. (in: Proceedings of IEEE conference on computer vision and pattern recognition (CVPR), 2017) and outperforms the data-driven approach of Engelmann et al. (in: Proceedings of the German conference on pattern recognition (GCPR), 2016), while requiring less supervision and being significantly faster.},
	language = {en},
	urldate = {2020-04-02},
	journal = {International Journal of Computer Vision},
	author = {Stutz, David and Geiger, Andreas},
	month = oct,
	year = {2018}
}

@article{gupta_cognitive_2019,
	title = {Cognitive {Mapping} and {Planning} for {Visual} {Navigation}},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-019-01236-7},
	doi = {10.1007/s11263-019-01236-7},
	abstract = {We introduce a neural architecture for navigation in novel environments. Our proposed architecture learns to map from first-person views and plans a sequence of actions towards goals in the environment. The Cognitive Mapper and Planner (CMP) is based on two key ideas: (a) a unified joint architecture for mapping and planning, such that the mapping is driven by the needs of the task, and (b) a spatial memory with the ability to plan given an incomplete set of observations about the world. CMP constructs a top-down belief map of the world and applies a differentiable neural net planner to produce the next action at each time step. The accumulated belief of the world enables the agent to track visited regions of the environment. We train and test CMP on navigation problems in simulation environments derived from scans of real world buildings. Our experiments demonstrate that CMP outperforms alternate learning-based architectures, as well as, classical mapping and path planning approaches in many cases. Furthermore, it naturally extends to semantically specified goals, such as “going to a chair”. We also deploy CMP on physical robots in indoor environments, where it achieves reasonable performance, even though it is trained entirely in simulation.},
	language = {en},
	urldate = {2020-04-02},
	journal = {International Journal of Computer Vision},
	author = {Gupta, Saurabh and Tolani, Varun and Davidson, James and Levine, Sergey and Sukthankar, Rahul and Malik, Jitendra},
	month = oct,
	year = {2019}
}

@article{wu_model-based_2019,
	title = {Model-{Based} {Robot} {Imitation} with {Future} {Image} {Similarity}},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-019-01238-5},
	doi = {10.1007/s11263-019-01238-5},
	abstract = {We present a visual imitation learning framework that enables learning of robot action policies solely based on expert samples without any robot trials. Robot exploration and on-policy trials in a real-world environment could often be expensive/dangerous. We present a new approach to address this problem by learning a future scene prediction model solely from a collection of expert trajectories consisting of unlabeled example videos and actions, and by enabling action selection using future image similarity. In this approach, the robot learns to visually imagine the consequences of taking an action, and obtains the policy by evaluating how similar the predicted future image is to an expert sample. We develop an action-conditioned convolutional autoencoder, and present how we take advantage of future images for zero-online-trial imitation learning. We conduct experiments in simulated and real-life environments using a ground mobility robot with and without obstacles in reaching target objects. We explicitly compare our models to multiple baseline methods requiring only offline samples. The results confirm that our proposed methods perform superior to previous methods, including 1.5 \$\${\textbackslash}times \$\$× and 2.5 \$\${\textbackslash}times \$\$× higher success rate in two different tasks than behavioral cloning.},
	language = {en},
	urldate = {2020-04-02},
	journal = {International Journal of Computer Vision},
	author = {Wu, A. and Piergiovanni, A. J. and Ryoo, M. S.},
	month = oct,
	year = {2019}
}

@article{hu_image-based_2019,
	title = {Image-{Based} {Geo}-{Localization} {Using} {Satellite} {Imagery}},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-019-01186-0},
	doi = {10.1007/s11263-019-01186-0},
	abstract = {The problem of localization on a geo-referenced satellite map given a query ground view image is useful yet remains challenging due to the drastic change in viewpoint. To this end, in this paper we work on the extension of our earlier work on the Cross-View Matching Network (CVM-Net) (Hu et al. in IEEE conference on computer vision and pattern recognition (CVPR), 2018) for the ground-to-aerial image matching task since the traditional image descriptors fail due to the drastic viewpoint change. In particular, we show more extensive experimental results and analyses of the network architecture on our CVM-Net. Furthermore, we propose a Markov localization framework that enforces the temporal consistency between image frames to enhance the geo-localization results in the case where a video stream of ground view images is available. Experimental results show that our proposed Markov localization framework can continuously localize the vehicle within a small error on our Singapore dataset.},
	language = {en},
	urldate = {2020-04-02},
	journal = {International Journal of Computer Vision},
	author = {Hu, Sixing and Lee, Gim Hee},
	month = jun,
	year = {2019}
}

@article{wu_correction_2019,
	title = {Correction to: {Model}-{Based} {Robot} {Imitation} with {Future} {Image} {Similarity}},
	issn = {1573-1405},
	shorttitle = {Correction to},
	url = {https://doi.org/10.1007/s11263-019-01272-3},
	doi = {10.1007/s11263-019-01272-3},
	abstract = {The acknowledgement section was omitted in the original version of this article, which is given below.},
	language = {en},
	urldate = {2020-04-02},
	journal = {International Journal of Computer Vision},
	author = {Wu, A. and Piergiovanni, A. J. and Ryoo, M. S.},
	month = dec,
	year = {2019}
}

@article{angelova_special_2020,
	title = {Special {Issue} on {Deep} {Learning} for {Robotic} {Vision}},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-020-01324-z},
	doi = {10.1007/s11263-020-01324-z},
	language = {en},
	urldate = {2020-04-02},
	journal = {International Journal of Computer Vision},
	author = {Angelova, Anelia and Carneiro, Gustavo and Sünderhauf, Niko and Leitner, Jürgen},
	month = mar,
	year = {2020}
}

@article{angelova_special_2020-1,
	title = {Special {Issue} on {Deep} {Learning} for {Robotic} {Vision}},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-020-01324-z},
	doi = {10.1007/s11263-020-01324-z},
	language = {en},
	urldate = {2020-04-02},
	journal = {International Journal of Computer Vision},
	author = {Angelova, Anelia and Carneiro, Gustavo and Sünderhauf, Niko and Leitner, Jürgen},
	month = mar,
	year = {2020}
}

@misc{noauthor_elc2009_nodate,
	title = {{ELC2009}: {Visualizing} memory usage with smem [{LWN}.net]},
	url = {https://lwn.net/Articles/329458/},
	urldate = {2020-03-31}
}

@misc{noauthor_elc_nodate,
	title = {{ELC}: {How} much memory are applications really using? [{LWN}.net]},
	url = {https://lwn.net/Articles/230975/},
	urldate = {2020-03-31}
}

@misc{rodola_random_2016,
	title = {Random writings and thoughts about {Python}: psutil 4.0.0 and how to get "real" process memory and environ in {Python}},
	shorttitle = {Random writings and thoughts about {Python}},
	url = {http://grodola.blogspot.com/2016/02/psutil-4-real-process-memory-and-environ.html},
	urldate = {2020-03-31},
	journal = {Random writings and thoughts about Python},
	author = {Rodola, Giampaolo},
	month = feb,
	year = {2016},
	note = {Library Catalog: Blogger},
	keywords = {environ, job, memory, memory uss, prague, process, pss, psutil, python, swap}
}

@misc{noauthor_psutil_nodate,
	title = {{PSutil} {Memory} documentation},
	url = {https://psutil.readthedocs.io/en/latest/#psutil.Process.memory_full_info},
	urldate = {2020-03-31}
}

@misc{noauthor_matrix-matrix_nodate,
	title = {Matrix-{Matrix} {Multiplication} on the {GPU} with {Nvidia} {CUDA} {\textbar} {QuantStart}},
	url = {https://www.quantstart.com/articles/Matrix-Matrix-Multiplication-on-the-GPU-with-Nvidia-CUDA/},
	urldate = {2020-03-31}
}

@inproceedings{gallos_active_2019,
	title = {Active {Vision} in the {Era} of {Convolutional} {Neural} {Networks}},
	doi = {10.1109/CRV.2019.00019},
	abstract = {In this work, we examine the literature of active object recognition in the past and present. We note that methods in the past used a notion of recognition ambiguity in order to find a next best view policy that could disambiguate the object with the fewest camera moves. Present methods on the other hand use deep reinforcement learning to learn camera control policies from the data. We show on a public dataset, that reinforcement learning methods are not superior to a policy of adequately sampling the object view-sphere. Instead of focusing on finding the next best view, we examine a recent method of quantifying recognition uncertainty in deep learning as a potential application to active object recognition. We find that predictions with this technique are well calibrated with respect to the performance of a network on a test-set, showing that it could be useful in an active vision scenario.},
	booktitle = {2019 16th {Conference} on {Computer} and {Robot} {Vision} ({CRV})},
	author = {Gallos, Dimitrios and Ferrie, Frank},
	month = may,
	year = {2019},
	keywords = {Cameras, Data acquisition, Deep learning, Lighting, Object recognition, Reinforcement learning, Uncertainty, active object recognition, active vision, camera control policies, cameras, convolutional neural nets, convolutional neural networks, deep learning, deep reinforcement learning, learning (artificial intelligence), object recognition, object view-sphere, recognition uncertainty, reinforcement learning, uncertainty},
	pages = {81--88}
}

@inproceedings{gonzalez_qut_2019,
	title = {{QUT} {Indoor} {Flying} {Arena}: {A} flexible teaching and learning space for aerospace and robotics engineering, and high school students.},
	copyright = {Aquellos autores/as que envíen propuestas aceptan los términos siguientes:   Los autores conceden a favor de los organizadores del congreso una licencia de uso de forma no exclusiva, con carácter gratuito y para el ámbito territorial mundial y durante el tiempo legal que duren los derechos de autor, para reproducir y comunicar públicamente el resumen de su propuesta a través de la página web del Congreso. Esta publicación irá siempre acompañada del nombre y apellidos del/los autor/es.},
	shorttitle = {{QUT} {Indoor} {Flying} {Arena}},
	url = {https://conferences.epistemopolis.org/index.php/educacion-y-aprendizaje/EDU2019/paper/view/9185},
	abstract = {The aerospace and robotics sector can provide a vast amount of learning opportunities for STEM fields. The large range of task difficulty in projects related to these sectors allows these opportunities to be relevant to all students, from high school level up to the far end of higher education. The ability to physically test prototypes developed by students provides a much greater sense of engagement. STEM concepts for high school students can be applied in a fundamental way to reinforce both their knowledge and practical skills, with higher education students able to delve in-depth into complex concepts while still being able to see the practical outcomes of their coursework or research. The aim of this paper is to describe the development and use of the Indoor Flying Arena (IFA) at Queensland University of Technology (QUT).

The IFA was developed primarily for engineering courses in aerospace and robotics, but is also used for the annual high school science week hosted by QUT. The flying arena is a 10x8x4m netted area which allows for hands-on prototyping and testing of flying drones in a safe and controlled manner. The IFA provides a flexible teaching environment and allows for multiple levels of task difficulty through the facet of programming drones. Student projects generally involve tasks such as gathering and analyzing telemetry data, designing control systems, and using navigation commands to move the drone around the flight space. Results show that the IFA allows for higher experimentation repeatability, and provides a higher level of reinforcement in the theoretical and practical knowledge of the students. The IFA also shows beneficial results from a teaching perspective, including consistency in marking, as well as an overall increase in student engagement, motivation, and participation},
	language = {En},
	urldate = {2020-03-26},
	booktitle = {[2019] {Congreso} {Internacional} de {Educación} y {Aprendizaje}},
	author = {Gonzalez, Luis Felipe},
	month = mar,
	year = {2019}
}

@article{welburn_navigational_2019,
	title = {A {Navigational} {System} for {Quadcopter} {Remote} {Inspection} of {Offshore} {Substations}},
	url = {https://www.research.manchester.ac.uk/portal/en/publications/a-navigational-system-for-quadcopter-remote-inspection-of-offshore-substations(6931ea92-70fa-4ea4-973d-d1e83c8081c0).html},
	language = {English},
	urldate = {2020-03-26},
	journal = {The Fifteenth International Conference on Autonomic and Autonomous Systems 2019},
	author = {Welburn, Elisabeth and Khalili, Hassan Hakim and Gupta, Ananya and Watson, Simon and Carrasco, Joaquin},
	month = jun,
	year = {2019}
}

@inproceedings{al-kaff_vbii-uav_2017,
	address = {Cham},
	series = {Advances in {Intelligent} {Systems} and {Computing}},
	title = {{VBII}-{UAV}: {Vision}-{Based} {Infrastructure} {Inspection}-{UAV}},
	isbn = {978-3-319-56538-5},
	shorttitle = {{VBII}-{UAV}},
	doi = {10.1007/978-3-319-56538-5_24},
	abstract = {Unmanned Aerial Vehicles (UAV) have the capabilities to undertake tasks in remote, dangerous and dull situations. One of these situations is the infrastructure inspection, at which, using the UAV decreases the risk and the operation time of the task comparing to a human inspector. Therefore, this paper presents a small vision-based UAV with the capability of inspection tasks of a civil and industrial infrastructure. The presented system is divided into three main algorithms; Depth-Color image correlation, Plane segmentation and distance estimation and Visual servoing. The system has been validated with real flight tests, and the obtained results show the accuracy of the system in both inspection measurements and the UAV maneuver controlling.},
	language = {en},
	booktitle = {Recent {Advances} in {Information} {Systems} and {Technologies}},
	publisher = {Springer International Publishing},
	author = {Al-Kaff, Abdulla and Moreno, Francisco Miguel and José, Luis Javier San and García, Fernando and Martín, David and de la Escalera, Arturo and Nieva, Alberto and Garcéa, José Luis Meana},
	editor = {Rocha, Álvaro and Correia, Ana Maria and Adeli, Hojjat and Reis, Luís Paulo and Costanzo, Sandra},
	year = {2017},
	keywords = {Computer vision, Inspection, UAV, Visual servoing},
	pages = {221--231}
}
@inproceedings{acuna_vision-based_2018,
	title = {Vision-{Based} {UAV} {Landing} on a {Moving} {Platform} in {GPS} {Denied} {Environments} {Using} {Motion} {Prediction}},
	doi = {10.1109/LARS/SBR/WRE.2018.00096},
	abstract = {In this paper, we propose a vision-based control system which enables a multi-rotor unmanned aerial vehicle (UAV) to track an unmanned ground vehicle (UGV) and land on it by using mainly the input of an integrated vision sensor without external localization systems. Our solution is able to generate and follow agile approaching maneuvers in which the target vehicle may leave the field of view of the UAV's vision sensor. This is particularly relevant in scenarios where external localization systems such as GPS are not available or not reliable. In our approach, the UAV observes the movement of the UGV, predicts its motion and generates a smooth approach trajectory to the predicted position. A 6-DOF controller in cascade form is used to track the trajectory, which can lead to movements were the UGV is lost from the field of view (FOV), and then once the UGV is back on the FOV a normal visual servoing tracking is used for landing. The UAV states required for the control law were obtained from an Extended Kalman Filter in combination with a Mahony complementary filter using only internal sensors. The control law and the landing state machine were implemented in ROS and the simulations were developed on Gazebo based on the Rotors simulator.},
	booktitle = {2018 {Latin} {American} {Robotic} {Symposium}, 2018 {Brazilian} {Symposium} on {Robotics} ({SBR}) and 2018 {Workshop} on {Robotics} in {Education} ({WRE})},
	author = {Acuna, Raul and Zhang, Ding and Willert, Volker},
	month = nov,
	year = {2018},
	keywords = {Cameras, FOV, GPS denied environments, Global Positioning System, Kalman filters, Target tracking, Trajectory, UAV, UAV states, UAV vision sensor, UGV, Unmanned aerial vehicles, Visual servoing, autonomous aerial vehicles, autonomous landing, control engineering computing, control law, external localization systems, integrated vision sensor, internal sensors, landing state machine, mobile robots, motion prediction, moving platform, multirotor unmanned aerial vehicle, normal visual servoing tracking, position control, predicted position, remotely operated vehicles, robot vision, smooth approach trajectory, target vehicle, tracking, vision-based UAV landing, vision-based control system, visual servoing},
	pages = {515--521}
}

@inproceedings{acuna_moma_2018,
	title = {{MOMA}: {Visual} {Mobile} {Marker} {Odometry}},
	shorttitle = {{MOMA}},
	doi = {10.1109/IPIN.2018.8533685},
	abstract = {In this paper, we present a cooperative visual odometry system based on the detection of mobile markers. To this end, we introduce a simple scheme that realizes visual mobile marker odometry via accurate fixed marker-based camera positioning and we discuss the characteristics of errors inherent to the method compared to classical fixed marker-based navigation and visual odometry. The proposed cooperative scheme has the advantage of not needing any feature or fiducial marker in the environment, which can be used for indoor and underwater applications where it can be harder to extract reliable features. We provide specific configurations of UAV and UGV robots including one that allows continuous movements of the UAV, and a minimal caterpillar-like configuration that works with one UGV alone. Finally, we present a real-world implementation and an evaluation of the proposed configurations.},
	booktitle = {2018 {International} {Conference} on {Indoor} {Positioning} and {Indoor} {Navigation} ({IPIN})},
	author = {Acuna, Raul and Li, Zaijuan and Willert, Volker},
	month = sep,
	year = {2018},
	note = {ISSN: 2471-917X},
	keywords = {Cameras, MOMA, Pose estimation, Robot kinematics, SLAM (robots), Three-dimensional displays, UAV, UAV robots, UGV, UGV robots, Visual odometry, Visualization, accurate fixed marker-based camera positioning, autonomous aerial vehicles, autonomous underwater vehicles, cameras, cooperative, cooperative visual odometry system, distance measurement, fiducial marker, indoor applications, mobile marker detection, mobile robots, object detection, path planning, pose estimation, robot vision, robots, underwater applications, visual mobile marker odometry, visual odometry},
	pages = {206--212}
}

@inproceedings{li_cooperative_2018,
	title = {Cooperative {Localization} by {Fusing} {Pose} {Estimates} from {Static} {Environmental} and {Mobile} {Fiducial} {Features}},
	doi = {10.1109/LARS/SBR/WRE.2018.00021},
	abstract = {In this paper, we propose a novel, purely vision-based cooperative localization approach for the multi-robot system to collaboratively improve the localization robustness and accuracy by fusing absolute pose estimates from static environment features with relative pose estimates from known mobile fiducial features. The fusion algorithm is formulated as an optimization problem combining two different objectives for two different feature sources based on the same error measure, namely the reprojection error. The optimization is solved at an on-line frame-by-frame rate to produce optimal positioning results during the robots' movement. The fiducial markers are attached to the mobile robots, thus no marker intervention is needed to add into the environment. A comparison between our cooperative localization approach and state-of-the-art localization algorithms for different configurations concerning various testing environments is given validating the improvements on both robustness and accuracy.},
	booktitle = {2018 {Latin} {American} {Robotic} {Symposium}, 2018 {Brazilian} {Symposium} on {Robotics} ({SBR}) and 2018 {Workshop} on {Robotics} in {Education} ({WRE})},
	author = {Li, Zaijuan and Acuna, Raul and Willert, Volker},
	month = nov,
	year = {2018},
	keywords = {Cameras, Measurement uncertainty, Robot kinematics, Robot vision systems, Robustness, cooperative localization, fiducial feature, fiducial markers, fusion algorithm, localization approach, mobile fiducial features, mobile robots, multi-robot systems, multirobot system, optimisation, optimization problem, pose estimates, pose estimation, pose fusion, robot vision, robots movement, static environment features, vision-based cooperative localization},
	pages = {65--70}
}

@inproceedings{acuna_dynamic_2018,
	title = {Dynamic {Markers}: {UAV} {Landing} {Proof} of {Concept}},
	shorttitle = {Dynamic {Markers}},
	doi = {10.1109/LARS/SBR/WRE.2018.00093},
	abstract = {In this paper, we introduce a dynamic fiducial marker which can change its appearance according to the spatiotemporal requirements of the visual perception task of a mobile robot using a camera as the sensor. We present a control scheme to dynamically change the appearance of the marker in order to increase the range of detection and to assure a better accuracy on the close range. The marker control takes into account the camera to marker distance (which influences the scale of the marker in image coordinates) to select which fiducial markers to display. Hence, we realize a tight coupling between the visual pose control of the mobile robot and the appearance of the dynamic fiducial marker. Additionally, we discuss the practical implications of time delays due to processing time and communication delays between the robot and the marker. Finally, we propose a real-time dynamic marker visual servoing control scheme for quadcopter landing and evaluate the performance on a real-world example.},
	booktitle = {2018 {Latin} {American} {Robotic} {Symposium}, 2018 {Brazilian} {Symposium} on {Robotics} ({SBR}) and 2018 {Workshop} on {Robotics} in {Education} ({WRE})},
	author = {Acuna, Raul and Willert, Volker},
	month = nov,
	year = {2018},
	keywords = {Cameras, Robot kinematics, Three-dimensional displays, UAV, UAV landing proof, Visual servoing, Visualization, autonomous aerial vehicles, cameras, dynamic fiducial marker, dynamic marker, dynamic markers, entry, descent and landing (spacecraft), fiducial marker, fiducial markers, helicopters, image sensors, landing, marker control, marker distance, mobile robot, mobile robots, real-time dynamic marker visual servoing control scheme, robot vision, visual perception, visual perception task, visual servoing},
	pages = {496--502}
}

@article{maciel-pearson_multi-task_2019,
	title = {Multi-{Task} {Regression}-{Based} {Learning} for {Autonomous} {Unmanned} {Aerial} {Vehicle} {Flight} {Control} {Within} {Unstructured} {Outdoor} {Environments}},
	volume = {4},
	issn = {2377-3774},
	doi = {10.1109/LRA.2019.2930496},
	abstract = {Increased growth in the global unmanned aerial vehicles (UAV) (drone) industry has expanded possibilities for fully autonomous UAV applications. A particular application which has in part motivated this research is the use of UAV in wide area search and surveillance operations in unstructured outdoor environments. The critical issue with such environments is the lack of structured features that could aid in autonomous flight, such as road lines or paths. In this letter, we propose an end-to-end multi-task regression-based learning approach capable of defining flight commands for navigation and exploration under the forest canopy, regardless of the presence of trails or additional sensors (i.e., GPS). Training and testing are performed using a software in the loop pipeline, which allows for a detailed evaluation against state-of-the-art pose estimation techniques. Our extensive experiments demonstrate that our approach excels in performing dense exploration within the required search perimeter, is capable of covering wider search regions, generalises to previously unseen and unexplored environments and outperforms contemporary state-ofthe-art techniques.},
	number = {4},
	journal = {IEEE Robotics and Automation Letters},
	author = {Maciel-Pearson, Bruna G. and Akçay, Samet and Atapour-Abarghouei, Amir and Holder, Christopher and Breckon, Toby P.},
	month = oct,
	year = {2019},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Aerial systems: perception and autonomy, Cameras, Collision avoidance, Forestry, Global Positioning System, Quaternions, Unmanned aerial vehicles, aerospace control, autonomous aerial vehicles, autonomous unmanned aerial vehicle flight control, autonomous vehicle navigation, computer vision for other robotic applications, deep learning in robotics and automation, end-to-end multitask regression-based learning, flight commands, forest canopy, fully autonomous UAV applications, global unmanned aerial vehicles industry, learning (artificial intelligence), path planning, regression analysis, rescue robots, road lines, robot vision, search perimeter, surveillance operations, unstructured outdoor environments, wide area search},
	pages = {4116--4123}
}

@article{gottipati_deep_2019,
	title = {Deep {Active} {Localization}},
	volume = {4},
	issn = {2377-3774},
	doi = {10.1109/LRA.2019.2932575},
	abstract = {Active localization consists of generating robot actions that allow it to maximally disambiguate its pose within a reference map. Traditional approaches use an information-theoretic criterion for action selection and hand-crafted perceptual models. In this work we propose an end-to-end differentiable method for learning to take informative actions that is trainable entirely in simulation and then transferable to real robot hardware with zero refinement. The system is composed of two learned modules: a convolutional neural network for perception, and a deep reinforcement learned planning module. We leverage a multi-scale approach in the perceptual model since the accuracy needed to take actions using reinforcement learning is much less than the accuracy needed for robot control. We demonstrate that the resulting system outperforms traditional approach for either perception or planning. We also demonstrate our approach's robustness to different map configurations and other nuisance parameters through the use of domain randomization in training. The code has been released: https://github.com/montrealrobotics/dal and is compatible with the OpenAI gym framework, as well as the Gazebo simulator.},
	number = {4},
	journal = {IEEE Robotics and Automation Letters},
	author = {Gottipati, Sai Krishna and Seo, Keehong and Bhatt, Dhaivat and Mai, Vincent and Murthy, Krishna and Paull, Liam},
	month = oct,
	year = {2019},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {AI-based methods, Deep learning, Localization, Motion planning, Path planning, Robot localization, Robot sensing systems, deep learning in robotics and automation, motion and path planning},
	pages = {4394--4401}
}

@article{nguyen_mavnet_2019,
	title = {{MAVNet}: {An} {Effective} {Semantic} {Segmentation} {Micro}-{Network} for {MAV}-{Based} {Tasks}},
	volume = {4},
	issn = {2377-3774},
	shorttitle = {{MAVNet}},
	doi = {10.1109/LRA.2019.2928734},
	abstract = {Real-time semantic image segmentation on platforms subject to size, weight, and power constraints is a key area of interest for air surveillance and inspection. In this letter, we propose MAVNet: a small, light-weight, deep neural network for real-time semantic segmentation on micro aerial vehicles (MAVs). MAVNet, inspired by ERFNet [E. Romera, J. M. lvarez, L. M. Bergasa, and R. Arroyo, “ErfNet: Efficient residual factorized convnet for real-time semantic segmentation,” IEEE Trans. Intell. Transp. Syst., vol. 19, no. 1, pp. 263–272, Jan. 2018.], features 400 times fewer parameters and achieves comparable performance with some reference models in empirical experiments. Additionally, we provide two novel datasets that represent challenges in semantic segmentation for real-time MAV tracking and infrastructure inspection tasks and verify MAVNet on these datasets. Our algorithm and datasets are made publicly available.},
	number = {4},
	journal = {IEEE Robotics and Automation Letters},
	author = {Nguyen, Ty and Shivakumar, Shreyas S. and Miller, Ian D. and Keller, James and Lee, Elijah S. and Zhou, Alex and Özaslan, Tolga and Loianno, Giuseppe and Harwood, Joseph H. and Wozencraft, Jennifer and Taylor, Camillo J. and Kumar, Vijay},
	month = oct,
	year = {2019},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Autonomous aerial vehicles, Deep learning, Image segmentation, Object detection, Real-time systems, Semantics, Target tracking, aerial systems: perception and autonomy, recognition, segmentation and categorization, semantic scene understanding, semantic segmentation},
	pages = {3908--3915}
}

@article{liu_submodular_2019,
	title = {Submodular {Optimization} for {Coupled} {Task} {Allocation} and {Intermittent} {Deployment} {Problems}},
	volume = {4},
	issn = {2377-3774},
	doi = {10.1109/LRA.2019.2925301},
	abstract = {In this letter, we demonstrate a formulation for optimizing coupled submodular maximization problems with provable sub-optimality bounds. In robotics applications, it is quite common that optimization problems are coupled with one another and therefore cannot be solved independently. Specifically, we consider two problems coupled if the outcome of the first problem affects the solution of a second problem that operates over a longer time scale. For example, in our motivating problem of environmental monitoring, we posit that multi-robot task allocation will potentially impact environmental dynamics and thus influence the quality of future monitoring, here modeled as a multi-robot intermittent deployment problem. The general theoretical approach for solving this type of coupled problem is demonstrated through this motivating example. Specifically, we propose a method for solving coupled problems modeled by submodular set functions with matroid constraints. A greedy algorithm for solving this class of problem is presented, along with sub-optimality guarantees. Finally, practical optimality ratios are shown through Monte Carlo simulations to demonstrate that the proposed algorithm can generate near-optimal solutions with high efficiency.},
	number = {4},
	journal = {IEEE Robotics and Automation Letters},
	author = {Liu, Jun and Williams, Ryan K.},
	month = oct,
	year = {2019},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {Environmental monitoring, Monte Carlo methods, Monte Carlo simulation, Multi-robot systems, Optimization, Resource management, Robot kinematics, Robot sensing systems, Task analysis, combinatorial mathematics, coupled, coupled problem, coupled task allocation, environmental monitoring, greedy algorithm, greedy algorithms, matrix algebra, multi-robot systems, multirobot intermittent deployment problem, multirobot task allocation, near-optimal solutions, optimality ratios, optimisation, provable sub-optimality bounds, robotics applications, scheduling and coordination, sub-optimality guarantees, submodular, submodular maximization problems, submodular optimization, submodular set functions},
	pages = {3169--3176}
}

@misc{ithinkwell_phd_nodate,
	title = {{PhD} {Toolkit}},
	url = {http://www.ithinkwell.com.au/resources/PhDToolkit},
	urldate = {2020-03-17},
	journal = {PhD Toolkit - Ithinkwell},
	author = {ithinkwell}
}

@misc{noauthor_which_nodate,
	title = {Which rating is better, mathematically speaking? {\textbar} {Probabilities} of probabilities, part 1 - {YouTube}},
	url = {https://www.youtube.com/watch?v=8idr1WZ1A7Q},
	urldate = {2020-03-16}
}

@book{david_i_spivak_category_2014,
	title = {Category {Theory} for the {Sciences}},
	copyright = {http://creativecommons.org/licenses/by-nc-sa/3.0/},
	url = {http://archive.org/details/cattheory},
	abstract = {Category theory was invented in the 1940s to unify and synthesize different areas in mathematics, and it has proven remarkably successful in enabling powerful communication between disparate fields and subfields within mathematics. This book shows that category theory can be useful outside of mathematics as a rigorous, flexible, and coherent modeling language throughout the sciences. Information is inherently dynamic; the same ideas can be organized and reorganized in countless ways, and the ability to translate between such organizational structures is becoming increasingly important in the sciences. Category theory offers a unifying framework for information modeling that can facilitate the translation of knowledge between disciplines.

Written in an engaging and straightforward style, and assuming little background in mathematics, the book is rigorous but accessible to non-mathematicians. Using databases as an entry to category theory, it begins with sets and functions, then introduces the reader to notions that are fundamental in mathematics: monoids, groups, orders, and graphs—categories in disguise. After explaining the “big three” concepts of category theory—categories, functors, and natural transformations—the book covers other topics, including limits, colimits, functor categories, sheaves, monads, and operads. The book explains category theory by examples and exercises rather than focusing on theorems and proofs. It includes more than 300 exercises, with solutions. 

Category Theory for the Sciences is intended to create a bridge between the vast array of mathematical concepts used by mathematicians and the models and frameworks of such scientific disciplines as computation, neuroscience, and physics.

Print and digital editions available from MIT Press. Archived by Unglue.it},
	language = {eng},
	urldate = {2020-03-11},
	author = {{David I. Spivak}},
	year = {2014},
	keywords = {category theory}
}

@article{loquercio_general_2020,
	title = {A {General} {Framework} for {Uncertainty} {Estimation} in {Deep} {Learning}},
	volume = {5},
	issn = {2377-3774},
	doi = {10.1109/LRA.2020.2974682},
	abstract = {Neural networks predictions are unreliable when the input sample is out of the training distribution or corrupted by noise. Being able to detect such failures automatically is fundamental to integrate deep learning algorithms into robotics. Current approaches for uncertainty estimation of neural networks require changes to the network and optimization process, typically ignore prior knowledge about the data, and tend to make over-simplifying assumptions which underestimate uncertainty. To address these limitations, we propose a novel framework for uncertainty estimation. Based on Bayesian belief networks and Monte-Carlo sampling, our framework not only fully models the different sources of prediction uncertainty, but also incorporates prior data information, e.g. sensor noise. We show theoretically that this gives us the ability to capture uncertainty better than existing methods. In addition, our framework has several desirable properties: (i) it is agnostic to the network architecture and task; (ii) it does not require changes in the optimization process; (iii) it can be applied to already trained architectures. We thoroughly validate the proposed framework through extensive experiments on both computer vision and control tasks, where we outperform previous methods by up to 23\% in accuracy. The video available at https://youtu.be/X7n-bRS5vSM shows qualitative results of our experiments. The project's code is available at: https://tinyurl.com/s3nygw7.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Loquercio, Antonio and Segu, Mattia and Scaramuzza, Davide},
	month = apr,
	year = {2020},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {AI-based methods, Data models, Deep learning in robotics and automation, Estimation, Neural networks, Robot sensing systems, Task analysis, Uncertainty, probability and statistical methods},
	pages = {3153--3160}
}

@misc{noauthor_davis_nodate,
	title = {{DAVIS}: {Densely} {Annotated} {VIdeo} {Segmentation}},
	url = {https://davischallenge.org/},
	urldate = {2020-03-11}
}

@article{cutting_how_1997,
	title = {How the eye measures reality and virtual reality},
	volume = {29},
	issn = {1532-5970},
	url = {https://doi.org/10.3758/BF03200563},
	doi = {10.3758/BF03200563},
	abstract = {If virtual reality systems are to make good on their name, designers must know how people perceive space in natural environments, in photographs, and in cinema. Perceivers understand the layout of a cluttered natural environment through the use of nine or more sources of information, each based on different assumptions—occlusion, height in the visual field, relative size, relative density, aerial perspective, binocular disparities, accommodation, convergence, and motion perspective. The relative utility of these sources at different distances is compared, using their ordinal depth-threshold functions. From these, three classes of space around a moving observer are postulated: personal space, action space, and vista space. Within each, a smaller number of sources act in consort, with different relative strengths. Given the general ordinality of the sources, these spaces are likely to be affine in character, stretching and collapsing with viewing conditions. One of these conditions is controlled by lens length in photography and cinematography or by field-of-view commands in computer graphics. These have striking effects on many of these sources of information and, consequently, on how the layout of a scene is perceived.},
	language = {en},
	number = {1},
	urldate = {2020-03-11},
	journal = {Behavior Research Methods, Instruments, \& Computers},
	author = {Cutting, James E.},
	month = mar,
	year = {1997},
	pages = {27--36}
}

@inproceedings{dang_visual_2018,
	title = {Visual {Saliency}-{Aware} {Receding} {Horizon} {Autonomous} {Exploration} with {Application} to {Aerial} {Robotics}},
	doi = {10.1109/ICRA.2018.8460992},
	abstract = {This paper presents a novel strategy for autonomous visual saliency-aware receding horizon exploration of unknown environments using aerial robots. Through a model of visual attention, incrementally built maps are annotated regarding the visual importance and saliency of different objects and entities in the environment. Provided this information, a path planner that simultaneously optimizes for exploration of unknown space, and also directs the robot's attention to focus on the most salient objects, is developed. Following a two-step optimization paradigm, the algorithm first samples a random tree and identifies the branch maximizing for new volume to be explored. The first viewpoint of this path is then provided as a reference to the second planning step. Within that, a new tree is spanned, admissible branches arriving at the reference viewpoint while respecting a time budget dependent on the robot endurance and its environment exploration rate are found and evaluated in terms of reobserving salient regions at sufficient resolution. The best branch is then selected and executed by the robot, and the whole process is iteratively repeated. The proposed method is evaluated regarding its ability to provide increased attention toward salient objects, is verified to run onboard a small aerial robot, and is demonstrated in a set of challenging experimental studies.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Dang, Tung and Papachristos, Christos and Alexis, Kostas},
	month = may,
	year = {2018},
	note = {ISSN: 2577-087X},
	keywords = {Computational modeling, Path planning, Planning, Robot sensing systems, Visualization, aerial robotics, environment exploration rate, mobile robots, optimisation, path planner, path planning, random tree, reobserving salient regions, robot endurance, robot vision, salient objects, trees (mathematics), two-step optimization paradigm, visual attention, visual saliency-aware receding horizon autonomous exploration},
	pages = {2526--2533}
}

@misc{noauthor_sneaky_nodate,
	title = {Sneaky {Topology} {\textbar} {The} {Borsuk}-{Ulam} theorem and stolen necklaces},
	url = {https://www.youtube.com/watch?v=yuVqxCSsE7c},
	abstract = {Solving a discrete math puzzle using topology.
Home page: https://www.3blue1brown.com
Brought to you by you: http://3b1b.co/borsuk-thanks

Want more fair division math fun?  Check out this Mathologer video
https://youtu.be/7s-YM-kcKME
(Seriously, Mathologer is great)

These videos are supported by the community.
https://www.patreon.com/3blue1brown

The original 1986 by Alon and West with this proof
https://m.tau.ac.il/{\textasciitilde}nogaa/PDFS/Publi...

VSauce on fixed points
https://youtu.be/csInNn6pfT4

EE Paper using ideas related to this puzzle
https://dl.acm.org/citation.cfm?id=80...

I first came across this paper thanks to Alon Amit's answer on this Quora post
https://www.quora.com/As-of-2016-what...

If you want to contribute translated subtitles or to help review those that have already been made by others and need approval, you can click the gear icon in the video and go to subtitles/cc, then "add subtitles/cc".  I really appreciate those who do this, as it helps make the lessons accessible to more people.

Music by Vincent Rubinetti:
https://vincerubinetti.bandcamp.com/a...

------------------

3blue1brown is a channel about animating math, in all senses of the word animate.  And you know the drill with YouTube, if you want to stay posted on new videos, subscribe: http://3b1b.co/subscribe

Various social media stuffs:
Website: https://www.3blue1brown.com
Twitter: https://twitter.com/3blue1brown
Reddit: https://www.reddit.com/r/3blue1brown
Instagram: https://www.instagram.com/3blue1brown...
Patreon: https://patreon.com/3blue1brown
Facebook: https://www.facebook.com/3blue1brown},
	urldate = {2020-03-09}
}

@misc{noauthor_nyt_nodate,
	title = {{NYT}: {Sperner}'s lemma defeats the rental harmony problem},
	shorttitle = {{NYT}},
	url = {https://www.youtube.com/watch?v=7s-YM-kcKME},
	abstract = {TRICKY PROBLEM: A couple of friends want to rent an apartment. The rooms are quite different and the friends have different preferences and different ideas about what's worth what. Is there a way to split the rent and assign rooms to the friends so that everybody  ends up being happy? In this video the Mathologer sets out to explain a very elegant new solution to this and related hard fair division problems that even made it into the New York Times.  

Featuring Sperner's lemma and  Viviviani's theorem.

Check out 3Blue1Brown's video on another fair division problem here: https://www.youtube.com/channel/UCYO\_...

Francis Su's article in the American Mathematical Monthly on which this video is based lives here https://www.math.hmc.edu/{\textasciitilde}su/papers.d... 

You can find his fair division page here
https://www.math.hmc.edu/{\textasciitilde}su/fairdivi...

To find the New York Times article "To Divide the Rent, Start With a Triangle" just google this title (the url is ages long and I don't want to reproduce it here).

The NY Times fair division calculator.
https://www.nytimes.com/interactive/2...

A proof of Brouwer's fixed-point theorem using Sperner's lemma www.math.harvard.edu/{\textasciitilde}amathew/HMMT.pdf

Enjoy :)

P.S.: One more thing you can think about is the following: how can what I show in the video be used to prove Viviani’s theorem.},
	urldate = {2020-03-09}
}

@misc{maklin_gaussian_2019,
	title = {Gaussian {Mixture} {Models} {Clustering} {Algorithm} {Explained}},
	url = {https://towardsdatascience.com/gaussian-mixture-models-d13a5e915c8e},
	abstract = {Gaussian mixture models can be used to cluster unlabeled data in much the same way as k-means.},
	language = {en},
	urldate = {2020-03-05},
	journal = {Medium},
	author = {Maklin, Cory},
	month = jul,
	year = {2019},
	note = {Library Catalog: towardsdatascience.com}
}

@misc{noauthor_introduction_nodate,
	title = {Introduction to {EM}: {Gaussian} {Mixture} {Models}},
	url = {https://stephens999.github.io/fiveMinuteStats/intro_to_em.html},
	urldate = {2020-03-05}
}

@misc{noauthor_freeing_nodate,
	title = {Freeing up memory - {Headless} {GUI} and killing processes},
	url = {https://devtalk.nvidia.com/default/topic/1049266/jetson-nano/headless-os/},
	urldate = {2020-03-04}
}

@misc{nvidia_real-time_nodate,
	title = {Real-{Time} {Object} {Detection} in 10 {Lines} of {Python} {Code} on {Jetson} {Nano}},
	url = {https://www.youtube.com/watch?v=bcM5AQSAzUY},
	abstract = {In this tutorial, you’ll learn how to setup your NVIDIA Jetson Nano, run several object detection examples and code your own real-time object detection program in Python from a live camera feed.  Several DNN models are supported, including SSD-Mobilenet and SSD-Inception, which are pre-trained on the 90-class MS COCO dataset and can detect a variety of objects.  https://news.developer.nvidia.com/rea...},
	urldate = {2020-03-03},
	author = {nVidia}
}

@misc{noauthor_jetson_nodate,
	title = {Jetson {Nano} - {eLinux}.org},
	url = {https://elinux.org/Jetson_Nano},
	urldate = {2020-03-03}
}

@misc{noauthor_rosprofiler_nodate,
	title = {rosprofiler - {ROS} {Wiki}},
	url = {http://wiki.ros.org/rosprofiler},
	urldate = {2020-03-02}
}

@misc{noauthor_profiling_nodate,
	title = {Profiling {Applications} running on {Jetson} {Nano} - {NVIDIA} {Developer} {Forums}},
	url = {https://devtalk.nvidia.com/default/topic/1051232/jetson-nano/profiling-applications-running-on-jetson-nano/},
	urldate = {2020-03-02}
}

@article{talbot_robot_2020,
	title = {Robot {Navigation} in {Unseen} {Spaces} using an {Abstract} {Map}},
	url = {http://arxiv.org/abs/2001.11684},
	abstract = {Human navigation in built environments depends on symbolic spatial information which has unrealised potential to enhance robot navigation capabilities. Information sources such as labels, signs, maps, planners, spoken directions, and navigational gestures communicate a wealth of spatial information to the navigators of built environments; a wealth of information that robots typically ignore. We present a robot navigation system that uses the same symbolic spatial information employed by humans to purposefully navigate in unseen built environments with a level of performance comparable to humans. The navigation system uses a novel data structure called the abstract map to imagine malleable spatial models for unseen spaces from spatial symbols. Sensorimotor perceptions from a robot are then employed to provide purposeful navigation to symbolic goal locations in the unseen environment. We show how a dynamic system can be used to create malleable spatial models for the abstract map, and provide an open source implementation to encourage future work in the area of symbolic navigation. Symbolic navigation performance of humans and a robot is evaluated in a real-world built environment. The paper concludes with a qualitative analysis of human navigation strategies, providing further insights into how the symbolic navigation capabilities of robots in unseen built environments can be improved in the future.},
	urldate = {2020-03-02},
	journal = {arXiv:2001.11684 [cs]},
	author = {Talbot, Ben and Dayoub, Feras and Corke, Peter and Wyeth, Gordon},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.11684},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics}
}

@book{siegwart_introduction_2011,
	address = {Cambridge},
	edition = {2nd ed.},
	series = {Intelligent {Robotics} and {Autonomous} {Agents} {Ser}.},
	title = {Introduction to {Autonomous} {Mobile} {Robots}.},
	isbn = {978-0-262-29532-1},
	abstract = {The second edition of a comprehensive introduction to all aspects of mobile robotics, from algorithms to mechanisms.},
	language = {eng},
	publisher = {MIT Press},
	author = {Siegwart, Roland},
	collaborator = {Nourbakhsh, Illah Reza and Scaramuzza, Davide and Arkin, Ronald C.},
	year = {2011},
	keywords = {Autonomous robots, Electronic books, Electronic books., Mobile robots, local}
}

@phdthesis{albuquerque_domain_2019,
	address = {Lincoln, Nebraska},
	type = {Thesis},
	title = {Domain {Adaptation} in {Unmanned} {Aerial} {Vehicles} {Landing} using {Reinforcement} {Learning}},
	copyright = {Open Access},
	url = {https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1207&context=computerscidiss},
	language = {en},
	urldate = {2020-02-28},
	school = {University of Nebraska},
	author = {Albuquerque, Pedro Lucas Franca},
	month = dec,
	year = {2019}
}

@misc{noauthor_udacity_2014,
	title = {Udacity {CS344}: {Intro} to {Parallel} {Programming}},
	shorttitle = {Udacity {CS344}},
	url = {https://developer.nvidia.com/udacity-cs344-intro-parallel-programming},
	abstract = {What: Intro to Parallel Programming is a free online course created by NVIDIA and Udacity. In this class you will learn the fundamentals of parallel computing using the CUDA parallel computing platform and programming model. Who:This class is for developers, scientists, engineers, researchers and students who want to learn about GPU programming, algorithms, and optimization techniques. Why: Learn new skills, enhance your career opportunities, and have fun. How: Currently this class is closed - but please visit us again soon for any updates. Instructors Dr.},
	language = {en},
	urldate = {2020-02-27},
	journal = {NVIDIA Developer},
	month = apr,
	year = {2014},
	note = {Library Catalog: developer.nvidia.com}
}

@misc{nvidia_jetson_nodate,
	title = {Jetson {Nano} {Specs}},
	url = {https://docs.nvidia.com/jetson/archives/l4t-archived/l4t-321/index.html#page/Tegra%2520Linux%2520Driver%2520Package%2520Development%2520Guide%2Fsoftware_features_jetson_nano.html%23wwpID0E0DB0HA},
	abstract = {Coming Straight from nVidia},
	urldate = {2020-02-25},
	author = {nVidia}
}

@misc{noauthor_jetson_nodate-1,
	title = {Jetson {Nano} {UART} {C}/{C}++ {Example} - {NVIDIA} {Developer} {Forums}},
	url = {https://devtalk.nvidia.com/default/topic/1057441/jetson-nano/jetson-nano-uart-c-c-example/2},
	urldate = {2020-02-24}
}

@misc{noauthor_nvidia_nodate,
	title = {{NVIDIA} {Jetson} {Nano} {J41} {Header} {Pinout}},
	url = {https://www.jetsonhacks.com/nvidia-jetson-nano-j41-header-pinout/},
	abstract = {JetsonHacks is a site devoted to developing on the NVIDIA Jetson Development Kits.},
	language = {en-US},
	urldate = {2020-02-24},
	journal = {JetsonHacks}
}

@misc{noauthor_serial_nodate,
	title = {Serial {Console} {Setup}/{Parameters} - {NVIDIA} {Developer} {Forums}},
	url = {https://devtalk.nvidia.com/default/topic/1050148/},
	urldate = {2020-02-24}
}

@inproceedings{diuk_object-oriented_2008,
	address = {Helsinki, Finland},
	series = {{ICML} '08},
	title = {An object-oriented representation for efficient reinforcement learning},
	isbn = {978-1-60558-205-4},
	url = {https://doi.org/10.1145/1390156.1390187},
	doi = {10.1145/1390156.1390187},
	abstract = {Rich representations in reinforcement learning have been studied for the purpose of enabling generalization and making learning feasible in large state spaces. We introduce Object-Oriented MDPs (OO-MDPs), a representation based on objects and their interactions, which is a natural way of modeling environments and offers important generalization opportunities. We introduce a learning algorithm for deterministic OO-MDPs and prove a polynomial bound on its sample complexity. We illustrate the performance gains of our representation and algorithm in the well-known Taxi domain, plus a real-life videogame.},
	urldate = {2020-02-24},
	booktitle = {Proceedings of the 25th international conference on {Machine} learning},
	publisher = {Association for Computing Machinery},
	author = {Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
	month = jul,
	year = {2008},
	pages = {240--247}
}

@incollection{kulkarni_hierarchical_2016,
	title = {Hierarchical {Deep} {Reinforcement} {Learning}: {Integrating} {Temporal} {Abstraction} and {Intrinsic} {Motivation}},
	shorttitle = {Hierarchical {Deep} {Reinforcement} {Learning}},
	url = {http://papers.nips.cc/paper/6233-hierarchical-deep-reinforcement-learning-integrating-temporal-abstraction-and-intrinsic-motivation.pdf},
	urldate = {2020-02-24},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {Kulkarni, Tejas D and Narasimhan, Karthik and Saeedi, Ardavan and Tenenbaum, Josh},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	pages = {3675--3683}
}

@incollection{barbu_objectnet_2019,
	title = {{ObjectNet}: {A} large-scale bias-controlled dataset for pushing the limits of object recognition models},
	shorttitle = {{ObjectNet}},
	url = {http://papers.nips.cc/paper/9142-objectnet-a-large-scale-bias-controlled-dataset-for-pushing-the-limits-of-object-recognition-models.pdf},
	urldate = {2020-02-24},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 32},
	publisher = {Curran Associates, Inc.},
	author = {Barbu, Andrei and Mayo, David and Alverio, Julian and Luo, William and Wang, Christopher and Gutfreund, Dan and Tenenbaum, Josh and Katz, Boris},
	editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alché-Buc, F. d{\textbackslash}textquotesingle and Fox, E. and Garnett, R.},
	year = {2019},
	pages = {9453--9463}
}

@book{lavalle_planning_2006,
	address = {Cambridge, Mass},
	edition = {2nd Ed},
	title = {Planning {Algorithms}},
	isbn = {978-0-521-86205-9},
	url = {http://planning.cs.uiuc.edu/},
	language = {En},
	urldate = {2020-02-24},
	publisher = {Cambridge University Press},
	author = {LaValle, S.},
	month = may,
	year = {2006}
}

@misc{abbeel_cs287_nodate,
	title = {{CS287} {Fall} 2019 - {Advanced} {Robotics}},
	url = {https://people.eecs.berkeley.edu/~pabbeel/cs287-fa19/},
	urldate = {2020-02-19},
	author = {Abbeel, Pieter and Berkley, UC}
}

@misc{noauthor_friendly_nodate,
	title = {A friendly introduction to {Recurrent} {Neural} {Networks}},
	url = {https://www.youtube.com/watch?v=UNmqTiOnRfg},
	abstract = {Announcement: New Book by Luis Serrano! Grokking Machine Learning. bit.ly/grokkingML

A friendly explanation of how computers predict and generate sequences, based on Recurrent Neural Networks.
For a brush up on Neural Networks, check out this video: https://www.youtube.com/watch?v=BR9h4...},
	urldate = {2020-02-20}
}

@misc{3blue_bayes_nodate,
	title = {Bayes theorem, and making probability intuitive},
	url = {https://www.youtube.com/watch?v=HZGCoVF3YvM},
	abstract = {Perhaps the most important formula in probability.
Brought to you by you: http://3b1b.co/bayes-thanks 
The quick proof: https://youtu.be/U\_85TaXbeIo

Interactive made by Reddit user Thoggalluth: https://nskobelevs.github.io/p5js/Bay...

The study with Steve:
https://science.sciencemag.org/conten...
http://www.its.caltech.edu/{\textasciitilde}camerer/E...

You can read more about Kahneman and Tversky's work in Thinking Fast and Slow, or in one of my favorite books, The Undoing Project.
 
------------------ 
 
These animations are largely made using manim, a scrappy open-source python library:  https://github.com/3b1b/manim 
 
If you want to check it out, I feel compelled to warn you that it's not the most well-documented tool, and it has many other quirks you might expect in a library someone wrote with only their own use in mind. 
 
Music by Vincent Rubinetti. 
Download the music on Bandcamp: 
https://vincerubinetti.bandcamp.com/a... 
 
Stream the music on Spotify: 
https://open.spotify.com/album/1dVyjw... 
 
If you want to contribute translated subtitles or to help review those that have already been made by others and need approval, you can click the gear icon in the video and go to subtitles/cc, then "add subtitles/cc".  I really appreciate those who do this, as it helps make the lessons accessible to more people. 
 
------------------ 
 
3blue1brown is a channel about animating math, in all senses of the word animate.  And you know the drill with YouTube, if you want to stay posted on new videos, subscribe: http://3b1b.co/subscribe 
 
Various social media stuffs: 
Website: https://www.3blue1brown.com 
Twitter: https://twitter.com/3blue1brown 
Reddit: https://www.reddit.com/r/3blue1brown 
Instagram: https://www.instagram.com/3blue1brown... 
Patreon: https://patreon.com/3blue1brown 
Facebook: https://www.facebook.com/3blue1brown},
	urldate = {2020-02-19},
	author = {3Blue, 1Brown}
}

@misc{noauthor_ordinary_nodate,
	title = {Ordinary {Least} {Squares} {Estimators} - derivation in matrix form - part 3},
	url = {https://www.youtube.com/watch?v=C-uW45FSsNQ},
	abstract = {This video provides a derivation of the form of ordinary least squares estimators, using the matrix notation of econometrics. Check out https://ben-lambert.com/econometrics-... for course materials, and information regarding updates on each of the courses. Quite excitingly (for me at least), I am about to publish a whole series of new videos on Bayesian statistics on youtube. See here for information: https://ben-lambert.com/bayesian/ Accompanying this series, there will be a book: https://www.amazon.co.uk/gp/product/1...},
	urldate = {2020-02-19}
}

@misc{skydio_skydio_nodate,
	title = {Skydio 2: {The} drone you've been waiting for.},
	shorttitle = {Skydio 2},
	url = {https://www.skydio.com/},
	abstract = {The all-new Skydio 2 drone delivers the easiest and most intuitive flight experience ever.},
	language = {en},
	urldate = {2020-02-19},
	journal = {Skydio, Inc.},
	author = {Skydio}
}

@misc{noauthor_aws_nodate,
	title = {{AWS} {JPL} {Open}-{Source} {Rover} {Challenge}},
	url = {https://spacechallenge.tech/},
	abstract = {The exploration of space continues to occur at a rapid pace. We want you to journey to Mars and use your skills to improve how rovers on the Red Planet help unlock the secrets of the universe.},
	language = {en-US},
	urldate = {2020-02-19},
	journal = {AWS JPL Open-Source Rover Challenge}
}

@article{harnad_symbol_1990,
	title = {The symbol grounding problem},
	volume = {42},
	issn = {0167-2789},
	url = {http://www.sciencedirect.com/science/article/pii/0167278990900876},
	doi = {10.1016/0167-2789(90)90087-6},
	abstract = {There has been much discussion recently about the scope and limits of purely symbolic models of the mind and about the proper role of connectionism in cognitive modeling. This paper describes the “symbol grounding problem”: How can the semantic interpretation of a formal symbol system be made intrinsic to the system, rather than just parasitic on the meanings in our heads? How can the meanings of the meaningless symbol tokens, manipulated solely on the basis of their (arbitrary) shapes, be grounded in anything but other meaningless symbols? The problem is analogous to trying to learn Chinese from a Chinese/Chinese dictionary alone. A candidate solution is sketched: Symbolic representations must be grounded bottom-up in nonsymbolic representations of two kinds: (1) iconic representations, which are analogs of the proximal sensory projections of distal objects and events, and (2) categorical representations, which are learned and innate feature detectors that pick out the invariant features of object and event categories from their sensory projections. Elementary symbols are the names of these object and event categories, assigned on the basis of their (nonsymbolic) categorical representations. Higher-order (3) symbolic representations, grounded in these elementary symbols, consist of symbol strings describing category membership relations (e.g. “An X is a Y that is Z”). Connectionism is one natural candidate for the mechanism that learns the invariant features underlying categorical representations, thereby connecting names to the proximal projections of the distal objects they stand for. In this way connectionism can be seen as a complementary component in a hybrid nonsymbolic/symbolic model of the mind, rather than a rival to purely symbolic modeling. Such a hybrid model would not have an autonomous symbolic “module,” however; the symbolic functions would emerge as an intrinsically “dedicated” symbol system as a consequence of the bottom-up grounding of categories' names in their sensory representations. Symbol manipulation would be governed not just by the arbitrary shapes of the symbol tokens, but by the nonarbitrary shapes of the icons and category invariants in which they are grounded.},
	language = {en},
	number = {1},
	urldate = {2020-02-17},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Harnad, Stevan},
	month = jun,
	year = {1990},
	pages = {335--346}
}

@inproceedings{florence_nanomap_2018,
	title = {{NanoMap}: {Fast}, {Uncertainty}-{Aware} {Proximity} {Queries} with {Lazy} {Search} {Over} {Local} {3D} {Data}},
	shorttitle = {{NanoMap}},
	doi = {10.1109/ICRA.2018.8463195},
	abstract = {We would like robots to be able to safely navigate at high speed, efficiently use local 3D information, and robustly plan motions that consider pose uncertainty of measurements in a local map structure. This is hard to do with previously existing mapping approaches, like occupancy grids, that are focused on incrementally fusing 3D data into a common world frame. In particular, both their fragile sensitivity to state estimation errors and computational cost can be limiting. We develop an alternative framework, NanoMap, which alleviates the need for global map fusion and enables a motion planner to efficiently query pose-uncertainty-aware local 3D geometric information. The key idea of NanoMap is to store a history of noisy relative pose transforms and search over a corresponding set of depth sensor measurements for the minimum-uncertainty view of a queried point in space. This approach affords a variety of capabilities not offered by traditional mapping techniques: (a) the pose uncertainty associated with 3D data can be incorporated in motion planning, (b) poses can be updated (i.e., from loop closures) with minimal computational effort, and (c) 3D data can be fused lazily for the purpose of planning. We provide an open-source implementation of NanoMap, and analyze its capabilities and computational efficiency in simulation experiments. Finally, we demonstrate in hardware its effectiveness for fast 3D obstacle avoidance onboard a quadrotor flying up to 10 m/s.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Florence, Peter R. and Carter, John and Ware, Jake and Tedrake, Russ},
	month = may,
	year = {2018},
	note = {ISSN: 2577-087X},
	keywords = {Collision avoidance, Current measurement, History, NanoMap, Planning, Robot sensing systems, Three-dimensional displays, Uncertainty, cartography, collision avoidance, depth sensor measurements, fast 3D obstacle avoidance, global map fusion, lazy search, local 3D data, local 3D information, local map structure, mapping approaches, mapping techniques, minimum-uncertainty view, mobile robots, motion planner, motion planning, navigation, noisy relative pose transforms, pose-uncertainty-aware local 3D geometric information, robustly plan motions, sensors, uncertainty-aware proximity queries},
	pages = {7631--7638}
}

@inproceedings{engel_lsd-slam_2014,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{LSD}-{SLAM}: {Large}-{Scale} {Direct} {Monocular} {SLAM}},
	isbn = {978-3-319-10605-2},
	shorttitle = {{LSD}-{SLAM}},
	doi = {10.1007/978-3-319-10605-2_54},
	abstract = {We propose a direct (feature-less) monocular SLAM algorithm which, in contrast to current state-of-the-art regarding direct methods, allows to build large-scale, consistent maps of the environment. Along with highly accurate pose estimation based on direct image alignment, the 3D environment is reconstructed in real-time as pose-graph of keyframes with associated semi-dense depth maps. These are obtained by filtering over a large number of pixelwise small-baseline stereo comparisons. The explicitly scale-drift aware formulation allows the approach to operate on challenging sequences including large variations in scene scale. Major enablers are two key novelties: (1) a novel direct tracking method which operates on sim(3)sim(3){\textbackslash}mathfrak\{sim\}(3), thereby explicitly detecting scale-drift, and (2) an elegant probabilistic solution to include the effect of noisy depth values into tracking. The resulting direct monocular SLAM system runs in real-time on a CPU.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2014},
	publisher = {Springer International Publishing},
	author = {Engel, Jakob and Schöps, Thomas and Cremers, Daniel},
	editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
	year = {2014},
	keywords = {Augmented Reality, Convergence Radius, Image Alignment, Inverse Depth, Visual Odometry},
	pages = {834--849}
}

@inproceedings{engel_camera-based_2012,
	title = {Camera-based navigation of a low-cost quadrocopter},
	doi = {10.1109/IROS.2012.6385458},
	abstract = {In this paper, we describe a system that enables a low-cost quadrocopter coupled with a ground-based laptop to navigate autonomously in previously unknown and GPS-denied environments. Our system consists of three components: a monocular SLAM system, an extended Kalman filter for data fusion and state estimation and a PID controller to generate steering commands. Next to a working system, the main contribution of this paper is a novel, closed-form solution to estimate the absolute scale of the generated visual map from inertial and altitude measurements. In an extensive set of experiments, we demonstrate that our system is able to navigate in previously unknown environments at absolute scale without requiring artificial markers or external sensors. Furthermore, we show (1) its robustness to temporary loss of visual tracking and significant delays in the communication process, (2) the elimination of odometry drift as a result of the visual SLAM system and (3) accurate, scale-aware pose estimation and navigation.},
	booktitle = {2012 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Engel, Jakob and Sturm, Jürgen and Cremers, Daniel},
	month = oct,
	year = {2012},
	note = {ISSN: 2153-0858},
	keywords = {Accuracy, Cameras, Delay, GPS-denied environments, Kalman filters, Navigation, PID controller, SLAM (robots), Simultaneous localization and mapping, Visualization, artificial markers, camera-based navigation, closed-form solution, data fusion, extended Kalman filter, external sensors, ground-based laptop, helicopters, image sensors, low-cost quadrocopter, mobile robots, monocular SLAM system, pose estimation, robot vision, scale-aware pose estimation, sensor fusion, state estimation, steering commands, three-term control, visual map},
	pages = {2815--2821}
}

@inproceedings{del_pero_bayesian_2012,
	title = {Bayesian geometric modeling of indoor scenes},
	doi = {10.1109/CVPR.2012.6247994},
	abstract = {We propose a method for understanding the 3D geometry of indoor environments (e.g. bedrooms, kitchens) while simultaneously identifying objects in the scene (e.g. beds, couches, doors). We focus on how modeling the geometry and location of specific objects is helpful for indoor scene understanding. For example, beds are shorter than they are wide, and are more likely to be in the center of the room than cabinets, which are tall and narrow. We use a generative statistical model that integrates a camera model, an enclosing room “box”, frames (windows, doors, pictures), and objects (beds, tables, couches, cabinets), each with their own prior on size, relative dimensions, and locations. We fit the parameters of this complex, multi-dimensional statistical model using an MCMC sampling approach that combines discrete changes (e.g, adding a bed), and continuous parameter changes (e.g., making the bed larger). We find that introducing object category leads to state-of-the-art performance on room layout estimation, while also enabling recognition based only on geometry.},
	booktitle = {2012 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Del Pero, Luca and Bowdish, Joshua and Fried, Daniel and Kermgard, Bonnie and Hartley, Emily and Barnard, Kobus},
	month = jun,
	year = {2012},
	note = {ISSN: 1063-6919},
	keywords = {3D geometry, Bayesian geometric modeling, Cameras, Catalogs, Geometry, Image edge detection, Layout, MCMC sampling approach, Object recognition, Solid modeling, belief networks, cabinets, camera model, computational geometry, enclosing room box, generative statistical model, image sensors, indoor environments, indoor scene understanding, multidimensional statistical model, object category, object recognition, room layout estimation, sampling methods, solid modelling},
	pages = {2719--2726}
}

@article{bain_physiology_2018,
	title = {Physiology of static breath holding in elite apneists},
	volume = {103},
	copyright = {© 2018 The Authors. Experimental Physiology © 2018 The Physiological Society},
	issn = {1469-445X},
	url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/EP086269},
	doi = {10.1113/EP086269},
	abstract = {New Findings What is the topic of this review? This review provides an up-to-date assessment of the physiology involved with extreme static dry-land breath holding in trained apneists. What advances does it highlight? We specifically highlight the recent findings involved with the cardiovascular, cerebrovascular and metabolic function during a maximal breath hold in elite apneists. Abstract Breath-hold-related activities have been performed for centuries, but only recently, within the last ∼30 years, has it emerged as an increasingly popular competitive sport. In apnoea sport, competition relates to underwater distances or simply maximal breath-hold duration, with the current (oxygen-unsupplemented) static breath-hold record at 11 min 35 s. Remarkably, many ultra-elite apneists are able to suppress respiratory urges to the point where consciousness fundamentally limits a breath-hold duration. Here, arterial oxygen saturations as low as ∼50\% have been reported. In such cases, oxygen conservation to maintain cerebral functioning is critical, where responses ascribed to the mammalian dive reflex, e.g. sympathetically mediated peripheral vasoconstriction and vagally mediated bradycardia, are central. In defence of maintaining global cerebral oxygen delivery during prolonged breath holds, the cerebral blood flow may increase by ∼100\% from resting values. Interestingly, near the termination of prolonged dry static breath holds, recent studies also indicate that reductions in the cerebral oxidative metabolism can occur, probably attributable to the extreme hypercapnia and irrespective of the hypoxaemia. In this review, we highlight and discuss the recent data on the cardiovascular, metabolic and, particularly, cerebrovascular function in competitive apneists performing maximal static breath holds. The physiological adaptation and maladaptation with regular breath-hold training are also summarized, and future research areas in this unique physiological field are highlighted; particularly, the need to determine the potential long-term health impacts of extreme breath holding.},
	language = {en},
	number = {5},
	urldate = {2020-02-16},
	journal = {Experimental Physiology},
	author = {Bain, Anthony R. and Drvis, Ivan and Dujic, Zeljko and MacLeod, David B. and Ainslie, Philip N.},
	year = {2018},
	keywords = {apnoea, breath-holding, diving, free diving},
	pages = {635--651}
}

@misc{noauthor_how_nodate,
	title = {How can {I} include subfiles in to a subfiles?},
	url = {https://tex.stackexchange.com/questions/147502/how-can-i-include-subfiles-in-to-a-subfiles},
	urldate = {2020-02-13},
	journal = {TeX - LaTeX Stack Exchange}
}

@misc{noauthor_management_nodate,
	title = {Management in a large project},
	url = {https://www.overleaf.com/learn/latex/Management_in_a_large_project},
	abstract = {An online LaTeX editor that's easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
	urldate = {2020-02-13}
}

@misc{noauthor_opencv_2020,
	title = {{OpenCV} 'dnn' with {NVIDIA} {GPUs}: 1549\% faster {YOLO}, {SSD}, and {Mask} {R}-{CNN}},
	shorttitle = {{OpenCV} 'dnn' with {NVIDIA} {GPUs}},
	url = {https://www.pyimagesearch.com/2020/02/10/opencv-dnn-with-nvidia-gpus-1549-faster-yolo-ssd-and-mask-r-cnn/},
	abstract = {In this tutorial, you’ll learn how to use OpenCV’s “dnn” module with an NVIDIA GPU for up to 1,549\% faster object detection (YOLO and SSD) and instance segmentation (Mask R-CNN). Last week, we discovered how to configure and install…},
	language = {en-US},
	urldate = {2020-02-12},
	journal = {PyImageSearch},
	month = feb,
	year = {2020}
}

@article{loquercio_deep_2020,
	title = {Deep {Drone} {Racing}: {From} {Simulation} to {Reality} {With} {Domain} {Randomization}},
	volume = {36},
	issn = {1941-0468},
	shorttitle = {Deep {Drone} {Racing}},
	doi = {10.1109/TRO.2019.2942989},
	abstract = {Dynamically changing environments, unreliable state estimation, and operation under severe resource constraints are fundamental challenges that limit the deployment of small autonomous drones. We address these challenges in the context of autonomous, vision-based drone racing in dynamic environments. A racing drone must traverse a track with possibly moving gates at high speed. We enable this functionality by combining the performance of a state-of-the-art planning and control system with the perceptual awareness of a convolutional neural network. The resulting modular system is both platform independent and domain independent: it is trained in simulation and deployed on a physical quadrotor without any fine-tuning. The abundance of simulated data, generated via domain randomization, makes our system robust to changes of illumination and gate appearance. To the best of our knowledge, our approach is the first to demonstrate zero-shot sim-to-real transfer on the task of agile drone flight. We extensively test the precision and robustness of our system, both in simulation and on a physical platform, and show significant improvements over the state of the art.},
	number = {1},
	journal = {IEEE Transactions on Robotics},
	author = {Loquercio, Antonio and Kaufmann, Elia and Ranftl, René and Dosovitskiy, Alexey and Koltun, Vladlen and Scaramuzza, Davide},
	month = feb,
	year = {2020},
	keywords = {Drone racing, Drones, Navigation, Robot sensing systems, State estimation, Training, Trajectory, learning agile flight, learning for control},
	pages = {1--14}
}

@misc{noauthor_bash_nodate,
	title = {bash - {How} to change the output color of echo in {Linux}},
	url = {https://stackoverflow.com/questions/5947742/how-to-change-the-output-color-of-echo-in-linux},
	urldate = {2020-02-12},
	journal = {Stack Overflow}
}

@misc{noauthor_shell_nodate,
	title = {shell - {How} to set up tmux so that it starts up with specified windows opened?},
	url = {https://stackoverflow.com/questions/5609192/how-to-set-up-tmux-so-that-it-starts-up-with-specified-windows-opened},
	urldate = {2020-02-12},
	journal = {Stack Overflow}
}

@misc{noauthor_cublas_nodate,
	type = {concept},
	title = {{cuBLAS}},
	url = {http://docs.nvidia.com/cuda/cublas/index.html},
	abstract = {The API Reference guide for cuBLAS, the CUDA Basic Linear Algebra Subroutine library.},
	language = {en-us},
	urldate = {2020-02-12}
}

@misc{noauthor_cub_nodate,
	title = {{CUB}: {Main} {Page}},
	url = {https://nvlabs.github.io/cub/},
	urldate = {2020-02-12}
}

@misc{dave_deep_2019,
	title = {Deep learning has a new friend — {Tabular} datasets},
	url = {https://towardsdatascience.com/deep-learning-has-a-new-friend-tabular-datasets-f34169b9ea79},
	abstract = {Going beyond deep learning just for image datasets},
	language = {en},
	urldate = {2020-02-12},
	journal = {Medium},
	author = {Dave, Pranay},
	month = nov,
	year = {2019}
}

@misc{folkman_top_2019,
	title = {The {Top} {Five} {Most} {Useful} {Commands} in {Pandas}},
	url = {https://towardsdatascience.com/the-top-five-most-useful-commands-in-pandas-4390d4e165a5},
	abstract = {That I use every day},
	language = {en},
	urldate = {2020-02-12},
	journal = {Medium},
	author = {Folkman, Tyler},
	month = dec,
	year = {2019}
}

@misc{noauthor_python_nodate,
	title = {python - {Function} parameter with colon},
	url = {https://stackoverflow.com/questions/54962869/function-parameter-with-colon},
	urldate = {2020-02-10},
	journal = {Stack Overflow}
}

@misc{noauthor_kabsch_2019,
	title = {Kabsch algorithm},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Kabsch_algorithm&oldid=930118690},
	abstract = {The Kabsch algorithm, named after Wolfgang Kabsch, is a method for calculating the optimal rotation matrix that minimizes the RMSD (root mean squared deviation) between two paired sets of points. It is useful in graphics, cheminformatics to compare molecular structures, and also bioinformatics for comparing protein structures (in particular, see root-mean-square deviation (bioinformatics)).
The algorithm only computes the rotation matrix, but it also requires the computation of a translation vector. When both the translation and rotation are actually performed, the algorithm is sometimes called partial Procrustes superimposition (see also orthogonal Procrustes problem).},
	language = {en},
	urldate = {2020-02-10},
	journal = {Wikipedia},
	month = dec,
	year = {2019},
	note = {Page Version ID: 930118690}
}

@misc{262588213843476_umeyama_nodate,
	title = {Umeyama algorithm for absolute orientation problem in {Python}},
	url = {https://gist.github.com/CarloNicolini/7118015},
	abstract = {Umeyama algorithm for absolute orientation problem in Python - ralign},
	language = {en},
	urldate = {2020-02-10},
	journal = {Gist},
	author = {262588213843476}
}

@book{noauthor_linear_2015,
	title = {The {Linear} {Algebra} {Survival} {Guide}},
	isbn = {978-0-12-409520-5},
	url = {https://linkinghub.elsevier.com/retrieve/pii/C20120068366},
	language = {en},
	urldate = {2020-02-10},
	publisher = {Elsevier},
	year = {2015},
	doi = {10.1016/C2012-0-06836-6}
}

@misc{noauthor_learn_nodate,
	title = {Learn {Docker} in 12 {Minutes} 🐳},
	url = {https://www.youtube.com/watch?v=YFl2mCHdv24},
	abstract = {Docker is all the rage right now. In 12 minutes I'll give you comprehensive introduction to docker, covering:

1. What is Docker
2. Virtual Machines vs. Docker
3. Introduction to Dockerfiles, images and containers
4. The Docker Hub
5. Writing a Dockerfile
6. Building an image
7. Running a container
8. Mounting volumes
9. One process per container

Download Docker for Mac
https://docs.docker.com/docker-for-mac/

Download Docker for Windows
https://docs.docker.com/docker-for-wi...

Support this channel at https://www.patreon.com/jakewright

----------------------------------------
MORE TUTORIALS

Docker Compose in 12 Minutes: https://youtu.be/Qw9zlE3t8Ko
Deploy Docker Containers https://youtu.be/F82K07NmRpk
Learn HTML in 12 Minutes: https://youtu.be/bWPMSSsVdPk
Learn CSS in 12 Minutes: https://youtu.be/0afZj1G0BIE
Learn JavaScript in 12 Minutes: https://youtu.be/Ukg\_U3CnJWI
Learn PHP in 15 Minutes: https://youtu.be/ZdP0KM49IVk

----------------------------------------
I deploy Docker containers to a Digital Ocean VPS. Get \$10 credit with this link: https://m.do.co/c/791d593997b2
----------------------------------------

SUBSCRIBE FOR MORE
http://youtube.com/subscription\_cente...

TWITTER http://twitter.com/jakewrightuk
FACEBOOK https://www.facebook.com/jakewrightuk
INSTAGRAM http://instagram.com/jakewrightuk

http://jakewright.net},
	urldate = {2020-02-10}
}

@misc{noauthor_atlassian_nodate,
	title = {Atlassian {Confluence} {Tutorial} for {Beginners}: {A} {Complete} {Guide}},
	url = {https://www.softwaretestinghelp.com/atlassian-confluence-tutorial/},
	urldate = {2020-02-10}
}

@misc{noauthor_confluence_nodate,
	title = {Confluence in (roughly) 60 seconds},
	url = {https://www.youtube.com/watch?v=09CuRQoJzB8&list=PLaD4FvsFdarRngi46OIHZq9jPf0Pb43b9},
	abstract = {Learn the basic concepts of Confluence, including spaces, pages, comments, and @mentions in (a little over) 60 seconds! A must watch for new Confluence users.},
	urldate = {2020-02-10}
}

@inproceedings{vanegas_uncertainty_2016,
	title = {Uncertainty based online planning for {UAV} target finding in cluttered and {GPS}-denied environments},
	doi = {10.1109/AERO.2016.7500566},
	abstract = {There are some scenarios in which Unmmaned Aerial Vehicle (UAV) navigation becomes a challenge due to the occlusion of GPS systems signal, the presence of obstacles and constraints in the space in which a UAV operates. An additional challenge is presented when a target whose location is unknown must be found within a confined space. In this paper we present a UAV navigation and target finding mission, modelled as a Partially Observable Markov Decision Process (POMDP) using a state-of-the-art online solver in a real scenario using a low cost commercial multi rotor UAV and a modular system architecture running under the Robotic Operative System (ROS). Using POMDP has several advantages to conventional approaches as they take into account uncertainties in sensor information. We present a framework for testing the mission with simulation tests and real flight tests in which we model the system dynamics and motion and perception uncertainties. The system uses a quad-copter aircraft with an board downwards looking camera without the need of GPS systems while avoiding obstacles within a confined area. Results indicate that the system has 100\% success rate in simulation and 80\% rate during flight test for finding targets located at different locations.},
	booktitle = {2016 {IEEE} {Aerospace} {Conference}},
	author = {Vanegas, Fernando and Gonzalez, Felipe},
	month = mar,
	year = {2016},
	note = {ISSN: null},
	keywords = {GPS systems signal, GPS-denied environments, Markov processes, Navigation, POMDP, Planning, ROS, Robot sensing systems, Systems architecture, UAV navigation, UAV target finding mission, Uncertainty, aerospace testing, autonomous aerial vehicles, board downwards looking camera, cluttered environments, collision avoidance, commercial multirotor UAV, confined space, flight test, modular system architecture, motion uncertainties, obstacle avoidance, partially observable Markov decision process, perception uncertainties, quadcopter aircraft, robotic operative system, sensor information, system dynamics, uncertainty based online planning, unmaned aerial vehicle navigation},
	pages = {1--9}
}

@book{marr_vision_1982,
	address = {San Francisco ; ;},
	title = {Vision: a computational investigation into the human representation and processing of visual information},
	isbn = {978-0-7167-1284-8},
	shorttitle = {Vision},
	language = {eng},
	publisher = {WHFreeman},
	author = {Marr, David},
	year = {1982},
	keywords = {Data processing, Human information processing, Mathematical models, Vision}
}

@misc{drummond_3d_nodate,
	title = {{3D} {Geometry} and {Lie} {Groups}},
	url = {http://twd20g.blogspot.com/p/notes-on-lie-groups.html},
	abstract = {The draft of a book for 3D Geometry and Lie Group maths
Can be found in folder Tutorials},
	author = {Drummond, Tom}
}

@book{anderson_optimal_2012,
	address = {Newburyport},
	series = {Dover {Books} on {Electrical} {Engineering}},
	title = {Optimal {Filtering}},
	isbn = {978-0-486-13689-9},
	abstract = {This graduate-level text augments and extends beyond undergraduate studies of signal processing, particularly in regard to communication systems and digital filtering theory. Vital for students in the fields of control and communications, its contents are also relevant to students in such diverse areas as statistics, economics, bioengineering, and operations research.Topics include filtering, linear systems, and estimation; the discrete-time Kalman filter; time-invariant filters; properties of Kalman filters; computational aspects; and smoothing of discrete-time signals. Additional subjects e},
	language = {eng},
	publisher = {Dover Publications},
	author = {Anderson, Brian D. O.},
	collaborator = {Moore, John B.},
	year = {2012},
	keywords = {Electric filters, Electrical \& Computer Engineering, Electronic books, Engineering \& Applied Sciences, Signal processing, Telecommunications}
}

@book{slotine_applied_1991,
	address = {Englewood Cliffs, N.J},
	title = {Applied nonlinear control},
	isbn = {978-0-13-040890-7},
	language = {eng},
	publisher = {Prentice-Hall},
	author = {Slotine, J.-J. E.},
	collaborator = {Li, Weiping},
	year = {1991},
	keywords = {Nonlinear control theory}
}

@misc{slotine_lecture_nodate,
	title = {Lecture on {Nonlinear} {Systems} and {Control} - {NLMPC}},
	url = {http://web.mit.edu/nsl/www/videos/lectures.html},
	abstract = {MIT lectures on NLMPC as suggested by VLAD to learn about time derivatives},
	urldate = {2020-02-09},
	author = {Slotine, Jean J.}
}

@misc{noauthor_rvss2020_nodate,
	title = {{RVSS2020} {Tutorial} {Material} – {Google} {Drive}},
	url = {https://drive.google.com/drive/folders/1mMG_SovuKczRtp1ieVKNvZbWYtZc9LWK},
	urldate = {2020-02-09}
}

@misc{noauthor_rvss_nodate,
	title = {{RVSS} 2020 {Workshop} - {Calibration}},
	url = {https://sites.google.com/view/rvss-2020-workshop/calibration},
	language = {de},
	urldate = {2020-02-09}
}

@misc{noauthor_kennegervss_2020_workshop_nodate,
	title = {kennege/{RVSS}\_2020\_Workshop},
	url = {https://github.com/kennege/RVSS_2020_Workshop},
	abstract = {Repository for code used for the workshop for the 2020 Robotic Vision Summer School - kennege/RVSS\_2020\_Workshop},
	language = {en},
	urldate = {2020-02-09},
	journal = {GitHub}
}

@misc{noauthor_slam_nodate,
	title = {{SLAM} - {Brenner} {Github}},
	url = {https://github.com/jfjensen/SLAM},
	abstract = {Python files for SLAM course by Claus Brenner. Contribute to jfjensen/SLAM development by creating an account on GitHub.},
	language = {en},
	urldate = {2020-02-09},
	journal = {GitHub}
}

@misc{brenner_slam_nodate,
	address = {Hannover},
	title = {{SLAM} {A} 00},
	url = {https://www.youtube.com/watch?v=B2qzYCeT9oQ&list=PLpUPoM7Rgzi_7YWn14Va2FODh7LzADBSm},
	abstract = {Python code: https://drive.google.com/open?id=0Bxw...},
	urldate = {2020-02-09},
	author = {Brenner, Claus}
}

@article{arjovsky_wasserstein_2017,
	title = {Wasserstein {GAN}},
	url = {http://arxiv.org/abs/1701.07875},
	abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.},
	urldate = {2020-02-05},
	journal = {arXiv:1701.07875 [cs, stat]},
	author = {Arjovsky, Martin and Chintala, Soumith and Bottou, Léon},
	month = dec,
	year = {2017},
	note = {arXiv: 1701.07875},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@inproceedings{kouris_informed_2019,
	title = {Informed {Region} {Selection} for {Efficient} {UAV}-based {Object} {Detectors}: {Altitude}-aware {Vehicle} {Detection} with {CyCAR} {Dataset}},
	shorttitle = {Informed {Region} {Selection} for {Efficient} {UAV}-based {Object} {Detectors}},
	doi = {10.1109/IROS40897.2019.8967722},
	abstract = {Deep Learning-based object detectors enhance the capabilities of remote sensing platforms, such as Unmanned Aerial Vehicles (UAVs), in a wide spectrum of machine vision applications. However, the integration of deep learning introduces heavy computational requirements, preventing the deployment of such algorithms in scenarios that impose low-latency constraints during inference, in order to make mission-critical decisions in real-time. In this paper, we address the challenge of efficient deployment of region-based object detectors in aerial imagery, by introducing an informed methodology for extracting candidate detection regions (proposals). Our approach considers information from the UAV on-board sensors, such as flying altitude and light-weight computer vision filters, along with prior domain knowledge to intelligently decrease the number of region proposals by eliminating false-positives at an early stage of the computation, reducing significantly the computational workload while sustaining the detection accuracy. We apply and evaluate the proposed approach on the task of vehicle detection. Our experiments demonstrate that state-of-the-art detection models can achieve up to 2.6x faster inference by employing our altitude-aware data-driven methodology. Alongside, we introduce and provide to the community a novel vehicle-annotated and altitude-stamped dataset of real UAV imagery, captured at numerous flying heights under a wide span of traffic scenarios.},
	booktitle = {2019 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Kouris, Alexandros and Kyrkou, Christos and Bouganis, Christos-Savvas},
	month = nov,
	year = {2019},
	note = {ISSN: 2153-0858},
	pages = {51--58}
}

@inproceedings{manglik_forecasting_2019,
	title = {Forecasting {Time}-to-{Collision} from {Monocular} {Video}: {Feasibility}, {Dataset}, and {Challenges}},
	shorttitle = {Forecasting {Time}-to-{Collision} from {Monocular} {Video}},
	doi = {10.1109/IROS40897.2019.8967730},
	abstract = {We explore the possibility of using a single monocular camera to forecast the time to collision between a suitcase-shaped robot being pushed by its user and other nearby pedestrians. We develop a purely image-based deep learning approach that directly estimates the time to collision without the need of relying on explicit geometric depth estimates or velocity information to predict future collisions. While previous work has focused on detecting immediate collision in the context of navigating Unmanned Aerial Vehicles, the detection was limited to a binary variable (i.e., collision or no collision). We propose a more fine-grained approach to collision forecasting by predicting the exact time to collision in terms of milliseconds, which is more helpful for collision avoidance in the context of dynamic path planning. To evaluate our method, we have collected a novel dataset of over 13,000 indoor video segments each showing a trajectory of at least one person ending in a close proximity (a near collision) with the camera mounted on a mobile suitcase-shaped platform. Using this dataset, we do extensive experimentation on different temporal windows as input using an exhaustive list of state-of-the-art convolutional neural networks (CNNs). Our results show that our proposed multi-stream CNN is the best model for predicting time to near-collision. The average prediction error of our time to near-collision is 0.75 seconds across the test videos. The project webpage can be found at https://aashi7.github.io/NearCollision.html.},
	booktitle = {2019 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Manglik, Aashi and Weng, Xinshuo and Ohn-Bar, Eshed and Kitanil, Kris M.},
	month = nov,
	year = {2019},
	note = {ISSN: 2153-0858},
	pages = {8081--8088}
}

@inproceedings{vespa_adaptive-resolution_2019,
	title = {Adaptive-{Resolution} {Octree}-{Based} {Volumetric} {SLAM}},
	doi = {10.1109/3DV.2019.00077},
	abstract = {We introduce a novel volumetric SLAM pipeline for the integration and rendering of depth images at an adaptive level of detail. Our core contribution is a fusion algorithm which dynamically selects the appropriate integration scale based on the effective sensor resolution given the distance from the observed scene, addressing aliasing issues, reconstruction quality, and efficiency simultaneously. We implement our approach using an efficient octree structure which supports multi-resolution rendering allowing for online frame-to-model alignment. Our qualitative and quantitative experiments demonstrate significantly improved reconstruction quality and up to six-fold execution time speed-ups compared to single resolution grids.},
	booktitle = {2019 {International} {Conference} on {3D} {Vision} ({3DV})},
	author = {Vespa, Emanuele and Funk, Nils and Kelly, Paul H. J. and Leutenegger, Stefan},
	month = sep,
	year = {2019},
	note = {ISSN: 2378-3826},
	keywords = {3D Reconstruction, Cameras, Indexes, Mapping, Octrees, Pipelines, Rendering (computer graphics), SLAM, SLAM (robots), Simultaneous localization and mapping, Three-dimensional displays, adaptive-resolution octree-based volumetric SLAM, depth images, fusion algorithm, image fusion, image reconstruction, image resolution, integration scale, multiresolution rendering, octrees, online frame-to-model alignment, reconstruction quality, rendering (computer graphics), sensor resolution},
	pages = {654--662}
}

@misc{kneip_laurentkneipopengv_2020,
	title = {laurentkneip/opengv},
	url = {https://github.com/laurentkneip/opengv},
	abstract = {OpenGV is a collection of computer vision methods for solving geometric vision problems.},
	urldate = {2020-02-04},
	author = {Kneip, Laurent},
	month = jan,
	year = {2020},
	note = {original-date: 2013-08-10T03:56:55Z}
}

@article{kajita_overview_nodate,
	title = {Overview of {ZMP}-based {Biped} {Walking}},
	url = {http://www.cs.cmu.edu/~cga/ew/kajita-dw08.pdf},
	language = {en},
	author = {Kajita, Shuuji},
	pages = {37}
}

@misc{caron_equations_nodate,
	title = {Equations of motion - {Stéphane} {Caron}},
	url = {https://scaron.info/teaching/equations-of-motion.html},
	urldate = {2020-02-03},
	author = {Caron, S}
}

@article{corke_what_2020,
	title = {What can robotics research learn from computer vision research?},
	url = {http://arxiv.org/abs/2001.02366},
	abstract = {The computer vision and robotics research communities are each strong. However progress in computer vision has become turbo-charged in recent years due to big data, GPU computing, novel learning algorithms and a very effective research methodology. By comparison, progress in robotics seems slower. It is true that robotics came later to exploring the potential of learning -- the advantages over the well-established body of knowledge in dynamics, kinematics, planning and control is still being debated, although reinforcement learning seems to offer real potential. However, the rapid development of computer vision compared to robotics cannot be only attributed to the former's adoption of deep learning. In this paper, we argue that the gains in computer vision are due to research methodology -- evaluation under strict constraints versus experiments; bold numbers versus videos.},
	urldate = {2020-02-03},
	journal = {arXiv:2001.02366 [cs]},
	author = {Corke, Peter and Dayoub, Feras and Hall, David and Skinner, John and Sünderhauf, Niko},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.02366},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics}
}

@article{galindo_robot_2008,
	series = {Semantic {Knowledge} in {Robotics}},
	title = {Robot task planning using semantic maps},
	volume = {56},
	issn = {0921-8890},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889008001188},
	doi = {10.1016/j.robot.2008.08.007},
	abstract = {Task planning for mobile robots usually relies solely on spatial information and on shallow domain knowledge, such as labels attached to objects and places. Although spatial information is necessary for performing basic robot operations (navigation and localization), the use of deeper domain knowledge is pivotal to endow a robot with higher degrees of autonomy and intelligence. In this paper, we focus on semantic knowledge, and show how this type of knowledge can be profitably used for robot task planning. We start by defining a specific type of semantic maps, which integrates hierarchical spatial information and semantic knowledge. We then proceed to describe how these semantic maps can improve task planning in two ways: extending the capabilities of the planner by reasoning about semantic information, and improving the planning efficiency in large domains. We show several experiments that demonstrate the effectiveness of our solutions in a domain involving robot navigation in a domestic environment.},
	language = {en},
	number = {11},
	urldate = {2020-01-31},
	journal = {Robotics and Autonomous Systems},
	author = {Galindo, Cipriano and Fernández-Madrigal, Juan-Antonio and González, Javier and Saffiotti, Alessandro},
	month = nov,
	year = {2008},
	keywords = {Cognitive robotics, Knowledge representation, Mobile robotics, Robot maps, Task planning},
	pages = {955--966}
}

@article{gschwindt_can_2019,
	title = {Can a {Robot} {Become} a {Movie} {Director}? {Learning} {Artistic} {Principles} for {Aerial} {Cinematography}},
	shorttitle = {Can a {Robot} {Become} a {Movie} {Director}?},
	url = {http://arxiv.org/abs/1904.02579},
	abstract = {Aerial filming is constantly gaining importance due to the recent advances in drone technology. It invites many intriguing, unsolved problems at the intersection of aesthetical and scientific challenges. In this work, we propose a deep reinforcement learning agent which supervises motion planning of a filming drone by making desirable shot mode selections based on aesthetical values of video shots. Unlike most of the current state-of-the-art approaches that require explicit guidance by a human expert, our drone learns how to make favorable viewpoint selections by experience. We propose a learning scheme that exploits aesthetical features of retrospective shots in order to extract a desirable policy for better prospective shots. We train our agent in realistic AirSim simulations using both a hand-crafted reward function as well as reward from direct human input. We then deploy the same agent on a real DJI M210 drone in order to test the generalization capability of our approach to real world conditions. To evaluate the success of our approach in the end, we conduct a comprehensive user study in which participants rate the shot quality of our methods. Videos of the system in action can be seen at https://youtu.be/qmVw6mfyEmw.},
	urldate = {2020-01-31},
	journal = {arXiv:1904.02579 [cs]},
	author = {Gschwindt, Mirko and Camci, Efe and Bonatti, Rogerio and Wang, Wenshan and Kayacan, Erdal and Scherer, Sebastian},
	month = oct,
	year = {2019},
	note = {arXiv: 1904.02579},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, Computer Science - Robotics}
}

@misc{noauthor_gumgum_nodate,
	title = {{GumGum} {\textbar} {Applied} {Computer} {Vision}},
	url = {http://gumgum.com/},
	abstract = {GumGum is a leading computer vision company on a mission to unlock the value of every online image and video for marketers using patented image-recognition technology.},
	language = {en},
	urldate = {2020-01-30}
}

@patent{katz_machine_2019,
	title = {Machine learning models for identifying sports teams depicted in image or video data},
	url = {https://patents.google.com/patent/US10417499B2/en},
	nationality = {US},
	language = {en},
	assignee = {GumGum Inc},
	number = {US10417499B2},
	urldate = {2020-01-30},
	author = {Katz, Jeffrey Benjamin and Carter, Cambron Neil and Kim, Brian Jongmin},
	month = sep,
	year = {2019},
	keywords = {depicted, media, media content, team, video}
}

@inproceedings{petsas_soccer_2016,
	title = {Soccer player tracking using particle filters},
	doi = {10.1109/ISSPIT.2016.7886009},
	abstract = {We present a multi-target tracking system for estimating the position of multiple soccer players as they move around during a soccer game. Our system relies on silhouette observations recorded by a static camera, and utilises 3D models and particle filter methods to estimate athlete positions. Tracking parameters can be adapted in order to tip the scales towards precision or performance. We present the system's software architecture as a client-server application, and demonstrate results based on a simulated yet realistic dataset produced using the Unity3D game engine.},
	booktitle = {2016 {IEEE} {International} {Symposium} on {Signal} {Processing} and {Information} {Technology} ({ISSPIT})},
	author = {Petsas, Panagiotis and Kaimakis, Paris},
	month = dec,
	year = {2016},
	note = {ISSN: null},
	keywords = {3D models, Cameras, Data models, Servers, Signal processing, Soccer player tracking, Solid modeling, Three-dimensional displays, Trajectory, Unity3D game engine, athlete positions, athlete tracking, client-server application, image filtering, image motion analysis, multi-target tracking, multitarget tracking system, object tracking, particle filtering (numerical methods), particle filters, silhouette observations, soccer game, soccer player tracking, sport, static camera, target tracking},
	pages = {57--62}
}

@incollection{thomas_sports_2011,
	address = {London},
	title = {Sports {TV} {Applications} of {Computer} {Vision}},
	isbn = {978-0-85729-997-0},
	url = {https://doi.org/10.1007/978-0-85729-997-0_28},
	abstract = {This chapter focusses on applications of Computer Vision that help the sports broadcaster illustrate, analyse and explain sporting events, by the generation of images and graphics that can be incorporated in the broadcast, providing visual support to the commentators and pundits. After a discussion of simple graphics overlay on static images, systems are described that rely on calibrated cameras to insert graphics or to overlay content from other images. Approaches are then discussed that use computer vision to provide more advanced effects, for tasks such as segmenting people from the background, and inferring the 3D position of people and balls. As camera calibration is a key component for all but the simplest applications, an approach to real-time calibration of broadcast cameras is then presented. The chapter concludes with a discussion of some current challenges.},
	language = {en},
	urldate = {2020-01-30},
	booktitle = {Visual {Analysis} of {Humans}: {Looking} at {People}},
	publisher = {Springer},
	author = {Thomas, Graham},
	editor = {Moeslund, Thomas B. and Hilton, Adrian and Krüger, Volker and Sigal, Leonid},
	year = {2011},
	doi = {10.1007/978-0-85729-997-0_28},
	pages = {563--579}
}

@inproceedings{kono_jackin_2017,
	address = {Gothenburg, Sweden},
	series = {{VRST} '17},
	title = {{JackIn} {Airsoft}: localization and view sharing for strategic sports},
	isbn = {978-1-4503-5548-3},
	shorttitle = {{JackIn} {Airsoft}},
	url = {http://doi.org/10.1145/3139131.3139161},
	doi = {10.1145/3139131.3139161},
	abstract = {We present JackIn Airsoft, a system for generating maps for multi-player sport activities and sharing their first-person views (FPVs). In first-person shooting (FPS) games, maps are generated for the visualization of the player's location; these maps are used for strategic play and discussions. FPS games are a virtual experience of shooting or of military activities; the displaying of maps on a screen is a technique designed for game playing. We address the challenge of adapting this effective map visualization technique to real-world strategic sports. In this paper, we introduce our prototype map generator for airsoft sports that is based on the usage of wearable cameras and simultaneous localization and mapping (SLAM). The system enables users to switch between the FPV and the generated map in order to share a player's experience and a strategic overview for team sports. We applied ORB-SLAM2 to multiple recorded FPV videos to discuss the situations and conditions appropriate for our system.},
	urldate = {2020-01-30},
	booktitle = {Proceedings of the 23rd {ACM} {Symposium} on {Virtual} {Reality} {Software} and {Technology}},
	publisher = {Association for Computing Machinery},
	author = {Kono, Michinari and Miyaki, Takashi and Rekimoto, Jun},
	month = nov,
	year = {2017},
	keywords = {SLAM, airsoft, augmented sports, first-person view, wearable camera},
	pages = {1--4}
}

@incollection{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	pages = {1097--1105}
}

@article{alom_history_2018,
	title = {The {History} {Began} from {AlexNet}: {A} {Comprehensive} {Survey} on {Deep} {Learning} {Approaches}},
	shorttitle = {The {History} {Began} from {AlexNet}},
	url = {http://arxiv.org/abs/1803.01164},
	abstract = {Deep learning has demonstrated tremendous success in variety of application domains in the past few years. This new field of machine learning has been growing rapidly and applied in most of the application domains with some new modalities of applications, which helps to open new opportunity. There are different methods have been proposed on different category of learning approaches, which includes supervised, semi-supervised and un-supervised learning. The experimental results show state-of-the-art performance of deep learning over traditional machine learning approaches in the field of Image Processing, Computer Vision, Speech Recognition, Machine Translation, Art, Medical imaging, Medical information processing, Robotics and control, Bio-informatics, Natural Language Processing (NLP), Cyber security, and many more. This report presents a brief survey on development of DL approaches, including Deep Neural Network (DNN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) including Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). In addition, we have included recent development of proposed advanced variant DL techniques based on the mentioned DL approaches. Furthermore, DL approaches have explored and evaluated in different application domains are also included in this survey. We have also comprised recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys have published on Deep Learning in Neural Networks [1, 38] and a survey on RL [234]. However, those papers have not discussed the individual advanced techniques for training large scale deep learning models and the recently developed method of generative models [1].},
	urldate = {2020-01-30},
	journal = {arXiv:1803.01164 [cs]},
	author = {Alom, Md Zahangir and Taha, Tarek M. and Yakopcic, Christopher and Westberg, Stefan and Sidike, Paheding and Nasrin, Mst Shamima and Van Esesn, Brian C. and Awwal, Abdul A. S. and Asari, Vijayan K.},
	month = sep,
	year = {2018},
	note = {arXiv: 1803.01164},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{russakovsky_imagenet_2015,
	title = {{ImageNet} {Large} {Scale} {Visual} {Recognition} {Challenge}},
	volume = {115},
	issn = {0920-5691},
	url = {http://doi.org/10.1007/s11263-015-0816-y},
	doi = {10.1007/s11263-015-0816-y},
	abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.},
	number = {3},
	urldate = {2020-01-30},
	journal = {International Journal of Computer Vision},
	author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
	month = dec,
	year = {2015},
	keywords = {Benchmark, Dataset, Large-scale, Object detection, Object recognition},
	pages = {211--252}
}

@misc{gabriela_how_nodate,
	title = {How to insert {PDF} into {LaTeX} – {PDFConverters} {Official} {Website}},
	url = {https://www.pdfconverters.net/how-to/insert-pdf-to-latex/},
	language = {en-US},
	urldate = {2020-01-29},
	author = {{Gabriela}}
}

@misc{noauthor_human36m_nodate,
	title = {Human3.{6M} {Dataset}},
	url = {http://vision.imar.ro/human3.6m/description.php},
	urldate = {2020-01-29}
}

@misc{noauthor_densepose_nodate,
	title = {{DensePose}},
	url = {http://densepose.org/},
	urldate = {2020-01-29}
}

@misc{noauthor_posetrack_nodate,
	title = {{PoseTrack}},
	url = {https://posetrack.net},
	abstract = {PoseTrack Dataset and Benchmark},
	language = {en},
	urldate = {2020-01-29}
}

@article{wang_efficient_2019,
	title = {Efficient {Autonomous} {Robotic} {Exploration} {With} {Semantic} {Road} {Map} in {Indoor} {Environments}},
	volume = {4},
	issn = {2377-3774},
	doi = {10.1109/LRA.2019.2923368},
	abstract = {This letter presents a novel and integrated framework for Next-Best-View (NBV) selection toward autonomous robotic exploration in indoor environments. A topological map, named semantic road map (SRM), is proposed to represent the explored environment during the exploration. The basic concept of the SRM is to construct a graph with nodes containing the exploration states and with edges satisfying the collision-free constraints. Especially, the SRM integrates both semantic and structure information of the environment, which possesses the beneficial properties of using a topological map in the exploration. It is worth noting that the proposed SRM is incrementally built along with the exploration process, thereby, avoiding the unnecessary reconsideration of the explored areas when constructing the topological map. Based on the SRM, a novel decision model with semantic information is presented for determining the NBV during the exploration. Moreover, the decision model takes into account both information gain and cost-to-go of a candidate NBV, which can be queried efficiently on the SRM, enabling the efficient exploration of the environment. The effectiveness and efficiency of the proposed system are assessed and demonstrated using both simulated and real-world indoor experiments.},
	number = {3},
	journal = {IEEE Robotics and Automation Letters},
	author = {Wang, Chaoqun and Zhu, Delong and Li, Teng and Meng, Max Q.-H. and de Silva, Clarence W.},
	month = jul,
	year = {2019},
	keywords = {Indoor environment, Measurement, NBV, Path planning, Roads, Robot sensing systems, SRM, Search and rescue robots, Semantics, autonomous robotic exploration, collision-free constraints, decision model, exploration process, exploration states, graph theory, indoor environments, integrated framework, mobile robots, motion and path planning, next-best-view selection, path planning, query processing, semantic information, semantic road map, semantic structure information, surveillance systems, topological map},
	pages = {2989--2996}
}

@article{hepp_plan3d_2018,
	title = {{Plan3D}: {Viewpoint} and {Trajectory} {Optimization} for {Aerial} {Multi}-{View} {Stereo} {Reconstruction}},
	url = {http://dl.acm.org/doi/abs/10.1145/3233794},
	abstract = {We introduce a new method that efficiently computes a set of viewpoints and trajectories for high-quality 3D reconstructions in outdoor environments. Our goal is to automatically explore an unknown...},
	language = {EN},
	urldate = {2020-01-28},
	journal = {ACM Transactions on Graphics (TOG)},
	author = {Hepp, B and Niessner, M and Hilliges, O},
	month = dec,
	year = {2018}
}
@inproceedings{roberts_submodular_2017,
	title = {Submodular {Trajectory} {Optimization} for {Aerial} {3D} {Scanning}},
	doi = {10.1109/ICCV.2017.569},
	abstract = {Drones equipped with cameras are emerging as a powerful tool for large-scale aerial 3D scanning, but existing automatic flight planners do not exploit all available information about the scene, and can therefore produce inaccurate and incomplete 3D models. We present an automatic method to generate drone trajectories, such that the imagery acquired during the flight will later produce a high-fidelity 3D model. Our method uses a coarse estimate of the scene geometry to plan camera trajectories that: (1) cover the scene as thoroughly as possible; (2) encourage observations of scene geometry from a diverse set of viewing angles; (3) avoid obstacles; and (4) respect a user-specified flight time budget. Our method relies on a mathematical model of scene coverage that exhibits an intuitive diminishing returns property known as submodularity. We leverage this property extensively to design a trajectory planning algorithm that reasons globally about the non-additive coverage reward obtained across a trajectory, jointly with the cost of traveling between views. We evaluate our method by using it to scan three large outdoor scenes, and we perform a quantitative evaluation using a photorealistic video game simulator.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Roberts, Mike and Shah, Shital and Dey, Debadeepta and Truong, Anh and Sinha, Sudipta and Kapoor, Ashish and Hanrahan, Pat and Joshi, Neel},
	month = oct,
	year = {2017},
	note = {ISSN: 2380-7504},
	keywords = {Cameras, Drones, Geometry, Image reconstruction, Surface reconstruction, Three-dimensional displays, Trajectory, automatic flight planners, autonomous aerial vehicles, camera trajectories, collision avoidance, drone trajectories, high-fidelity 3D model, intuitive diminishing returns property, large-scale aerial 3D scanning, mathematical model, mobile robots, nonadditive coverage reward, robot vision, solid modelling, submodular trajectory optimization, trajectory optimisation (aerospace), trajectory planning algorithm, user-specified flight time budget},
	pages = {5334--5343}
}

@inproceedings{peng_adaptive_2019,
	title = {Adaptive {View} {Planning} for {Aerial} {3D} {Reconstruction}},
	doi = {10.1109/ICRA.2019.8793532},
	abstract = {With the proliferation of small aerial vehicles, acquiring close up imagery for high quality reconstruction is gaining importance. We present an adaptive view planning method to collect such images in an automated fashion. We first start by sampling a small set of views to build a coarse proxy to the scene. We then present (i) a method that builds a set of adaptive viewing planes for efficient view selection and (ii) an algorithm to plan a trajectory that guarantees high reconstruction quality which does not deviate too much from the optimal one. The vehicle then follows the trajectory to cover the scene, and the procedure is repeated until reconstruction quality converges or a desired level of quality is achieved. The set of viewing planes provides an effective compromise between using the entire 3D free space and using a single view hemisphere to select the views. We compare our algorithm to existing methods in three challenging scenes. Our algorithm generates views which produce the least reconstruction error comparing to three different baseline approaches.},
	booktitle = {2019 {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Peng, Cheng and Isler, Volkan},
	month = may,
	year = {2019},
	note = {ISSN: 1050-4729},
	keywords = {3D free space, Drones, Feature extraction, Image reconstruction, Image resolution, Planning, Three-dimensional displays, Trajectory, adaptive view planning method, aerial 3D reconstruction, aerial vehicles, autonomous aerial vehicles, coarse proxy, high quality reconstruction, image reconstruction, optimisation, reconstruction error, trajectory control},
	pages = {2981--2987}
}

@article{liu_ground_2019,
	title = {Ground {Feature} {Oriented} {Path} {Planning} for {Unmanned} {Aerial} {Vehicle} {Mapping}},
	volume = {12},
	issn = {2151-1535},
	doi = {10.1109/JSTARS.2019.2899369},
	abstract = {Unmanned aerial vehicles (UAVs) are being used to take roles that were previously performed by traditional manned aircraft, such as remote sensing and photogrammetry. The standard path planning for UAV mapping is mainly executed by adopting the “lawnmower” mode. However, some situations that have sparse or repetitive features are problematic to map with this technique, given that orthoimage stitching relies heavily on the number and quality of image tie points. Traditional path planning can result in some unregistered images due to a lack of tie points. This paper proposes a ground feature oriented path-planning method for UAV mapping. The method first estimates the distribution of the ground feature points from a lower-resolution image. Then, image footprints are selected by applying a three-step optimization. The flight path for the UAV is then generated by solving the “grouped traveling salesman” problem. This approach ensures the georegistration of images during orthoimage stitching while maximizing the orthoimage coverage. Two cases, including a simulation and a real-world case, together with standard path-planning modes with different overlaps, are selected to evaluate the proposed method. The results show that the proposed method covers the same area with the smallest number of images. The model excludes problematic areas from the scanning path to generate a more efficient processing dataset.},
	number = {4},
	journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	author = {Liu, Chun and Zhang, Shuhang and Akbar, Akram},
	month = apr,
	year = {2019},
	keywords = {Feature extraction, Image matching, Optimization, Path planning, Planning, Remote sensing, Scale-invariant feature transform (SIFT), UAV mapping, Unmanned aerial vehicles, autonomous aerial vehicles, flight path, ground feature oriented path planning, ground feature oriented path-planning method, ground feature points, grouped traveling salesman problem, image footprints, image resolution, image tie points, lawnmower mode, lower-resolution image, mobile robots, orthoimage coverage, orthoimage stitching, path planning, photogrammetry, remote sensing, robot vision, scanning path, standard path planning, standard path-planning modes, submodular optimization, three-step optimization, traditional path planning, travelling salesman problems, unmanned aerial vehicle, unmanned aerial vehicle (UAV), unregistered images},
	pages = {1175--1187}
}

@article{hollinger_active_2013,
	title = {Active planning for underwater inspection and the benefit of adaptivity},
	volume = {32},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364912467485},
	doi = {10.1177/0278364912467485},
	abstract = {We discuss the problem of inspecting an underwater structure, such as a submerged ship hull, with an autonomous underwater vehicle (AUV). Unlike a large body of prior work, we focus on planning the views of the AUV to improve the quality of the inspection, rather than maximizing the accuracy of a given data stream. We formulate the inspection planning problem as an extension to Bayesian active learning, and we show connections to recent theoretical guarantees in this area. We rigorously analyze the benefit of adaptive re-planning for such problems, and we prove that the potential benefit of adaptivity can be reduced from an exponential to a constant factor by changing the problem from cost minimization with a constraint on information gain to variance reduction with a constraint on cost. Such analysis allows the use of robust, non-adaptive planning algorithms that perform competitively with adaptive algorithms. Based on our analysis, we propose a method for constructing 3D meshes from sonar-derived point clouds, and we introduce uncertainty modeling through non-parametric Bayesian regression. Finally, we demonstrate the benefit of active inspection planning using sonar data from ship hull inspections with the Bluefin-MIT Hovering AUV.},
	language = {en},
	number = {1},
	urldate = {2020-01-28},
	journal = {The International Journal of Robotics Research},
	author = {Hollinger, Geoffrey A and Englot, Brendan and Hover, Franz S and Mitra, Urbashi and Sukhatme, Gaurav S},
	month = jan,
	year = {2013},
	keywords = {active perception, adaptivity gaps, motion planning, sensor coverage, underwater robotics},
	pages = {3--18}
}

@inproceedings{zhang_submodular_2016,
	title = {Submodular {Optimization} with {Routing} {Constraints}},
	copyright = {Authors who publish a paper in this conference agree to the following terms:   Author(s) agree to transfer their copyrights in their article/paper to the Association for the Advancement of Artificial Intelligence (AAAI), in order to deal with future requests for reprints, translations, anthologies, reproductions, excerpts, and other publications. This grant will include, without limitation, the entire copyright in the article/paper in all countries of the world, including all renewals, extensions, and reversions thereof, whether such rights current exist or hereafter come into effect, and also the exclusive right to create electronic versions of the article/paper, to the extent that such right is not subsumed under copyright.  The author(s) warrants that they are the sole author and owner of the copyright in the above article/paper, except for those portions shown to be in quotations; that the article/paper is original throughout; and that the undersigned right to make the grants set forth above is complete and unencumbered.  The author(s) agree that if anyone brings any claim or action alleging facts that, if true, constitute a breach of any of the foregoing warranties, the author(s) will hold harmless and indemnify AAAI, their grantees, their licensees, and their distributors against any liability, whether under judgment, decree, or compromise, and any legal fees and expenses arising out of that claim or actions, and the undersigned will cooperate fully in any defense AAAI may make to such claim or action. Moreover, the undersigned agrees to cooperate in any claim or other action seeking to protect or enforce any right the undersigned has granted to AAAI in the article/paper. If any such claim or action fails because of facts that constitute a breach of any of the foregoing warranties, the undersigned agrees to reimburse whomever brings such claim or action for expenses and attorneys’ fees incurred therein.  Author(s) retain all proprietary rights other than copyright (such as patent rights).  Author(s) may make personal reuse of all or portions of the above article/paper in other works of their own authorship.  Author(s) may reproduce, or have reproduced, their article/paper for the author’s personal use, or for company use provided that AAAI copyright and the source are indicated, and that the copies are not used in a way that implies AAAI endorsement of a product or service of an employer, and that the copies per se are not offered for sale. The foregoing right shall not permit the posting of the article/paper in electronic or digital form on any computer network, except by the author or the author’s employer, and then only on the author’s or the employer’s own web page or ftp site. Such web page or ftp site, in addition to the aforementioned requirements of this Paragraph, must provide an electronic reference or link back to the AAAI electronic server, and shall not post other AAAI copyrighted materials not of the author’s or the employer’s creation (including tables of contents with links to other papers) without AAAI’s written permission.  Author(s) may make limited distribution of all or portions of their article/paper prior to publication.  In the case of work performed under U.S. Government contract, AAAI grants the U.S. Government royalty-free permission to reproduce all or portions of the above article/paper, and to authorize others to do so, for U.S. Government purposes.  In the event the above article/paper is not accepted and published by AAAI, or is withdrawn by the author(s) before acceptance by AAAI, this agreement becomes null and void.},
	url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11911/11670},
	abstract = {Submodular optimization, particularly under cardinality or cost constraints, has received considerable attention, stemming from its breadth of application, ranging from sensor placement to targeted marketing. However, the constraints faced in many real domains are more complex. We investigate an important and very general class of problems of maximizing a submodular function subject to general cost constraints, especially focusing on costs coming from route planning. Canoni- cal problems that motivate our framework include mobile robotic sensing, and door-to-door marketing. We propose a generalized cost-benefit (GCB) greedy al- gorithm for our problem, and prove bi-criterion approximation guarantees under significantly weaker assumptions than those in related literature. Experimental evaluation on realistic mobile sensing and door-to-door marketing problems, as well as using simulated networks, show that our algorithm achieves significantly higher utility than state-of-the-art alternatives, and has either lower or competitive running time.},
	language = {en},
	urldate = {2020-01-28},
	booktitle = {Thirtieth {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Zhang, Haifeng and Vorobeychik, Yevgeniy},
	month = feb,
	year = {2016}
}

@inproceedings{chandra_chekuri_recursive_2005,
	title = {A recursive greedy algorithm for walks in directed graphs},
	doi = {10.1109/SFCS.2005.9},
	abstract = {Given an arc-weighted directed graph G = (V, A, /spl lscr/) and a pair of nodes s, t, we seek to find an s-t walk of length at most B that maximizes some given function f of the set of nodes visited by the walk. The simplest case is when we seek to maximize the number of nodes visited: this is called the orienteering problem. Our main result is a quasi-polynomial time algorithm that yields an O(log OPT) approximation for this problem when f is a given submodular set function. We then extend it to the case when a node v is counted as visited only if the walk reaches v in its time window [R(v), D(v)]. We apply the algorithm to obtain several new results. First, we obtain an O(log OPT) approximation for a generalization of the orienteering problem in which the profit for visiting each node may vary arbitrarily with time. This captures the time window problem considered earlier for which, even in undirected graphs, the best approximation ratio known [Bansal, N et al. (2004)] is O(log/sup 2/ OPT). The second application is an O(log/sup 2/ k) approximation for the k-TSP problem in directed graphs (satisfying asymmetric triangle inequality). This is the first non-trivial approximation algorithm for this problem. The third application is an O(log/sup 2/ k) approximation (in quasi-poly time) for the group Steiner problem in undirected graphs where k is the number of groups. This improves earlier ratios (Garg, N et al.) by a logarithmic factor and almost matches the inapproximability threshold on trees (Halperin and Krauthgamer, 2003). This connection to group Steiner trees also enables us to prove that the problem we consider is hard to approximate to a ratio better than /spl Omega/(log/sup 1-/spl epsi// OPT), even in undirected graphs. Even though our algorithm runs in quasi-poly time, we believe that the implications for the approximability of several basic optimization problems are interesting.},
	booktitle = {46th {Annual} {IEEE} {Symposium} on {Foundations} of {Computer} {Science} ({FOCS}'05)},
	author = {Chandra Chekuri and Pal, M.},
	month = oct,
	year = {2005},
	note = {ISSN: 0272-5428},
	keywords = {Approximation algorithms, Delay, Floors, Greedy algorithms, Optimized production technology, Routing, Steiner problem, Steiner trees, Traveling salesman problems, Tree graphs, Vehicles, computational complexity, directed graphs walk, graph theory, greedy algorithm, greedy algorithms, k-traveling salesman problem, orienteering problem, quasi-poly time, quasipolynomial time algorithm, time window problem, travelling salesman problems},
	pages = {245--253}
}

@article{iyer_fast_2013,
	title = {Fast {Semidifferential}-based {Submodular} {Function} {Optimization}},
	url = {http://arxiv.org/abs/1308.1006},
	abstract = {We present a practical and powerful new framework for both unconstrained and constrained submodular function optimization based on discrete semidifferentials (sub- and super-differentials). The resulting algorithms, which repeatedly compute and then efficiently optimize submodular semigradients, offer new and generalize many old methods for submodular optimization. Our approach, moreover, takes steps towards providing a unifying paradigm applicable to both submodular min- imization and maximization, problems that historically have been treated quite distinctly. The practicality of our algorithms is important since interest in submodularity, owing to its natural and wide applicability, has recently been in ascendance within machine learning. We analyze theoretical properties of our algorithms for minimization and maximization, and show that many state-of-the-art maximization algorithms are special cases. Lastly, we complement our theoretical analyses with supporting empirical experiments.},
	urldate = {2020-01-27},
	journal = {arXiv:1308.1006 [cs]},
	author = {Iyer, Rishabh and Jegelka, Stefanie and Bilmes, Jeff},
	month = aug,
	year = {2013},
	note = {arXiv: 1308.1006},
	keywords = {Computer Science - Data Structures and Algorithms, Computer Science - Discrete Mathematics, Computer Science - Machine Learning}
}

@inproceedings{binney_informative_2010,
	title = {Informative path planning for an autonomous underwater vehicle},
	doi = {10.1109/ROBOT.2010.5509714},
	abstract = {We present a path planning method for autonomous underwater vehicles in order to maximize mutual information. We adapt a method previously used for surface vehicles, and extend it to deal with the unique characteristics of underwater vehicles. We show how to generate near-optimal paths while ensuring that the vehicle stays out of high-traffic areas during predesignated time intervals. In our objective function we explicitly account for the fact that underwater vehicles typically take measurements while moving, and that they do not have the ability to communicate until they resurface. We present field results from ocean trials on planning paths for a specific AUV, an underwater glider.},
	booktitle = {2010 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Binney, Jonathan and Krause, Andreas and Sukhatme, Gaurav S.},
	month = may,
	year = {2010},
	note = {ISSN: 1050-4729},
	keywords = {Boats, Computer science, Ocean temperature, Path planning, Remotely operated vehicles, Robotics and automation, Sea measurements, Sea surface, Spatial resolution, Underwater vehicles, autonomous underwater vehicle, informative path planning, mobile robots, path planning, remotely operated vehicles, underwater glider, underwater vehicles},
	pages = {4791--4796}
}

@article{singh_efficient_2009,
	title = {Efficient {Informative} {Sensing} using {Multiple} {Robots}},
	volume = {34},
	copyright = {Copyright (c)},
	issn = {1076-9757},
	url = {https://jair.org/index.php/jair/article/view/10602},
	doi = {10.1613/jair.2674},
	language = {en},
	urldate = {2020-01-27},
	journal = {Journal of Artificial Intelligence Research},
	author = {Singh, A. and Krause, A. and Guestrin, C. and Kaiser, W. J.},
	month = apr,
	year = {2009},
	pages = {707--755}
}

@misc{noauthor_opengl_nodate,
	title = {{OpenGL} {Mathematics} {API} {Documentation} - functions},
	url = {https://glm.g-truc.net/0.9.9/api/modules.html},
	urldate = {2020-01-24}
}

@misc{noauthor_opengl_nodate-1,
	title = {{OpenGL} {Mathematics}},
	url = {https://github.com/g-truc/glm},
	abstract = {OpenGL Mathematics (GLM). Contribute to g-truc/glm development by creating an account on GitHub.},
	language = {en},
	urldate = {2020-01-24},
	journal = {GitHub}
}

@misc{noauthor_building_nodate,
	title = {Building your own {C} application},
	url = {http://www.opengl-tutorial.org/miscellaneous/building-your-own-c-application/},
	urldate = {2020-01-24}
}

@mastersthesis{chitchian_adapting_2011,
	address = {Delft},
	title = {Adapting {Particle} {Filter} {Algorithms} to the {GPU} {Architecture}},
	copyright = {reserved},
	url = {https://pdfs.semanticscholar.org/f41c/3d5cd972ffeec91bb7428fa3988487763d6e.pdf},
	abstract = {The particle filter is a Bayesian estimation technique based on Monte
Carlo simulations. ĉe non-parametric nature of particle ėlters makes
them ideal for non-linear non-Gaussian systems. ĉis greater ėltering
accuracy, however, comes at the price of increased computational complexity which limits their practical use for real-time applications.
ĉis thesis presents an aĨempt to enable real-time particle ėltering for
complex estimation problems using modern GPU hardware. We propose a GPU-based generic particle ėltering framework which can be applied to various estimation problems. We implement a real-time estimation application using this particle ėltering framework and measure
the estimation error with different ėlter parameters. Furthermore, we
present an in-depth performance analysis of our GPU implementation
followed by a number of optimisations in order to increase implementation efficiency.},
	language = {en},
	urldate = {2020-01-24},
	school = {TU Delft},
	author = {Chitchian, Mehdi},
	year = {2011}
}

@misc{michaelwillett_michaelwillettcuda-particle-filter_2019,
	title = {michaelwillett/{CUDA}-{Particle}-{Filter}},
	url = {https://github.com/michaelwillett/CUDA-Particle-Filter},
	abstract = {Contribute to michaelwillett/CUDA-Particle-Filter development by creating an account on GitHub.},
	urldate = {2020-01-24},
	author = {michaelwillett},
	month = nov,
	year = {2019},
	note = {original-date: 2016-11-09T16:48:14Z}
}

@inproceedings{hosseinzadeh_real-time_2019,
	title = {Real-{Time} {Monocular} {Object}-{Model} {Aware} {Sparse} {SLAM}},
	doi = {10.1109/ICRA.2019.8793728},
	abstract = {Simultaneous Localization And Mapping (SLAM) is a fundamental problem in mobile robotics. While sparse point-based SLAM methods provide accurate camera localization, the generated maps lack semantic information. On the other hand, state of the art object detection methods provide rich information about entities present in the scene from a single image. This work incorporates a real-time deep-learned object detector to the monocular SLAM framework for representing generic objects as quadrics that permit detections to be seamlessly integrated while allowing the real-time performance. Finer reconstruction of an object, learned by a CNN network, is also incorporated and provides a shape prior for the quadric leading further refinement. To capture the structure of the scene, additional planar landmarks are detected by a CNN-based plane detector and modelled as independent landmarks in the map. Extensive experiments support our proposed inclusion of semantic objects and planar structures directly in the bundle-adjustment of SLAM - Semantic SLAM- that enriches the reconstructed map semantically, while significantly improving the camera localization.},
	booktitle = {2019 {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Hosseinzadeh, Mehdi and Li, Kejie and Latif, Yasir and Reid, Ian},
	month = may,
	year = {2019},
	note = {ISSN: 1050-4729},
	keywords = {CNN network, CNN-based plane detector, Cameras, Image reconstruction, Real-time systems, SLAM (robots), Semantics, Simultaneous localization and mapping, Three-dimensional displays, camera localization, cameras, convolutional neural nets, deep-learned object detector, feature extraction, learning (artificial intelligence), mobile robotics, mobile robots, monocular object-model aware sparse SLAM framework, object detection, robot vision, semantic SLAM, semantic objects representation, simultaneous localization and mapping, sparse point-based SLAM methods},
	pages = {7123--7129}
}

@misc{noauthor_cristiano_nodate,
	title = {Cristiano {Ronaldo} scores in complete darkness (greatest goals) - {YouTube}},
	url = {https://www.youtube.com/watch?v=aoScYO2osb0},
	urldate = {2020-01-23}
}

@inproceedings{bowman_probabilistic_2017,
	title = {Probabilistic data association for semantic {SLAM}},
	doi = {10.1109/ICRA.2017.7989203},
	abstract = {Traditional approaches to simultaneous localization and mapping (SLAM) rely on low-level geometric features such as points, lines, and planes. They are unable to assign semantic labels to landmarks observed in the environment. Furthermore, loop closure recognition based on low-level features is often viewpoint-dependent and subject to failure in ambiguous or repetitive environments. On the other hand, object recognition methods can infer landmark classes and scales, resulting in a small set of easily recognizable landmarks, ideal for view-independent unambiguous loop closure. In a map with several objects of the same class, however, a crucial data association problem exists. While data association and recognition are discrete problems usually solved using discrete inference, classical SLAM is a continuous optimization over metric information. In this paper, we formulate an optimization problem over sensor states and semantic landmark positions that integrates metric information, semantic information, and data associations, and decompose it into two interconnected problems: an estimation of discrete data association and landmark class probabilities, and a continuous optimization over the metric states. The estimated landmark and robot poses affect the association and class distributions, which in turn affect the robot-landmark pose optimization. The performance of our algorithm is demonstrated on indoor and outdoor datasets.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Bowman, Sean L. and Atanasov, Nikolay and Daniilidis, Kostas and Pappas, George J.},
	month = may,
	year = {2017},
	note = {ISSN: null},
	keywords = {Feature extraction, Measurement, Optimization, SLAM (robots), Semantics, Simultaneous localization and mapping, discrete data association, indoor datasets, landmark class probabilities, low-level geometric features, object recognition, optimisation, optimization problem, outdoor datasets, pose estimation, probabilistic data association, robot-landmark pose optimization, semantic SLAM, semantic information, semantic landmark positions, sensor fusion, simultaneous localization-and-mapping, view-independent unambiguous loop closure recognition},
	pages = {1722--1729}
}

@inproceedings{salas-moreno_slam_2013,
	title = {{SLAM}++: {Simultaneous} {Localisation} and {Mapping} at the {Level} of {Objects}},
	shorttitle = {{SLAM}++},
	doi = {10.1109/CVPR.2013.178},
	abstract = {We present the major advantages of a new 'object oriented' 3D SLAM paradigm, which takes full advantage in the loop of prior knowledge that many scenes consist of repeated, domain-specific objects and structures. As a hand-held depth camera browses a cluttered scene, real-time 3D object recognition and tracking provides 6DoF camera-object constraints which feed into an explicit graph of objects, continually refined by efficient pose-graph optimisation. This offers the descriptive and predictive power of SLAM systems which perform dense surface reconstruction, but with a huge representation compression. The object graph enables predictions for accurate ICP-based camera to model tracking at each live frame, and efficient active search for new objects in currently undescribed image regions. We demonstrate real-time incremental SLAM in large, cluttered environments, including loop closure, relocalisation and the detection of moved objects, and of course the generation of an object level scene description with the potential to enable interaction.},
	booktitle = {2013 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Salas-Moreno, Renato F. and Newcombe, Richard A. and Strasdat, Hauke and Kelly, Paul H.J. and Davison, Andrew J.},
	month = jun,
	year = {2013},
	note = {ISSN: 1063-6919},
	keywords = {6DoF camera-object constraints, Cameras, GPGPU, ICP, ICP-based camera, Iterative closest point algorithm, KinectFusion, Labeling, Real-time systems, SLAM, SLAM (robots), SLAM++, Search problems, Simultaneous localization and mapping, Three-dimensional displays, augmented reality, cluttered scene, data compression, graph theory, hand-held depth camera, loop closure, model tracking, moved object detection, moved object relocalisation, object detection, object graph, object level scene description, object oriented 3D SLAM paradigm, object recognition, object tracking, object-oriented, objects, pose estimation, pose-graph optimisation, real-time, real-time 3D object recognition, real-time 3D object tracking, real-time incremental SLAM, representation compression, scene understanding, simultaneous localisation and mapping, surface reconstruction},
	pages = {1352--1359}
}

@article{mohammad_distributional_2012,
	title = {Distributional {Measures} as {Proxies} for {Semantic} {Relatedness}},
	url = {http://arxiv.org/abs/1203.1889},
	abstract = {The automatic ranking of word pairs as per their semantic relatedness and ability to mimic human notions of semantic relatedness has widespread applications. Measures that rely on raw data (distributional measures) and those that use knowledge-rich ontologies both exist. Although extensive studies have been performed to compare ontological measures with human judgment, the distributional measures have primarily been evaluated by indirect means. This paper is a detailed study of some of the major distributional measures; it lists their respective merits and limitations. New measures that overcome these drawbacks, that are more in line with the human notions of semantic relatedness, are suggested. The paper concludes with an exhaustive comparison of the distributional and ontology-based measures. Along the way, significant research problems are identified. Work on these problems may lead to a better understanding of how semantic relatedness is to be measured.},
	urldate = {2020-01-23},
	journal = {arXiv:1203.1889 [cs]},
	author = {Mohammad, Saif M. and Hirst, Graeme},
	month = mar,
	year = {2012},
	note = {arXiv: 1203.1889},
	keywords = {Computer Science - Computation and Language}
}

@article{weeds_co-occurrence_2005,
	title = {Co-occurrence {Retrieval}: {A} {Flexible} {Framework} for {Lexical} {Distributional} {Similarity}},
	volume = {31},
	issn = {0891-2017},
	shorttitle = {Co-occurrence {Retrieval}},
	url = {http://www.mitpressjournals.org/doi/10.1162/089120105775299122},
	doi = {10.1162/089120105775299122},
	abstract = {Techniques that exploit knowledge of distributional similarity between words have been proposed in many areas of Natural Language Processing. For example, in language modeling, the sparse data problem can be alleviated by estimating the probabilities of unseen co-occurrences of events from the probabilities of seen co-occurrences of similar events. In other applications, distributional similarity is taken to be an approximation to semantic similarity. However, due to the wide range of potential applications and the lack of a strict definition of the concept of distributional similarity, many methods of calculating distributional similarity have been proposed or adopted. In this work, a flexible, parameterized framework for calculating distributional similarity is proposed. Within this framework, the problem of finding distributionally similar words is cast as one of co-occurrence retrieval (CR) for which precision and recall can be measured by analogy with the way they are measured in document retrieval. As will be shown, a number of popular existing measures of distributional similarity are simulated with parameter settings within the CR framework. In this article, the CR framework is then used to systematically investigate three fundamental questions concerning distributional similarity. First, is the relationship of lexical similarity necessarily symmetric, or are there advantages to be gained from considering it as an asymmetric relationship? Second, are some co-occurrences inherently more salient than others in the calculation of distributional similarity? Third, is it necessary to consider the difference in the extent to which each word occurs in each co-occurrence type? Two application-based tasks are used for evaluation: automatic thesaurus generation and pseudo-disambiguation. It is possible to achieve significantly better results on both these tasks by varying the parameters within the CR framework rather than using other existing distributional similarity measures; it will also be shown that any single unparameterized measure is unlikely to be able to do better on both tasks. This is due to an inherent asymmetry in lexical substitutability and therefore also in lexical distributional similarity.},
	number = {4},
	urldate = {2020-01-23},
	journal = {Computational Linguistics},
	author = {Weeds, Julie and Weir, David},
	month = dec,
	year = {2005},
	pages = {439--475}
}

@article{dagan_similarity-based_1999,
	title = {Similarity-{Based} {Models} of {Word} {Cooccurrence} {Probabilities}},
	volume = {34},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1007537716579},
	doi = {10.1023/A:1007537716579},
	abstract = {In many applications of natural language processing (NLP) it is necessary to determine the likelihood of a given word combination. For example, a speech recognizer may need to determine which of the two word combinations “eat a peach” and ”eat a beach” is more likely. Statistical NLP methods determine the likelihood of a word combination from its frequency in a training corpus. However, the nature of language is such that many word combinations are infrequent and do not occur in any given corpus. In this work we propose a method for estimating the probability of such previously unseen word combinations using available information on “most similar” words.We describe probabilistic word association models based on distributional word similarity, and apply them to two tasks, language modeling and pseudo-word disambiguation. In the language modeling task, a similarity-based model is used to improve probability estimates for unseen bigrams in a back-off language model. The similarity-based method yields a 20\% perplexity improvement in the prediction of unseen bigrams and statistically significant reductions in speech-recognition error.We also compare four similarity-based estimation methods against back-off and maximum-likelihood estimation methods on a pseudo-word sense disambiguation task in which we controlled for both unigram and bigram frequency to avoid giving too much weight to easy-to-disambiguate high-frequency configurations. The similarity-based methods perform up to 40\% better on this particular task.},
	language = {en},
	number = {1},
	urldate = {2020-01-23},
	journal = {Machine Learning},
	author = {Dagan, Ido and Lee, Lillian and Pereira, Fernando C. N.},
	month = feb,
	year = {1999},
	keywords = {Statistical language modeling, sense disambiguation},
	pages = {43--69}
}

@article{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2020-01-22},
	journal = {arXiv:1810.04805 [cs]},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv: 1810.04805},
	keywords = {Computer Science - Computation and Language}
}

@article{strubell_energy_2019,
	title = {Energy and {Policy} {Considerations} for {Deep} {Learning} in {NLP}},
	url = {http://arxiv.org/abs/1906.02243},
	abstract = {Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.},
	urldate = {2020-01-22},
	journal = {arXiv:1906.02243 [cs]},
	author = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.02243},
	keywords = {Computer Science - Computation and Language}
}

@article{schwartz_green_2019,
	title = {Green {AI}},
	url = {http://arxiv.org/abs/1907.10597},
	abstract = {The computations required for deep learning research have been doubling every few months, resulting in an estimated 300,000x increase from 2012 to 2018 [2]. These computations have a surprisingly large carbon footprint [38]. Ironically, deep learning was inspired by the human brain, which is remarkably energy efficient. Moreover, the financial cost of the computations can make it difficult for academics, students, and researchers, in particular those from emerging economies, to engage in deep learning research. This position paper advocates a practical solution by making efficiency an evaluation criterion for research alongside accuracy and related measures. In addition, we propose reporting the financial cost or "price tag" of developing, training, and running models to provide baselines for the investigation of increasingly efficient methods. Our goal is to make AI both greener and more inclusive---enabling any inspired undergraduate with a laptop to write high-quality research papers. Green AI is an emerging focus at the Allen Institute for AI.},
	urldate = {2020-01-22},
	journal = {arXiv:1907.10597 [cs, stat]},
	author = {Schwartz, Roy and Dodge, Jesse and Smith, Noah A. and Etzioni, Oren},
	month = aug,
	year = {2019},
	note = {arXiv: 1907.10597},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computers and Society, Computer Science - Machine Learning, Statistics - Methodology}
}

@article{reijgwart_voxgraph_2020,
	title = {Voxgraph: {Globally} {Consistent}, {Volumetric} {Mapping} {Using} {Signed} {Distance} {Function} {Submaps}},
	volume = {5},
	issn = {2377-3774},
	shorttitle = {Voxgraph},
	doi = {10.1109/LRA.2019.2953859},
	abstract = {Globally consistent dense maps are a key requirement for long-term robot navigation in complex environments. While previous works have addressed the challenges of dense mapping and global consistency, most require more computational resources than may be available on-board small robots. We propose a framework that creates globally consistent volumetric maps on a CPU and is lightweight enough to run on computationally constrained platforms. Our approach represents the environment as a collection of overlapping signed distance function (SDF) submaps and maintains global consistency by computing an optimal alignment of the submap collection. By exploiting the underlying SDF representation, we generate correspondence-free constraints between submap pairs that are computationally efficient enough to optimize the global problem each time a new submap is added. We deploy the proposed system on a hexacopter micro aerial vehicle (MAV) with an Intel i7-8650 U CPU in two realistic scenarios: mapping a large-scale area using a 3D LiDAR and mapping an industrial space using an RGB-D camera. In the large-scale outdoor experiments, the system optimizes a 120 × 80 m map in less than 4 s and produces absolute trajectory RMSEs of less than 1 m over 400 m trajectories. Our complete system, called voxgraph, is available as open source.11https://github.com/ethz-asl/voxgraph.},
	number = {1},
	journal = {IEEE Robotics and Automation Letters},
	author = {Reijgwart, Victor and Millane, Alexander and Oleynikova, Helen and Siegwart, Roland and Cadena, Cesar and Nieto, Juan},
	month = jan,
	year = {2020},
	keywords = {Mapping, SLAM, aerial systems: perception and autonomy},
	pages = {227--234}
}

@article{blake_fprfast_2020,
	title = {{FPR}—{Fast} {Path} {Risk} {Algorithm} to {Evaluate} {Collision} {Probability}},
	volume = {5},
	issn = {2377-3774},
	doi = {10.1109/LRA.2019.2943074},
	abstract = {As mobile robots and autonomous vehicles become increasingly prevalent in human-centred environments, there is a need to control the risk of collision. Perceptual modules, for example machine vision, provide uncertain estimates of object location. In that context, the frequently made assumption of an exactly known free-space is invalid. Clearly, no paths can be guaranteed to be collision free. Instead, it is necessary to compute the probabilistic risk of collision on any proposed path. The FPR algorithm, proposed here, efficiently calculates an upper bound on the risk of collision for a robot moving on the plane. That computation orders candidate trajectories according to (the bound on) their degree of risk. Then paths within a user-defined threshold of primary risk could be selected according to secondary criteria such as comfort and efficiency. The key contribution of this letter is the FPR algorithm and its `convolution trick' to factor the integrals used to bound the risk of collision. As a consequence of the convolution trick, given K obstacles and N candidate paths, the computational load is reduced from the naive O(NK), to the qualitatively faster O(N + K).},
	number = {1},
	journal = {IEEE Robotics and Automation Letters},
	author = {Blake, Andrew and Bordallo, Alejandro and Brestnichki, Kamen and Hawasly, Majd and Penkov, Svetlin Valentinov and Ramamoorthy, Subramanian and Silva, Alexandre},
	month = jan,
	year = {2020},
	keywords = {Collision avoidance, Convolution, FPR algorithm, Handheld computers, Robot sensing systems, Shape, Uncertainty, autonomous vehicles, collision avoidance, collision probability, computational load, convolution trick, fast path risk algorithm, free-space, human-centred environments, machine vision, mobile robots, object location, perceptual modules, probabilistic risk, probability, probability and statistical methods, robot vision, uncertain estimates},
	pages = {1--7}
}

@inproceedings{ye_obstacle_2019,
	title = {Obstacle {Avoidance} with {Reinforcement} {Learning} and {Adaptive} {Resonance} {Theory}},
	doi = {10.1109/ROBIO49542.2019.8961847},
	abstract = {The reinforcement learning (RL) of the autonomous mobile agent is one of the actual research topics. It permits mobile agents to interact constantly with their environment and to avoid obstacles. First, this paper presents an algorithm which integrates Deep Deterministic Policy Gradient (DDPG) algorithm and Fuzzy Adaptive Resonance Theory (ART) in order to improve generalization performance of RL. Then the curiosity is introduced to integrate with the first proposed algorithm to solve the problem of slow convergence caused by Fuzzy ART. Results of the simulation experiments demonstrate the effectiveness of the proposed algorithm. It shows that the algorithms perform well in both low-dimension and high-dimension state space.},
	booktitle = {2019 {IEEE} {International} {Conference} on {Robotics} and {Biomimetics} ({ROBIO})},
	author = {Ye, Lingjian and Zhou, Yimin},
	month = dec,
	year = {2019},
	note = {ISSN: null},
	keywords = {Deep Deterministic Policy Gradient, Fuzzy Adaptive Resonance Theory, Obstacle avoidance, Reinforcement Learning, curiosity},
	pages = {1127--1132}
}

@article{ieee_ieee_2015,
	title = {{IEEE} {Standard} for {Robot} {Map} {Data} {Representation} for {Navigation}},
	issn = {null},
	doi = {10.1109/IEEESTD.2015.7300355},
	abstract = {A map data representation of environments of a mobile robot performing a navigation task is specified in this standard. It provides data models and data formats for two-dimensional (2D) metric and topological maps.},
	journal = {1873-2015 IEEE Standard for Robot Map Data Representation for Navigation},
	author = {IEEE},
	month = oct,
	year = {2015},
	keywords = {IEEE 1873(TM), IEEE Standards, IEEE Std 1873-2015, IEEE standards, Map data representation, Navigation, Robots, data formats, data models, map data representation, metric map, mobile robot, mobile robots, path planning, robot map data representation, robot navigation, topological map, topological maps, two-dimensional metric},
	pages = {1--54}
}

@misc{noauthor_7473_nodate,
	title = {7.4.7.3. {Bonferroni}'s method},
	url = {https://www.itl.nist.gov/div898/handbook/prc/section4/prc473.htm},
	urldate = {2020-01-22}
}

@misc{noauthor_comparing_2009,
	title = {Comparing {Multiple} {Treatment} {Means}: {Bonferroni}'s {Method}},
	shorttitle = {Comparing {Multiple} {Treatment} {Means}},
	url = {https://www.spcforexcel.com/knowledge/comparing-processes/bonferronis-method},
	abstract = {January 2009 In This Issue: Comparing Multiple Treatments Bonferroni's Method Confidence Intervals Conclusion Summary Quick Links Best wishes to all of you in this New Year. This marks the start of our sixth year of newsletters. This month's newsletter will examine one method of comparing multiple process means (treatments). The method we will use is called Bonferroni's method. We will build on the analysis we started last month using ANOVA. Comparing Multiple Treatments Quite often, you will want to test a single factor at various treatments.},
	language = {en},
	urldate = {2020-01-22},
	journal = {BPI Consulting},
	month = jan,
	year = {2009}
}

@misc{noauthor_bonferroni_2020,
	title = {Bonferroni correction},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Bonferroni_correction&oldid=935852166},
	abstract = {In statistics, the Bonferroni correction is one of several methods used to counteract the problem of multiple comparisons.},
	language = {en},
	urldate = {2020-01-22},
	journal = {Wikipedia},
	month = jan,
	year = {2020},
	note = {Page Version ID: 935852166}
}

@article{grisetti_tutorial_2010,
	title = {A {Tutorial} on {Graph}-{Based} {SLAM}},
	volume = {2},
	issn = {1941-1197},
	doi = {10.1109/MITS.2010.939925},
	abstract = {Being able to build a map of the environment and to simultaneously localize within this map is an essential skill for mobile robots navigating in unknown environments in absence of external referencing systems such as GPS. This so-called simultaneous localization and mapping (SLAM) problem has been one of the most popular research topics in mobile robotics for the last two decades and efficient approaches for solving this task have been proposed. One intuitive way of formulating SLAM is to use a graph whose nodes correspond to the poses of the robot at different points in time and whose edges represent constraints between the poses. The latter are obtained from observations of the environment or from movement actions carried out by the robot. Once such a graph is constructed, the map can be computed by finding the spatial configuration of the nodes that is mostly consistent with the measurements modeled by the edges. In this paper, we provide an introductory description to the graph-based SLAM problem. Furthermore, we discuss a state-of-the-art solution that is based on least-squares error minimization and exploits the structure of the SLAM problems during optimization. The goal of this tutorial is to enable the reader to implement the proposed methods from scratch.},
	number = {4},
	journal = {IEEE Intelligent Transportation Systems Magazine},
	author = {Grisetti, Giorgio and Kümmerle, Rainer and Stachniss, Cyrill and Burgard, Wolfram},
	year = {2010},
	keywords = {Global Positioning System, Graph theory, Mapping, Mobile robots, SLAM (robots), Tutorials, graph based SLAM, least square error minimization, mobile robot, mobile robots, navigation, path planning, simultaneous localization and mapping, spatial configuration},
	pages = {31--43}
}

@article{mittal_vision-based_2019,
	title = {Vision-{Based} {Autonomous} {UAV} {Navigation} and {Landing} for {Urban} {Search} and {Rescue}},
	url = {http://arxiv.org/abs/1906.01304},
	abstract = {Unmanned Aerial Vehicles (UAVs) equipped with bioradars are a life-saving technology that can enable identification of survivors under collapsed buildings in the aftermath of natural disasters such as earthquakes or gas explosions. However, these UAVs have to be able to autonomously navigate in disaster struck environments and land on debris piles in order to accurately locate the survivors. This problem is extremely challenging as pre-existing maps cannot be leveraged for navigation due to structural changes that may have occurred. Furthermore, existing landing site detection algorithms are not suitable to identify safe landing regions on debris piles. In this work, we present a computationally efficient system for autonomous UAV navigation and landing that does not require any prior knowledge about the environment. We propose a novel landing site detection algorithm that computes costmaps based on several hazard factors including terrain flatness, steepness, depth accuracy, and energy consumption information. We also introduce a first-of-a-kind synthetic dataset of over 1.2 million images of collapsed buildings with groundtruth depth, surface normals, semantics and camera pose information. We demonstrate the efficacy of our system using experiments from a city scale hyperrealistic simulation environment and in real-world scenarios with collapsed buildings.},
	urldate = {2020-01-22},
	journal = {arXiv:1906.01304 [cs]},
	author = {Mittal, Mayank and Mohan, Rohit and Burgard, Wolfram and Valada, Abhinav},
	month = sep,
	year = {2019},
	note = {arXiv: 1906.01304},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics}
}

@misc{stachniss_openslamorg_nodate,
	title = {{OpenSLAM}.org},
	url = {https://openslam-org.github.io/},
	abstract = {The simultaneous localization and mapping (SLAM) problem has been intensively studied in the robotics community in the past. Different techniques have been proposed but only a few of them are available as implementations to the community. The goal of OpenSLAM.org is to provide a platform for SLAM researchers which gives them the possibility to publish their algorithms. OpenSLAM.org was established in 2006 and in 2018, it has been moved to github.},
	urldate = {2020-01-22},
	author = {Stachniss, Cyrill and Grisetti, Giorgio and Frese, Udo}
}

@misc{noauthor_state---art_nodate,
	title = {State-of-the-art table for {Pose} {Estimation} on {Leeds} {Sports} {Poses}},
	url = {https://paperswithcode.com/sota/pose-estimation-on-leeds-sports-poses},
	abstract = {A performance comparison of 8 methods.},
	language = {en},
	urldate = {2020-01-22}
}

@inproceedings{bridgeman_multi-person_2019,
	title = {Multi-{Person} {3D} {Pose} {Estimation} and {Tracking} in {Sports}},
	url = {http://openaccess.thecvf.com/content_CVPRW_2019/html/CVSports/Bridgeman_Multi-Person_3D_Pose_Estimation_and_Tracking_in_Sports_CVPRW_2019_paper.html},
	urldate = {2020-01-22},
	author = {Bridgeman, Lewis and Volino, Marco and Guillemaut, Jean-Yves and Hilton, Adrian},
	year = {2019},
	pages = {0--0}
}

@inproceedings{andriluka_2d_2014,
	title = {{2D} {Human} {Pose} {Estimation}: {New} {Benchmark} and {State} of the {Art} {Analysis}},
	shorttitle = {{2D} {Human} {Pose} {Estimation}},
	url = {http://openaccess.thecvf.com/content_cvpr_2014/html/Andriluka_2D_Human_Pose_2014_CVPR_paper.html},
	urldate = {2020-01-22},
	author = {Andriluka, Mykhaylo and Pishchulin, Leonid and Gehler, Peter and Schiele, Bernt},
	year = {2014},
	pages = {3686--3693}
}

@inproceedings{fastovets_athlete_2013,
	title = {Athlete {Pose} {Estimation} from {Monocular} {TV} {Sports} {Footage}},
	doi = {10.1109/CVPRW.2013.152},
	abstract = {Human pose estimation from monocular video streams is a challenging problem. Much of the work on this problem has focused on developing inference algorithms and probabilistic prior models based on learned measurements. Such algorithms face challenges in generalization beyond the learned dataset. We propose an interactive model-based generative approach for estimating the human pose in 2D from uncalibrated monocular video in unconstrained sports TV footage without any prior learning on motion captured or annotated data. Belief-propagation over a spatio-temporal graph of candidate body part hypotheses is used to estimate a temporally consistent pose between key-frame constraints. Experimental results show that the proposed generative pose estimation framework is capable of estimating pose even in very challenging unconstrained scenarios.},
	booktitle = {2013 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops}},
	author = {Fastovets, Mykyta and Guillemaut, Jean-Yves and Hilton, Adrian},
	month = jun,
	year = {2013},
	note = {ISSN: 2160-7508},
	keywords = {Estimation, Hidden Markov models, Histograms, Image color analysis, Interpolation, Joints, Three-dimensional displays, athlete pose estimation, belief networks, belief-propagation, candidate body part hypotheses, constrained optimisation, generative pose estimation framework, graph theory, human pose estimation, human pose tracking, inference algorithms, inference mechanisms, interactive model-based generative approach, key-frame constraints, learned dataset, learned measurements, monocular TV sport footage, monocular video streams, motion capturing, motion estimation, pose estimation, probabilistic prior models, spatiotemporal graph, spatiotemporal phenomena, sport, temporal smoothing, uncalibrated monocular video, unconstrained sport TV footage, video streaming},
	pages = {1048--1054}
}

@article{afrouzian_pose_2016,
	title = {Pose estimation of soccer players using multiple uncalibrated cameras},
	volume = {75},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-015-2611-8},
	doi = {10.1007/s11042-015-2611-8},
	abstract = {Fully automatic algorithm for estimating the 3D human pose from multiple uncalibrated cameras is presented. Unlike the state-of-the-art methods which use the estimated pose of previous frames to restrict the candidates of current frame, the proposed method uses the viewpoint of previous frame in order to obtain an accurate pose. This paper also introduces a method to incorporate pose estimation results of several cameras without using the calibration information. The algorithm employs a rich descriptor for matching purposes. The performance of the proposed method is evaluated on a soccer database which is captured by multiple cameras. The dataset of silhouettes, in which the related 3D skeleton poses are known, is also constructed. Experimental results show that the proposed algorithm has a high accuracy rate in estimation of 3D pose of soccer players.},
	language = {en},
	number = {12},
	urldate = {2020-01-22},
	journal = {Multimedia Tools and Applications},
	author = {Afrouzian, Reza and Seyedarabi, Hadi and Kasaei, Shohreh},
	month = jun,
	year = {2016},
	keywords = {3D human pose estimation, Shape context, Silhouette, Soccer match, Uncalibrated cameras},
	pages = {6809--6827}
}

@inproceedings{germann_space-time_2011,
	title = {Space-{Time} {Body} {Pose} {Estimation} in {Uncontrolled} {Environments}},
	doi = {10.1109/3DIMPVT.2011.38},
	abstract = {We propose a data-driven, multi-view body pose estimation algorithm for video. It can operate in uncontrolled environments with loosely calibrated and low resolution cameras and without restricting assumptions on the family of possible poses or motions. Our algorithm first estimates a rough pose estimation using a spatial and temporal silhouette based search in a database of known poses. The estimated pose is improved in a novel pose consistency step acting locally on single frames and globally over the entire sequence. Finally, the resulting pose estimation is refined in a spatial and temporal pose optimization consisting of novel constraints to obtain an accurate pose. Our method proved to perform well on low resolution video footage from real broadcast of soccer games.},
	booktitle = {Visualization and {Transmission} 2011 {International} {Conference} on {3D} {Imaging}, {Modeling}, {Processing}},
	author = {Germann, Marcel and Popa, Tiberiu and Ziegler, Remo and Keiser, Richard and Gross, Markus},
	month = may,
	year = {2011},
	note = {ISSN: 1550-6185},
	keywords = {Cameras, Databases, Estimation, Labeling, Leg, Pixel, Three dimensional displays, body pose estimation, multiview body pose estimation, pose estimation, space-time body pose estimation, spatial silhouette based search, temporal silhouette based search, uncontrolled environments, video footage, video signal processing},
	pages = {244--251}
}

@mastersthesis{skyttner_multi-person_2018,
	address = {Linkoeping},
	title = {Multi-{Person} {Pose} {Estimation} in {Soccer} {Videos} with {Convolutional} {Neural} {Networks}},
	url = {https://liu.diva-portal.org/smash/get/diva2:1244986/FULLTEXT01.pdf},
	abstract = {Pose estimation is the problem of detecting poses of people in images, multiperson pose estimation is the problem of detecting poses of multiple persons in
images. This thesis investigates multi-person pose estimation by applying the
associative embedding method [14] on images from soccer videos. Three models
are compared, first a pre-trained model, second a fine-tuned model and third a
model extended to handle image sequences.
The pre-trained method performed well on soccer images and the fine-tuned
model performed better then the pre-trained model. The image sequence model
performed equally as the fine-tuned model but not better. This thesis concludes
that the associative embedding model is a feasible option for pose estimation in
soccer videos and should be further researched.},
	language = {en},
	urldate = {2020-01-22},
	school = {Linkoeping University},
	author = {Skyttner, Axel},
	month = may,
	year = {2018}
}

@misc{noauthor_space-time_nodate,
	title = {Space-{Time} {Body} {Pose} {Estimation} in {Uncontrolled} {Environments} ({3DIMPVT} 2011)},
	url = {https://www.youtube.com/watch?v=INI2IvbJgNY},
	abstract = {M. Germann, T. Popa, R. Ziegler, R. Keiser, M. Gross: Space-Time Body Pose Estimation in Uncontrolled Environments

We propose a data-driven, multi-view body pose estimation algorithm for video. It can operate in uncontrolled environments with loosely calibrated and low resolution cameras and without restricting assumptions on the family of possible poses or motions. Our algorithm first estimates a rough pose estimation using a spatial and temporal silhouette based search in a database of known poses. The estimated pose is improved in a novel pose consistency step acting locally on single frames and globally over the entire sequence. Finally, the resulting pose estimation is refined in a spatial and temporal pose optimization consisting of novel constraints to obtain an accurate pose. Our method proved to perform well on low resolution video footage from real broadcast of soccer games.

Proceedings of 3DIMPVT (Hangzhou, China, May 16-19, 2011), pp. 244-251

More publications from the CGL can be found here: https://cgl.ethz.ch/publications/pape...},
	urldate = {2020-01-22}
}

@incollection{stachniss_decision-theoretic_2009,
	address = {Berlin, Heidelberg},
	series = {Springer {Tracts} in {Advanced} {Robotics}},
	title = {Decision-{Theoretic} {Exploration} {Using} {Coverage} {Maps}},
	isbn = {978-3-642-01097-2},
	url = {https://doi.org/10.1007/978-3-642-01097-2_3},
	abstract = {There exist several applications in which the exploration task is an integral part of the robotic mission. The complete and efficient coverage of terrain is one of the elementary problems in planetary exploration [6], reconnaissance [63], rescue [110, 149], mowing [67], or cleaning [68, 38, 137].Throughout this chapter, we focus on the problem of how to efficiently explore an environment with a single mobile robot. We describe a decision-theoretic approach to exploration of unknown terrain with noisy sensors. The goal is to come up with an accurate model of the environment without steering the robot manually. Our approach seeks to minimize the uncertainty in the map over time. Therefore, the next viewpoint of the robot is chosen in a way that its action provides the highest expected uncertainty reduction. In the first part of this book, we assume that the movement of the vehicle is not affected by noise. Later on, we relax this assumption and present a technique to deal with the pose uncertainty of a mobile robot.},
	language = {en},
	urldate = {2020-01-22},
	booktitle = {Robotic {Mapping} and {Exploration}},
	publisher = {Springer},
	author = {Stachniss, Cyrill},
	editor = {Stachniss, Cyrill},
	year = {2009},
	doi = {10.1007/978-3-642-01097-2_3},
	keywords = {Average Path Length, Exploration Strategy, Grid Cell, Information Gain, Mobile Robot},
	pages = {23--41}
}

@incollection{stachniss_information_2009,
	address = {Berlin, Heidelberg},
	series = {Springer {Tracts} in {Advanced} {Robotics}},
	title = {Information {Gain}-based {Exploration}},
	isbn = {978-3-642-01097-2},
	url = {https://doi.org/10.1007/978-3-642-01097-2_9},
	abstract = {So far, we investigated different aspects of the map learning problem. We started in Chapter 3 with an information gain-based approach to exploration, where we assumed that the poses of the robot were known during exploration. After dealing with the problem of coordinating a team of robots, we addressed the SLAM problem to find a way to deal with the pose uncertainty of a mobile robot. We then presented in the previous two chapters an exploration system that takes into account the pose uncertainty and carries out loop-closing actions in order to relocalize the robot. This has been shown to provide better maps than exploration approaches focusing on new terrain acquisition only.},
	language = {en},
	urldate = {2020-01-22},
	booktitle = {Robotic {Mapping} and {Exploration}},
	publisher = {Springer},
	author = {Stachniss, Cyrill},
	editor = {Stachniss, Cyrill},
	year = {2009},
	doi = {10.1007/978-3-642-01097-2_9},
	keywords = {Exploration Approach, Laser Range, Left Image, Mobile Robot, Occupancy Grid},
	pages = {143--160}
}

@book{stachniss_robotic_2009,
	address = {Berlin, Heidelberg},
	edition = {1st ed. 2009.},
	series = {Springer {Tracts} in {Advanced} {Robotics}, 55},
	title = {Robotic {Mapping} and {Exploration}},
	isbn = {978-3-642-01097-2},
	abstract = {"Robotic Mapping and Exploration" is an important contribution in the area of simultaneous localization and mapping (SLAM) for autonomous robots, which has been receiving a great deal of attention by the research community in the latest few years. The contents are focused on the autonomous mapping learning problem. Solutions include uncertainty-driven exploration, active loop closing, coordination of multiple robots, learning and incorporating background knowledge, and dealing with dynamic environments. Results are accompanied by a rich set of experiments, revealing a promising outlook toward the application to a wide range of mobile robots and field settings, such as search and rescue, transportation tasks, or automated vacuum cleaning.},
	language = {eng},
	publisher = {Springer Berlin Heidelberg},
	author = {Stachniss, Cyrill},
	year = {2009},
	keywords = {Artificial Intelligence, Artificial intelligence, Control, Robotics, Mechatronics, Robotics and Automation, Systems Theory, Control, Systems theory}
}

@article{kim_active_2015,
	title = {Active visual {SLAM} for robotic area coverage: {Theory} and experiment},
	volume = {34},
	issn = {0278-3649},
	shorttitle = {Active visual {SLAM} for robotic area coverage},
	url = {https://doi.org/10.1177/0278364914547893},
	doi = {10.1177/0278364914547893},
	abstract = {This paper reports on an integrated navigation algorithm for the visual simultaneous localization and mapping (SLAM) robotic area coverage problem. In the robotic area coverage problem, the goal is to explore and map a given target area within a reasonable amount of time. This goal necessitates the use of minimally redundant overlap trajectories for coverage efficiency; however, visual SLAM’s navigation estimate will inevitably drift over time in the absence of loop closures. Therefore, efficient area coverage and good SLAM navigation performance represent competing objectives. To solve this decision-making problem, we introduce perception-driven navigation, an integrated navigation algorithm that automatically balances between exploration and revisitation using a reward framework. This framework accounts for SLAM localization uncertainty, area coverage performance, and the identification of good candidate regions in the environment for visual perception. Results are shown for both a hybrid simulation and real-world demonstration of a visual SLAM system for autonomous underwater ship hull inspection.},
	language = {en},
	number = {4-5},
	urldate = {2020-01-21},
	journal = {The International Journal of Robotics Research},
	author = {Kim, Ayoung and Eustice, Ryan M.},
	month = apr,
	year = {2015},
	keywords = {Active SLAM, computer vision, information gain, marine robotics, planning, visual saliency},
	pages = {457--475}
}

@inproceedings{carrillo_comparison_2012,
	title = {On the comparison of uncertainty criteria for active {SLAM}},
	doi = {10.1109/ICRA.2012.6224890},
	abstract = {In this paper, we consider the computation of the D-optimality criterion as a metric for the uncertainty of a SLAM system. Properties regarding the use of this uncertainty criterion in the active SLAM context are highlighted, and comparisons against the A-optimality criterion and entropy are presented. This paper shows that contrary to what has been previously reported, the D-optimality criterion is indeed capable of giving fruitful information as a metric for the uncertainty of a robot performing SLAM. Finally, through various experiments with simulated and real robots, we support our claims and show that the use of D-opt has desirable effects in various SLAM related tasks such as active mapping and exploration.},
	booktitle = {2012 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Carrillo, Henry and Reid, Ian and Castellanos, José A.},
	month = may,
	year = {2012},
	note = {ISSN: 1050-4729},
	keywords = {A-optimality criterion, Covariance matrix, D-optimality criterion, Measurement, Planning, SLAM (robots), Simultaneous localization and mapping, Trajectory, Uncertainty, active SLAM, entropy, mobile robots, robot, simultaneous localization and mapping, statistical testing, uncertainty criteria, uncertainty handling, uncertainty metric},
	pages = {2080--2087}
}

@inproceedings{carrillo_monotonicity_2015,
	title = {On the monotonicity of optimality criteria during exploration in active {SLAM}},
	doi = {10.1109/ICRA.2015.7139384},
	abstract = {In this paper we investigate the monotonicity of various optimality criteria during the exploration phase of an active SLAM algorithm. Optimality criteria such as A-opt, D-opt or E-opt are used in active SLAM to account for uncertainty in the map or the robot's pose, and these criteria are usually part of utility functions which help active SLAM algorithms decide where the robot should move next. The monotonicity of the optimality criteria is of utmost importance. During the exploration phase, i.e. when the robot is traversing new territory or cannot perform a loop closure, the most common way of estimating the pose of the robot is through dead-reckoning. Correctly accounting for the uncertainty is important for an active SLAM algorithm and in particular for a dead-reckoning scenario, where by definition the uncertainty in the robot's pose grows. If monotonicity does not hold in this scenario, active SLAM algorithms can execute actions under the false belief that the uncertainty has reduced. We show analytically and experimentally some conditions in which the A-opt and E-opt criteria lose monotonicity in a dead-reckoning scenario, where the propagation of the robot's pose is done using a linearized framework. We also show analytically and experimentally that under the same conditions the D-opt does not lose monotonicity and, in general for the linearized framework under consideration, D-opt does not break monotonicity.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Carrillo, Henry and Latif, Yasir and Rodriguez-Arevalo, Maria L. and Neira, José and Castellanos, José A.},
	month = may,
	year = {2015},
	note = {ISSN: 1050-4729},
	keywords = {A-opt, Approximation methods, Covariance matrices, D-opt, E-opt, Optimized production technology, SLAM (robots), Simultaneous localization and mapping, Trajectory, Uncertainty, action execution, active SLAM algorithm, dead-reckoning scenario, exploration phase, linearisation techniques, linearized framework, mobile robots, optimality criteria monotonicity, pose estimation, robot vision, utility functions},
	pages = {1476--1483}
}

@article{carlone_active_2014,
	title = {Active {SLAM} and {Exploration} with {Particle} {Filters} {Using} {Kullback}-{Leibler} {Divergence}},
	volume = {75},
	issn = {1573-0409},
	url = {https://doi.org/10.1007/s10846-013-9981-9},
	doi = {10.1007/s10846-013-9981-9},
	abstract = {Autonomous exploration under uncertain robot location requires the robot to use active strategies to trade-off between the contrasting tasks of exploring the unknown scenario and satisfying given constraints on the admissible uncertainty in map estimation. The corresponding problem, namely active SLAM (Simultaneous Localization and Mapping) and exploration, has received a large attention from the robotic community for its relevance in mobile robotics applications. In this work we tackle the problem of active SLAM and exploration with Rao-Blackwellized Particle Filters. We propose an application of Kullback-Leibler divergence for the purpose of evaluating the particle-based SLAM posterior approximation. This metric is then applied in the definition of the expected information from a policy, which allows the robot to autonomously decide between exploration and place revisiting actions (i.e., loop closing). Extensive tests are performed in typical indoor and office environments and on well-known benchmarking scenarios belonging to SLAM literature, with the purpose of comparing the proposed approach with the state-of-the-art techniques and to evaluate the maturity of truly autonomous navigation systems based on particle filtering.},
	language = {en},
	number = {2},
	urldate = {2020-01-21},
	journal = {Journal of Intelligent \& Robotic Systems},
	author = {Carlone, Luca and Du, Jingjing and Kaouk Ng, Miguel and Bona, Basilio and Indri, Marina},
	month = aug,
	year = {2014},
	keywords = {Active SLAM, Autonomous exploration, Mobile robot, Rao-Blackwellized Particle Filters},
	pages = {291--311}
}

@misc{noauthor_gaussian_2019,
	title = {Gaussian {Processes}, not quite for dummies},
	url = {https://thegradient.pub/gaussian-process-not-quite-for-dummies/},
	abstract = {I recall always having this vague impression about Gaussian Processes (GPs) being a magical algorithm that is able to define probability distributions over sets of functions, but I had always procrastinated reading up on the details. It's not completely my fault though! Whenever I Google \&quot;Gaussian Processes\&quot;, I},
	language = {en},
	urldate = {2020-01-21},
	journal = {The Gradient},
	month = nov,
	year = {2019}
}

@techreport{dellaert_factor_2012,
	type = {Technical {Report}},
	title = {Factor {Graphs} and {GTSAM}: {A} {Hands}-on {Introduction}},
	shorttitle = {Factor {Graphs} and {GTSAM}},
	url = {https://smartech.gatech.edu/handle/1853/45226},
	abstract = {In this document I provide a hands-on introduction to both factor graphs and GTSAM. 
Factor graphs are graphical models (Koller and Friedman, 2009) that are well suited to modeling 
complex estimation problems, such as Simultaneous Localization and Mapping (SLAM) or 
Structure from Motion (SFM). You might be familiar with another often used graphical model, 
Bayes networks, which are directed acyclic graphs. A factor graph, however, is a bipartite graph 
consisting of factors connected to variables. The variables represent the unknown random variables 
in the estimation problem, whereas the factors represent probabilistic information on those 
variables, derived from measurements or prior knowledge. In the following sections I will show 
many examples from both robotics and vision. 
The GTSAM toolbox (GTSAM stands for “Georgia Tech Smoothing and Mapping”) toolbox is 
a BSD-licensed C++ library based on factor graphs, developed at the Georgia Institute of Technology 
by myself, many of my students, and collaborators. It provides state of the art solutions to the 
SLAM and SFM problems, but can also be used to model and solve both simpler and more complex 
estimation problems. It also provides a MATLAB interface which allows for rapid prototype 
development, visualization, and user interaction. 
GTSAM exploits sparsity to be computationally efficient. Typically measurements only provide 
information on the relationship between a handful of variables, and hence the resulting factor graph 
will be sparsely connected. This is exploited by the algorithms implemented in GTSAM to reduce 
computational complexity. Even when graphs are too dense to be handled efficiently by direct 
methods, GTSAM provides iterative methods that are quite efficient regardless. 
You can download the latest version of GTSAM at http://tinyurl.com/gtsam.},
	language = {en\_US},
	urldate = {2020-01-21},
	institution = {Georgia Institute of Technology},
	author = {Dellaert, Frank},
	month = sep,
	year = {2012}
}

@inproceedings{cadena_fast_2015,
	title = {A fast, modular scene understanding system using context-aware object detection},
	doi = {10.1109/ICRA.2015.7139874},
	abstract = {We propose a semantic scene understanding system that is suitable for real robotic operations. The system solves different tasks (semantic segmentation and object detections) in an opportunistic and distributed fashion but still allows communication between modules to improve their respective performances. We propose the use of the semantic space to improve specific out-of-the-box object detectors and an update model to take the evidence from different detection into account in the semantic segmentation process. Our proposal is evaluated with the KITTI dataset, on the object detection benchmark and on five different sequences manually annotated for the semantic segmentation task, demonstrating the efficacy of our approach.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Cadena, Cesar and Dick, Anthony and Reid, Ian D.},
	month = may,
	year = {2015},
	note = {ISSN: 1050-4729},
	keywords = {Benchmark testing, Context, Detectors, Object detection, Robots, Semantics, Training, context-aware object detection, control engineering computing, image segmentation, modular scene understanding system, object detection, object detections, out-of-the-box object detectors, robotic operations, robots, semantic scene understanding system, semantic segmentation process, semantic segmentation task, ubiquitous computing},
	pages = {4859--4866}
}

@techreport{ieee_1873-2015_2015,
	title = {1873-2015 - {IEEE} {Standard} for {Robot} {Map} {Data} {Representation} for {Navigation}},
	url = {https://standards.ieee.org/standard/1873-2015.html},
	language = {en},
	number = {1873-2015},
	urldate = {2020-01-21},
	institution = {IEEE},
	author = {IEEE},
	month = oct,
	year = {2015},
	pages = {1 -- 54}
}

@inproceedings{grisetti_hierarchical_2010,
	title = {Hierarchical optimization on manifolds for online {2D} and {3D} mapping},
	doi = {10.1109/ROBOT.2010.5509407},
	abstract = {In this paper, we present a new hierarchical optimization solution to the graph-based simultaneous localization and mapping (SLAM) problem. During online mapping, the approach corrects only the coarse structure of the scene and not the overall map. In this way, only updates for the parts of the map that need to be considered for making data associations are carried out. The hierarchical approach provides accurate non-linear map estimates while being highly efficient. Our error minimization approach exploits the manifold structure of the underlying space. In this way, it avoids singularities in the state space parameterization. The overall approach is accurate, efficient, designed for online operation, overcomes singularities, provides a hierarchical representation, and outperforms a series of state-of-the-art methods.},
	booktitle = {2010 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Grisetti, Giorgio and Kümmerle, Rainer and Stachniss, Cyrill and Frese, Udo and Hertzberg, Christoph},
	month = may,
	year = {2010},
	note = {ISSN: 1050-4729},
	keywords = {Layout, Least squares methods, Newton method, Recursive estimation, Robotics and automation, Robots, SLAM (robots), Simultaneous localization and mapping, State-space methods, Testing, USA Councils, error minimization approach, hierarchical optimization, online 2D mapping, online 3D mapping, optimisation, sensor fusion, simultaneous localization and mapping, state space parameterization},
	pages = {273--278}
}

@inproceedings{milford_seqslam_2012,
	title = {{SeqSLAM}: {Visual} route-based navigation for sunny summer days and stormy winter nights},
	shorttitle = {{SeqSLAM}},
	doi = {10.1109/ICRA.2012.6224623},
	abstract = {Learning and then recognizing a route, whether travelled during the day or at night, in clear or inclement weather, and in summer or winter is a challenging task for state of the art algorithms in computer vision and robotics. In this paper, we present a new approach to visual navigation under changing conditions dubbed SeqSLAM. Instead of calculating the single location most likely given a current image, our approach calculates the best candidate matching location within every local navigation sequence. Localization is then achieved by recognizing coherent sequences of these “local best matches”. This approach removes the need for global matching performance by the vision front-end - instead it must only pick the best match within any short sequence of images. The approach is applicable over environment changes that render traditional feature-based techniques ineffective. Using two car-mounted camera datasets we demonstrate the effectiveness of the algorithm and compare it to one of the most successful feature-based SLAM algorithms, FAB-MAP. The perceptual change in the datasets is extreme; repeated traverses through environments during the day and then in the middle of the night, at times separated by months or years and in opposite seasons, and in clear weather and extremely heavy rain. While the feature-based method fails, the sequence-based algorithm is able to match trajectory segments at 100\% precision with recall rates of up to 60\%.},
	booktitle = {2012 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Milford, Michael J. and Wyeth, Gordon. F.},
	month = may,
	year = {2012},
	note = {ISSN: 1050-4729},
	keywords = {Cameras, FAB-MAP, Navigation, Robot sensing systems, SLAM (robots), SeqSLAM, Trajectory, Vectors, Videos, Visualization, candidate matching location, car-mounted camera datasets, coherent sequence recognition, computer vision, feature extraction, feature-based SLAM algorithms, feature-based techniques, global matching performance, image matching, image sequences, local navigation sequence, mobile robots, object recognition, path planning, place visual recognition, robot vision, robotics, route recognition, simultaneous localization-and-mapping, stormy winter nights, sunny summer days, visual route-based navigation},
	pages = {1643--1649}
}

@article{lepetit_epnp_2008,
	title = {{EPnP}: {An} {Accurate} {O}(n) {Solution} to the {PnP} {Problem}},
	volume = {81},
	issn = {1573-1405},
	shorttitle = {{EPnP}},
	url = {https://doi.org/10.1007/s11263-008-0152-6},
	doi = {10.1007/s11263-008-0152-6},
	abstract = {We propose a non-iterative solution to the PnP problem—the estimation of the pose of a calibrated camera from n 3D-to-2D point correspondences—whose computational complexity grows linearly with n. This is in contrast to state-of-the-art methods that are O(n 5) or even O(n 8), without being more accurate. Our method is applicable for all n≥4 and handles properly both planar and non-planar configurations. Our central idea is to express the n 3D points as a weighted sum of four virtual control points. The problem then reduces to estimating the coordinates of these control points in the camera referential, which can be done in O(n) time by expressing these coordinates as weighted sum of the eigenvectors of a 12×12 matrix and solving a small constant number of quadratic equations to pick the right weights. Furthermore, if maximal precision is required, the output of the closed-form solution can be used to initialize a Gauss-Newton scheme, which improves accuracy with negligible amount of additional time. The advantages of our method are demonstrated by thorough testing on both synthetic and real-data.},
	language = {en},
	number = {2},
	urldate = {2020-01-21},
	journal = {International Journal of Computer Vision},
	author = {Lepetit, Vincent and Moreno-Noguer, Francesc and Fua, Pascal},
	month = jul,
	year = {2008},
	keywords = {Absolute orientation, Perspective-n-Point, Pose estimation},
	pages = {155}
}

@article{giusti_machine_2016,
	title = {A {Machine} {Learning} {Approach} to {Visual} {Perception} of {Forest} {Trails} for {Mobile} {Robots}},
	volume = {1},
	issn = {2377-3774},
	doi = {10.1109/LRA.2015.2509024},
	abstract = {We study the problem of perceiving forest or mountain trails from a single monocular image acquired from the viewpoint of a robot traveling on the trail itself. Previous literature focused on trail segmentation, and used low-level features such as image saliency or appearance contrast; we propose a different approach based on a deep neural network used as a supervised image classifier. By operating on the whole image at once, our system outputs the main direction of the trail compared to the viewing direction. Qualitative and quantitative results computed on a large real-world dataset (which we provide for download) show that our approach outperforms alternatives, and yields an accuracy comparable to the accuracy of humans that are tested on the same image classification task. Preliminary results on using this information for quadrotor control in unseen trails are reported. To the best of our knowledge, this is the first letter that describes an approach to perceive forest trials, which is demonstrated on a quadrotor micro aerial vehicle.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Giusti, Alessandro and Guzzi, Jérôme and Cireşan, Dan C. and He, Fang-Lin and Rodríguez, Juan P. and Fontana, Flavio and Faessler, Matthias and Forster, Christian and Schmidhuber, Jürgen and Caro, Gianni Di and Scaramuzza, Davide and Gambardella, Luca M.},
	month = jul,
	year = {2016},
	keywords = {Aerial Robotics, Cameras, Deep Learning, Image segmentation, Machine Learning, Mobile robots, Roads, Robot vision systems, Visual perception, Visual-Based Navigation, autonomous aerial vehicles, deep-neural network, forest trails, helicopters, image classification, learning (artificial intelligence), machine learning approach, microrobots, mobile robots, monocular image, neural nets, quadrotor microaerial vehicle control, qualitative analysis, quantitative analysis, robot vision, supervised image classifier, viewing direction, visual perception},
	pages = {661--667}
}

@inproceedings{prokhorov_measuring_2019,
	title = {Measuring robustness of {Visual} {SLAM}},
	doi = {10.23919/MVA.2019.8758020},
	abstract = {Simultaneous localisation and mapping (SLAM) is an essential component of robotic systems. In this work we perform a feasibility study of RGB-D SLAM for the task of indoor robot navigation. Recent visual SLAM methods, e.g. ORBSLAM2 [9], demonstrate really impressive accuracy, but the experiments in the papers are usually conducted on just a few sequences, that makes it difficult to reason about the robustness of the methods. Another problem is that all available RGB-D datasets contain the trajectories with very complex camera motions. In this work we extensively evaluate ORBSLAM2 to better understand the state-of-the-art. First, we conduct experiments on the popular publicly available datasets for RGB-D SLAM across the conventional metrics. We perform statistical analysis of the results and find correlations between the metrics and the attributes of the trajectories. Then, we introduce a new large and diverse HomeRobot dataset where we model the motions of a simple home robot. Our dataset is created using physically-based rendering with realistic lighting and contains the scenes composed by human designers. It includes thousands of sequences, that is two orders of magnitude greater than in previous works. We find that while in many cases the accuracy of SLAM is very good, the robustness is still an issue.},
	booktitle = {2019 16th {International} {Conference} on {Machine} {Vision} {Applications} ({MVA})},
	author = {Prokhorov, David and Zhukov, Dmitry and Barinova, Olga and Anton, Konushin and Vorontsova, Anna},
	month = may,
	year = {2019},
	note = {ISSN: null},
	keywords = {Benchmark testing, Cameras, Measurement, ORBSLAM2, SLAM (robots), Simultaneous localization and mapping, Three-dimensional displays, Trajectory, available RGB-D datasets, cameras, complex camera motions, diverse HomeRobot dataset, essential component, feasibility study, indoor robot navigation, mobile robots, new large HomeRobot dataset, path planning, popular publicly available datasets, rendering (computer graphics), robot vision, robotic systems, simple home robot, statistical analysis, trajectories, visual SLAM methods},
	pages = {1--6}
}

@inproceedings{kerl_dense_2015,
	title = {Dense {Continuous}-{Time} {Tracking} and {Mapping} with {Rolling} {Shutter} {RGB}-{D} {Cameras}},
	doi = {10.1109/ICCV.2015.261},
	abstract = {We propose a dense continuous-time tracking and mapping method for RGB-D cameras. We parametrize the camera trajectory using continuous B-splines and optimize the trajectory through dense, direct image alignment. Our method also directly models rolling shutter in both RGB and depth images within the optimization, which improves tracking and reconstruction quality for low-cost CMOS sensors. Using a continuous trajectory representation has a number of advantages over a discrete-time representation (e.g. camera poses at the frame interval). With splines, less variables need to be optimized than with a discrete representation, since the trajectory can be represented with fewer control points than frames. Splines also naturally include smoothness constraints on derivatives of the trajectory estimate. Finally, the continuous trajectory representation allows to compensate for rolling shutter effects, since a pose estimate is available at any exposure time of an image. Our approach demonstrates superior quality in tracking and reconstruction compared to approaches with discrete-time or global shutter assumptions.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Kerl, Christian and Stückler, Jörg and Cremers, Daniel},
	month = dec,
	year = {2015},
	note = {ISSN: 2380-7504},
	keywords = {B-spline, Cameras, Image reconstruction, SLAM, SLAM (robots), Simultaneous localization and mapping, Splines (mathematics), Three-dimensional displays, Trajectory, camera trajectory representation, continuous trajectory representation, dense continuous-time tracking, estimation theory, image alignment, image representation, optimisation, pose estimation, rolling shutter RGB-D camera, simultaneous localization and mapping, splines (mathematics), trajectory estimation, trajectory optimization},
	pages = {2264--2272}
}

@inproceedings{von_stumberg_monocular_2017,
	title = {From monocular {SLAM} to autonomous drone exploration},
	doi = {10.1109/ECMR.2017.8098709},
	abstract = {Micro aerial vehicles (MAVs) are strongly limited in their payload and power capacity. In order to implement autonomous navigation, algorithms are therefore desirable that use sensory equipment that is as small, low-weight, and low- power consuming as possible. In this paper, we propose a method for autonomous MAV navigation and exploration using a low-cost consumer-grade quadrocopter equipped with a monocular camera. Our vision-based navigation system builds on LSD-SLAM which estimates the MAV trajectory and a semidense reconstruction of the environment in real-time. Since LSD-SLAM only determines depth at high gradient pixels, texture-less areas are not directly observed so that previous exploration methods that assume dense map information cannot directly be applied. We propose an obstacle mapping and exploration approach that takes the properties of our semidense monocular SLAM system into account. In experiments, we demonstrate our vision-based autonomous navigation and exploration system with a Parrot Bebop MAV.},
	booktitle = {2017 {European} {Conference} on {Mobile} {Robots} ({ECMR})},
	author = {von Stumberg, Lukas and Usenko, Vladyslav and Engel, Jakob and Stückler, Jörg and Cremers, Daniel},
	month = sep,
	year = {2017},
	note = {ISSN: null},
	keywords = {Cameras, LSD-SLAM, MAV trajectory, MAVs, Motion measurement, Navigation, Parrot Bebop MAV, SLAM (robots), Simultaneous localization and mapping, Three-dimensional displays, Visualization, aerospace control, autonomous drone exploration, autonomous navigation, dense map information, exploration approach, exploration system, helicopters, high gradient pixels, low- power consuming, low-cost consumer-grade quadrocopter, microaerial vehicles, microrobots, monocular camera, navigation system, obstacle mapping, path planning, power capacity, robot vision, semidense monocular SLAM system, semidense reconstruction, trajectory control, use sensory equipment},
	pages = {1--8}
}

@incollection{corke_navigation_2017,
	address = {Cham},
	series = {Springer {Tracts} in {Advanced} {Robotics}},
	title = {Navigation},
	isbn = {978-3-319-54413-7},
	url = {https://doi.org/10.1007/978-3-319-54413-7_5},
	abstract = {Robot navigation is the problem of guiding a robot towards a goal. The human approach to navigation is to make maps and erect signposts, and at first glance it seems obvious that robots should operate the same way. However many robotic tasks can be achieved without any map at all, using an approach referred to as reactive navigation. For example, navigating by heading towards a light, following a white line on the ground, moving through a maze by following a wall, or vacuuming a room by following a random path.},
	language = {en},
	urldate = {2020-01-20},
	booktitle = {Robotics, {Vision} and {Control}: {Fundamental} {Algorithms} {In} {MATLAB}® {Second}, {Completely} {Revised}, {Extended} {And} {Updated} {Edition}},
	publisher = {Springer International Publishing},
	author = {Corke, Peter},
	editor = {Corke, Peter},
	year = {2017},
	doi = {10.1007/978-3-319-54413-7_5},
	keywords = {Lattice Planner, Occupancy Grid, Query Phase, Robot Navigation, Voronoi Diagram},
	pages = {125--149}
}

@article{liu_deep_2019,
	title = {Deep {Learning} for {Generic} {Object} {Detection}: {A} {Survey}},
	issn = {1573-1405},
	shorttitle = {Deep {Learning} for {Generic} {Object} {Detection}},
	url = {https://doi.org/10.1007/s11263-019-01247-4},
	doi = {10.1007/s11263-019-01247-4},
	abstract = {Object detection, one of the most fundamental and challenging problems in computer vision, seeks to locate object instances from a large number of predefined categories in natural images. Deep learning techniques have emerged as a powerful strategy for learning feature representations directly from data and have led to remarkable breakthroughs in the field of generic object detection. Given this period of rapid evolution, the goal of this paper is to provide a comprehensive survey of the recent achievements in this field brought about by deep learning techniques. More than 300 research contributions are included in this survey, covering many aspects of generic object detection: detection frameworks, object feature representation, object proposal generation, context modeling, training strategies, and evaluation metrics. We finish the survey by identifying promising directions for future research.},
	language = {en},
	urldate = {2020-01-20},
	journal = {International Journal of Computer Vision},
	author = {Liu, Li and Ouyang, Wanli and Wang, Xiaogang and Fieguth, Paul and Chen, Jie and Liu, Xinwang and Pietikäinen, Matti},
	month = oct,
	year = {2019},
	keywords = {Convolutional neural networks, Deep learning, Object detection, Object recognition}
}

@misc{noauthor_long_nodate,
	title = {A long table in the landscape page},
	url = {https://tex.stackexchange.com/questions/395852/a-long-table-in-the-landscape-page},
	urldate = {2020-01-20},
	journal = {TeX - LaTeX Stack Exchange}
}

@misc{noauthor_how_nodate,
	title = {How to change certain pages into landscape/portrait mode},
	url = {https://tex.stackexchange.com/questions/337/how-to-change-certain-pages-into-landscape-portrait-mode},
	urldate = {2020-01-20},
	journal = {TeX - LaTeX Stack Exchange}
}

@misc{noauthor_how_nodate-1,
	title = {How to fit big table},
	url = {https://tex.stackexchange.com/questions/170955/how-to-fit-big-table/170962},
	urldate = {2020-01-20},
	journal = {TeX - LaTeX Stack Exchange}
}

@article{kim_deep_2015,
	title = {Deep {Neural} {Network} for {Real}-{Time} {Autonomous} {Indoor} {Navigation}},
	url = {http://arxiv.org/abs/1511.04668},
	abstract = {Autonomous indoor navigation of Micro Aerial Vehicles (MAVs) possesses many challenges. One main reason is that GPS has limited precision in indoor environments. The additional fact that MAVs are not able to carry heavy weight or power consuming sensors, such as range finders, makes indoor autonomous navigation a challenging task. In this paper, we propose a practical system in which a quadcopter autonomously navigates indoors and finds a specific target, i.e., a book bag, by using a single camera. A deep learning model, Convolutional Neural Network (ConvNet), is used to learn a controller strategy that mimics an expert pilot's choice of action. We show our system's performance through real-time experiments in diverse indoor locations. To understand more about our trained network, we use several visualization techniques.},
	urldate = {2020-01-20},
	journal = {arXiv:1511.04668 [cs]},
	author = {Kim, Dong Ki and Chen, Tsuhan},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.04668},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@inproceedings{ross_learning_2013,
	title = {Learning monocular reactive {UAV} control in cluttered natural environments},
	doi = {10.1109/ICRA.2013.6630809},
	abstract = {Autonomous navigation for large Unmanned Aerial Vehicles (UAVs) is fairly straight-forward, as expensive sensors and monitoring devices can be employed. In contrast, obstacle avoidance remains a challenging task for Micro Aerial Vehicles (MAVs) which operate at low altitude in cluttered environments. Unlike large vehicles, MAVs can only carry very light sensors, such as cameras, making autonomous navigation through obstacles much more challenging. In this paper, we describe a system that navigates a small quadrotor helicopter autonomously at low altitude through natural forest environments. Using only a single cheap camera to perceive the environment, we are able to maintain a constant velocity of up to 1.5m/s. Given a small set of human pilot demonstrations, we use recent state-of-the-art imitation learning techniques to train a controller that can avoid trees by adapting the MAVs heading. We demonstrate the performance of our system in a more controlled environment indoors, and in real natural forest environments outdoors.},
	booktitle = {2013 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Ross, Stéphane and Melik-Barkhudarov, Narek and Shankar, Kumar Shaurya and Wendel, Andreas and Dey, Debadeepta and Bagnell, J. Andrew and Hebert, Martial},
	month = may,
	year = {2013},
	note = {ISSN: 1050-4729},
	keywords = {Cameras, MAV heading, Optical imaging, Sensors, Training, Trajectory, Vegetation, Visualization, autonomous aerial vehicles, autonomous navigation, cluttered natural environments, collision avoidance, helicopters, human pilot demonstrations, image sensors, imitation learning techniques, learning (artificial intelligence), learning monocular reactive UAV control, microaerial vehicles, microrobots, natural forest environments, obstacle avoidance, quadrotor helicopter, robot vision, sensors, single cheap camera, unmanned aerial vehicles},
	pages = {1765--1772}
}

@inproceedings{daftry_introspective_2016,
	title = {Introspective perception: {Learning} to predict failures in vision systems},
	shorttitle = {Introspective perception},
	doi = {10.1109/IROS.2016.7759279},
	abstract = {As robots aspire for long-term autonomous operations in complex dynamic environments, the ability to reliably take mission-critical decisions in ambiguous situations becomes critical. This motivates the need to build systems that have situational awareness to assess how qualified they are at that moment to make a decision. We call this self-evaluating capability as introspection. In this paper, we take a small step in this direction and propose a generic framework for introspective behavior in perception systems. Our goal is to learn a model to reliably predict failures in a given system, with respect to a task, directly from input sensor data. We present this in the context of vision-based autonomous MAV flight in outdoor natural environments, and show that it effectively handles uncertain situations.},
	booktitle = {2016 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Daftry, Shreyansh and Zeng, Sam and Bagnell, J. Andrew and Hebert, Martial},
	month = oct,
	year = {2016},
	note = {ISSN: 2153-0866},
	keywords = {Context, Prediction algorithms, Reliability, Robot sensing systems, Support vector machines, Training, autonomous aerial vehicles, autonomous robot operations, failure prediction, introspection, introspective behavior, learning, learning (artificial intelligence), mission-critical decisions, mobile robots, outdoor natural environments, perception systems, robot vision, self-evaluating capability, situational awareness, vision systems, vision-based autonomous MAV flight, visual perception},
	pages = {1743--1750}
}

@misc{noauthor_markov_nodate,
	title = {Markov {Matrices} {\textbar} {MIT} 18.{06SC} {Linear} {Algebra}, {Fall} 2011},
	url = {https://www.youtube.com/watch?v=nnssRe5DewE},
	abstract = {Markov Matrices

Instructor: David Shirokoff

View the complete course: http://ocw.mit.edu/18-06SCF11

License: Creative Commons BY-NC-SA
More information at http://ocw.mit.edu/terms
More courses at http://ocw.mit.edu},
	urldate = {2020-01-20}
}

@misc{noauthor_random_nodate,
	title = {A {Random} {Walk} \& {Monte} {Carlo} {Simulation}  {\textbar}{\textbar}  {Python} {Tutorial}  {\textbar}{\textbar}  {Learn} {Python} {Programming}},
	url = {https://www.youtube.com/watch?v=BfS2H1y6tzQ&t=322s},
	abstract = {A random walk is a process where each step is chosen randomly.  This technique has many applications.  In this video we solve a random walk puzzle using Monte Carlo simulations and the random module in Python.

➢➢➢➢➢➢➢➢➢➢
To learn Python, you can watch our playlist from the beginning: https://www.youtube.com/watch?v=bY6m6...

➢➢➢➢➢➢➢➢➢➢
We recommend:
Python Cookbook, Third edition from O’Reilly
http://amzn.to/2sCNYlZ

The Mythical Man Month - Essays on Software Engineering \&amp; Project Management
http://amzn.to/2tYdNeP

Shop Amazon Used Textbooks - Save up to 90\%
http://amzn.to/2pllk4B

➢➢➢➢➢➢➢➢➢➢
Subscribe to Socratica: http://bit.ly/1ixuu9W

To support more videos from Socratica, visit
Socratica Patreon
https://www.patreon.com/socratica

Socratica Paypal
https://www.paypal.me/socratica

We also accept Bitcoin!  :)
Our address is:  1EttYyGwJmpy9bLY2UcmEqMJuBfaZ1HdG9

➢➢➢➢➢➢➢➢➢➢
Python instructor: Ulka Simone Mohanty
Written \&amp; Produced by Michael Harrison
FX by Andriy Kostyuk},
	urldate = {2020-01-20}
}

@misc{noauthor_introduction_nodate,
	title = {Introduction to {Bayesian} statistics, part 2: {MCMC} and the {Metropolis} {Hastings} algorithm},
	shorttitle = {Introduction to {Bayesian} statistics, part 2},
	url = {https://www.youtube.com/watch?v=OTO1DygELpY},
	abstract = {An introduction to Markov chain Monte Carlo (MCMC) and the Metropolis-Hastings algorithm using Stata 14. We introduce the concepts and demonstrate the basic calculations using a coin toss experiment. Copyright 2011-2019 StataCorp LLC. All rights reserved.},
	urldate = {2020-01-20}
}

@misc{noauthor_markov_nodate-1,
	title = {Markov {Chain} {Monte} {Carlo} and the {Metropolis} {Alogorithm}},
	url = {https://www.youtube.com/watch?v=h1NOS_wxgGg},
	abstract = {An introduction to the intuition and implementation of the Metropolis algorithm.},
	urldate = {2020-01-20}
}

@misc{noauthor_google_nodate,
	title = {Google {Coding} {Interview} {With} {A} {Competitive} {Programmer}},
	url = {https://www.youtube.com/watch?v=EuPSibuIKIg},
	abstract = {In this video, I conduct a mock Google coding interview with a competitive programmer, Errichto. As a Google Software Engineer, I interviewed dozens of candidates. This is exactly the type of coding interview that you would get at Google or any other big tech company.

Check out the video we made on Errichto's channel: https://www.youtube.com/watch?v=Y8Vey...

Prepping for coding interviews? Practice with 77 video explanations of popular interview questions and a full-fledged coding workspace on AlgoExpert: https://www.algoexpert.io (use "clem" promo code for a discount!)},
	urldate = {2020-01-20}
}

@misc{noauthor_friendly_nodate,
	title = {A friendly introduction to {Bayes} {Theorem} and {Hidden} {Markov} {Models}},
	url = {https://www.youtube.com/watch?v=kqSzLo9fenk},
	abstract = {Announcement: New Book by Luis Serrano! Grokking Machine Learning. bit.ly/grokkingML

A friendly introduction to Bayes Theorem and Hidden Markov Models, with simple examples. No background knowledge needed, except basic probability.
Accompanying notebook:
https://github.com/luisguiserrano/hmm},
	urldate = {2020-01-20}
}

@misc{noauthor_bayesian_nodate,
	title = {The {Bayesian} {Trap}},
	url = {https://www.youtube.com/watch?v=R13BD8qKeTg},
	abstract = {Bayes' theorem explained with examples and implications for life.
Check out Audible: http://ve42.co/audible
Support Veritasium on Patreon: http://ve42.co/patreon

I didn't say it explicitly in the video, but in my view the Bayesian trap is interpreting events that happen repeatedly as events that happen inevitably. They may be inevitable OR they may simply be the outcome of a series of steps, which likely depend on our behaviour. Yet our expectation of a certain outcome often leads us to behave just as we always have which only ensures that outcome. To escape the Bayesian trap, we must be willing to experiment.

Special thanks to Patreon supporters:
Tony Fadell, Jeff Straathof, Donal Botkin, Zach Mueller, Ron Neal, Nathan Hansen, Saeed Alghamdi

Useful references:
The Signal and the Noise, Nate Silver
The Theory That Would Not Die: How Bayes’ Rule Cracked the Enigma Code, Hunted Down Russian Submarines, and Emerged Triumphant from Two Centuries of Controversy, by Sharon Bertsch McGrayne

Bayes' theorem or rule (there are many different versions of the same concept) has fascinated me for a long time due to its uses both in mathematics and statistics, and to solve real world problems. Bayesian inference has been used to crack the Enigma Code and to filter spam email. Bayes has also been used to locate the wreckage from plane crashes deep beneath the sea.

Music from http://epidemicsound.com "Flourishing Views 3"},
	urldate = {2020-01-20}
}

@misc{noauthor_intuitive_nodate,
	title = {An {Intuitive} (and {Short}) {Explanation} of {Bayes}’ {Theorem} – {BetterExplained}},
	url = {https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/},
	urldate = {2020-01-20}
}

@misc{noauthor_conversion_nodate,
	title = {conversion - {Comprehensive} list of tools that simplify the generation of {LaTeX} tables},
	url = {https://tex.stackexchange.com/questions/49414/comprehensive-list-of-tools-that-simplify-the-generation-of-latex-tables},
	urldate = {2020-01-15},
	journal = {TeX - LaTeX Stack Exchange}
}

@misc{noauthor_export_nodate,
	title = {Export {Excel} tables to {Overleaf}},
	url = {https://tex.stackexchange.com/questions/458502/export-excel-tables-to-overleaf},
	abstract = {Using Pandas or the website for tablegeneration},
	urldate = {2020-01-15},
	journal = {TeX - LaTeX Stack Exchange}
}

@techreport{iso_250212012_2012,
	address = {Geneva},
	type = {Standard},
	title = {25021:2012 - {Systems} and software engineering - {Systems} and software {Quality} {Requirements} and {Evaluation} ({SQuaRE}) - {Quality} measure elements},
	url = {https://www.iso.org/standard/55477.html},
	language = {en},
	number = {25021:2012},
	urldate = {2020-01-09},
	institution = {ISO/IEC},
	author = {ISO and IEC},
	month = nov,
	year = {2012},
	note = {Revised 2019},
	pages = {37}
}

@techreport{iso_250232016_2016,
	address = {Geneva},
	type = {Standard},
	title = {25023:2016 - {Systems} and software engineering - {Systems} and software {Quality} {Requirements} and {Evaluation} ({SQuaRE}) - {Measurement} of system and software product quality},
	url = {https://www.iso.org/standard/35747.html},
	language = {en},
	number = {25023:2016},
	urldate = {2020-01-09},
	institution = {ISO/IEC},
	author = {ISO and IEC},
	month = jun,
	year = {2016},
	pages = {45}
}

@techreport{iso_250102011_2011,
	address = {Geneva},
	type = {Standard},
	title = {25010:2011 - {Systems} and software engineering - {Systems} and software {Quality} {Requirements} and {Evaluation} ({SQuaRE}) - {System} and software quality models},
	url = {https://www.iso.org/standard/35733.html},
	language = {en},
	number = {25010:2011},
	urldate = {2019-02-12},
	institution = {ISO/IEC},
	author = {ISO and IEC},
	month = mar,
	year = {2011},
	pages = {34}
}

@mastersthesis{vilhjalmsson_risk-based_2016,
	address = {Zurich},
	title = {Risk-based {Pathfinding} for {Drones}},
	abstract = {Minimizing both distance and risks in graph search},
	language = {English},
	school = {ETH Zurich},
	author = {Vilhjalmsson, Vilhjalmur and Meier, Lorenz},
	month = may,
	year = {2016}
}

@misc{noauthor_deep_nodate,
	title = {Deep {Learning} {State} of the {Art} (2020) {\textbar} {MIT} {Deep} {Learning} {Series}},
	url = {https://www.youtube.com/watch?v=0VH1Lim8gL8},
	abstract = {Lecture on most recent research and developments in deep learning, and hopes for 2020. This is not intended to be a list of SOTA benchmark results, but rather a set of highlights of machine learning and AI innovations and progress in academia, industry, and society in general. This lecture is part of the MIT Deep Learning Lecture Series.

Website: https://deeplearning.mit.edu
Slides: http://bit.ly/2QEfbAm
Playlist: http://bit.ly/deep-learning-playlist

OUTLINE:
0:00 - Introduction
0:33 - AI in the context of human history
5:47 - Deep learning celebrations, growth, and limitations
6:35 - Deep learning early key figures
9:29 - Limitations of deep learning
11:01 - Hopes for 2020: deep learning community and research
12:50 - Deep learning frameworks: TensorFlow and PyTorch
15:11 - Deep RL frameworks
16:13 - Hopes for 2020: deep learning and deep RL frameworks
17:53 - Natural language processing
19:42 - Megatron, XLNet, ALBERT
21:21 - Write with transformer examples
24:28 - GPT-2 release strategies report
26:25 - Multi-domain dialogue
27:13 - Commonsense reasoning
28:26 - Alexa prize and open-domain conversation
33:44 - Hopes for 2020: natural language processing
35:11 - Deep RL and self-play
35:30 - OpenAI Five and Dota 2
37:04 - DeepMind Quake III Arena
39:07 - DeepMind AlphaStar
41:09 - Pluribus: six-player no-limit Texas hold'em poker
43:13 - OpenAI Rubik's Cube
44:49 - Hopes for 2020: Deep RL and self-play
45:52 - Science of deep learning
46:01 - Lottery ticket hypothesis
47:29 - Disentangled representations
48:34 - Deep double descent
49:30 - Hopes for 2020: science of deep learning
50:56 - Autonomous vehicles and AI-assisted driving
51:50 - Waymo
52:42 - Tesla Autopilot
57:03 - Open question for Level 2 and Level 4 approaches
59:55 - Hopes for 2020: autonomous vehicles and AI-assisted driving
1:01:43 - Government, politics, policy
1:03:03 - Recommendation systems and policy
1:05:36 - Hopes for 2020: Politics, policy and recommendation systems
1:06:50 - Courses, Tutorials, Books
1:10:05 - General hopes for 2020
1:11:19 - Recipe for progress in AI
1:14:15 - Q\&amp;A: what made you interested in AI
1:15:21 - Q\&amp;A: Will machines ever be able to think and feel?
1:18:20 - Q\&amp;A: Is RL a good candidate for achieving AGI?
1:21:31 - Q\&amp;A: Are autonomous vehicles responsive to sound?
1:22:43 - Q\&amp;A: What does the future with AGI look like? 
1:25:50 - Q\&amp;A: Will AGI systems become our masters?

CONNECT:
- If you enjoyed this video, please subscribe to this channel.
- Twitter: https://twitter.com/lexfridman
- LinkedIn: https://www.linkedin.com/in/lexfridman
- Facebook: https://www.facebook.com/lexfridman
- Instagram: https://www.instagram.com/lexfridman},
	urldate = {2020-01-12}
}

@misc{noauthor_how_2015,
	title = {How to undo (almost) anything with {Git}},
	url = {https://github.blog/2015-06-08-how-to-undo-almost-anything-with-git/},
	abstract = {One of the most useful features of any version control system is the ability to “undo” your mistakes. In Git, “undo” can mean many slightly different things. When you make a new commit, Git stores},
	language = {en-US},
	urldate = {2020-01-11},
	journal = {The GitHub Blog},
	month = jun,
	year = {2015}
}

@misc{noauthor_git_nodate,
	title = {git checkout - {How} do {I} revert a {Git} repository to a previous commit?},
	url = {https://stackoverflow.com/questions/4114095/how-do-i-revert-a-git-repository-to-a-previous-commit},
	urldate = {2020-01-11},
	journal = {Stack Overflow}
}

@misc{noauthor_cmake_nodate,
	title = {{CMake} {Tutorial} — {CMake} 3.16.0 {Documentation}},
	url = {https://cmake.org/cmake/help/latest/guide/tutorial/index.html},
	abstract = {GitHub Documentation at:
https://github.com/Kitware/CMake/tree/master/Help/guide/tutorial},
	urldate = {2019-12-04}
}

@inproceedings{joukov_human_2017,
	address = {Cham},
	series = {Springer {Proceedings} in {Advanced} {Robotics}},
	title = {Human {Pose} {Estimation} from {Imperfect} {Sensor} {Data} via the {Extended} {Kalman} {Filter}},
	isbn = {978-3-319-50115-4},
	doi = {10.1007/978-3-319-50115-4_68},
	abstract = {Accurate human pose estimation is of vital importance for a variety of human-robot interaction applications, including cooperative task execution, imitation learning and robot-assisted rehabilitation. As robots move from controlled indoor environments to unstructured and outdoor environments, the ability to accurately measure human pose without fixed sensors becomes increasingly important. In this paper, we present a general framework for accurately estimating human pose from a variety of sensors, including body-worn inertial measurement units and cameras, that can be used in indoor and outdoor environments to accurately estimate human pose during arbitrary 3D movements. Using a kinematic model of the human body, the sensor data is fused to estimate the body joint angles and velocities using a constrained Extended Kalman Filter which automatically incorporates feasible joint limits. For periodic movement such as gait, performance can be further improved via online learning of the gait model, individualized to the user. The proposed approach can deal with intermittent data availability and measurement errors during highly dynamic movements.},
	language = {en},
	booktitle = {2016 {International} {Symposium} on {Experimental} {Robotics}},
	publisher = {Springer International Publishing},
	author = {Joukov, Vlad and D’Souza, Rollen and Kulić, Dana},
	editor = {Kulić, Dana and Nakamura, Yoshihiko and Khatib, Oussama and Venture, Gentiane},
	year = {2017},
	keywords = {Extended Kalman Filter, Human pose estimation, Motion capture},
	pages = {789--798}
}

@article{pavllo_3d_2019,
	title = {{3D} human pose estimation in video with temporal convolutions and semi-supervised training},
	url = {http://arxiv.org/abs/1811.11742},
	abstract = {In this work, we demonstrate that 3D poses in video can be effectively estimated with a fully convolutional model based on dilated temporal convolutions over 2D keypoints. We also introduce back-projection, a simple and effective semi-supervised training method that leverages unlabeled video data. We start with predicted 2D keypoints for unlabeled video, then estimate 3D poses and finally back-project to the input 2D keypoints. In the supervised setting, our fully-convolutional model outperforms the previous best result from the literature by 6 mm mean per-joint position error on Human3.6M, corresponding to an error reduction of 11\%, and the model also shows significant improvements on HumanEva-I. Moreover, experiments with back-projection show that it comfortably outperforms previous state-of-the-art results in semi-supervised settings where labeled data is scarce. Code and models are available at https://github.com/facebookresearch/VideoPose3D},
	urldate = {2020-01-11},
	journal = {arXiv:1811.11742 [cs]},
	author = {Pavllo, Dario and Feichtenhofer, Christoph and Grangier, David and Auli, Michael},
	month = mar,
	year = {2019},
	note = {arXiv: 1811.11742},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@misc{noauthor_2019_nodate,
	title = {A 2019 guide to {3D} {Pose} {Estimation}},
	url = {https://nanonets.com/blog/human-pose-estimation-3d-guide/},
	urldate = {2020-01-11}
}

@article{chen_active_2011,
	title = {Active vision in robotic systems: {A} survey of recent developments},
	volume = {30},
	issn = {0278-3649},
	shorttitle = {Active vision in robotic systems},
	url = {https://doi.org/10.1177/0278364911410755},
	doi = {10.1177/0278364911410755},
	abstract = {In this paper we provide a broad survey of developments in active vision in robotic applications over the last 15 years. With increasing demand for robotic automation, research in this area has received much attention. Among the many factors that can be attributed to a high-performance robotic system, the planned sensing or acquisition of perceptions on the operating environment is a crucial component. The aim of sensor planning is to determine the pose and settings of vision sensors for undertaking a vision-based task that usually requires obtaining multiple views of the object to be manipulated. Planning for robot vision is a complex problem for an active system due to its sensing uncertainty and environmental uncertainty. This paper describes such problems arising from many applications, e.g. object recognition and modeling, site reconstruction and inspection, surveillance, tracking and search, as well as robotic manipulation and assembly, localization and mapping, navigation and exploration. A bundle of solutions and methods have been proposed to solve these problems in the past. They are summarized in this review while enabling readers to easily refer solution methods for practical applications. Representative contributions, their evaluations, analyses, and future research trends are also addressed in an abstract level.},
	language = {en},
	number = {11},
	urldate = {2020-01-11},
	journal = {The International Journal of Robotics Research},
	author = {Chen, Shengyong and Li, Youfu and Kwok, Ngai Ming},
	month = sep,
	year = {2011},
	keywords = {Active vision, computer vision, purposive perception planning, robotics, sensor placement, uncertainty, viewpoint scheduling},
	pages = {1343--1377}
}

@article{vansteenwegen_orienteering_2011,
	title = {The orienteering problem: {A} survey},
	volume = {209},
	issn = {0377-2217},
	shorttitle = {The orienteering problem},
	url = {http://www.sciencedirect.com/science/article/pii/S0377221710002973},
	doi = {10.1016/j.ejor.2010.03.045},
	abstract = {During the last decade, a number of challenging applications in logistics, tourism and other fields were modelled as orienteering problems (OP). In the orienteering problem, a set of vertices is given, each with a score. The goal is to determine a path, limited in length, that visits some vertices and maximises the sum of the collected scores. In this paper, the literature about the orienteering problem and its applications is reviewed. The OP is formally described and many relevant variants are presented. All published exact solution approaches and (meta) heuristics are discussed and compared. Interesting open research questions concerning the OP conclude this paper.},
	language = {en},
	number = {1},
	urldate = {2020-01-11},
	journal = {European Journal of Operational Research},
	author = {Vansteenwegen, Pieter and Souffriau, Wouter and Oudheusden, Dirk Van},
	month = feb,
	year = {2011},
	keywords = {Combinatorial optimisation, Orienteering problem, Survey},
	pages = {1--10}
}

@misc{noauthor_c_nodate,
	title = {c++ - {Undefined} symbol using {Boost}/{Python}},
	url = {https://stackoverflow.com/questions/42276194/undefined-symbol-using-boost-python?rq=1},
	urldate = {2020-01-08},
	journal = {Stack Overflow}
}

@misc{noauthor_swig_nodate,
	title = {{SWIG} {Tutorial}},
	url = {http://www.swig.org/tutorial.html},
	urldate = {2020-01-08}
}

@misc{noauthor_c_nodate-1,
	title = {c++ - {Ubuntu} - {Linking} boost.python - {Fatal} error: pyconfig cannot be found},
	shorttitle = {c++ - {Ubuntu} - {Linking} boost.python - {Fatal} error},
	url = {https://stackoverflow.com/questions/19810940/ubuntu-linking-boost-python-fatal-error-pyconfig-cannot-be-found},
	urldate = {2020-01-08},
	journal = {Stack Overflow}
}

@misc{noauthor_c_nodate-2,
	title = {c++ - {How} to properly add include directories with {CMake}},
	url = {https://stackoverflow.com/questions/13703647/how-to-properly-add-include-directories-with-cmake},
	urldate = {2020-01-08},
	journal = {Stack Overflow}
}

@misc{noauthor_when_nodate,
	title = {When should {I} wrap variables with \$\{...\} in {CMake}?},
	url = {https://stackoverflow.com/questions/25809332/when-should-i-wrap-variables-with-in-cmake/25809646},
	urldate = {2020-01-08},
	journal = {Stack Overflow}
}

@misc{noauthor_c_nodate-3,
	title = {c++ - {Difference} between (target\_)link\_libraries and (target\_)include\_directories},
	url = {https://stackoverflow.com/questions/56565665/difference-between-target-link-libraries-and-target-include-directories},
	urldate = {2020-01-08},
	journal = {Stack Overflow}
}

@misc{noauthor_zeit_nodate,
	title = {{ZEIT} {Campus} {Ratgeber} {Promotion}: {Entscheiden}, planen, durchhalten},
	shorttitle = {{ZEIT} {Campus} {Ratgeber} {Promotion}},
	url = {https://www.zeit.de/campus/ratgeber-promotion/index},
	abstract = {Die wichtigsten Tipps für die Dissertation in allen großen Fachgebieten},
	language = {de},
	urldate = {2020-01-08},
	journal = {ZEIT Campus}
}

@misc{dilorenzo_c_nodate,
	title = {C++ {Pointers} for {REAL} dummies},
	url = {http://alumni.cs.ucr.edu/~pdiloren/C++_Pointers/},
	urldate = {2020-01-07},
	journal = {Learning C++ Pointers for Real Dummies},
	author = {DiLorenzo, Paul}
}

@misc{noauthor_parameter_2020,
	title = {Parameter {Search} {Package}},
	url = {https://github.com/automl/SMAC3},
	abstract = {Sequential Model-based Algorithm Configuration. Contribute to automl/SMAC3 development by creating an account on GitHub.},
	urldate = {2020-01-07},
	publisher = {AutoML-Freiburg-Hannover},
	month = jan,
	year = {2020},
	note = {original-date: 2016-08-17T10:58:05Z},
	keywords = {algorithm-configuration, automated-machine-learning, automl, bayesian-optimisation, bayesian-optimization, configuration, hyperparameter-optimization, hyperparameter-search, hyperparameter-tuning}
}
@misc{noauthor_cvpr_nodate,
	title = {{CVPR} {Hints} on {Paper} {Writing}, {Reviewing}, etc.},
	url = {https://www.cc.gatech.edu/~parikh/citizenofcvpr/},
	abstract = {What does it take to be a good citizen of the CVPR community?},
	urldate = {2020-01-07},
	journal = {Good Citizen of CVPR}
}

@book{bast_cmake_2018,
	edition = {1st edition},
	title = {{CMake} {Cookbook}},
	abstract = {Learn CMake through a series of task-based recipes that provide you with practical, simple, and ready-to-use CMake solutions for your code Key Features Learn to configure, build, test, and package software written in C, C++, and Fortran Progress from simple to advanced tasks with examples tested on Linux, macOS, and Windows Manage code complexity and library dependencies with reusable CMake building blocks Book Description CMake is cross-platform, open-source software for managing the build process in a portable fashion. This book features a collection of recipes and building blocks with tips and techniques for working with CMake, CTest, CPack, and CDash. CMake Cookbook includes real-world examples in the form of recipes that cover different ways to structure, configure, build, and test small- to large-scale code projects. You will learn to use CMake's command-line tools and master modern CMake practices for configuring, building, and testing binaries and libraries. With this book, you will be able to work with external libraries and structure your own projects in a modular and reusable way. You will be well-equipped to generate native build scripts for Linux, MacOS, and Windows, simplify and refactor projects using CMake, and port projects to CMake. What you will learn Configure, build, test, and install code projects using CMake Detect operating systems, processors, libraries, files, and programs for conditional compilation Increase the portability of your code Refactor a large codebase into modules with the help of CMake Build multi-language projects Know where and how to tweak CMake configuration files written by somebody else Package projects for distribution Port projects to CMake Who this book is for If you are a software developer keen to manage build systems using CMake or would like to understand and modify CMake code written by others, this book is for you. A basic knowledge of C++, C, or Fortran is required to understand the topics covered in this book. Downloading the example code for this book You can download the example code files for all Packt books you have purchased from your account at http://www.PacktPub.com. If you purchased this book elsewhere, you can visit http://www.PacktPub.com/support and register to have the files e-mailed directly to you.},
	language = {eng},
	publisher = {Packt Publishing},
	author = {Bast, Radovan},
	collaborator = {Di Remigio, Roberto and Safari, an O'Reilly Media Company},
	year = {2018},
	keywords = {Electronic books}
}

@book{willmore_introduction_2017,
	address = {Boca Raton},
	title = {Introduction to scientific and technical computing},
	isbn = {978-1-4987-4506-2},
	abstract = {Created to help scientists and engineers write computer code, this practical book addresses the important tools and techniques that are necessary for scientific computing, but which are not yet commonplace in science and engineering curricula.},
	language = {eng},
	publisher = {Taylor \& Francis, CRC Press},
	author = {Willmore, Frank T.},
	collaborator = {Jankowski, Eric and Colina, Coray},
	year = {2017},
	keywords = {Data processing, Electronic books, Engineering, Research, Science}
}

@misc{lanusse_interfacing_2017,
	title = {Interfacing {C}++ and {Python} with {Boost}.{Python}},
	url = {https://flanusse.net/interfacing-c++-with-python.html},
	abstract = {This blog post demonstrates how to simply interface C++ code and Python using the powerful Boost.Python API.},
	language = {en},
	urldate = {2020-01-03},
	journal = {François Lanusse},
	author = {Lanusse, François},
	month = apr,
	year = {2017}
}

@misc{noauthor_swig_nodate,
	title = {{SWIG} {Tutorial}},
	url = {http://www.swig.org/tutorial.html},
	urldate = {2020-01-03}
}

@misc{patel_python_2017,
	title = {Python - {C}++ bindings},
	url = {https://www.hardikp.com/2017/12/30/python-cpp/},
	abstract = {Python - C++ bindings are useful for several reasons. Performance is one of them. Exposing existing C++ classes to a python module is another important reason.},
	language = {en-us},
	urldate = {2020-01-03},
	journal = {Hardik Patel},
	author = {Patel, Hardik},
	month = dec,
	year = {2017}
}

@misc{noauthor_keeping_nodate,
	title = {Keeping your code clean by sweeping out "if" statements},
	url = {https://dev.to/tomazlemos/keeping-your-code-clean-by-sweeping-out-if-statements-4in8},
	abstract = {Thoughts on cleaner code},
	language = {en},
	urldate = {2020-01-03},
	journal = {The DEV Community}
}

@article{he_bag_2018,
	title = {Bag of {Tricks} for {Image} {Classification} with {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1812.01187},
	abstract = {Much of the recent progress made in image classification research can be credited to training procedure refinements, such as changes in data augmentations and optimization methods. In the literature, however, most refinements are either briefly mentioned as implementation details or only visible in source code. In this paper, we will examine a collection of such refinements and empirically evaluate their impact on the final model accuracy through ablation study. We will show that, by combining these refinements together, we are able to improve various CNN models significantly. For example, we raise ResNet-50's top-1 validation accuracy from 75.3\% to 79.29\% on ImageNet. We will also demonstrate that improvement on image classification accuracy leads to better transfer learning performance in other application domains such as object detection and semantic segmentation.},
	urldate = {2020-01-03},
	journal = {arXiv:1812.01187 [cs]},
	author = {He, Tong and Zhang, Zhi and Zhang, Hang and Zhang, Zhongyue and Xie, Junyuan and Li, Mu},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.01187},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@inproceedings{maturana_looking_2017,
	title = {Looking forward: {A} semantic mapping system for scouting with micro-aerial vehicles},
	volume = {2017-September},
	shorttitle = {Looking forward},
	doi = {10.1109/IROS.2017.8206585},
	abstract = {The last decade has seen a massive growth in applications for Micro-Aerial Vehicles (MAVs), due in large part to their versatility for data gathering with cameras, LiDAR and various other sensors. Their ability to quickly go from assessing large spaces from a high vantage points to flying in close to capture high-resolution data makes them invaluable for applications where we are interested in a specific target with an a priori unknown location, e.g. survivors in disaster response scenarios, vehicles in surveillance, animals in wildlife monitoring, etc., a task we will refer to scouting. Our ultimate goal is to enable MAVs to perform autonomous scouting. In this paper, we describe a semantic mapping system designed to support this goal. The system maintains a 2.5D map describing its belief about the location of semantic classes of interest, using forward-looking cameras and state estimation. The map is continuously updated on the fly, using only onboard processing. The system couples a deep learning 2D semantic segmentation algorithm with a novel mapping method to project and aggregate the 2D semantic measurements into a global 2.5D grid map. We train and evaluate our segmentation method on a novel dataset of cars labelled in oblique aerial imagery. We also study the performance of the mapping system in isolation. Finally, we show the integrated system performing a fully autonomous car scouting mission in the field. © 2017 IEEE.},
	booktitle = {{IEEE} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	publisher = {IEEE},
	author = {Maturana, D. and Arora, S. and Scherer, S.},
	year = {2017},
	pages = {6691--6698}
}

@misc{by_linux_2019,
	title = {Linux {Fu}: {Stupid} {SSH} {Tricks}},
	shorttitle = {Linux {Fu}},
	url = {https://hackaday.com/2019/12/17/linux-fu-stupid-ssh-tricks/},
	abstract = {If you connect to remote computers over the Internet, it is a pretty good chance you use some form of SSH or secure shell. On Linux or Unix you’ll use the ssh command. Same goes for Linux-lik…},
	language = {en-US},
	urldate = {2019-12-20},
	journal = {Hackaday},
	author = {By},
	month = dec,
	year = {2019}
}

@misc{noauthor_using_2019,
	title = {Using the {SSH} {Config} {File}},
	url = {https://linuxize.com/post/using-the-ssh-config-file/},
	abstract = {OpenSSH allows you to set up a per-user configuration file where you can store different SSH options for each remote machine you connect to. This guide covers the basics of the SSH client configuration file and explains some of the most common configuration options.},
	language = {en-us},
	urldate = {2019-12-20},
	month = jan,
	year = {2019}
}

@misc{noauthor_ssh_2019,
	title = {{SSH} {Command}},
	url = {https://linuxize.com/post/ssh-command-in-linux/},
	abstract = {In this article, we will explain how to use the OpenSSH command-line client (ssh) to login to a remote machine and run commands or perform other operations.},
	language = {en-us},
	urldate = {2019-12-20},
	month = dec,
	year = {2019}
}

@book{vansteenwegen_orienteering_2019,
	address = {Cham},
	edition = {1st ed. 2019.},
	series = {{EURO} {Advanced} {Tutorials} on {Operational} {Research}},
	title = {Orienteering {Problems} {Models} and {Algorithms} for {Vehicle} {Routing} {Problems} with {Profits}},
	isbn = {978-3-030-29746-6},
	abstract = {This tutorial introduces readers to several variants of routing problems with profits. In these routing problems each node has a certain profit, and not all nodes need to be visited. Since the orienteering problem (OP) is by far the most frequently studied problem in this category of routing problems, the book mainly focuses on the OP. In turn, other problems are presented as variants of the OP, focusing on the similarities and differences. The goal of the OP is to determine a subset of nodes to visit and in which order, so that the total collected profit is maximized and a given time budget is not exceeded. The book provides a comprehensive review of variants of the OP, such as the team OP, the team OP with time windows, the profitable tour problem, and the prize-collecting travelling salesperson problem. In addition, it presents mathematical models and techniques for solving these OP variants and discusses their complexity. Several simple examples and benchmark instances, together with their best-known results, are also included. Finally, the book reviews the latest applications of these problems in the fields of logistics, tourism and others.},
	language = {eng},
	publisher = {Springer International Publishing},
	author = {Vansteenwegen, Pieter},
	collaborator = {Gunawan, Aldy},
	year = {2019},
	keywords = {Business logistics, Calculus of Variations and Optimal Control; Optimization, Logistics, Mathematical optimization, Operations Research, Management Science, Operations Research/Decision Theory, Operations research}
}

@misc{noauthor_ssh_2019-1,
	title = {{SSH} {Command}},
	url = {/post/ssh-command-in-linux/},
	abstract = {In this article, we will explain how to use the OpenSSH command-line client (ssh) to login to a remote machine and run commands or perform other operations.},
	language = {en-us},
	urldate = {2019-12-20},
	month = dec,
	year = {2019}
}

@misc{noauthor_using_2019-1,
	title = {Using the {SSH} {Config} {File}},
	url = {/post/using-the-ssh-config-file/},
	abstract = {OpenSSH allows you to set up a per-user configuration file where you can store different SSH options for each remote machine you connect to. This guide covers the basics of the SSH client configuration file and explains some of the most common configuration options.},
	language = {en-us},
	urldate = {2019-12-20},
	month = jan,
	year = {2019}
}

@article{fraundorfer_visual_2012,
	title = {Visual {Odometry} : {Part} {II}: {Matching}, {Robustness}, {Optimization}, and {Applications}},
	volume = {19},
	issn = {1558-223X},
	shorttitle = {Visual {Odometry}},
	doi = {10.1109/MRA.2012.2182810},
	abstract = {Part II of the tutorial has summarized the remaining building blocks of the VO pipeline: specifically, how to detect and match salient and repeatable features across frames and robust estimation in the presence of outliers and bundle adjustment. In addition, error propagation, applications, and links to publicly available code are included. VO is a well understood and established part of robotics. VO has reached a maturity that has allowed us to successfully use it for certain classes of applications: space, ground, aerial, and underwater. In the presence of loop closures, VO can be used as a building block for a complete SLAM algorithm to reduce motion drift. Challenges that still remain are to develop and demonstrate large-scale and long-term implementations, such as driving autonomous cars for hundreds of miles. Such systems have recently been demonstrated using Lidar and Radar sensors [86]. However, for VO to be used in such systems, technical issues regarding robustness and, especially, long-term stability have to be resolved. Eventually, VO has the potential to replace Lidar-based systems for egomotion estimation, which are currently leading the state of the art in accuracy, robustness, and reliability. VO offers a cheaper and mechanically easier-to-manufacture solution for egomotion estimation, while, additionally, being fully passive. Furthermore, the ongoing miniaturization of digital cameras offers the possibility to develop smaller and smaller robotic systems capable of ego-motion estimation.},
	number = {2},
	journal = {IEEE Robotics Automation Magazine},
	author = {Fraundorfer, Friedrich and Scaramuzza, Davide},
	month = jun,
	year = {2012},
	keywords = {Cameras, Computer vision, Estimation, Feature extraction, Lidar-based system, Odemtry, Optimization, Robust control, SLAM (robots), SLAM algorithm, Tutorials, VIsualization, VO pipeline, aerial application, cameras, digital camera, distance measurement, driving autonomous car, easier-to-manufacture solution, egomotion estimation, error propagation, ground application, loop closures, motion drift, motion estimation, radar sensor, robot vision, robotic system, robust estimation, space application, underwater application, visual odometry},
	pages = {78--90}
}

@inproceedings{lianos_vso:_2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{VSO}: {Visual} {Semantic} {Odometry}},
	isbn = {978-3-030-01225-0},
	shorttitle = {{VSO}},
	doi = {10.1007/978-3-030-01225-0_15},
	abstract = {Robust data association is a core problem of visual odometry, where image-to-image correspondences provide constraints for camera pose and map estimation. Current state-of-the-art direct and indirect methods use short-term tracking to obtain continuous frame-to-frame constraints, while long-term constraints are established using loop closures. In this paper, we propose a novel visual semantic odometry (VSO) framework to enable medium-term continuous tracking of points using semantics. Our proposed framework can be easily integrated into existing direct and indirect visual odometry pipelines. Experiments on challenging real-world datasets demonstrate a significant improvement over state-of-the-art baselines in the context of autonomous driving simply by integrating our semantic constraints.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2018},
	publisher = {Springer International Publishing},
	author = {Lianos, Konstantinos-Nektarios and Schönberger, Johannes L. and Pollefeys, Marc and Sattler, Torsten},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	year = {2018},
	keywords = {SLAM, Semantic segmentation, Visual odometry},
	pages = {246--263}
}

@misc{noauthor_google_nodate,
	title = {Google {Scholar} reveals its most influential papers for 2019},
	url = {https://www.natureindex.com/news-blog/google-scholar-reveals-most-influential-papers-research-citations-twenty-nineteen},
	abstract = {These 7 high-impact papers are citations gold.},
	urldate = {2019-12-19}
}

@misc{noauthor_drone_nodate,
	title = {Drone market set to take off with new {ISO} standard},
	url = {http://www.iso.org/cms/render/live/en/sites/isoorg/contents/news/2019/12/Ref2461.html},
	abstract = {Estimated to grow from USD 4 billion to USD 40 billion in the next five years [1], the global commercial drone market has skyrocketed in recent years and shows no signs of abating. Yet, where the pace of technology outruns regulations, International Standards are essential to ensure a minimum level of …},
	language = {en},
	urldate = {2019-12-16},
	journal = {ISO}
}

@misc{noauthor_sourcetrail_nodate,
	title = {Sourcetrail - {Documentation}},
	url = {https://www.sourcetrail.com/documentation/#OnLinux},
	urldate = {2019-12-16}
}

@misc{preshing_learn_nodate,
	title = {Learn {CMake}'s {Scripting} {Language} in 15 {Minutes}},
	url = {https://preshing.com/20170522/learn-cmakes-scripting-language-in-15-minutes},
	abstract = {As explained in my previous post, every CMake-based project must contain a script named CMakeLists.txt. This script defines targets, but it can also do a lot of other things, such …},
	language = {en},
	urldate = {2019-12-16},
	author = {Preshing, Jeff}
}

@misc{micro_visual_2019,
	title = {Visual {Studio} {Code} {Tips} and {Tricks}},
	url = {https://github.com/microsoft/vscode-tips-and-tricks},
	abstract = {Collection of helpful tips and tricks for VS Code.},
	urldate = {2019-12-16},
	publisher = {Microsoft},
	author = {Micro, Soft},
	month = dec,
	year = {2019},
	note = {original-date: 2016-03-16T01:56:50Z}
}

@article{estrada_hierarchical_2005,
	title = {Hierarchical {SLAM}: real-time accurate mapping of large environments},
	volume = {21},
	issn = {1941-0468},
	shorttitle = {Hierarchical {SLAM}},
	doi = {10.1109/TRO.2005.844673},
	abstract = {In this paper, we present a hierarchical mapping method that allows us to obtain accurate metric maps of large environments in real time. The lower (or local) map level is composed of a set of local maps that are guaranteed to be statistically independent. The upper (or global) level is an adjacency graph whose arcs are labeled with the relative location between local maps. An estimation of these relative locations is maintained at this level in a relative stochastic map. We propose a close to optimal loop closing method that, while maintaining independence at the local level, imposes consistency at the global level at a computational cost that is linear with the size of the loop. Experimental results demonstrate the efficiency and precision of the proposed method by mapping the Ada Byron building at our campus. We also analyze, using simulations, the precision and convergence of our method for larger loops.},
	number = {4},
	journal = {IEEE Transactions on Robotics},
	author = {Estrada, C. and Neira, J. and Tardos, J.D.},
	month = aug,
	year = {2005},
	keywords = {Ada Byron building, Analytical models, Computational complexity, Computational efficiency, Computational modeling, Convergence, Information filtering, Information filters, Large maps, Robots, Simultaneous localization and mapping, Stochastic processes, closed loop systems, hierarchical mapping method, local maps, loop closing, metric maps, mobile robots, optimal loop closing method, path planning, simultaneous localization and mapping, stochastic mapping},
	pages = {588--596}
}

@misc{tensorflow_real-time_2018,
	title = {Real-time {Human} {Pose} {Estimation} in the {Browser} with {TensorFlow}.js},
	url = {https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5},
	abstract = {Posted by: Dan Oved, freelance creative technologist at Google Creative Lab, graduate student at ITP, NYU. 
Editing and illustrations…},
	language = {en},
	urldate = {2019-12-13},
	journal = {Medium},
	author = {TensorFlow},
	month = sep,
	year = {2018}
}

@misc{noauthor_2019_2019,
	title = {A 2019 guide to {3D} {Pose} {Estimation}},
	url = {https://nanonets.com/blog/human-pose-estimation-3d-guide/},
	abstract = {Human Pose Estimation is an important step towards understanding people in images and videos. In this post, I write about the basics of 3D Human Pose Estimation and review the literature on this topic.},
	language = {en},
	urldate = {2019-12-13},
	journal = {AI \& Machine Learning Blog},
	month = may,
	year = {2019}
}

@misc{noauthor_qut_nodate,
	title = {{QUT} {Robot} {Academy}},
	url = {https://robotacademy.net.au/},
	abstract = {University-level, short video lessons and full online courses to help you understand and prepare for this technology of the future.},
	language = {en-US},
	urldate = {2019-12-13},
	journal = {Robot Academy}
}

@article{kuipers_spatial_2000,
	title = {The {Spatial} {Semantic} {Hierarchy}},
	volume = {119},
	issn = {0004-3702},
	url = {http://www.sciencedirect.com/science/article/pii/S0004370200000175},
	doi = {10.1016/S0004-3702(00)00017-5},
	abstract = {The Spatial Semantic Hierarchy is a model of knowledge of large-scale space consisting of multiple interacting representations, both qualitative and quantitative. The SSH is inspired by the properties of the human cognitive map, and is intended to serve both as a model of the human cognitive map and as a method for robot exploration and map-building. The multiple levels of the SSH express states of partial knowledge, and thus enable the human or robotic agent to deal robustly with uncertainty during both learning and problem-solving. The control level represents useful patterns of sensorimotor interaction with the world in the form of trajectory-following and hill-climbing control laws leading to locally distinctive states. Local geometric maps in local frames of reference can be constructed at the control level to serve as observers for control laws in particular neighborhoods. The causal level abstracts continuous behavior among distinctive states into a discrete model consisting of states linked by actions. The topological level introduces the external ontology of places, paths and regions by abduction to explain the observed pattern of states and actions at the causal level. Quantitative knowledge at the control, causal and topological levels supports a “patchwork map” of local geometric frames of reference linked by causal and topological connections. The patchwork map can be merged into a single global frame of reference at the metrical level when sufficient information and computational resources are available. We describe the assumptions and guarantees behind the generality of the SSH across environments and sensorimotor systems. Evidence is presented from several partial implementations of the SSH on simulated and physical robots.},
	language = {en},
	number = {1},
	urldate = {2019-12-13},
	journal = {Artificial Intelligence},
	author = {Kuipers, Benjamin},
	month = may,
	year = {2000},
	keywords = {Cognitive map, Map learning, Qualitative reasoning, Robot exploration, Spatial reasoning},
	pages = {191--233}
}

@article{perez-arnal_visual_2018,
	title = {A {Visual} {Distance} for {WordNet}},
	url = {https://arxiv.org/abs/1804.09558v2},
	abstract = {Measuring the distance between concepts is an important field of study of
Natural Language Processing, as it can be used to improve tasks related to the
interpretation of those same concepts. WordNet, which includes a wide variety
of concepts associated with words (i.e., synsets), is often used as a source
for computing those distances. In this paper, we explore a distance for WordNet
synsets based on visual features, instead of lexical ones. For this purpose, we
extract the graphic features generated within a deep convolutional neural
networks trained with ImageNet and use those features to generate a
representative of each synset. Based on those representatives, we define a
distance measure of synsets, which complements the traditional lexical
distances. Finally, we propose some experiments to evaluate its performance and
compare it with the current state-of-the-art.},
	language = {en},
	urldate = {2019-06-28},
	author = {Pérez-Arnal, Raquel and Vilalta, Armand and Garcia-Gasulla, Dario and Cortés, Ulises and Ayguadé, Eduard and Labarta, Jesus},
	month = apr,
	year = {2018}
}

@article{perez-arnal_visual_2018-1,
	title = {A {Visual} {Distance} for {WordNet}},
	url = {https://arxiv.org/abs/1804.09558v2},
	abstract = {Measuring the distance between concepts is an important field of study of
Natural Language Processing, as it can be used to improve tasks related to the
interpretation of those same concepts. WordNet, which includes a wide variety
of concepts associated with words (i.e., synsets), is often used as a source
for computing those distances. In this paper, we explore a distance for WordNet
synsets based on visual features, instead of lexical ones. For this purpose, we
extract the graphic features generated within a deep convolutional neural
networks trained with ImageNet and use those features to generate a
representative of each synset. Based on those representatives, we define a
distance measure of synsets, which complements the traditional lexical
distances. Finally, we propose some experiments to evaluate its performance and
compare it with the current state-of-the-art.},
	language = {en},
	urldate = {2019-06-28},
	author = {Pérez-Arnal, Raquel and Vilalta, Armand and Garcia-Gasulla, Dario and Cortés, Ulises and Ayguadé, Eduard and Labarta, Jesus},
	month = apr,
	year = {2018}
}

@book{noauthor_nltk_nodate,
	title = {{NLTK} {Book}},
	url = {http://www.nltk.org/book/},
	urldate = {2019-07-01}
}

@article{yu_neuroslam:_2019,
	title = {{NeuroSLAM}: a brain-inspired {SLAM} system for {3D} environments},
	volume = {113},
	issn = {1432-0770},
	shorttitle = {{NeuroSLAM}},
	doi = {10.1007/s00422-019-00806-9},
	abstract = {Roboticists have long drawn inspiration from nature to develop navigation and simultaneous localization and mapping (SLAM) systems such as RatSLAM. Animals such as birds and bats possess superlative navigation capabilities, robustly navigating over large, three-dimensional environments, leveraging an internal neural representation of space combined with external sensory cues and self-motion cues. This paper presents a novel neuro-inspired 4DoF (degrees of freedom) SLAM system named NeuroSLAM, based upon computational models of 3D grid cells and multilayered head direction cells, integrated with a vision system that provides external visual cues and self-motion cues. NeuroSLAM's neural network activity drives the creation of a multilayered graphical experience map in a real time, enabling relocalization and loop closure through sequences of familiar local visual cues. A multilayered experience map relaxation algorithm is used to correct cumulative errors in path integration after loop closure. Using both synthetic and real-world datasets comprising complex, multilayered indoor and outdoor environments, we demonstrate NeuroSLAM consistently producing topologically correct three-dimensional maps.},
	language = {eng},
	number = {5-6},
	journal = {Biological Cybernetics},
	author = {Yu, Fangwen and Shang, Jianga and Hu, Youjian and Milford, Michael},
	month = dec,
	year = {2019},
	pmid = {31571007},
	keywords = {3D grid cells, Bio-inspired robotics, Brain-inspired navigation, Multilayered head direction cells, Simultaneous localization and mapping (SLAM)},
	pages = {515--545}
}

@misc{noauthor_google_2019,
	title = {Google {Style} {Guide}},
	url = {http://google.github.io/styleguide/pyguide.html},
	abstract = {Style guides for Google-originated open-source projects},
	language = {en-US},
	urldate = {2019-05-03},
	journal = {styleguide},
	month = may,
	year = {2019}
}

@misc{noauthor_aerial_2019,
	title = {Aerial {Semantic} {Segmentation} {Benchmark}.},
	copyright = {CC-BY-SA-4.0},
	url = {https://github.com/ishann/aeroscapes},
	urldate = {2019-06-11},
	month = jun,
	year = {2019},
	note = {original-date: 2017-12-12T02:41:00Z}
}

@misc{sunderhauf_robotic_2019,
	title = {The {Robotic} {Vision} {Challenge}},
	url = {https://nikosuenderhauf.github.io/roboticvisionchallenges/cvpr2019.html},
	abstract = {Benchmarking Scene Understanding, and Active \& Continuous Learning for Robotic Vision.Powered by the Australian Centre for Robotic Vision.},
	language = {en-US},
	urldate = {2019-04-15},
	journal = {The Robotic Vision Challenges},
	author = {Sünderhauf, Niko},
	month = apr,
	year = {2019}
}

@misc{noauthor_deep_nodate,
	title = {Deep {Learning} {Onramp}},
	url = {https://au.mathworks.com/learn/tutorials/deep-learning-onramp.html},
	abstract = {This free, two-hour deep learning tutorial provides an interactive introduction to practical deep learning methods. You will learn to use deep learning techniques in MATLAB for image recognition.},
	language = {en},
	urldate = {2019-06-30}
}

@inproceedings{delmerico_benchmark_2018,
	title = {A {Benchmark} {Comparison} of {Monocular} {Visual}-{Inertial} {Odometry} {Algorithms} for {Flying} {Robots}},
	isbn = {978-1-5386-3081-5},
	url = {https://www.research-collection.ethz.ch/handle/20.500.11850/302155},
	doi = {10.1109/ICRA.2018.8460664},
	language = {en},
	urldate = {2019-08-07},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {Delmerico, Jeffrey and Scaramuzza, Davide},
	year = {2018},
	note = {https://www.youtube.com/watch?v=ymI3FmwU9AY\&feature=youtu.be},
	pages = {2502--2509}
}

@book{noauthor_deep_2019,
	title = {Deep {Learning}},
	url = {https://www.deeplearningbook.org/},
	urldate = {2019-04-09},
	month = apr,
	year = {2019}
}

@misc{tenorth_knowrob_2019,
	title = {{KnowRob} {Documentation}},
	url = {http://www.knowrob.org/doc},
	abstract = {Knowledgebase for roboters to interact with},
	urldate = {2019-04-09},
	author = {Tenorth},
	month = apr,
	year = {2019}
}

@misc{noauthor_nanonets_nodate,
	title = {{NanoNets}, {Machine} {Learning} {API}},
	url = {https://nanonets.com/?utm_source=Medium&utm_campaign=data%20augmentation%2F&source=post_page---------------------------},
	urldate = {2019-07-30}
}

@misc{noauthor_ben_nodate,
	title = {Ben {Eater} {YouTube} {Channel} - {Computer} {Science} and {Electronics}},
	url = {https://www.youtube.com/channel/UCS0N5baNlQWJCUrhCEo8WlA},
	abstract = {Subscribe to see tutorial-style videos about electronics, computer architecture, networking, and various other technical subjects. If you want to see more on...},
	language = {de-DE},
	urldate = {2019-08-09},
	journal = {YouTube}
}

@misc{rosebrock_install_2018,
	title = {Install {OpenCV} 4 on your {Raspberry} {Pi}},
	url = {https://www.pyimagesearch.com/2018/09/26/install-opencv-4-on-your-raspberry-pi/},
	abstract = {Learn how to install OpenCV 4 on your Raspberry Pi. Follow by simple, step-by-step instructions and you'll have OpenCV 4 installed on Raspbian in no time.},
	language = {en-US},
	urldate = {2019-12-10},
	journal = {PyImageSearch},
	author = {Rosebrock, Adrian},
	month = sep,
	year = {2018}
}

@misc{noauthor_installing_nodate,
	title = {Installing {OpenCV} on the {Raspberry} {Pi}},
	url = {https://tutorials-raspberrypi.com/installing-opencv-on-the-raspberry-pi/},
	abstract = {Anyone who has dealt with image processing in relation to the Raspberry Pi will sooner or later come across the OpenCV library. It provides many very useful features such as face recognition, the creation of depth maps (stereo vision, optical flow), text recognition or even for machine learning. In addition, OpenCV (Open Source Computer Vision) …},
	language = {en-US},
	urldate = {2019-12-10},
	journal = {Raspberry Pi Tutorials}
}

@misc{noauthor_how_2018,
	title = {How to enable support for {Raspberry} {Pi} {3B}+ and {3A}+ in {Ubuntu} {MATE}},
	url = {https://ubuntu-mate.community/t/how-to-enable-support-for-raspberry-pi-3b-and-3a-in-ubuntu-mate/18471},
	abstract = {These instructions also apply to the Lubuntu and Xubuntu images available on the Ubuntu Pi Flavour Maker website, as well as any other 32-bit distro for the Raspberry Pi.  People have been reporting that Ubuntu MATE has not been booting on the Pi 3B+ but boots perfectly on older Pi models. This is because Ubuntu MATE and some other distros uses old bootloader files which are incompatible with the Pi 3B+ and 3A+. You can easily update the bootloader files to the latest available versions using rp...},
	language = {en},
	urldate = {2019-12-10},
	journal = {Ubuntu MATE Community},
	month = dec,
	year = {2018}
}

@misc{noauthor_install_nodate,
	title = {Install {Ubuntu} {Core} on a {Raspberry} {Pi} 2 or 3},
	url = {https://ubuntu.com/download/raspberry-pi-2-3-core},
	abstract = {Ubuntu is an open source software operating system that runs from the desktop, to the cloud, to all your internet connected things.},
	language = {en},
	urldate = {2019-12-09},
	journal = {Ubuntu}
}

@misc{fazzari_your_2017,
	title = {Your first robot: {A} beginner’s guide to {ROS} and {Ubuntu} {Core} [1/5]},
	shorttitle = {Your first robot},
	url = {https://snapcraft.io/blog/your-first-robot-a-beginners-guide-to-ros-and-ubuntu-core-1-5},
	abstract = {Some time ago I created a blog/video series that walked the reader through creating a prototype using the Robot Operating System (ROS) and taking it to production using Ubuntu Core. However, that series was intended more for robotics professionals; it assumed quite a bit of ROS knowledge, and required some costly equipment (the robot was  […]},
	language = {en},
	urldate = {2019-12-09},
	journal = {Snapcraft},
	author = {Fazzari, Kyle},
	month = dec,
	year = {2017}
}

@article{cadena_past_2016,
	title = {Past, {Present}, and {Future} of {Simultaneous} {Localization} and {Mapping}: {Toward} the {Robust}-{Perception} {Age}},
	volume = {32},
	issn = {1941-0468},
	shorttitle = {Past, {Present}, and {Future} of {Simultaneous} {Localization} and {Mapping}},
	doi = {10.1109/TRO.2016.2624754},
	abstract = {Simultaneous localization and mapping (SLAM) consists in the concurrent construction of a model of the environment (the map), and the estimation of the state of the robot moving within it. The SLAM community has made astonishing progress over the last 30 years, enabling large-scale real-world applications and witnessing a steady transition of this technology to industry. We survey the current state of SLAM and consider future directions. We start by presenting what is now the de-facto standard formulation for SLAM. We then review related work, covering a broad set of topics including robustness and scalability in long-term mapping, metric and semantic representations for mapping, theoretical performance guarantees, active SLAM and exploration, and other new frontiers. This paper simultaneously serves as a position paper and tutorial to those who are users of SLAM. By looking at the published research with a critical eye, we delineate open challenges and new research issues, that still deserve careful scientific investigation. The paper also contains the authors' take on two questions that often animate discussions during robotics conferences: Do robots need SLAM? and Is SLAM solved?},
	number = {6},
	journal = {IEEE Transactions on Robotics},
	author = {Cadena, Cesar and Carlone, Luca and Carrillo, Henry and Latif, Yasir and Scaramuzza, Davide and Neira, José and Reid, Ian and Leonard, John J.},
	month = dec,
	year = {2016},
	keywords = {Factor graphs, Graph theory, Localization, Robustness, SLAM (robots), SLAM community, SLAM users, Service robots, Simultaneous location and mapping, critical eye, localization, long-term mapping, mapping, maximum a posteriori estimation, perception, robots, semantic representations, sensing, simultaneous localization and mapping (SLAM), simultaneous-localization-and-mapping},
	pages = {1309--1332}
}

@article{bailey_simultaneous_2006,
	title = {Simultaneous localization and mapping ({SLAM}): part {II}},
	volume = {13},
	issn = {1558-223X},
	shorttitle = {Simultaneous localization and mapping ({SLAM})},
	doi = {10.1109/MRA.2006.1678144},
	abstract = {This paper discusses the recursive Bayesian formulation of the simultaneous localization and mapping (SLAM) problem in which probability distributions or estimates of absolute or relative locations of landmarks and vehicle pose are obtained. The paper focuses on three key areas: computational complexity; data association; and environment representation},
	number = {3},
	journal = {IEEE Robotics Automation Magazine},
	author = {Bailey, T. and Durrant-Whyte, H.},
	month = sep,
	year = {2006},
	keywords = {Bayes methods, Bayesian methods, Computational complexity, Computational efficiency, Delay estimation, Mobile robots, Robotics and automation, Robustness, Simultaneous localization and mapping, Uncertainty, Vehicles, computational complexity, data association, environment representation, mobile robot, mobile robots, path planning, probability distributions, recursive Bayesian formulation, simultaneous localization and mapping, statistical distributions, vehicle pose},
	pages = {108--117}
}

@article{durrant-whyte_simultaneous_2006,
	title = {Simultaneous localization and mapping: part {I}},
	volume = {13},
	issn = {1558-223X},
	shorttitle = {Simultaneous localization and mapping},
	doi = {10.1109/MRA.2006.1638022},
	abstract = {This paper describes the simultaneous localization and mapping (SLAM) problem and the essential methods for solving the SLAM problem and summarizes key implementations and demonstrations of the method. While there are still many practical issues to overcome, especially in more complex outdoor environments, the general SLAM method is now a well understood and established part of robotics. Another part of the tutorial summarized more recent works in addressing some of the remaining issues in SLAM, including computation, feature representation, and data association},
	number = {2},
	journal = {IEEE Robotics Automation Magazine},
	author = {Durrant-Whyte, H. and Bailey, T.},
	month = jun,
	year = {2006},
	keywords = {Artificial intelligence, Bayesian methods, Buildings, History, Mobile robots, Navigation, Particle filters, Robotics and automation, SLAM problem, Simultaneous localization and mapping, Vehicles, mobile robots, path planning, simultaneous localization and mapping problem},
	pages = {99--110}
}

@article{koschorreck_optimisation_2009,
	title = {Optimisation of somersaults and twists in platform diving},
	volume = {12},
	issn = {1025-5842},
	url = {https://doi.org/10.1080/10255840903091353},
	doi = {10.1080/10255840903091353},
	number = {sup1},
	urldate = {2019-12-08},
	journal = {Computer Methods in Biomechanics and Biomedical Engineering},
	author = {Koschorreck, J. and Mombaur, K.},
	month = aug,
	year = {2009},
	keywords = {numerical optimisation, optimal motion, physics-based computer model, sports biomechanics},
	pages = {157--159}
}

@article{hatze_complete_1976,
	title = {The complete optimization of a human motion},
	volume = {28},
	issn = {0025-5564},
	url = {http://www.sciencedirect.com/science/article/pii/0025556476900985},
	doi = {10.1016/0025-5564(76)90098-5},
	abstract = {The dynamical behavior of a musculo-skeletal link system, consisting of the right leg of a human subject, is simulated by a mathematical model which contains two control parameters for each of the five muscle groups involved. A time-optimal problem in which the right-hand end point of the state trajectory is variable is formulated and an optimization performed. The computational procedure is based on an algorithm of differential dynamic programming. The optimal model solution is then compared with the performance of the living system. It is found that any motion of the biosystem which deviates from the predicted optimal one takes a longer time to complete and is thus not optimal. Moreover, the trajectories and control functions of near-optimal motions as measured on the living system were indeed found to be very close to the theoretical optimal process thus again confirming the optimality of the model solution. In addition, the model predicts biologically highly significant phenomena such as the occurence of a stretch reflex, the incompatibility of speed and accuracy in a genetically non-determined biomotion, etc. Certain characteristic changes in the motion pattern occuring when the subject became fatigued are analyzed, and a possible explanation for this phenomenon is suggested. It is believed that this is the first time that an optimization of this kind has been performed successfully. Possible practical applications of the findings of this study are discussed.},
	language = {en},
	number = {1},
	urldate = {2019-12-08},
	journal = {Mathematical Biosciences},
	author = {Hatze, Herbert},
	month = jan,
	year = {1976},
	pages = {99--135}
}

@misc{noauthor_lagrange_nodate,
	title = {Lagrange multipliers, examples},
	url = {https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-examples},
	abstract = {Examples of the Lagrangian and Lagrange multiplier technique in action.},
	language = {en},
	urldate = {2019-12-06},
	journal = {Khan Academy}
}

@misc{saroufim_how_2019,
	title = {How {To} {Turn} {Physics} into an {Optimization} {Problem}?},
	url = {https://blog.usejournal.com/how-to-turn-physics-into-an-optimization-problem-11b3fbf83062},
	abstract = {If you know the basics of Machine Learning you already know how to solve a large body of physics problems without realizing it.},
	language = {en},
	urldate = {2019-12-06},
	journal = {Medium},
	author = {Saroufim, Mark},
	month = nov,
	year = {2019}
}

@misc{noauthor_coatisoftware/sourcetrail_2019,
	title = {{CoatiSoftware}/{Sourcetrail}},
	copyright = {GPL-3.0},
	url = {https://github.com/CoatiSoftware/Sourcetrail},
	abstract = {Sourcetrail},
	urldate = {2019-12-06},
	publisher = {Coati Software},
	month = dec,
	year = {2019},
	note = {original-date: 2015-12-09T12:32:11Z},
	keywords = {c, cpp, java, python}
}

@article{cervera_try_2019,
	title = {Try to {Start} {It}! {The} {Challenge} of {Reusing} {Code} in {Robotics} {Research}},
	volume = {4},
	issn = {2377-3774},
	doi = {10.1109/LRA.2018.2878604},
	abstract = {This letter reviews the source code published with the papers of a flagship robotics research conference, 2017 International Conference on Robotics and Automation. The aim is to investigate whether the code is actually useful, i.e., can be reused by an interested reader without much effort. The interest is twofold: for one side, it makes possible to replicate and validate the results of the research; for another side, it facilitates new progress on the field, since researchers can build new systems on top of existing work. Unfortunately, reusing code is not as straightforward as it could seem, and there is a need for tools that alleviate the effort for integrating someone else's code into the own user's system. We propose the use of Docker, a Linux container technology, to turn the source code repositories into executable images, that can be run and tested locally, in an isolated environment, without the need of a costly integration with the host system.},
	number = {1},
	journal = {IEEE Robotics and Automation Letters},
	author = {Cervera, Enric},
	month = jan,
	year = {2019},
	keywords = {C++ languages, Linux, Matlab, Operating systems, Python, Robots, Software, cloud computing, flagship robotics research conference, middleware and programming environments, reusing code, software engineering, source code repositories, virtualisation},
	pages = {49--56}
}

@misc{stanford_cs229_nodate,
	title = {{CS229} - {Machine} {Learning}},
	url = {https://see.stanford.edu/Course/CS229},
	urldate = {2019-12-05},
	author = {Stanford, Engineering}
}

@article{churchill_experience-based_2013,
	title = {Experience-based navigation for long-term localisation},
	volume = {32},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364913499193},
	doi = {10.1177/0278364913499193},
	abstract = {This paper is about long-term navigation in environments whose appearance changes over time, suddenly or gradually. We describe, implement and validate an approach which allows us to incrementally learn a model whose complexity varies naturally in accordance with variation of scene appearance. It allows us to leverage the state of the art in pose estimation to build over many runs, a world model of sufficient richness to allow simple localisation despite a large variation in conditions. As our robot repeatedly traverses its workspace, it accumulates distinct visual experiences that in concert, implicitly represent the scene variation: each experience captures a visual mode. When operating in a previously visited area, we continually try to localise in these previous experiences while simultaneously running an independent vision-based pose estimation system. Failure to localise in a sufficient number of prior experiences indicates an insufficient model of the workspace and instigates the laying down of the live image sequence as a new distinct experience. In this way, over time we can capture the typical time-varying appearance of an environment and the number of experiences required tends to a constant. Although we focus on vision as a primary sensor throughout, the ideas we present here are equally applicable to other sensor modalities. We demonstrate our approach working on a road vehicle operating over a 3-month period at different times of day, in different weather and lighting conditions. We present extensive results analysing different aspects of the system and approach, in total processing over 136,000 frames captured from 37 km of driving.},
	language = {en},
	number = {14},
	urldate = {2019-12-05},
	journal = {The International Journal of Robotics Research},
	author = {Churchill, Winston and Newman, Paul},
	month = dec,
	year = {2013},
	pages = {1645--1661}
}

@misc{noauthor_tutorial_nodate,
	title = {Tutorial 1: {Let}'s start with {CMake} {\textbar} {Learning} {CMake}: {A} beginner's guide},
	url = {https://tuannguyen68.gitbooks.io/learning-cmake-a-beginner-s-guide/content/chap1/chap1.html},
	urldate = {2019-12-04}
}

@misc{derek_introduction_nodate,
	title = {Introduction to {CMake} by {Example}},
	url = {http://derekmolloy.ie/hello-world-introductions-to-cmake/},
	abstract = {Article describes a set of C++ “Hello World!” introductions and CMakeLists.txt files to use CMake for building projects with sub-directories, and shared libraries.},
	language = {en-US},
	urldate = {2019-12-04},
	journal = {derekmolloy.ie},
	author = {{Derek}}
}

@inproceedings{stein_object_2014,
	title = {Object {Partitioning} {Using} {Local} {Convexity}},
	doi = {10.1109/CVPR.2014.46},
	abstract = {The problem of how to arrive at an appropriate 3D-segmentation of a scene remains difficult. While current state-of-the-art methods continue to gradually improve in benchmark performance, they also grow more and more complex, for example by incorporating chains of classifiers, which require training on large manually annotated data-sets. As an alternative to this, we present a new, efficient learning- and model-free approach for the segmentation of 3D point clouds into object parts. The algorithm begins by decomposing the scene into an adjacency-graph of surface patches based on a voxel grid. Edges in the graph are then classified as either convex or concave using a novel combination of simple criteria which operate on the local geometry of these patches. This way the graph is divided into locally convex connected subgraphs, which – with high accuracy – represent object parts. Additionally, we propose a novel depth dependent voxel grid to deal with the decreasing point-density at far distances in the point clouds. This improves segmentation, allowing the use of fixed parameters for vastly different scenes. The algorithm is straightforward to implement and requires no training data, while nevertheless producing results that are comparable to state-of-the-art methods which incorporate high-level concepts involving classification, learning and model fitting.},
	booktitle = {2014 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Stein, Simon Christoph and Schoeler, Markus and Papon, Jeremie and Wörgötter, Florentin},
	month = jun,
	year = {2014},
	note = {ISSN: 1063-6919},
	keywords = {3D object segmentation, 3D part segmentation, 3D point clouds, 3D-segmentation, Cameras, Convexity based, Image segmentation, LCCP, Noise, Object segmentation, Octrees, Supervoxels, Surface treatment, Three-dimensional displays, adjacency-graph, computer graphics, convex connected subgraphs, convex programming, depth dependent voxel grid, graph theory, image classification, image segmentation, learning (artificial intelligence), learning-free approach, local convexity, manually annotated data-set, model-free approach, object partitioning, point-density, surface patches},
	pages = {304--311}
}

@misc{noauthor_thrust_nodate,
	title = {Thrust {Library} - {C}++ parallel processing},
	url = {https://github.com/thrust/thrust},
	abstract = {Thrust is a C++ parallel programming library which resembles the C++ Standard Library. - thrust/thrust},
	language = {en},
	urldate = {2019-12-03},
	journal = {GitHub}
}

@misc{noauthor_hardware-unterstutztes_nodate,
	title = {Hardware-unterstütztes {OpenGL} for {Raspberry} {Pi} {3A} +},
	url = {https://pi-buch.info/hardware-unterstuetztes-opengl/},
	language = {de-DE},
	urldate = {2019-12-03}
}

@misc{noauthor_opengl/hello_nodate,
	title = {{OpenGL}/{Hello} {World} - {Wikiversity}},
	url = {https://en.wikiversity.org/wiki/OpenGL/Hello_World},
	urldate = {2019-12-03}
}

@misc{noauthor_c++_nodate,
	title = {C++ - {Boost} - {Converting} std::vector to {Boost}.{Python} {Numpy} ndarray {\textbar} {BadproG}.com},
	url = {https://www.badprog.com/c-boost-converting-stdvector-to-boost-python-numpy-ndarray},
	urldate = {2019-12-03}
}

@misc{noauthor_c++_nodate-1,
	title = {C++ - {OpenGL} - {Hello} {World}! {\textbar} {BadproG}.com},
	url = {https://www.badprog.com/c-opengl-hello-world},
	urldate = {2019-12-03}
}

@misc{noauthor_calling_nodate,
	title = {Calling {C}/{C}++ from {Python}?},
	url = {https://stackoverflow.com/questions/145270/calling-c-c-from-python},
	urldate = {2019-12-03},
	journal = {Stack Overflow}
}

@book{bishop_pattern_2006,
	address = {New York, NY},
	series = {Information science and statistics.},
	title = {Pattern recognition and machine learning},
	isbn = {978-0-387-31073-2},
	language = {eng},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	year = {2006},
	keywords = {Apprentissage automatique, Machine learning, Pattern perception, Pattern recognition systems, Reconnaissance des formes (Informatique), Statistique mathématique}
}

@article{vanegas_novel_2018,
	title = {A {Novel} {Methodology} for {Improving} {Plant} {Pest} {Surveillance} in {Vineyards} and {Crops} {Using} {UAV}-{Based} {Hyperspectral} and {Spatial} {Data}},
	volume = {18},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/18/1/260},
	doi = {10.3390/s18010260},
	abstract = {Recent advances in remote sensed imagery and geospatial image processing using unmanned aerial vehicles (UAVs) have enabled the rapid and ongoing development of monitoring tools for crop management and the detection/surveillance of insect pests. This paper describes a (UAV) remote sensing-based methodology to increase the efficiency of existing surveillance practices (human inspectors and insect traps) for detecting pest infestations (e.g., grape phylloxera in vineyards). The methodology uses a UAV integrated with advanced digital hyperspectral, multispectral, and RGB sensors. We implemented the methodology for the development of a predictive model for phylloxera detection. In this method, we explore the combination of airborne RGB, multispectral, and hyperspectral imagery with ground-based data at two separate time periods and under different levels of phylloxera infestation. We describe the technology used—the sensors, the UAV, and the flight operations—the processing workflow of the datasets from each imagery type, and the methods for combining multiple airborne with ground-based datasets. Finally, we present relevant results of correlation between the different processed datasets. The objective of this research is to develop a novel methodology for collecting, processing, analising and integrating multispectral, hyperspectral, ground and spatial data to remote sense different variables in different applications, such as, in this case, plant pest surveillance. The development of such methodology would provide researchers, agronomists, and UAV practitioners reliable data collection protocols and methods to achieve faster processing techniques and integrate multiple sources of data in diverse remote sensing applications.},
	language = {en},
	number = {1},
	urldate = {2019-12-02},
	journal = {Sensors},
	author = {Vanegas, Fernando and Bratanov, Dmitry and Powell, Kevin and Weiss, John and Gonzalez, Felipe},
	month = jan,
	year = {2018},
	keywords = {RGB, digital elevation model, digital vigour assessment, hyperspectral, multispectral, phylloxera, remote sensing, unmanned aerial vehicle},
	pages = {260}
}

@article{gonzalez_unmanned_2016,
	title = {Unmanned {Aerial} {Vehicles} ({UAVs}) and {Artificial} {Intelligence} {Revolutionizing} {Wildlife} {Monitoring} and {Conservation}},
	volume = {16},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/16/1/97},
	doi = {10.3390/s16010097},
	abstract = {Surveying threatened and invasive species to obtain accurate population estimates is an important but challenging task that requires a considerable investment in time and resources. Estimates using existing ground-based monitoring techniques, such as camera traps and surveys performed on foot, are known to be resource intensive, potentially inaccurate and imprecise, and difficult to validate. Recent developments in unmanned aerial vehicles (UAV), artificial intelligence and miniaturized thermal imaging systems represent a new opportunity for wildlife experts to inexpensively survey relatively large areas. The system presented in this paper includes thermal image acquisition as well as a video processing pipeline to perform object detection, classification and tracking of wildlife in forest or open areas. The system is tested on thermal video data from ground based and test flight footage, and is found to be able to detect all the target wildlife located in the surveyed area. The system is flexible in that the user can readily define the types of objects to classify and the object characteristics that should be considered during classification.},
	language = {en},
	number = {1},
	urldate = {2019-12-02},
	journal = {Sensors},
	author = {Gonzalez, Luis F. and Montes, Glen A. and Puig, Eduard and Johnson, Sandra and Mengersen, Kerrie and Gaston, Kevin J.},
	month = jan,
	year = {2016},
	keywords = {Unmanned Aerial Vehicle (UAV), artificial intelligence, automatic classification, conservation, deer, dingo, koala, robotics, thermal imaging, wild pigs, wildlife monitoring},
	pages = {97}
}

@article{villa_overview_2016,
	title = {An {Overview} of {Small} {Unmanned} {Aerial} {Vehicles} for {Air} {Quality} {Measurements}: {Present} {Applications} and {Future} {Prospectives}},
	volume = {16},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {An {Overview} of {Small} {Unmanned} {Aerial} {Vehicles} for {Air} {Quality} {Measurements}},
	url = {https://www.mdpi.com/1424-8220/16/7/1072},
	doi = {10.3390/s16071072},
	abstract = {Assessment of air quality has been traditionally conducted by ground based monitoring, and more recently by manned aircrafts and satellites. However, performing fast, comprehensive data collection near pollution sources is not always feasible due to the complexity of sites, moving sources or physical barriers. Small Unmanned Aerial Vehicles (UAVs) equipped with different sensors have been introduced for in-situ air quality monitoring, as they can offer new approaches and research opportunities in air pollution and emission monitoring, as well as for studying atmospheric trends, such as climate change, while ensuring urban and industrial air safety. The aims of this review were to: (1) compile information on the use of UAVs for air quality studies; and (2) assess their benefits and range of applications. An extensive literature review was conducted using three bibliographic databases (Scopus, Web of Knowledge, Google Scholar) and a total of 60 papers was found. This relatively small number of papers implies that the field is still in its early stages of development. We concluded that, while the potential of UAVs for air quality research has been established, several challenges still need to be addressed, including: the flight endurance, payload capacity, sensor dimensions/accuracy, and sensitivity. However, the challenges are not simply technological, in fact, policy and regulations, which differ between countries, represent the greatest challenge to facilitating the wider use of UAVs in atmospheric research.},
	language = {en},
	number = {7},
	urldate = {2019-12-02},
	journal = {Sensors},
	author = {Villa, Tommaso Francesco and Gonzalez, Felipe and Miljievic, Branka and Ristovski, Zoran D. and Morawska, Lidia},
	month = jul,
	year = {2016},
	keywords = {UAVs, aerosols, air quality, atmosphere, pollution, sensors},
	pages = {1072}
}

@misc{noauthor_cocomo_2019,
	title = {{COCOMO}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://de.wikipedia.org/w/index.php?title=COCOMO&oldid=193097636},
	abstract = {COCOMO (Constructive Cost Model) ist ein algorithmisches Kostenmodell, das in der Softwareentwicklung zur Kosten- bzw. Aufwandsschätzung verwendet wird. Mit Hilfe von mathematischen Funktionen wird ein Zusammenhang zwischen gewissen Softwaremetriken und den Kosten eines Projekts dargestellt.
Es fließen mehrere firmenspezifische Parameter in die Berechnung hinein, die feststellt, wie viele Personenmonate oder Personenjahre notwendig sind, um ein Softwareprojekt zu realisieren. Weiterhin kann die Gesamtdauer des Projekts abgeschätzt werden. COCOMO beruht auf vielfältiger Erfahrung, die in der Großindustrie, z. B. bei Boeing, bei der Softwareentwicklung gemacht worden ist. Das Verfahren wurde bereits 1981 durch Barry W. Boehm, Softwareingenieur bei Boeing, entwickelt.},
	language = {de},
	urldate = {2019-12-01},
	journal = {Wikipedia},
	month = oct,
	year = {2019},
	note = {Page Version ID: 193097636}
}

@article{jorgensen_impact_2011,
	title = {The {Impact} of {Irrelevant} and {Misleading} {Information} on {Software} {Development} {Effort} {Estimates}: {A} {Randomized} {Controlled} {Field} {Experiment}},
	volume = {37},
	issn = {2326-3881},
	shorttitle = {The {Impact} of {Irrelevant} and {Misleading} {Information} on {Software} {Development} {Effort} {Estimates}},
	doi = {10.1109/TSE.2010.78},
	abstract = {Studies in laboratory settings report that software development effort estimates can be strongly affected by effort-irrelevant and misleading information. To increase our knowledge about the importance of these effects in field settings, we paid 46 outsourcing companies from various countries to estimate the required effort of the same five software development projects. The companies were allocated randomly to either the original requirement specification or a manipulated version of the original requirement specification. The manipulations were as follows: 1) reduced length of requirement specification with no change of content, 2) information about the low effort spent on the development of the old system to be replaced, 3) information about the client's unrealistic expectations about low cost, and 4) a restriction of a short development period with start up a few months ahead. We found that the effect sizes in the field settings were much smaller than those found for similar manipulations in laboratory settings. Our findings suggest that we should be careful about generalizing to field settings the effect sizes found in laboratory settings. While laboratory settings can be useful to demonstrate the existence of an effect and better understand it, field studies may be needed to study the size and importance of these effects.},
	number = {5},
	journal = {IEEE Transactions on Software Engineering},
	author = {Jorgensen, Magne and Grimstad, Stein},
	month = sep,
	year = {2011},
	keywords = {Companies, Cost estimation, Estimation, Laboratories, Materials, Programming, Project management, Software, formal specification, irrelevant information impact, laboratory settings, misleading information impact, original requirement specification, randomized controlled field experiment, requirements/specifications., software cost estimation, software development effort estimates, software development projects, software psychology},
	pages = {695--707}
}

@article{rak_effort_2019,
	title = {Effort estimation model for software development projects based on use case reuse},
	volume = {31},
	copyright = {© 2018 The Authors. Journal of Software: Evolution and Process Published by John Wiley \& Sons Ltd.},
	issn = {2047-7481},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.2119},
	doi = {10.1002/smr.2119},
	abstract = {This paper describes a new effort estimation model based on use case reuse, called the use case reusability (UCR), intended for the projects that are reusing artifacts previously developed in past projects with similar scope. Analysis of the widely spread effort estimation techniques for software development projects shows that these techniques were primarily intended for the development of new software solutions. The baseline for the new effort estimation model is the use case points model. The UCR model introduces new classification of use cases based on their reusability, and it includes only those technical and environmental factors that according to the effort estimation experts have significant impact on effort for the target projects. This paper also presents a study which validates the usage of UCR model. The study is conducted within industry and academic environments using industry project teams and postgraduate students as subjects. The analysis results show that UCR model can be applied in different project environments and that according to the observed mean magnitude relative error, it produced very promising effort estimates.},
	language = {en},
	number = {2},
	urldate = {2019-12-01},
	journal = {Journal of Software: Evolution and Process},
	author = {Rak, Katija and Car, Željka and Lovrek, Ignac},
	year = {2019},
	keywords = {effort estimation, reusability, software development, use case, use case points},
	pages = {e2119}
}

@book{brooks_mythical_1995,
	address = {Reading, Mass},
	edition = {Jubiläumsausg.},
	title = {The {Mythical} {Man}-{Month}. {Essays} on {Software} {Engineering}},
	isbn = {978-0-201-83595-3},
	abstract = {Few books on software project management have been as influential and timeless as The Mythical Man-Month. With a blend of software engineering facts and thought-provoking opinions, Fred Brooks offers insight for anyone managing complex projects. These essays draw from his experience as project manager for the IBM System/360 computer family and then for OS/360, its massive software system. Now, 20 years after the initial publication of his book, Brooks has revisited his original ideas and added new thoughts and advice, both for readers already familiar with his work and for readers discovering it for the first time.   The added chapters contain (1) a crisp condensation of all the propositions asserted in the original book, including Brooks' central argument in The Mythical Man-Month: that large programming projects suffer management problems different from small ones due to the division of labor; that the conceptual integrity of the product is therefore critical; and that it is difficult but possible to achieve this unity; (2) Brooks' view of these propositions a generation later; (3) a reprint of his classic 1986 paper "No Silver Bullet"; and (4) today's thoughts on the 1986 assertion, "There will be no silver bullet within ten years."},
	language = {Englisch},
	publisher = {Addison-Wesley Longman},
	author = {Brooks, Frederick P.},
	month = aug,
	year = {1995}
}

@inproceedings{katz_improving_2013,
	title = {Improving the {Visual} {Comprehension} of {Point} {Sets}},
	doi = {10.1109/CVPR.2013.23},
	abstract = {Point sets are the standard output of many 3D scanning systems and depth cameras. Presenting the set of points as is, might "hide" the prominent features of the object from which the points are sampled. Our goal is to reduce the number of points in a point set, for improving the visual comprehension from a given viewpoint. This is done by controlling the density of the reduced point set, so as to create bright regions (low density) and dark regions (high density), producing an effect of shading. This data reduction is achieved by leveraging a limitation of a solution to the classical problem of determining visibility from a viewpoint. In addition, we introduce a new dual problem, for determining visibility of a point from infinity, and show how a limitation of its solution can be leveraged in a similar way.},
	booktitle = {2013 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Katz, Sagi and Tal, Ayellet},
	month = jun,
	year = {2013},
	note = {ISSN: 1063-6919},
	keywords = {3D scanning systems, Approximation algorithms, Image reconstruction, Noise, Observers, Surface reconstruction, Three-dimensional displays, computer graphics, data reduction, depth cameras, point sets, visual comprehension},
	pages = {121--128}
}

@inproceedings{katz_visibility_2015,
	title = {On the {Visibility} of {Point} {Clouds}},
	doi = {10.1109/ICCV.2015.159},
	abstract = {Is it possible to determine the visible subset of points directly from a given point cloud? Interestingly, it was shown that this is indeed the case - despite the fact that points cannot occlude each other, this task can be performed without surface reconstruction or normal estimation. The operator is very simple - it first transforms the points to a new domain and then constructs the convex hull in that domain. Points that lie on the convex hull of the transformed set of points are the images of the visible points. This operator found numerous applications in computer vision, including face reconstruction, keypoint detection, finding the best viewpoints, reduction of points, and many more. The current paper addresses a fundamental question: What properties should a transformation function satisfy, in order to be utilized in this operator? We show that three such properties are sufficient: the sign of the function, monotonicity, and a condition regarding the function's parameter. The correctness of an algorithm that satisfies these three properties is proved. Finally, we show an interesting application of the operator - assignment of visibility-confidence score. This feature is missing from previous approaches, where a binary yes/no visibility is determined. This score can be utilized in various applications, we illustrate its use in view-dependent curvature estimation.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Katz, Sagi and Tal, Ayellet},
	month = dec,
	year = {2015},
	note = {ISSN: 2380-7504},
	keywords = {Computer vision, Estimation, Face, Image reconstruction, Kernel, Surface reconstruction, Three-dimensional displays, computer vision, convex hull, convex programming, estimation theory, face recognition, image reconstruction, keypoint detection, object detection, point clouds, surface reconstruction, transformation function, view-dependent curvature estimation, visibility-confidence score},
	pages = {1350--1358}
}

@misc{sikchi_convex_2017,
	title = {Convex {Hulls}: {Explained}},
	shorttitle = {Convex {Hulls}},
	url = {https://medium.com/@harshitsikchi/convex-hulls-explained-baab662c4e94},
	abstract = {Convex Hull Computation},
	language = {en},
	urldate = {2019-11-28},
	journal = {Medium},
	author = {Sikchi, Harshit},
	month = apr,
	year = {2017}
}

@inproceedings{katz_direct_2007,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '07},
	title = {Direct {Visibility} of {Point} {Sets}},
	url = {http://doi.acm.org/10.1145/1275808.1276407},
	doi = {10.1145/1275808.1276407},
	abstract = {This paper proposes a simple and fast operator, the "Hidden" Point Removal operator, which determines the visible points in a point cloud, as viewed from a given viewpoint. Visibility is determined without reconstructing a surface or estimating normals. It is shown that extracting the points that reside on the convex hull of a transformed point cloud, amounts to determining the visible points. This operator is general - it can be applied to point clouds at various dimensions, on both sparse and dense point clouds, and on viewpoints internal as well as external to the cloud. It is demonstrated that the operator is useful in visualizing point clouds, in view-dependent reconstruction and in shadow casting.},
	urldate = {2019-11-28},
	booktitle = {{ACM} {SIGGRAPH} 2007 {Papers}},
	publisher = {ACM},
	author = {Katz, Sagi and Tal, Ayellet and Basri, Ronen},
	year = {2007},
	note = {event-place: San Diego, California},
	keywords = {point-based graphics, visibility, visualizing point sets}
}

@article{gunawan_orienteering_2016,
	title = {Orienteering {Problem}: {A} survey of recent variants, solution approaches and applications},
	volume = {255},
	issn = {0377-2217},
	shorttitle = {Orienteering {Problem}},
	url = {http://www.sciencedirect.com/science/article/pii/S037722171630296X},
	doi = {10.1016/j.ejor.2016.04.059},
	abstract = {The Orienteering Problem (OP) has received a lot of attention in the past few decades. The OP is a routing problem in which the goal is to determine a subset of nodes to visit, and in which order, so that the total collected score is maximized and a given time budget is not exceeded. A number of typical variants has been studied, such as the Team OP, the (Team) OP with Time Windows and the Time Dependent OP. Recently, a number of new variants of the OP was introduced, such as the Stochastic OP, the Generalized OP, the Arc OP, the Multi-agent OP, the Clustered OP and others. This paper focuses on a comprehensive and thorough survey of recent variants of the OP, including the proposed solution approaches. Moreover, the OP has been used as a model in many different practical applications. The most recent applications of the OP, such as the Tourist Trip Design Problem and the mobile-crowdsourcing problem are discussed. Finally, we also present some promising topics for future research.},
	language = {en},
	number = {2},
	urldate = {2019-11-27},
	journal = {European Journal of Operational Research},
	author = {Gunawan, Aldy and Lau, Hoong Chuin and Vansteenwegen, Pieter},
	month = dec,
	year = {2016},
	keywords = {Orienteering Problem, Practical Applications, Scheduling, Survey},
	pages = {315--332}
}

@inproceedings{heng_efficient_2015,
	title = {Efficient visual exploration and coverage with a micro aerial vehicle in unknown environments},
	doi = {10.1109/ICRA.2015.7139309},
	abstract = {In this paper, we propose a novel and computationally efficient algorithm for simultaneous exploration and coverage with a vision-guided micro aerial vehicle (MAV) in unknown environments. This algorithm continually plans a path that allows the MAV to fulfil two objectives at the same time while avoiding obstacles: observe as much unexplored space as possible, and observe as much of the surface of the environment as possible given viewing angle and distance constraints. The former and latter objectives are known as the exploration and coverage problems respectively. Our algorithm is particularly useful for automated 3D reconstruction at the street level and in indoor environments where obstacles are omnipresent. By solving the exploration problem, we maximize the size of the reconstructed model. By solving the coverage problem, we maximize the completeness of the model. Our algorithm leverages the state lattice concept such that the planned path adheres to specified motion constraints. Furthermore, our algorithm is computationally efficient and able to run on-board the MAV in real-time. We assume that the MAV is equipped with a forward-looking depth-sensing camera in the form of either a stereo camera or RGB-D camera. We use simulation experiments to validate our algorithm. In addition, we show that our algorithm achieves a significantly higher level of coverage as compared to an exploration-only approach while still allowing the MAV to fully explore the environment.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Heng, Lionel and Gotovos, Alkis and Krause, Andreas and Pollefeys, Marc},
	month = may,
	year = {2015},
	note = {ISSN: 1050-4729},
	keywords = {Cameras, Face, Lattices, MAV, Planning, RGB-D camera, Real-time systems, Solid modeling, Three-dimensional displays, autonomous aerial vehicles, collision avoidance, coverage problems, exploration problems, forwardlooking depth-sensing camera, lattice theory, mobile robots, obstacle avoidance, path planning, robot vision, state lattice concept, stereo camera, stereo image processing, telerobotics, vision-guided micro aerial vehicle, visual exploration},
	pages = {1071--1078}
}

@inproceedings{mu_slam_2016,
	title = {{SLAM} with objects using a nonparametric pose graph},
	doi = {10.1109/IROS.2016.7759677},
	abstract = {Mapping and self-localization in unknown environments are fundamental capabilities in many robotic applications. These tasks typically involve the identification of objects as unique features or landmarks, which requires the objects both to be detected and then assigned a unique identifier that can be maintained when viewed from different perspectives and in different images. The data association and simultaneous localization and mapping (SLAM) problems are, individually, well-studied in the literature. But these two problems are inherently tightly coupled, and that has not been well-addressed. Without accurate SLAM, possible data associations are combinatorial and become intractable easily. Without accurate data association, the error of SLAM algorithms diverge easily. This paper proposes a novel nonparametric pose graph that models data association and SLAM in a single framework. An algorithm is further introduced to alternate between inferring data association and performing SLAM. Experimental results show that our approach has the new capability of associating object detections and localizing objects at the same time, leading to significantly better performance on both the data association and SLAM problems than achieved by considering only one and ignoring imperfections in the other.},
	booktitle = {2016 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Mu, Beipeng and Liu, Shih-Yuan and Paull, Liam and Leonard, John and How, Jonathan P.},
	month = oct,
	year = {2016},
	note = {ISSN: 2153-0866},
	keywords = {Machine learning, Object detection, Proposals, Robustness, SLAM, SLAM (robots), Simultaneous localization and mapping, Three-dimensional displays, data association, graph theory, nonparametric pose graph, object detection, pose estimation, robot vision, robotic application, sensor fusion, simultaneous localization and mapping},
	pages = {4602--4609}
}

@inproceedings{sunderhauf_meaningful_2017,
	title = {Meaningful maps with object-oriented semantic mapping},
	doi = {10.1109/IROS.2017.8206392},
	abstract = {For intelligent robots to interact in meaningful ways with their environment, they must understand both the geometric and semantic properties of the scene surrounding them. The majority of research to date has addressed these mapping challenges separately, focusing on either geometric or semantic mapping. In this paper we address the problem of building environmental maps that include both semantically meaningful, object-level entities and point- or mesh-based geometrical representations. We simultaneously build geometric point cloud models of previously unseen instances of known object classes and create a map that contains these object models as central entities. Our system leverages sparse, feature-based RGB-D SLAM, image-based deep-learning object detection and 3D unsupervised segmentation.},
	booktitle = {2017 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Sünderhauf, Niko and Pham, Trung T. and Latif, Yasir and Milford, Michael and Reid, Ian},
	month = sep,
	year = {2017},
	note = {ISSN: 2153-0866},
	keywords = {3D unsupervised segmentation, Image segmentation, Object detection, Object oriented modeling, SLAM (robots), Semantics, Simultaneous localization and mapping, Solid modeling, Three-dimensional displays, environmental maps, geometric mapping, geometric point cloud models, geometric properties, image colour analysis, image representation, image segmentation, image-based deep-learning object detection, intelligent robots, known object classes, learning (artificial intelligence), mapping challenges, meaningful maps, mesh-based geometrical representations, object detection, object models, object-level entities, object-oriented semantic mapping, point-based geometrical representations, semantic properties, sparse feature-based RGB-D SLAM},
	pages = {5079--5085}
}

@inproceedings{tulsiani_viewpoints_2015,
	title = {Viewpoints and keypoints},
	doi = {10.1109/CVPR.2015.7298758},
	abstract = {We characterize the problem of pose estimation for rigid objects in terms of determining viewpoint to explain coarse pose and keypoint prediction to capture the finer details. We address both these tasks in two different settings - the constrained setting with known bounding boxes and the more challenging detection setting where the aim is to simultaneously detect and correctly estimate pose of objects. We present Convolutional Neural Network based architectures for these and demonstrate that leveraging viewpoint estimates can substantially improve local appearance based keypoint predictions. In addition to achieving significant improvements over state-of-the-art in the above tasks, we analyze the error modes and effect of object characteristics on performance to guide future efforts towards this goal.},
	booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Tulsiani, Shubham and Malik, Jitendra},
	month = jun,
	year = {2015},
	note = {ISSN: 1063-6919},
	keywords = {Computer architecture, Prediction algorithms, Predictive models, Solid modeling, Training, coarse pose prediction, convolutional neural network based architectures, error modes, local appearance based keypoint predictions, neural net architecture, object characteristics, pose estimation, prediction theory, viewpoint determination},
	pages = {1510--1519}
}

@misc{august_31_dirichlet_nodate,
	title = {The {Dirichlet} process for dummies (i.e., biologists, like me)},
	url = {http://phyletica.org/dirichlet-process/},
	abstract = {An accessible introduction to how the Dirichlet process works and why it's useful.},
	language = {en},
	urldate = {2019-11-27},
	journal = {phyletica},
	author = {August 31, The Dirichlet process for dummieswas published on and {2015.}}
}

@misc{penn_coursera_nodate,
	title = {{COURSERA} - {ROBOTICS} {PERCEPTION} {AND} {FURTHER} {COURSES}},
	shorttitle = {Robotics},
	url = {https://www.coursera.org/learn/robotics-perception#syllabus},
	abstract = {Learn Robotics: Perception from University of Pennsylvania. How can robots perceive the world and their own movements so that they accomplish navigation and manipulation tasks?  In this module, we will study how images and videos acquired by ...},
	language = {en},
	urldate = {2019-11-26},
	journal = {Coursera},
	author = {Penn, State}
}

@misc{noauthor_coursera_nodate,
	title = {{COURSERA} - {Penn} {State} {Robotics}},
	shorttitle = {{RANSAC}},
	url = {https://www.coursera.org/lecture/robotics-perception/ransac-random-sample-consensus-i-z0GWq},
	abstract = {Video created by University of Pennsylvania for the course "Robotics: Perception". In this module we will be learning about feature extraction and pose estimation from two images. We will learn how to find the most salient parts of an image and ...},
	language = {en},
	urldate = {2019-11-26},
	journal = {Coursera}
}

@article{zhang_hierarchical_2019,
	title = {Hierarchical {Topic} {Model} {Based} {Object} {Association} for {Semantic} {SLAM}},
	volume = {25},
	issn = {2160-9306},
	doi = {10.1109/TVCG.2019.2932216},
	abstract = {Object-based simultaneous localization and mapping (SLAM) is a more natural and robust way for agents to interact with their surrounding environment. However, it introduces a problem of semantic objects association. Correct object association is the key factor to achieve a successful object SLAM system because object association and SLAM are inherently coupled and have not been well tackled yet. A novel formulation of the object association problem based on a hierarchical Dirichlet process (HDP) is proposed. Through the HDP, we can hierarchically associate the grouped object measurements. This can improve the object association accuracy and computation efficiency. Thanks to the novel formulation, the proposed method is also able to correct failure object associations according to its sampling inference algorithm. Furthermore, we introduce object poses to the processing of pose optimization. The object association and pose optimization are then solved in a tightly coupled way, by which both aspects can promote each other. The proposed method is evaluated on indoor and outdoor datasets and the experimental results show a very impressive improvement with respect to the traditional SLAM.},
	number = {11},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Zhang, Jianhua and Gui, Mengping and Wang, Qichao and Liu, Ruyu and Xu, Junzhe and Chen, Shengyong},
	month = nov,
	year = {2019},
	keywords = {Atmospheric modeling, Cameras, Computer science, Hierarchical Dirichlet Process, Image reconstruction, Object Association, Optimization, SLAM (robots), Semantics, Simultaneous localization and mapping, Visual Semantic SLAM, computation efficiency, failure object associations, grouped object measurements, hierarchical topic model based object association, inference mechanisms, object SLAM system, object-based simultaneous localization and mapping, sampling inference algorithm, semantic SLAM, semantic objects association},
	pages = {3052--3062}
}

@misc{uni_cuda_nodate,
	title = {{CUDA} {Tutorials}},
	url = {http://www.ieap.uni-kiel.de/et/people/kruse/tutorial02.html},
	urldate = {2019-11-26},
	author = {Uni, Kiel}
}

@misc{parallelvision_accelerating_2019,
	title = {Accelerating {OpenCV} 4 – build with {CUDA} 10.0, {Intel} {MKL} + {TBB} and python bindings in {Windows}},
	url = {https://jamesbowley.co.uk/build-opencv-4-0-0-with-cuda-10-0-and-intel-mkl-tbb-in-windows/},
	abstract = {OpenCV 4.1.0 which is compatible with CUDA 10.1 was released on 08/04/2019, see Accelerating OpenCV 4 – build with CUDA, Intel MKL + TBB and python bindings, for the updated guide. Because the pre-…},
	language = {en-US},
	urldate = {2019-11-25},
	journal = {James Bowley},
	author = {{ParallelVision}},
	month = jan,
	year = {2019}
}

@misc{parallelvision_opencv_2018,
	title = {{OpenCV} 3.4 {GPU} {CUDA} {Performance} {Comparison} (nvidia vs intel)},
	url = {https://jamesbowley.co.uk/opencv-3-4-gpu-cuda-performance-comparison-nvidia-vs-intel/},
	abstract = {In this post I am going to use the OpenCV’s performance tests to compare the CUDA and CPU implementations. The idea, is to get an indication of which OpenCV and/or Computer Vision algorithms,…},
	language = {en-US},
	urldate = {2019-11-25},
	journal = {James Bowley},
	author = {{ParallelVision}},
	month = feb,
	year = {2018}
}

@misc{noauthor_iso_nodate,
	title = {{ISO} 25010},
	url = {https://iso25000.com/index.php/en/iso-25000-standards/iso-25010},
	urldate = {2019-11-25}
}

@misc{noauthor_iso_2017,
	title = {{ISO} 25010 {Software} {Quality} {Model}},
	url = {https://blog.codacy.com/iso-25010-software-quality-model/},
	abstract = {Code quality frameworks describe code quality characteristics and their decomposition. For Enterprise software development, one model stands out: the ISO/IEC 25010, which was launched in 2011. In ISO/IEC 2510, software quality is divided in two broad dimensions: (1) product quality and (2) quality in use. Product quality decomposition Product quality relates to the static and …},
	language = {en-GB},
	urldate = {2019-11-25},
	journal = {Codacy {\textbar} Blog},
	month = feb,
	year = {2017}
}

@misc{noauthor_software_nodate,
	title = {Software {Quality} {Standards}—{How} and {Why} {We} {Applied} {ISO} 25010},
	url = {https://www.monterail.com/blog/software-qa-standards-iso-25010},
	abstract = {ISO 25010 software quality standard defines software metrics vital for successful development projects. Check how to use it and what benefits it brings.},
	language = {en-us},
	urldate = {2019-11-25}
}

@misc{buenaflor_iso_2017,
	title = {{ISO} 9126 {Software} {Quality} {Characteristics}},
	url = {https://medium.com/@leanardbuenaflor/iso-9126-software-quality-characteristics-a25a26e7d046},
	abstract = {An overview of the ISO 9126–1 software quality model definition, with an explanation of the major characteristics.},
	language = {en},
	urldate = {2019-11-24},
	journal = {Medium},
	author = {Buenaflor, Leanard},
	month = sep,
	year = {2017}
}

@inproceedings{washizaki_experiments_2006,
	address = {New York, NY, USA},
	series = {{ICSE} '06},
	title = {Experiments on {Quality} {Evaluation} of {Embedded} {Software} in {Japan} {Robot} {Software} {Design} {Contest}},
	isbn = {978-1-59593-375-1},
	url = {http://doi.acm.org/10.1145/1134285.1134363},
	doi = {10.1145/1134285.1134363},
	abstract = {As a practical opportunity for educating Japanese young developers in the field of embedded software development, a software design contest involving the design of software to automatically control a line-trace robot, and conduct running performance tests was held. In this paper,we give the results of the contest from the viewpoint of software quality evaluation. We create a framework for evaluating the software quality which integrated design model quality and the final system performance, and conduct analysis using the framework. As a result of analysis,it is found that the quantitative measurement of the structural complexity of the design models bears a strong relationship to qualitative evaluation of the design conducted by judges. It is also found that there is no strong correlation between design model quality evaluated by the judges and the final system performance. For embedded software development, it is particularly important to estimate and verify reliability and performance in the early stages,using the model. Based on the analysis result,we consider possible remedies with respect to the models submitted,the evaluation methods used and the contest specifications. In order to adequately measure several non-functional quality characteristics including performance on the model,it is necessary to improve the way of developing robot software (such as applying model driven development)and reexamine the evaluation methods.},
	urldate = {2019-11-24},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Washizaki, Hironori and Kobayashi, Yasuhide and Watanabe, Hiroyuki and Nakajima, Eiji and Hagiwara, Yuji and Hiranabe, Kenji and Fukuda, Kazuya},
	year = {2006},
	note = {event-place: Shanghai, China},
	keywords = {embedded software development, robot contest, software design, software model, software quality},
	pages = {551--560}
}

@article{abouzahir_embedding_2018,
	title = {Embedding {SLAM} algorithms: {Has} it come of age?},
	volume = {100},
	issn = {0921-8890},
	shorttitle = {Embedding {SLAM} algorithms},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889017301963},
	doi = {10.1016/j.robot.2017.10.019},
	abstract = {Development of Simultaneous Localization and Mapping (SLAM) systems in the era of autonomous navigation and the growing demand for autonomous robots have put into question how to reduce the computational complexity and make use of SLAM algorithms to operate in real time. Our work, aims to take advantage of low-power embedded architectures to implement SLAM algorithms. Precisely, we evaluate the promise held by the new modern low power architectures in accelerating the execution time of SLAM algorithms. Throughout this, we map and implement 4 well-known SLAM algorithms that find utility in very different robot applications and autonomous navigation, on different architectures based embedded systems. We present first a processing time evaluation of these algorithms on different CPU based architectures. Results demonstrate that FastSLAM2.0 allows a compromise between the computation time and the consistency of the localization results. The algorithm has been modified to be adapted to large environments. It is then optimized for parallel implementations on GPU and FPGA. A comparative study of the resulting implementations is given. Our results show that an embedded FPGA based SoC architecture is an interesting alternative for a SLAM algorithm implementation using the hardware–software co-design approach. Hence, the system meets performance requirements of a robot to operate in real-time constraints.},
	language = {en},
	urldate = {2019-11-24},
	journal = {Robotics and Autonomous Systems},
	author = {Abouzahir, Mohamed and Elouardi, Abdelhafid and Latif, Rachid and Bouaziz, Samir and Tajer, Abdelouahed},
	month = feb,
	year = {2018},
	keywords = {CPU, FPGA, GPU, Hardware–software codesign, Heterogeneous architectures, SLAM algorithms},
	pages = {14--26}
}

@misc{noauthor_about_nodate,
	title = {About {IP}},
	url = {https://www.wipo.int/about-ip/en/universities_research/ip_policies/index.html},
	abstract = {Intellectual property (IP) refers to creations of the mind, such as inventions; literary and artistic works; designs; and symbols, names and images used in commerce},
	language = {en},
	urldate = {2019-11-20}
}

@misc{noauthor_getting_nodate,
	title = {Getting {Started} with the {NVIDIA} {Jetson} {Nano} {Developer} {Kit}},
	url = {https://www.hackster.io/news/getting-started-with-the-nvidia-jetson-nano-developer-kit-43aa7c298797},
	abstract = {Getting started with NVIDIA’s GPU-based hardware},
	language = {en},
	urldate = {2019-11-19},
	journal = {Hackster.io}
}

@misc{noauthor_open_nodate,
	title = {Open {Source} {Licenses} {Explained}},
	url = {https://resources.whitesourcesoftware.com/blog-whitesource/open-source-licenses-explained},
	abstract = {What's the difference between copyleft and permissive? Should you use a GNU GPL or MIT open source license? Open source licensing basics explained.},
	urldate = {2019-11-18}
}

@misc{comments_open_nodate,
	title = {Open source licensing: {What} every technologist should know},
	shorttitle = {Open source licensing},
	url = {https://opensource.com/article/17/9/open-source-licensing},
	abstract = {Learn about different types of open source licenses and get answers to common licensing questions.},
	language = {en},
	urldate = {2019-11-18},
	journal = {Opensource.com},
	author = {comments, 21 Sep 2017 Heather Meeker Feed 651up 4}
}

@misc{noauthor_licenses_nodate,
	title = {Licenses},
	url = {https://choosealicense.com/licenses/},
	abstract = {Non-judgmental guidance on choosing a license for your open source project},
	language = {en},
	urldate = {2019-11-18},
	journal = {Choose a License}
}
@misc{noauthor_mehr_nodate,
	title = {Mehr über die {Lizenzen} - {Creative} {Commons}},
	url = {https://creativecommons.org/licenses/?lang=de},
	urldate = {2019-11-18}
}

@misc{noauthor_jetson_2019,
	title = {Jetson {Nano} - {Run} {From} {USB} {Drive}},
	url = {https://www.jetsonhacks.com/2019/09/17/jetson-nano-run-from-usb-drive/},
	abstract = {Here's a new way to setup your Jetson Nano to run from a USB drive. It only takes about 10 minutes to setup, saving 45 minutes from our previous method!},
	language = {en-US},
	urldate = {2019-11-18},
	journal = {JetsonHacks},
	month = sep,
	year = {2019}
}

@misc{noauthor_deep_nodate,
	title = {Deep {Learning} with {MATLAB}, {NVIDIA} {Jetson}, and {ROS} {Video}},
	url = {https://au.mathworks.com/videos/matlab-and-simulink-robotics-arena-deep-learning-with-nvidia-jetson-and-ros--1542015526909.html},
	abstract = {Learn how GPU Coder can be used to deploy deep learning algorithms from MATLAB to embedded NVIDIA GPUs, and how the deployed code can be used with the Robot Operating System (ROS).},
	language = {en},
	urldate = {2019-11-18}
}

@misc{noauthor_kronecker-delta:_nodate,
	title = {Kronecker-{Delta}: 4 {Rechenregeln} und {Du} bist {Pro}!},
	shorttitle = {Kronecker-{Delta}},
	url = {https://universaldenker.de/theorien/24},
	abstract = {Hier lernst Du alles über Kronecker-Delta! Dazu gehören 4 Rechenregeln mit Einsteinscher Summenkonvention, typische Fehler und mehr.},
	language = {de},
	urldate = {2019-10-30}
}

@misc{noauthor_gaussian_nodate,
	title = {Gaussian {Processes} for {Machine} {Learning}: {Book} webpage},
	url = {http://www.gaussianprocess.org/gpml/},
	urldate = {2019-10-30}
}

@misc{noauthor_gaussian_nodate-1,
	title = {Gaussian {Processes} for {Dummies} ·},
	url = {https://katbailey.github.io/post/gaussian-processes-for-dummies/},
	urldate = {2019-10-30}
}

@inproceedings{huang_visual-inertial_2019,
	title = {Visual-{Inertial} {Navigation}: {A} {Concise} {Review}},
	shorttitle = {Visual-{Inertial} {Navigation}},
	doi = {10.1109/ICRA.2019.8793604},
	abstract = {As inertial and visual sensors are becoming ubiquitous, visual-inertial navigation systems (VINS) have prevailed in a wide range of applications from mobile augmented reality to aerial navigation to autonomous driving, in part because of the complementary sensing capabilities and the decreasing costs and size of the sensors. In this paper, we survey thoroughly the research efforts taken in this field and strive to provide a concise but complete review of the related work - which is unfortunately missing in the literature while being greatly demanded by researchers and engineers - in the hope to accelerate the VINS research and beyond in our society as a whole.},
	booktitle = {2019 {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Huang, Guoquan},
	month = may,
	year = {2019},
	note = {ISSN: 2577-087X, 1050-4729},
	keywords = {Acceleration, Cameras, Fuses, Navigation, Noise measurement, SLAM, SLAM (robots), Sensors, VINS, Visualization, aerial navigation, augmented reality, autonomous driving, image sensors, inertial navigation, inertial sensors, mobile augmented reality, mobile computing, mobile robots, robot vision, visual sensors, visual-inertial navigation systems},
	pages = {9572--9582}
}

@inproceedings{mourikis_multi-state_2007,
	title = {A {Multi}-{State} {Constraint} {Kalman} {Filter} for {Vision}-aided {Inertial} {Navigation}},
	doi = {10.1109/ROBOT.2007.364024},
	abstract = {In this paper, we present an extended Kalman filter (EKF)-based algorithm for real-time vision-aided inertial navigation. The primary contribution of this work is the derivation of a measurement model that is able to express the geometric constraints that arise when a static feature is observed from multiple camera poses. This measurement model does not require including the 3D feature position in the state vector of the EKF and is optimal, up to linearization errors. The vision-aided inertial navigation algorithm we propose has computational complexity only linear in the number of features, and is capable of high-precision pose estimation in large-scale real-world environments. The performance of the algorithm is demonstrated in extensive experimental results, involving a camera/IMU system localizing within an urban area.},
	booktitle = {Proceedings 2007 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Mourikis, Anastasios I. and Roumeliotis, Stergios I.},
	month = apr,
	year = {2007},
	note = {ISSN: 1050-4729},
	keywords = {3D feature position, Cameras, Computational complexity, Inertial navigation, Kalman filters, Large-scale systems, Motion estimation, Motion measurement, Position measurement, Simultaneous localization and mapping, Solid modeling, Vectors, camera pose, extended Kalman filter, feature extraction, geometric constraints, inertial navigation, linear computational complexity, multistate constraint Kalman filter, pose estimation, state vector, static feature, vision-aided inertial navigation},
	pages = {3565--3572}
}

@article{huai_robocentric_2018,
	title = {Robocentric {Visual}-{Inertial} {Odometry}},
	url = {http://arxiv.org/abs/1805.04031},
	abstract = {In this paper, we propose a novel robocentric formulation of the visual-inertial navigation system (VINS) within a sliding-window filtering framework and design an efficient, lightweight, robocentric visual-inertial odometry (R-VIO) algorithm for consistent motion tracking even in challenging environments using only a monocular camera and a 6-axis IMU. The key idea is to deliberately reformulate the VINS with respect to a moving local frame, rather than a fixed global frame of reference as in the standard world-centric VINS, in order to obtain relative motion estimates of higher accuracy for updating global poses. As an immediate advantage of this robocentric formulation, the proposed R-VIO can start from an arbitrary pose, without the need to align the initial orientation with the global gravitational direction. More importantly, we analytically show that the linearized robocentric VINS does not undergo the observability mismatch issue as in the standard world-centric counterpart which was identified in the literature as the main cause of estimation inconsistency. Additionally, we investigate in-depth the special motions that degrade the performance in the world-centric formulation and show that such degenerate cases can be easily compensated in the proposed robocentric formulation, without resorting to additional sensors as in the world-centric formulation, thus leading to better robustness. The proposed R-VIO algorithm has been extensively tested through both Monte Carlo simulations and real-world experiments with different sensor platforms navigating in different environments, and shown to achieve better (or competitive at least) performance than the state-of-the-art VINS, in terms of consistency, accuracy and efficiency.},
	urldate = {2019-10-30},
	journal = {arXiv:1805.04031 [cs]},
	author = {Huai, Zheng and Huang, Guoquan},
	month = may,
	year = {2018},
	note = {arXiv: 1805.04031},
	keywords = {Computer Science - Robotics}
}

@misc{noauthor_ransac_nodate,
	title = {{RANSAC} {Homography} on the {GPU} using {CUDA} {\textbar} {Nghia} {Ho}},
	url = {http://nghiaho.com/?p=490},
	urldate = {2019-10-29}
}

@inproceedings{corke_combining_2009,
	title = {Combining {Cartesian} and polar coordinates in {IBVS}},
	doi = {10.1109/IROS.2009.5354569},
	abstract = {Image-based visual servo (IBVS) is a simple, efficient and robust technique for vision-based control. Although technically a local method in practice it demonstrates almost global convergence. However IBVS performs very poorly for cases that involve large rotations about the optical axis. It is well known that re-parameterizing the problem by using polar, instead of Cartesian coordinates, of feature points overcomes this limitation. First, simulation and experimental results are presented to show the complementarity of these two parameterizations. We then describe a new hybrid visual servo strategy based on combining polar and Cartesian image Jacobians.},
	booktitle = {2009 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Corke, Peter I. and Spindler, Fabien and Chaumette, Francois},
	month = oct,
	year = {2009},
	note = {ISSN: 2153-0858, 2153-0866},
	keywords = {Cameras, Cartesian coordinates, Cartesian image Jacobians, Control systems, Convergence, Equations, Jacobian matrices, Robot kinematics, Robot vision systems, Robust control, Servomechanisms, Visual servoing, convergence, global convergence, image-based visual servo, polar coordinates, polar image Jacobians, robot vision, robust control, robust technique, vision-based control, visual servoing},
	pages = {5962--5967}
}

@article{scaramuzza_visual_2011,
	title = {Visual {Odometry} [{Tutorial}]},
	volume = {18},
	issn = {1070-9932, 1558-223X},
	doi = {10.1109/MRA.2011.943233},
	abstract = {Visual odometry (VO) is the process of estimating the egomotion of an agent (e.g., vehicle, human, and robot) using only the input of a single or If multiple cameras attached to it. Application domains include robotics, wearable computing, augmented reality, and automotive. The term VO was coined in 2004 by Nister in his landmark paper. The term was chosen for its similarity to wheel odometry, which incrementally estimates the motion of a vehicle by integrating the number of turns of its wheels over time. Likewise, VO operates by incrementally estimating the pose of the vehicle through examination of the changes that motion induces on the images of its onboard cameras. For VO to work effectively, there should be sufficient illumination in the environment and a static scene with enough texture to allow apparent motion to be extracted. Furthermore, consecutive frames should be captured by ensuring that they have sufficient scene overlap.},
	number = {4},
	journal = {IEEE Robotics Automation Magazine},
	author = {Scaramuzza, Davide and Fraundorfer, Friedrich},
	month = dec,
	year = {2011},
	keywords = {augmented reality, automotive, cameras, egomotion estimation, illumination, image texture, motion estimation, multiple cameras, onboard cameras, pose estimation, road vehicles, robotics, robots, scene overlap, single camera, vehicle, visual odometry, wearable computing, wheel odometry, wheels},
	pages = {80--92}
}

@misc{noauthor_using_0100,
	title = {Using .gitignore the {Right} {Way}},
	url = {https://labs.consol.de/de/development/git/2017/02/22/gitignore.html},
	abstract = {Have you ever wondered what kind of patterns .gitignore allows? Was it **/*/target, target/* or *target*?? Read on and find out!},
	language = {de},
	urldate = {2019-10-21},
	journal = {Consol Labs},
	year = {0100}
}

@inproceedings{kang_generalization_2019,
	title = {Generalization through {Simulation}: {Integrating} {Simulated} and {Real} {Data} into {Deep} {Reinforcement} {Learning} for {Vision}-{Based} {Autonomous} {Flight}},
	shorttitle = {Generalization through {Simulation}},
	doi = {10.1109/ICRA.2019.8793735},
	abstract = {Deep reinforcement learning provides a promising approach for vision-based control of real-world robots. However, the generalization of such models depends critically on the quantity and variety of data available for training. This data can be difficult to obtain for some types of robotic systems, such as fragile, small-scale quadrotors. Simulated rendering and physics can provide for much larger datasets, but such data is inherently of lower quality: many of the phenomena that make the real-world autonomous flight problem challenging, such as complex physics and air currents, are modeled poorly or not at all, and the systematic differences between simulation and the real world are typically impossible to eliminate. In this work, we investigate how data from both simulation and the real world can be combined in a hybrid deep reinforcement learning algorithm. Our method uses real-world data to learn about the dynamics of the system, and simulated data to learn a generalizable perception system that can enable the robot to avoid collisions using only a monocular camera. We demonstrate our approach on a real-world nano aerial vehicle collision avoidance task, showing that with only an hour of real-world data, the quadrotor can avoid collisions in new environments with various lighting conditions and geometry. Code, instructions for building the aerial vehicles, and videos of the experiments can be found at github.com/gkahn13/GtS.},
	booktitle = {2019 {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Kang, Katie and Belkhale, Suneel and Kahn, Gregory and Abbeel, Pieter and Levine, Sergey},
	month = may,
	year = {2019},
	note = {ISSN: 2577-087X, 1050-4729},
	keywords = {Collision avoidance, Data models, Neural networks, Predictive models, Reinforcement learning, Robots, Task analysis, air currents, aircraft control, autonomous aerial vehicles, collision avoidance, complex physics, data analysis, fragile scale quadrotors, generalizable perception system, helicopters, hybrid deep reinforcement learning algorithm, learning (artificial intelligence), mobile robots, nanoaerial vehicle collision avoidance task, real data, robot vision, simulated data, small-scale quadrotors, vision-based autonomous flight},
	pages = {6008--6014}
}

@article{kuznetsova_open_2018,
	title = {The {Open} {Images} {Dataset} {V4}: {Unified} image classification, object detection, and visual relationship detection at scale},
	shorttitle = {The {Open} {Images} {Dataset} {V4}},
	url = {http://arxiv.org/abs/1811.00982},
	abstract = {We present Open Images V4, a dataset of 9.2M images with unified annotations for image classification, object detection and visual relationship detection. The images have a Creative Commons Attribution license that allows to share and adapt the material, and they have been collected from Flickr without a predefined list of class names or tags, leading to natural class statistics and avoiding an initial design bias. Open Images V4 offers large scale across several dimensions: 30.1M image-level labels for 19.8k concepts, 15.4M bounding boxes for 600 object classes, and 375k visual relationship annotations involving 57 classes. For object detection in particular, we provide 15x more bounding boxes than the next largest datasets (15.4M boxes on 1.9M images). The images often show complex scenes with several objects (8 annotated objects per image on average). We annotated visual relationships between them, which support visual relationship detection, an emerging task that requires structured reasoning. We provide in-depth comprehensive statistics about the dataset, we validate the quality of the annotations, and we study how the performance of many modern models evolves with increasing amounts of training data. We hope that the scale, quality, and variety of Open Images V4 will foster further research and innovation even beyond the areas of image classification, object detection, and visual relationship detection.},
	urldate = {2019-10-10},
	journal = {arXiv:1811.00982 [cs]},
	author = {Kuznetsova, Alina and Rom, Hassan and Alldrin, Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali, Shahab and Popov, Stefan and Malloci, Matteo and Duerig, Tom and Ferrari, Vittorio},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.00982},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{sim_autonomous_2009,
	series = {Canadian {Robotic} {Vision} 2005 and 2006},
	title = {Autonomous vision-based robotic exploration and mapping using hybrid maps and particle filters},
	volume = {27},
	issn = {0262-8856},
	url = {http://www.sciencedirect.com/science/article/pii/S0262885608000838},
	doi = {10.1016/j.imavis.2008.04.003},
	abstract = {This paper addresses the problem of exploring and mapping an unknown environment using a robot equipped with a stereo vision sensor. The main contribution of our work is a fully automatic mapping system that operates without the use of active range sensors (such as laser or sonic transducers), can operate on-line and can consistently produce accurate maps of large-scale environments. Our approach implements a Rao-Blackwellised particle filter (RBPF) to solve the simultaneous localization and mapping problem and uses efficient data structures for real-time data association, mapping, and spatial reasoning. We employ a hybrid map representation that infers 3D point landmarks from image features to achieve precise localization, coupled with occupancy grids for safe navigation. We demonstrate two exploration approaches, one based on a greedy strategy and one based on an iteratively deepening strategy. This paper describes our framework and implementation, and presents our exploration method, and experimental results illustrating the functionality of the system.},
	number = {1},
	urldate = {2019-10-08},
	journal = {Image and Vision Computing},
	author = {Sim, Robert and Little, James J.},
	month = jan,
	year = {2009},
	keywords = {Exploration, Hybrid maps, Mapping, RBPF, Robotics, SIFT, SLAM, Stereo vision},
	pages = {167--177}
}

@article{garrido-jurado_automatic_2014,
	title = {Automatic generation and detection of highly reliable fiducial markers under occlusion},
	volume = {47},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320314000235},
	doi = {10.1016/j.patcog.2014.01.005},
	abstract = {This paper presents a fiducial marker system specially appropriated for camera pose estimation in applications such as augmented reality and robot localization. Three main contributions are presented. First, we propose an algorithm for generating configurable marker dictionaries (in size and number of bits) following a criterion to maximize the inter-marker distance and the number of bit transitions. In the process, we derive the maximum theoretical inter-marker distance that dictionaries of square binary markers can have. Second, a method for automatically detecting the markers and correcting possible errors is proposed. Third, a solution to the occlusion problem in augmented reality applications is shown. To that aim, multiple markers are combined with an occlusion mask calculated by color segmentation. The experiments conducted show that our proposal obtains dictionaries with higher inter-marker distances and lower false negative rates than state-of-the-art systems, and provides an effective solution to the occlusion problem.},
	number = {6},
	urldate = {2019-10-08},
	journal = {Pattern Recognition},
	author = {Garrido-Jurado, S. and Muñoz-Salinas, R. and Madrid-Cuevas, F. J. and Marín-Jiménez, M. J.},
	month = jun,
	year = {2014},
	keywords = {Augmented reality, Computer vision, Fiducial marker},
	pages = {2280--2292}
}

@incollection{papachristos_autonomous_2019,
	address = {Cham},
	series = {Studies in {Computational} {Intelligence}},
	title = {Autonomous {Exploration} and {Inspection} {Path} {Planning} for {Aerial} {Robots} {Using} the {Robot} {Operating} {System}},
	isbn = {978-3-319-91590-6},
	url = {https://doi.org/10.1007/978-3-319-91590-6_3},
	abstract = {This use case chapter presents a set of algorithms for the problems of autonomous exploration, terrain monitoring and optimized inspection path planning using aerial robots. The autonomous exploration algorithms described employ a receding horizon structure to iteratively derive the action that the robot should take to optimally explore its environment when no prior map is available, with the extension to localization uncertainty–aware planning. Terrain monitoring is tackled by a finite–horizon informative planning algorithm that further respects time budget limitations. For the problem of optimized inspection with a model of the environment known a priori, an offline path planning algorithm is proposed. All methods proposed are characterized by computational efficiency and have been tested thoroughly via multiple experiments. The Robot Operating System corresponds to the common middleware for the outlined family of methods. By the end of this chapter, the reader should be able to use the open–source contributions of the algorithms presented, implement them from scratch, or modify them to further fit the needs of a particular autonomous exploration, terrain monitoring, or structural inspection mission using aerial robots. Four different open–source ROS packages (compatible with ROS Indigo, Jade and Kinetic) are released, while the repository https://github.com/unr-arl/informative-planning stands as a single point of reference for all of them.},
	language = {en},
	urldate = {2019-10-03},
	booktitle = {Robot {Operating} {System} ({ROS}): {The} {Complete} {Reference} ({Volume} 3)},
	publisher = {Springer International Publishing},
	author = {Papachristos, Christos and Kamel, Mina and Popović, Marija and Khattak, Shehryar and Bircher, Andreas and Oleynikova, Helen and Dang, Tung and Mascarich, Frank and Alexis, Kostas and Siegwart, Roland},
	editor = {Koubaa, Anis},
	year = {2019},
	doi = {10.1007/978-3-319-91590-6_3},
	pages = {67--111}
}

@article{krishna_visual_2016,
	title = {Visual {Genome}: {Connecting} {Language} and {Vision} {Using} {Crowdsourced} {Dense} {Image} {Annotations}},
	shorttitle = {Visual {Genome}},
	url = {https://arxiv.org/abs/1602.07332v1},
	abstract = {Despite progress in perceptual tasks such as image classification, computers
still perform poorly on cognitive tasks such as image description and question
answering. Cognition is core to tasks that involve not just recognizing, but
reasoning about our visual world. However, models used to tackle the rich
content in images for cognitive tasks are still being trained using the same
datasets designed for perceptual tasks. To achieve success at cognitive tasks,
models need to understand the interactions and relationships between objects in
an image. When asked "What vehicle is the person riding?", computers will need
to identify the objects in an image as well as the relationships riding(man,
carriage) and pulling(horse, carriage) in order to answer correctly that "the
person is riding a horse-drawn carriage".
  In this paper, we present the Visual Genome dataset to enable the modeling of
such relationships. We collect dense annotations of objects, attributes, and
relationships within each image to learn these models. Specifically, our
dataset contains over 100K images where each image has an average of 21
objects, 18 attributes, and 18 pairwise relationships between objects. We
canonicalize the objects, attributes, relationships, and noun phrases in region
descriptions and questions answer pairs to WordNet synsets. Together, these
annotations represent the densest and largest dataset of image descriptions,
objects, attributes, relationships, and question answers.},
	language = {en},
	urldate = {2019-10-03},
	author = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A. and Bernstein, Michael S. and Li, Fei-Fei},
	month = feb,
	year = {2016}
}

@article{joulin_bag_2016,
	title = {Bag of {Tricks} for {Efficient} {Text} {Classification}},
	url = {https://arxiv.org/abs/1607.01759v3},
	abstract = {This paper explores a simple and efficient baseline for text classification.
Our experiments show that our fast text classifier fastText is often on par
with deep learning classifiers in terms of accuracy, and many orders of
magnitude faster for training and evaluation. We can train fastText on more
than one billion words in less than ten minutes using a standard multicore{\textasciitilde}CPU,
and classify half a million sentences among{\textasciitilde}312K classes in less than a minute.},
	language = {en},
	urldate = {2019-10-03},
	author = {Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
	month = jul,
	year = {2016}
}

@inproceedings{wandzel_multi-object_2019,
	title = {Multi-{Object} {Search} using {Object}-{Oriented} {POMDPs}},
	doi = {10.1109/ICRA.2019.8793888},
	abstract = {A core capability of robots is to reason about multiple objects under uncertainty. Partially Observable Markov Decision Processes (POMDPs) provide a means of reasoning under uncertainty for sequential decision making, but are computationally intractable in large domains. In this paper, we propose Object-Oriented POMDPs (OO-POMDPs), which represent the state and observation spaces in terms of classes and objects. The structure afforded by OO-POMDPs support a factorization of the agent's belief into independent object distributions, which enables the size of the belief to scale linearly versus exponentially in the number of objects. We formulate a novel Multi-Object Search (MOS) task as an OO-POMDP for mobile robotics domains in which the agent must find the locations of multiple objects. Our solution exploits the structure of OO-POMDPs by featuring human language to selectively update the belief at task onset. Using this structure, we develop a new algorithm for efficiently solving OO-POMDPs: Object-Oriented Partially Observable Monte-Carlo Planning (OOPOMCP). We show that OO-POMCP with grounded language commands is sufficient for solving challenging MOS tasks both in simulation and on a physical mobile robot.},
	booktitle = {2019 {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Wandzel, A. and Oh, Y. and Fishman, M. and Kumar, N. and L.S, W. Lawson and Tellex, S.},
	month = may,
	year = {2019},
	keywords = {Markov processes, Monte Carlo methods, OO-POMDP, Object oriented modeling, Planning, Robot sensing systems, Search problems, Task analysis, Uncertainty, mobile robot, mobile robots, multiobject search task, object-oriented POMDPs, object-oriented partially observable Monte-Carlo planning, observable Markov decision process, path planning, sequential decision making},
	pages = {7194--7200}
}

@article{yang_visual_2018,
	title = {Visual {Semantic} {Navigation} using {Scene} {Priors}},
	url = {https://openreview.net/forum?id=HJeRkh05Km},
	abstract = {How do humans navigate to target objects in novel scenes? Do we use the semantic/functional priors we have built over years to efficiently search and navigate? For example, to search for mugs, we...},
	urldate = {2019-10-02},
	author = {Yang, Wei and Wang, Xiaolong and Farhadi, Ali and Gupta, Abhinav and Mottaghi, Roozbeh},
	month = sep,
	year = {2018}
}

@article{anderson_evaluation_2018,
	title = {On {Evaluation} of {Embodied} {Navigation} {Agents}},
	url = {http://arxiv.org/abs/1807.06757},
	abstract = {Skillful mobile operation in three-dimensional environments is a primary topic of study in Artificial Intelligence. The past two years have seen a surge of creative work on navigation. This creative output has produced a plethora of sometimes incompatible task definitions and evaluation protocols. To coordinate ongoing and future research in this area, we have convened a working group to study empirical methodology in navigation research. The present document summarizes the consensus recommendations of this working group. We discuss different problem statements and the role of generalization, present evaluation measures, and provide standard scenarios that can be used for benchmarking.},
	urldate = {2019-10-02},
	journal = {arXiv:1807.06757 [cs]},
	author = {Anderson, Peter and Chang, Angel and Chaplot, Devendra Singh and Dosovitskiy, Alexey and Gupta, Saurabh and Koltun, Vladlen and Kosecka, Jana and Malik, Jitendra and Mottaghi, Roozbeh and Savva, Manolis and Zamir, Amir R.},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.06757},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Robotics}
}

@article{koch_automatic_2019,
	title = {Automatic and {Semantically}-{Aware} {3D} {UAV} {Flight} {Planning} for {Image}-{Based} {3D} {Reconstruction}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2072-4292/11/13/1550},
	doi = {10.3390/rs11131550},
	abstract = {Small-scaled unmanned aerial vehicles (UAVs) emerge as ideal image acquisition platforms due to their high maneuverability even in complex and tightly built environments. The acquired images can be utilized to generate high-quality 3D models using current multi-view stereo approaches. However, the quality of the resulting 3D model highly depends on the preceding flight plan which still requires human expert knowledge, especially in complex urban and hazardous environments. In terms of safe flight plans, practical considerations often define prohibited and restricted airspaces to be accessed with the vehicle. We propose a 3D UAV path planning framework designed for detailed and complete small-scaled 3D reconstructions considering the semantic properties of the environment allowing for user-specified restrictions on the airspace. The generated trajectories account for the desired model resolution and the demands on a successful photogrammetric reconstruction. We exploit semantics from an initial flight to extract the target object and to define restricted and prohibited airspaces which have to be avoided during the path planning process to ensure a safe and short UAV path, while still aiming to maximize the object reconstruction quality. The path planning problem is formulated as an orienteering problem and solved via discrete optimization exploiting submodularity and photogrammetrical relevant heuristics. An evaluation of our method on a customized synthetic scene and on outdoor experiments suggests the real-world capability of our methodology by providing feasible, short and safe flight plans for the generation of detailed 3D reconstruction models.},
	language = {en},
	number = {13},
	urldate = {2019-10-02},
	journal = {Remote Sensing},
	author = {Koch, Tobias and Körner, Marco and Fraundorfer, Friedrich},
	month = jan,
	year = {2019},
	keywords = {3D reconstruction, UAV, discrete optimization, path planning, semantics, trajectory optimization, urban mapping},
	pages = {1550}
}

@inproceedings{kouris_towards_2019,
	title = {Towards {Efficient} {On}-{Board} {Deployment} of {DNNs} on {Intelligent} {Autonomous} {Systems}},
	doi = {10.1109/ISVLSI.2019.00107},
	abstract = {With their unprecedented performance in major AI tasks, deep neural networks (DNNs) have emerged as a primary building block in modern autonomous systems. Intelligent systems such as drones, mobile robots and driverless cars largely base their perception, planning and application-specific tasks on DNN models. Nevertheless, due to the nature of these applications, such systems require on-board local processing in order to retain their autonomy and meet latency and throughput constraints. In this respect, the large computational and memory demands of DNN workloads pose a significant barrier on their deployment on the resource-and power-constrained compute platforms that are available on-board. This paper presents an overview of recent methods and hardware architectures that address the system-level challenges of modern DNN-enabled autonomous systems at both the algorithmic and hardware design level. Spanning from latency-driven approximate computing techniques to high-throughput mixed-precision cascaded classifiers, the presented set of works paves the way for the on-board deployment of sophisticated DNN models on robots and autonomous systems.},
	booktitle = {2019 {IEEE} {Computer} {Society} {Annual} {Symposium} on {VLSI} ({ISVLSI})},
	author = {Kouris, A. and Venieris, S. I. and Bouganis, C.},
	month = jul,
	year = {2019},
	keywords = {Autonomous Systems, Autonomous systems, Computational modeling, Computer architecture, Convolutional Neural Networks, Deep Learning, Embedded Processing, FPGAs, Field programmable gate arrays, Hardware, Intelligent Systems, Long Short Term Memory Networks, Navigation, On Board Processing, Robotics, Task analysis},
	pages = {568--573}
}

@misc{noauthor_handling_nodate,
	title = {Handling and {Sharing} {Data} {Between} {Threads}},
	url = {https://www.pythonforthelab.com/blog/handling-and-sharing-data-between-threads},
	abstract = {Learn how to share data between threads},
	language = {en},
	urldate = {2019-09-25},
	journal = {Python For The Lab}
}

@article{mikolov_advances_2017,
	title = {Advances in {Pre}-{Training} {Distributed} {Word} {Representations}},
	url = {http://arxiv.org/abs/1712.09405},
	abstract = {Many Natural Language Processing applications nowadays rely on pre-trained word representations estimated from large text corpora such as news collections, Wikipedia and Web Crawl. In this paper, we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks.},
	urldate = {2019-09-19},
	journal = {arXiv:1712.09405 [cs]},
	author = {Mikolov, Tomas and Grave, Edouard and Bojanowski, Piotr and Puhrsch, Christian and Joulin, Armand},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.09405},
	keywords = {Computer Science - Computation and Language}
}

@article{mikolov_efficient_2013,
	title = {Efficient {Estimation} of {Word} {Representations} in {Vector} {Space}},
	url = {http://arxiv.org/abs/1301.3781},
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	urldate = {2019-09-19},
	journal = {arXiv:1301.3781 [cs]},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	month = jan,
	year = {2013},
	note = {arXiv: 1301.3781},
	keywords = {Computer Science - Computation and Language}
}

@article{mikolov_distributed_2013,
	title = {Distributed {Representations} of {Words} and {Phrases} and their {Compositionality}},
	url = {http://arxiv.org/abs/1310.4546},
	abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
	urldate = {2019-09-19},
	journal = {arXiv:1310.4546 [cs, stat]},
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	month = oct,
	year = {2013},
	note = {arXiv: 1310.4546},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{bojanowski_enriching_2016,
	title = {Enriching {Word} {Vectors} with {Subword} {Information}},
	url = {http://arxiv.org/abs/1607.04606},
	abstract = {Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character \$n\$-grams. A vector representation is associated to each character \$n\$-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.},
	urldate = {2019-09-19},
	journal = {arXiv:1607.04606 [cs]},
	author = {Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.04606},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning}
}

@article{sunderhauf_where_2019,
	title = {Where are the {Keys}? -- {Learning} {Object}-{Centric} {Navigation} {Policies} on {Semantic} {Maps} with {Graph} {Convolutional} {Networks}},
	shorttitle = {Where are the {Keys}?},
	url = {http://arxiv.org/abs/1909.07376},
	abstract = {Emerging object-based SLAM algorithms can build a graph representation of an environment comprising nodes for robot poses and object landmarks. However, while this map will contain static objects such as furniture or appliances, many moveable objects (e.g. the car keys, the glasses, or a magazine), are not suitable as landmarks and will not be part of the map due to their non-static nature. We show that Graph Convolutional Networks can learn navigation policies to find such unmapped objects by learning to exploit the hidden probabilistic model that governs where these objects appear in the environment. The learned policies can generalise to object classes unseen during training by using word vectors that express semantic similarity as representations for object nodes in the graph. Furthermore, we show that the policies generalise to unseen environments with only minimal loss of performance. We demonstrate that pre-training the policy network with a proxy task can significantly speed up learning, improving sample efficiency. Code for this paper is available at https://github.com/nikosuenderhauf/graphConvNetsForNavigation.},
	urldate = {2019-09-19},
	journal = {arXiv:1909.07376 [cs]},
	author = {Sünderhauf, Niko},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.07376},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics}
}

@misc{na_scikit_nodate,
	title = {Scikit {Learn} {Clustering} {Algorithms}},
	url = {https://scikit-learn.org/stable/modules/clustering.html#spectral-clustering},
	author = {NA}
}

@book{luxburg_tutorial_2007,
	title = {A {Tutorial} on {Spectral} {Clustering}},
	abstract = {In recent years, spectral clustering has become one of the most popular modern clustering algorithms. It is simple to implement, can be solved efficiently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm. On the first glance spectral clustering appears slightly mysterious, and it is not obvious to see why it works at all and what it really does. The goal of this tutorial is to give some intuition on to those questions. We describe different graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several different approaches. Advantages and disadvantages of the different spectral clustering algorithms are discussed.},
	author = {Luxburg, Ulrike Von},
	year = {2007}
}

@article{liu_weighted_2014,
	series = {2nd {International} {Conference} on {Information} {Technology} and {Quantitative} {Management}, {ITQM} 2014},
	title = {Weighted {Graph} {Clustering} for {Community} {Detection} of {Large} {Social} {Networks}},
	volume = {31},
	issn = {1877-0509},
	url = {http://www.sciencedirect.com/science/article/pii/S1877050914004256},
	doi = {10.1016/j.procs.2014.05.248},
	abstract = {This study mainly focuses on the methodology of weighted graph clustering with the purpose of community detection for large scale networks such as the users’ relationship on Internet social networks. Most of the networks in the real world are weighted networks, so we proposed a graph clustering algorithm based on the concept of density and attractiveness for weighted networks, including node weight and edge weight. With deep analysis on the Sina micro-blog user network and Renren social network, we defined the user's core degree as node weight and users’ attractiveness as edge weight, experiments of community detection were done with the algorithm, the results verify the effectiveness and reliability of the algorithm. The algorithm is designed to make some breakthrough on the time complexity of Internet community detection algorithm, because the research is for large social networks. And the another advantage is that the method does not require to specify the number of clusters.},
	urldate = {2019-09-19},
	journal = {Procedia Computer Science},
	author = {Liu, Ruifang and Feng, Shan and Shi, Ruisheng and Guo, Wenbin},
	month = jan,
	year = {2014},
	keywords = {Community Detection, Micro-blog, User Attractiveness, Weighted Graph Clustering},
	pages = {85--94}
}

@article{strubell_energy_2019,
	title = {Energy and {Policy} {Considerations} for {Deep} {Learning} in {NLP}},
	url = {http://arxiv.org/abs/1906.02243},
	abstract = {Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.},
	urldate = {2019-09-17},
	journal = {arXiv:1906.02243 [cs]},
	author = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.02243},
	keywords = {Computer Science - Computation and Language}
}

@misc{noauthor_lens_nodate,
	title = {lens - {How} do {I} calculate the ground footprint of an aerial camera?},
	url = {https://photo.stackexchange.com/questions/56596/how-do-i-calculate-the-ground-footprint-of-an-aerial-camera},
	urldate = {2019-09-16},
	journal = {Photography Stack Exchange}
}

@article{richardwebster_psyphy:_2019,
	title = {{PsyPhy}: {A} {Psychophysics} {Driven} {Evaluation} {Framework} for {Visual} {Recognition}},
	volume = {41},
	issn = {0162-8828},
	shorttitle = {{PsyPhy}},
	doi = {10.1109/TPAMI.2018.2849989},
	abstract = {By providing substantial amounts of data and standardized evaluation protocols, datasets in computer vision have helped fuel advances across all areas of visual recognition. But even in light of breakthrough results on recent benchmarks, it is still fair to ask if our recognition algorithms are doing as well as we think they are. The vision sciences at large make use of a very different evaluation regime known as Visual Psychophysics to study visual perception. Psychophysics is the quantitative examination of the relationships between controlled stimuli and the behavioral responses they elicit in experimental test subjects. Instead of using summary statistics to gauge performance, psychophysics directs us to construct item-response curves made up of individual stimulus responses to find perceptual thresholds, thus allowing one to identify the exact point at which a subject can no longer reliably recognize the stimulus class. In this article, we introduce a comprehensive evaluation framework for visual recognition models that is underpinned by this methodology. Over millions of procedurally rendered 3D scenes and 2D images, we compare the performance of well-known convolutional neural networks. Our results bring into question recent claims of human-like performance, and provide a path forward for correcting newly surfaced algorithmic deficiencies.},
	number = {9},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {RichardWebster, B. and Anthony, S. E. and Scheirer, W. J.},
	month = sep,
	year = {2019},
	keywords = {Computational modeling, Computer vision, Machine learning, Object recognition, Observers, Psychology, Task analysis, Visual Psychophysics, Visualization, behavioral responses, comprehensive evaluation framework, computer vision, deep learning, evaluation, experimental test subjects, feature extraction, individual stimulus responses, item-response curves, neurophysiology, neuroscience, object recognition, protocols, psychology, rendering (computer graphics), standardized evaluation protocols, vision sciences, visual perception, visual psychophysics, visual recognition models},
	pages = {2280--2286}
}

@misc{noauthor_latex_nodate,
	title = {{LaTeX} {Tutorial} - {YouTube}},
	url = {https://www.youtube.com/watch?v=VhmkLrOjLsw},
	urldate = {2019-09-06}
}

@misc{noauthor_c++_2014,
	title = {C++ {Programming}},
	url = {https://www.youtube.com/watch?v=Rub-JsjMhWY&feature=youtu.be},
	abstract = {Get the Cheat Sheet Here : http://goo.gl/OpJ209
Subscribe to Me: http://bit.ly/2FWQZTx
Best Book on C++ : http://goo.gl/GLLL0g
How to Install C++ on Windows : https://youtu.be/SykxWpFwMGs?t=1m47s
C++ for Beginners : https://youtu.be/DamuE8TM3xo

GET FREE STUFF WHILE SUPPORTING MY TUTORIALS
1. Get a Free Stock : share.robinhood.com/derekb1560
2. Get 2 Free Audiobooks : https://amzn.to/2Y5FV2p

Like the channel? Consider becoming a Patreon! Check it out here:
►► https://www.patreon.com/derekbanas

Data Types : 2:40
Arithmetic : 6:02
If Statement : 9:19
Switch Statement : 12:01
Ternary Operator : 13:08
Arrays : 13:49
For Loop : 16:30
While Loop : 17:56
Do While Loop : 19:42
User Input : 20:27
Convert String : 20:56
Strings : 21:39
Vectors : 27:47
Functions : 30:16
Recursive Function : 32:37
File I/O : 34:57
Exception Handling : 38:38
Pointers : 40:02
Reference Operator : 40:25
Classes / Objects : 47:12
Private : 47:55
Static Variables : 48:21
Public / Encapsulation: 49:02
Constructors : 50:42
Static Functions : 51:46
this : 53:16
Inheritance : 57:29
Call Superclass Constructor : 59:14
Execute Static Method : 1:00:34 
Virtual Methods : 1:02:45 
Polymorphism : 1:07:39
Abstract Data Type : 1:08:29

*Watch More Learn in One Videos*
►► Java - https://youtu.be/n-xAqcBCws4
►► C++ - https://youtu.be/Rub-JsjMhWY
►► Python - https://youtu.be/N4mEzFDjqtA
►► MySQL - https://youtu.be/yPu6qV5byu4
►► PHP - https://youtu.be/7TF00hJI78Y
►► Kotlin - https://youtu.be/H\_oGi8uuDpA
►► C\# - https://youtu.be/lisiwUZJXqQ
►► JavaScript - https://youtu.be/fju9ii8YsGs},
	urldate = {2019-09-06},
	month = nov,
	year = {2014}
}

@phdthesis{jing_coverage_2017,
	type = {{PhD} {Thesis}},
	title = {Coverage planning for robotic vision applications in complex {3D} environment},
	school = {Carnegie Mellon University},
	author = {Jing, Wei},
	year = {2017}
}

@article{bewley_simple_2016,
	title = {Simple {Online} and {Realtime} {Tracking}},
	url = {http://arxiv.org/abs/1602.00763},
	doi = {10.1109/ICIP.2016.7533003},
	abstract = {This paper explores a pragmatic approach to multiple object tracking where the main focus is to associate objects efficiently for online and realtime applications. To this end, detection quality is identified as a key factor influencing tracking performance, where changing the detector can improve tracking by up to 18.9\%. Despite only using a rudimentary combination of familiar techniques such as the Kalman Filter and Hungarian algorithm for the tracking components, this approach achieves an accuracy comparable to state-of-the-art online trackers. Furthermore, due to the simplicity of our tracking method, the tracker updates at a rate of 260 Hz which is over 20x faster than other state-of-the-art trackers.},
	urldate = {2019-08-19},
	journal = {2016 IEEE International Conference on Image Processing (ICIP)},
	author = {Bewley, Alex and Ge, Zongyuan and Ott, Lionel and Ramos, Fabio and Upcroft, Ben},
	month = sep,
	year = {2016},
	note = {arXiv: 1602.00763},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {3464--3468}
}

@misc{noauthor_fiducials_nodate,
	title = {fiducials - {ROS} {Wiki}},
	url = {http://wiki.ros.org/fiducials},
	urldate = {2019-08-19}
}

@misc{noauthor_aruco_nodate,
	title = {{ArUco} - {Browse} {Files} at {SourceForge}.net},
	url = {https://sourceforge.net/projects/aruco/files/},
	urldate = {2019-08-19}
}

@misc{rafael_munoz_salinas_4._2018,
	title = {4. {Aruco} {Simple} {Example} {Code} on {Video} and {Detection} modes},
	url = {https://www.youtube.com/watch?v=k5L4sujOCmk&list=PL7EOs-8ZXfMb2qRog9wOa3Ar-EyvRYdrp&index=4},
	abstract = {This video for developers explains the detection modes of Aruco. It explains how to speed up computation and to process video sequences.},
	urldate = {2019-08-19},
	author = {{Rafael Muñoz Salinas}},
	month = jan,
	year = {2018}
}

@article{romero-ramirez_speeded_2018,
	title = {Speeded up detection of squared fiducial markers},
	volume = {76},
	issn = {0262-8856},
	url = {http://www.sciencedirect.com/science/article/pii/S0262885618300799},
	doi = {10.1016/j.imavis.2018.05.004},
	abstract = {Squared planar markers have become a popular method for pose estimation in applications such as autonomous robots, unmanned vehicles and virtual trainers. The markers allow estimating the position of a monocular camera with minimal cost, high robustness, and speed. One only needs to create markers with a regular printer, place them in the desired environment so as to cover the working area, and then registering their location from a set of images. Nevertheless, marker detection is a time-consuming process, especially as the image dimensions grows. Modern cameras are able to acquire high resolutions images, but fiducial marker systems are not adapted in terms of computing speed. This paper proposes a multi-scale strategy for speeding up marker detection in video sequences by wisely selecting the most appropriate scale for detection, identification and corner estimation. The experiments conducted show that the proposed approach outperforms the state-of-the-art methods without sacrificing accuracy or robustness. Our method is up to 40 times faster than the state-of-the-art method, achieving over 1000 fps in 4 K images without any parallelization.},
	urldate = {2019-08-18},
	journal = {Image and Vision Computing},
	author = {Romero-Ramirez, Francisco J. and Muñoz-Salinas, Rafael and Medina-Carnicer, Rafael},
	month = aug,
	year = {2018},
	keywords = {Fiducial markers, Marker mapping, SLAM},
	pages = {38--47}
}

@article{garrido-jurado_generation_2016,
	title = {Generation of fiducial marker dictionaries using {Mixed} {Integer} {Linear} {Programming}},
	volume = {51},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320315003544},
	doi = {10.1016/j.patcog.2015.09.023},
	abstract = {Square-based fiducial markers are one of the most popular approaches for camera pose estimation due to its fast detection and robustness. In order to maximize their error correction capabilities, it is required to use an inner binary codification with a large inter-marker distance. This paper proposes two Mixed Integer Linear Programming (MILP) approaches to generate configurable square-based fiducial marker dictionaries maximizing their inter-marker distance. The first approach guarantees the optimal solution, however, it can only be applied to relatively small dictionaries and number of bits since the computing times are too long for many situations. The second approach is an alternative formulation to obtain suboptimal dictionaries within restricted time, achieving results that still surpass significantly the current state of the art methods.},
	urldate = {2019-08-18},
	journal = {Pattern Recognition},
	author = {Garrido-Jurado, S. and Muñoz-Salinas, R. and Madrid-Cuevas, F. J. and Medina-Carnicer, R.},
	month = mar,
	year = {2016},
	keywords = {Augmented reality, Computer vision, Fiducial markers, MILP, Mixed Integer Linear Programming},
	pages = {481--491}
}

@misc{noauthor_aruco_nodate-1,
	title = {{ArUco} {Library} {Documentation}},
	url = {https://docs.google.com/document/d/1QU9KoBtjSM2kF6ITOjQ76xqL7H0TEtXriJX5kwi9Kgc/edit?usp=embed_facebook},
	abstract = {ArUco: An efficient library for detection of planar markers and camera pose estimation News: Check out our latest project UcoSLAM  Markers + Keypoints!               Author: Rafael Muñoz Salinas email:rmsalinas@uco.es License and how to cite	2 Getting Support	2 Introduction	3 Markers	4 Enclosed...},
	language = {de},
	urldate = {2019-08-18},
	journal = {Google Docs}
}

@article{romero-ramirez_speeded_2018-1,
	title = {Speeded up detection of squared fiducial markers},
	volume = {76},
	issn = {0262-8856},
	url = {http://www.sciencedirect.com/science/article/pii/S0262885618300799},
	doi = {10.1016/j.imavis.2018.05.004},
	abstract = {Squared planar markers have become a popular method for pose estimation in applications such as autonomous robots, unmanned vehicles and virtual trainers. The markers allow estimating the position of a monocular camera with minimal cost, high robustness, and speed. One only needs to create markers with a regular printer, place them in the desired environment so as to cover the working area, and then registering their location from a set of images. Nevertheless, marker detection is a time-consuming process, especially as the image dimensions grows. Modern cameras are able to acquire high resolutions images, but fiducial marker systems are not adapted in terms of computing speed. This paper proposes a multi-scale strategy for speeding up marker detection in video sequences by wisely selecting the most appropriate scale for detection, identification and corner estimation. The experiments conducted show that the proposed approach outperforms the state-of-the-art methods without sacrificing accuracy or robustness. Our method is up to 40 times faster than the state-of-the-art method, achieving over 1000 fps in 4 K images without any parallelization.},
	urldate = {2019-08-18},
	journal = {Image and Vision Computing},
	author = {Romero-Ramirez, Francisco J. and Muñoz-Salinas, Rafael and Medina-Carnicer, Rafael},
	month = aug,
	year = {2018},
	keywords = {Fiducial markers, Marker mapping, SLAM},
	pages = {38--47}
}

@misc{noauthor_rectlabel_nodate,
	title = {{RectLabel} - {Labeling} images for bounding box object detection and segmentation},
	url = {https://rectlabel.com},
	abstract = {An image annotation tool to label images for bounding box object detection and segmentation.},
	urldate = {2019-08-15},
	journal = {RectLabel}
}

@misc{noauthor_models_2019,
	title = {Models and examples built with {TensorFlow}. {Contribute} to tensorflow/models development by creating an account on {GitHub}},
	url = {https://github.com/tensorflow/models},
	urldate = {2019-08-13},
	publisher = {tensorflow},
	month = aug,
	year = {2019},
	note = {original-date: 2016-02-05T01:15:20Z}
}

@misc{darrenl_:metal:_2019,
	title = {:metal: {LabelImg} is a graphical image annotation tool and label object bounding boxes in images: tzutalin/{labelImg}},
	copyright = {MIT},
	url = {https://github.com/tzutalin/labelImg},
	urldate = {2019-08-13},
	author = {darrenl},
	month = aug,
	year = {2019},
	note = {original-date: 2015-09-17T01:33:59Z}
}

@misc{noauthor_testing_nodate,
	title = {Testing self driving neural network model - {Python} plays {GTA} p.12 - {YouTube}},
	url = {https://www.youtube.com/watch?v=H5D-6IsFn40},
	urldate = {2019-08-13}
}

@incollection{saaty_analytic_2013,
	address = {Boston, MA},
	series = {International {Series} in {Operations} {Research} \& {Management} {Science}},
	title = {The {Analytic} {Network} {Process}},
	isbn = {978-1-4614-7279-7},
	url = {https://doi.org/10.1007/978-1-4614-7279-7_1},
	abstract = {Analysis to break down a problem into its constituent components to study their behavior has been the major tool of scientific inquiry to test hypotheses and solve problems. It has proven to be extremely successful in dealing with the world of matter and energy. It has enabled man to land on the moon, to harness the energy of the atom, to master global communication, to invent the computer and to produce tens of thousands of useful and not so useful things. But it has not been so effective in the world of man.},
	language = {en},
	urldate = {2019-08-12},
	booktitle = {Decision {Making} with the {Analytic} {Network} {Process}: {Economic}, {Political}, {Social} and {Technological} {Applications} with {Benefits}, {Opportunities}, {Costs} and {Risks}},
	publisher = {Springer US},
	author = {Saaty, Thomas L. and Vargas, Luis G.},
	editor = {Saaty, Thomas L. and Vargas, Luis G.},
	year = {2013},
	doi = {10.1007/978-1-4614-7279-7_1},
	pages = {1--40}
}

@misc{online_c++_nodate,
	title = {C++ {Recipes}: {A} {Problem}-{Solution} {Approach}},
	shorttitle = {C++ {Recipes}},
	url = {https://learning.oreilly.com/library/view/c-recipes-a/9781484201572/},
	abstract = {C++ Recipes: A Problem-Solution Approach is Apress' solution for those C++ programmers looking for a handy code cookbook reference guide. It covers the lates...},
	language = {en},
	urldate = {2019-08-09},
	author = {Online, Safari Books}
}

@misc{noauthor_30_2012,
	title = {30 {Handy} {Bash} {Shell} {Aliases} {For} {Linux} / {Unix} / {Mac} {OS} {X}},
	url = {https://www.cyberciti.biz/tips/bash-aliases-mac-centos-linux-unix.html},
	abstract = {Thirty bash shell aliases tutorials and examples to improve your productivity under a RHEL, CentOS, Debian, MacOS X, *BSD, Ubuntu, and Unix like operating systems.},
	language = {en-US},
	urldate = {2019-08-08},
	journal = {nixCraft},
	month = jun,
	year = {2012}
}

@misc{noauthor_icg_nodate,
	title = {{ICG} - {DroneDataset}},
	url = {https://www.tugraz.at/index.php?id=22387},
	urldate = {2019-08-07}
}

@misc{noauthor_kitti_nodate,
	title = {The {KITTI} {Vision} {Benchmark} {Suite}},
	url = {http://www.cvlibs.net/datasets/kitti/eval_odometry.php},
	urldate = {2019-08-07}
}

@article{recht_cifar-10_2018,
	title = {Do {CIFAR}-10 {Classifiers} {Generalize} to {CIFAR}-10?},
	url = {http://arxiv.org/abs/1806.00451},
	abstract = {Machine learning is currently dominated by largely experimental work focused on improvements in a few key tasks. However, the impressive accuracy numbers of the best performing models are questionable because the same test sets have been used to select these models for multiple years now. To understand the danger of overfitting, we measure the accuracy of CIFAR-10 classifiers by creating a new test set of truly unseen images. Although we ensure that the new test set is as close to the original data distribution as possible, we find a large drop in accuracy (4\% to 10\%) for a broad range of deep learning models. Yet more recent models with higher original accuracy show a smaller drop and better overall performance, indicating that this drop is likely not due to overfitting based on adaptivity. Instead, we view our results as evidence that current accuracy numbers are brittle and susceptible to even minute natural variations in the data distribution.},
	urldate = {2019-07-31},
	journal = {arXiv:1806.00451 [cs, stat]},
	author = {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.00451},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@misc{noauthor_data_nodate,
	title = {Data {Augmentation} {For} {Bounding} {Boxes}: {Rethinking} image transforms for object detection},
	shorttitle = {Data {Augmentation} {For} {Bounding} {Boxes}},
	url = {https://www.kdnuggets.com/2018/09/data-augmentation-bounding-boxes-image-transforms.html},
	language = {en-US},
	urldate = {2019-07-31}
}

@article{zoph_learning_2019,
	title = {Learning {Data} {Augmentation} {Strategies} for {Object} {Detection}},
	url = {http://arxiv.org/abs/1906.11172},
	abstract = {Data augmentation is a critical component of training deep learning models. Although data augmentation has been shown to significantly improve image classification, its potential has not been thoroughly investigated for object detection. Given the additional cost for annotating images for object detection, data augmentation may be of even greater importance for this computer vision task. In this work, we study the impact of data augmentation on object detection. We first demonstrate that data augmentation operations borrowed from image classification may be helpful for training detection models, but the improvement is limited. Thus, we investigate how learned, specialized data augmentation policies improve generalization performance for detection models. Importantly, these augmentation policies only affect training and leave a trained model unchanged during evaluation. Experiments on the COCO dataset indicate that an optimized data augmentation policy improves detection accuracy by more than +2.3 mAP, and allow a single inference model to achieve a state-of-the-art accuracy of 50.7 mAP. Importantly, the best policy found on COCO may be transferred unchanged to other detection datasets and models to improve predictive accuracy. For example, the best augmentation policy identified with COCO improves a strong baseline on PASCAL-VOC by +2.7 mAP. Our results also reveal that a learned augmentation policy is superior to state-of-the-art architecture regularization methods for object detection, even when considering strong baselines. Code for training with the learned policy is available online at https://github.com/tensorflow/tpu/tree/master/models/official/detection},
	urldate = {2019-07-31},
	journal = {arXiv:1906.11172 [cs]},
	author = {Zoph, Barret and Cubuk, Ekin D. and Ghiasi, Golnaz and Lin, Tsung-Yi and Shlens, Jonathon and Le, Quoc V.},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.11172},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning}
}

@misc{noauthor_nanonets_nodate,
	title = {{NanoNets}, {Machine} {Learning} {API}},
	url = {https://nanonets.com/?utm_source=Medium&utm_campaign=data%20augmentation%2F&source=post_page---------------------------},
	urldate = {2019-07-30}
}

@misc{raj_data_2018,
	title = {Data {Augmentation} {\textbar} {How} to use {Deep} {Learning} when you have {Limited} {Data} — {Part} 2},
	url = {https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced},
	abstract = {This article is a comprehensive review of Data Augmentation techniques for Deep Learning, specific to images. This is Part 2 of How to use…},
	language = {en},
	urldate = {2019-07-30},
	journal = {Medium},
	author = {Raj, Bharath},
	month = jun,
	year = {2018}
}

@misc{vittorio_download_2019,
	title = {Download and visualize single or multiple classes from the huge {Open} {Images} v4 dataset: {EscVM}/{OIDv4}\_ToolKit},
	copyright = {GPL-3.0},
	shorttitle = {Download and visualize single or multiple classes from the huge {Open} {Images} v4 dataset},
	url = {https://github.com/EscVM/OIDv4_ToolKit},
	urldate = {2019-07-30},
	author = {Vittorio},
	month = jul,
	year = {2019},
	note = {original-date: 2018-07-26T13:53:02Z}
}

@misc{noauthor_smote:_nodate,
	title = {{SMOTE}: {Synthetic} {Minority} {Over}-sampling {Technique}},
	url = {https://www.cs.cmu.edu/afs/cs/project/jair/pub/volume16/chawla02a-html/chawla2002.html},
	urldate = {2019-07-30}
}

@misc{noauthor_install_nodate,
	title = {Install {spaCy} · {spaCy} {Usage} {Documentation}},
	url = {https://spacy.io/usage},
	abstract = {spaCy is a free open-source library for Natural Language Processing in Python. It features NER, POS tagging, dependency parsing, word vectors and more.},
	language = {en},
	urldate = {2019-07-23},
	journal = {Install spaCy}
}

@misc{noauthor_open_nodate,
	title = {Open {Images} {Dataset} {Stats} {V5}},
	url = {https://storage.googleapis.com/openimages/web/factsfigures.html},
	urldate = {2019-07-17}
}

@misc{noauthor_understand_nodate,
	title = {Understand {How} {Much} {Memory} {Your} {Python} {Objects} {Use}},
	url = {https://code.tutsplus.com/tutorials/understand-how-much-memory-your-python-objects-use--cms-25609},
	urldate = {2019-07-16}
}

@misc{douillard_object_2018,
	title = {Object {Detection} with {Deep} {Learning} on {Aerial} {Imagery}},
	url = {https://medium.com/data-from-the-trenches/object-detection-with-deep-learning-on-aerial-imagery-2465078db8a9},
	abstract = {Imagine you’re in a landlocked country, and an infection has spread. The government has fallen, and rebels are roaming the country. If…},
	language = {en},
	urldate = {2019-07-16},
	journal = {Medium},
	author = {Douillard, Arthur},
	month = aug,
	year = {2018}
}

@misc{noauthor_python_nodate,
	title = {python - {How} to prevent tensorflow from allocating the totality of a {GPU} memory?},
	url = {https://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory},
	urldate = {2019-07-16},
	journal = {Stack Overflow}
}

@article{mescheder_occupancy_2018,
	title = {Occupancy {Networks}: {Learning} {3D} {Reconstruction} in {Function} {Space}},
	shorttitle = {Occupancy {Networks}},
	url = {http://arxiv.org/abs/1812.03828},
	abstract = {With the advent of deep neural networks, learning-based approaches for 3D reconstruction have gained popularity. However, unlike for images, in 3D there is no canonical representation which is both computationally and memory efficient yet allows for representing high-resolution geometry of arbitrary topology. Many of the state-of-the-art learning-based 3D reconstruction approaches can hence only represent very coarse 3D geometry or are limited to a restricted domain. In this paper, we propose Occupancy Networks, a new representation for learning-based 3D reconstruction methods. Occupancy networks implicitly represent the 3D surface as the continuous decision boundary of a deep neural network classifier. In contrast to existing approaches, our representation encodes a description of the 3D output at infinite resolution without excessive memory footprint. We validate that our representation can efficiently encode 3D structure and can be inferred from various kinds of input. Our experiments demonstrate competitive results, both qualitatively and quantitatively, for the challenging tasks of 3D reconstruction from single images, noisy point clouds and coarse discrete voxel grids. We believe that occupancy networks will become a useful tool in a wide variety of learning-based 3D tasks.},
	urldate = {2019-07-16},
	journal = {arXiv:1812.03828 [cs]},
	author = {Mescheder, Lars and Oechsle, Michael and Niemeyer, Michael and Nowozin, Sebastian and Geiger, Andreas},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.03828},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@misc{hui_object_2019,
	title = {Object detection: speed and accuracy comparison ({Faster} {R}-{CNN}, {R}-{FCN}, {SSD}, {FPN}, {RetinaNet} and…},
	shorttitle = {Object detection},
	url = {https://medium.com/@jonathan_hui/object-detection-speed-and-accuracy-comparison-faster-r-cnn-r-fcn-ssd-and-yolo-5425656ae359},
	abstract = {It is very hard to have a fair comparison among different object detectors. There is no straight answer on which model is the best. For…},
	language = {en},
	urldate = {2019-07-16},
	journal = {Medium},
	author = {Hui, Jonathan},
	month = mar,
	year = {2019}
}

@misc{noauthor_applications_nodate,
	title = {Applications - {Keras} {Documentation}},
	url = {https://keras.io/applications/},
	urldate = {2019-07-16}
}

@misc{noauthor_using_2018,
	title = {Using a different version of {OpenCV} in {Ros} (kinetic)},
	url = {https://www.robotexchange.io/t/using-a-different-version-of-opencv-in-ros-kinetic/482},
	abstract = {Hello,  At the moment I am trying to work with yolov3 in OpenCV in Ros Kinetic. Only yolov3 is supported from OpenCV 3.4.2 and up. Kinetic is natively on 3.3.1-dev.  Is there a way to either upgrade to a newer version of OpenCV in ROS? or is there an other way to get this to work?  A way to work with yolov3 configs and weights in OpenCV 3.3.1 is fine too!  If there is something unclear, please let me know  kind regards,  Mitchel Mulder},
	language = {en-US},
	urldate = {2019-07-15},
	journal = {TechCollectief},
	month = dec,
	year = {2018}
}

@misc{kammerlo_contribute_2019,
	title = {Contribute to {Kammerlo}/keras-yolo3-serving development by creating an account on {GitHub}},
	copyright = {MIT},
	url = {https://github.com/Kammerlo/keras-yolo3-serving},
	urldate = {2019-07-11},
	author = {Kammerlo},
	month = jun,
	year = {2019},
	note = {original-date: 2019-02-24T15:44:53Z}
}

@article{redmon_yolov3:_2018,
	title = {{YOLOv3}: {An} {Incremental} {Improvement}},
	shorttitle = {{YOLOv3}},
	url = {http://arxiv.org/abs/1804.02767},
	abstract = {We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at https://pjreddie.com/yolo/},
	urldate = {2019-07-09},
	journal = {arXiv:1804.02767 [cs]},
	author = {Redmon, Joseph and Farhadi, Ali},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.02767},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{yang_comparative_2016,
	title = {A {Comparative} {Analysis} of {Community} {Detection} {Algorithms} on {Artificial} {Networks}},
	volume = {6},
	copyright = {2016 Nature Publishing Group},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/srep30750},
	doi = {10.1038/srep30750},
	abstract = {Many community detection algorithms have been developed to uncover the mesoscopic properties of complex networks. However how good an algorithm is, in terms of accuracy and computing time, remains still open. Testing algorithms on real-world network has certain restrictions which made their insights potentially biased: the networks are usually small, and the underlying communities are not defined objectively. In this study, we employ the Lancichinetti-Fortunato-Radicchi benchmark graph to test eight state-of-the-art algorithms. We quantify the accuracy using complementary measures and algorithms’ computing time. Based on simple network properties and the aforementioned results, we provide guidelines that help to choose the most adequate community detection algorithm for a given network. Moreover, these rules allow uncovering limitations in the use of specific algorithms given macroscopic network properties. Our contribution is threefold: firstly, we provide actual techniques to determine which is the most suited algorithm in most circumstances based on observable properties of the network under consideration. Secondly, we use the mixing parameter as an easily measurable indicator of finding the ranges of reliability of the different algorithms. Finally, we study the dependency with network size focusing on both the algorithm’s predicting power and the effective computing time.},
	language = {en},
	urldate = {2019-07-08},
	journal = {Scientific Reports},
	author = {Yang, Zhao and Algesheimer, René and Tessone, Claudio J.},
	month = aug,
	year = {2016},
	pages = {30750}
}

@article{pares_fluid_2017,
	title = {Fluid {Communities}: {A} {Competitive}, {Scalable} and {Diverse} {Community} {Detection} {Algorithm}},
	shorttitle = {Fluid {Communities}},
	url = {http://arxiv.org/abs/1703.09307},
	abstract = {We introduce a community detection algorithm (Fluid Communities) based on the idea of fluids interacting in an environment, expanding and contracting as a result of that interaction. Fluid Communities is based on the propagation methodology, which represents the state-of-the-art in terms of computational cost and scalability. While being highly efficient, Fluid Communities is able to find communities in synthetic graphs with an accuracy close to the current best alternatives. Additionally, Fluid Communities is the first propagation-based algorithm capable of identifying a variable number of communities in network. To illustrate the relevance of the algorithm, we evaluate the diversity of the communities found by Fluid Communities, and find them to be significantly different from the ones found by alternative methods.},
	urldate = {2019-07-08},
	journal = {arXiv:1703.09307 [physics]},
	author = {Parés, Ferran and Garcia-Gasulla, Dario and Vilalta, Armand and Moreno, Jonatan and Ayguadé, Eduard and Labarta, Jesús and Cortés, Ulises and Suzumura, Toyotaro},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.09307},
	keywords = {Computer Science - Data Structures and Algorithms, Computer Science - Social and Information Networks, Physics - Physics and Society}
}

@article{raghavan_near_2007,
	title = {Near linear time algorithm to detect community structures in large-scale networks},
	volume = {76},
	issn = {1539-3755, 1550-2376},
	url = {http://arxiv.org/abs/0709.2938},
	doi = {10.1103/PhysRevE.76.036106},
	abstract = {Community detection and analysis is an important methodology for understanding the organization of various real-world networks and has applications in problems as diverse as consensus formation in social communities or the identification of functional modules in biochemical networks. Currently used algorithms that identify the community structures in large-scale real-world networks require a priori information such as the number and sizes of communities or are computationally expensive. In this paper we investigate a simple label propagation algorithm that uses the network structure alone as its guide and requires neither optimization of a pre-defined objective function nor prior information about the communities. In our algorithm every node is initialized with a unique label and at every step each node adopts the label that most of its neighbors currently have. In this iterative process densely connected groups of nodes form a consensus on a unique label to form communities. We validate the algorithm by applying it to networks whose community structures are known. We also demonstrate that the algorithm takes an almost linear time and hence it is computationally less expensive than what was possible so far.},
	number = {3},
	urldate = {2019-07-08},
	journal = {Physical Review E},
	author = {Raghavan, Usha Nandini and Albert, Reka and Kumara, Soundar},
	month = sep,
	year = {2007},
	note = {arXiv: 0709.2938},
	keywords = {Physics - Physics and Society},
	pages = {036106}
}

@misc{ml_introduction_2018,
	title = {Introduction to {Label} {Propagation} with {NetworkX} — {Part} 1},
	url = {https://medium.com/@graphml/introduction-to-label-propagation-with-networkx-part-1-abcbe954a2e8},
	abstract = {Networks tell us a lot. One interesting phenomenon that networks illustrate is that similar objects are likely to form a connection to each…},
	language = {en},
	urldate = {2019-07-08},
	journal = {Medium},
	author = {ML, Graph},
	month = sep,
	year = {2018}
}

@article{franek_judgment_2014,
	series = {17th {International} {Conference} {Enterprise} and {Competitive} {Environment} 2014},
	title = {Judgment {Scales} and {Consistency} {Measure} in {AHP}},
	volume = {12},
	issn = {2212-5671},
	url = {http://www.sciencedirect.com/science/article/pii/S2212567114003323},
	doi = {10.1016/S2212-5671(14)00332-3},
	abstract = {The Analytic Hierarchy Process (AHP) is widely used method in multiple-attribute decision making. In the recent literature many authors used different judgment scales which influenced the results and decisions. In this paper the author reviews and discusses effects of utilization of various judgment scales on priority estimation in AHP. There has been studies that have been concerned with the comparison of judgment scales but there were no studies concerned with consistency measures that are needed. The goal of this paper is to compare and discuss the application of various judgment scales on the results in particular practical example that has been used in previous paper by Saaty (2003). Thus the focus of the paper is to analyze the impact of using different judgment scales on the resulting priorities and consistency to default scale as proposed by Saaty. Results suggest that judgment scales have a profound impact on criteria priorities but not on ranking of criteria. However, the consistency varies among applied judgment scales. Authors calculated the values of random index needed for calculation of the consistency index in AHP for all concerned scales. Based on them the consistency index was computed and compared. Both consistent and inconsistent Saaty matrices were used for comparison.},
	urldate = {2019-07-06},
	journal = {Procedia Economics and Finance},
	author = {Franek, Jiří and Kresta, Aleš},
	month = jan,
	year = {2014},
	keywords = {AHP, analytic hierarchy process, consistency, inconsitency, judgement scales},
	pages = {164--173}
}

@book{bernard_python_2016,
	address = {Berkeley, CA},
	title = {Python {Recipes} {Handbook} {A} {Problem}-{Solution} {Approach}},
	isbn = {978-1-4842-0241-8},
	abstract = {Learn the code to write algorithms, numerical computations, data analysis and much more using the Python language: look up and re-use the recipes for your own Python coding. This book is your handy code cookbook reference. Whether you're a maker, game developer, cloud computing programmer and more, this is a must-have reference for your library. Python Recipes Handbook gives you the most common and contemporary code snippets, using pandas (Python Data Analysis Library), NumPy, and other numerical Python packages. What You'll Learn Code with the pandas (Python Data Analysis Library) Work with the various Python algorithms useful for today's big data analytics and cloud applications Use NumPy and other numerical Python packages and code for doing various kinds of analysis Discover Python's new popular modules, packages, extensions and templates library Who This Book Is For This handy reference is for those with some experience with Python. .},
	language = {eng},
	publisher = {Apress},
	author = {Bernard, Joey},
	year = {2016},
	keywords = {Computer Science, general, Computer science, Electronic books, Python, Python (Computer program language)}
}

@book{press_numerical_2002,
	address = {Cambridge, U.K. ;},
	edition = {[Rev.] 2nd ed.},
	title = {Numerical recipes in {C}++: the art of scientific computing},
	isbn = {978-0-521-75033-2},
	shorttitle = {Numerical recipes in {C}++},
	language = {eng},
	publisher = {Cambridge University Press},
	author = {Press, William H.},
	year = {2002},
	keywords = {C++ (Computer program language), Numerical analysis}
}

@book{vetterling_numerical_1992,
	address = {Cambridge ; ;},
	edition = {2nd ed.},
	title = {Numerical recipes example book ({C})},
	isbn = {978-0-521-43715-8},
	language = {eng},
	publisher = {Cambridge University Press},
	author = {Vetterling, William T.},
	year = {1992},
	keywords = {C (Computer program language)}
}

@misc{wieser_tools_2019,
	title = {Tools for converting {ROS} messages to and from numpy arrays: eric-wieser/ros\_numpy},
	copyright = {MIT},
	shorttitle = {Tools for converting {ROS} messages to and from numpy arrays},
	url = {https://github.com/eric-wieser/ros_numpy},
	urldate = {2019-07-03},
	author = {Wieser, Eric},
	month = jun,
	year = {2019},
	note = {original-date: 2016-02-26T23:02:10Z}
}

@inproceedings{morris_non-classical_2004,
	address = {Stroudsburg, PA, USA},
	series = {{CLS} '04},
	title = {Non-classical {Lexical} {Semantic} {Relations}},
	url = {http://dl.acm.org/citation.cfm?id=1596431.1596438},
	abstract = {NLP methods and applications need to take account not only of "classical" lexical relations, as found in WordNet, but the less-structural, more context-dependent "non-classical" relations that readers intuit in text. In a reader-based study of lexical relations in text, most were found to be of the latter type. The relationships themselves are analyzed, and consequences for NLP are discussed.},
	urldate = {2019-07-02},
	booktitle = {Proceedings of the {HLT}-{NAACL} {Workshop} on {Computational} {Lexical} {Semantics}},
	publisher = {Association for Computational Linguistics},
	author = {Morris, Jane and Hirst, Graeme},
	year = {2004},
	note = {event-place: Boston, Massachusetts},
	pages = {46--51}
}

@incollection{fellbaum_nouns_1998,
	title = {Nouns in {WordNet}},
	isbn = {978-0-262-27255-1},
	url = {http://ieeexplore.ieee.org/document/6285393},
	abstract = {This chapter contains sections titled: Lexical Hierarchy, Unique Beginners, Some Psycho Linguistic Assumptions, Some Things Not In Wordnet, Parts And Meronymy, Antonymy, Attributes And Modification, Similar Meanings Of Polysemous Nouns, Conclusion, References},
	urldate = {2019-07-02},
	booktitle = {{WordNet}: {An} {Electronic} {Lexical} {Database}},
	publisher = {MITP},
	author = {Fellbaum, C. and Miller, G.},
	year = {1998}
}

@article{budanitsky_evaluating_2006,
	title = {Evaluating {WordNet}-based {Measures} of {Lexical} {Semantic} {Relatedness}},
	volume = {32},
	issn = {0891-2017},
	url = {http://dx.doi.org/10.1162/coli.2006.32.1.13},
	doi = {10.1162/coli.2006.32.1.13},
	abstract = {The quantification of lexical semantic relatedness has many applications in NLP, and many different measures have been proposed. We evaluate five of these measures, all of which use WordNet as their central resource, by comparing their performance in detecting and correcting real-word spelling errors. An information-content-based measure proposed by Jiang and Conrath is found superior to those proposed by Hirst and St-Onge, Leacock and Chodorow, Lin, and Resnik. In addition, we explain why distributional similarity is not an adequate proxy for lexical semantic relatedness.},
	number = {1},
	urldate = {2019-07-01},
	journal = {Comput. Linguist.},
	author = {Budanitsky, Alexander and Hirst, Graeme},
	month = mar,
	year = {2006},
	pages = {13--47}
}

@inproceedings{pedersen_information_2010,
	address = {Stroudsburg, PA, USA},
	series = {{HLT} '10},
	title = {Information {Content} {Measures} of {Semantic} {Similarity} {Perform} {Better} {Without} {Sense}-tagged {Text}},
	isbn = {978-1-932432-65-7},
	url = {http://dl.acm.org/citation.cfm?id=1857999.1858046},
	abstract = {This paper presents an empirical comparison of similarity measures for pairs of concepts based on Information Content. It shows that using modest amounts of untagged text to derive Information Content results in higher correlation with human similarity judgments than using the largest available corpus of manually annotated sense--tagged text.},
	urldate = {2019-07-01},
	booktitle = {Human {Language} {Technologies}: {The} 2010 {Annual} {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Pedersen, Ted},
	year = {2010},
	note = {event-place: Los Angeles, California},
	pages = {329--332}
}

@incollection{silyn-roberts_writing_2013,
	address = {Oxford},
	title = {Writing for {Science} and {Engineering}},
	isbn = {978-0-08-098285-4},
	url = {http://www.sciencedirect.com/science/article/pii/B9780080982854000212},
	urldate = {2019-06-28},
	booktitle = {Writing for {Science} and {Engineering} ({Second} {Edition})},
	publisher = {Elsevier},
	editor = {Silyn-Roberts, Heather},
	month = jan,
	year = {2013},
	doi = {10.1016/B978-0-08-098285-4.00021-2},
	pages = {i--iii}
}

@article{hegde_link_2010,
	title = {A {Link} between {Visual} {Disambiguation} and {Visual} {Memory}},
	volume = {30},
	issn = {0270-6474},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3040725/},
	doi = {10.1523/JNEUROSCI.4415-09.2010},
	abstract = {Sensory information in the retinal image is typically too ambiguous to support visual object recognition by itself. Theories of visual disambiguation posit that in order to disambiguate, and thus interpret, the incoming images, the visual system must integrate the sensory information with prior knowledge of the visual world. However, the underlying neural mechanisms remain unclear. Using functional magnetic resonance imaging (fMRI) of human subjects, we have found evidence for functional specialization for storing disambiguating information in memory vs. interpreting incoming ambiguous images. Subjects viewed two-tone, ‘Mooney’ images, which are typically ambiguous when seen for the first time, but are quickly disambiguated after viewing the corresponding unambiguous color images. Activity in one set of regions, including a region in the medial parietal cortex previously reported to play a key role in Mooney image disambiguation, closely reflected memory for previously seen color images, but not the subsequent disambiguation of Mooney images. A second set of regions, including the superior temporal sulcus, showed the opposite pattern, in that their responses closely reflected the subjects’ percepts of the disambiguated Mooney images on a stimulus-to-stimulus basis, but not the memory of the corresponding color images. Functional connectivity between the two sets of regions was stronger during those trials in which the disambiguated percept was stronger. This functional interaction between brain regions that specialize in storing disambiguating information in memory vs. interpreting incoming ambiguous images may represent a general mechanism by which prior knowledge disambiguates visual sensory information.},
	number = {45},
	urldate = {2019-06-28},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Hegdé, Jay and Kersten, Daniel},
	month = nov,
	year = {2010},
	pmid = {21068318},
	pmcid = {PMC3040725},
	pages = {15124--15133}
}

@article{lord_semantic_2003,
	title = {Semantic similarity measures as tools for exploring the gene ontology},
	issn = {2335-6928},
	abstract = {Many bioinformatics resources hold data in the form of sequences. Often this sequence data is associated with a large amount of annotation. In many cases this data has been hard to model, and has been represented as scientific natural language, which is not readily computationally amenable. The development of the Gene Ontology provides us with a more accessible representation of some of this data. However it is not clear how this data can best be searched, or queried. Recently we have adapted information content based measures for use with the Gene Ontology (GO). In this paper we present detailed investigation of the properties of these measures, and examine various properties of GO, which may have implications for its future design.},
	language = {eng},
	journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
	author = {Lord, P. W. and Stevens, R. D. and Brass, A. and Goble, C. A.},
	year = {2003},
	pmid = {12603061},
	keywords = {Classification, Computational Biology, Databases, Protein, Genomics, Humans, Proteomics, Sequence Alignment},
	pages = {601--612}
}

@article{perez-arnal_visual_2018,
	title = {A {Visual} {Distance} for {WordNet}},
	url = {https://arxiv.org/abs/1804.09558v2},
	abstract = {Measuring the distance between concepts is an important field of study of
Natural Language Processing, as it can be used to improve tasks related to the
interpretation of those same concepts. WordNet, which includes a wide variety
of concepts associated with words (i.e., synsets), is often used as a source
for computing those distances. In this paper, we explore a distance for WordNet
synsets based on visual features, instead of lexical ones. For this purpose, we
extract the graphic features generated within a deep convolutional neural
networks trained with ImageNet and use those features to generate a
representative of each synset. Based on those representatives, we define a
distance measure of synsets, which complements the traditional lexical
distances. Finally, we propose some experiments to evaluate its performance and
compare it with the current state-of-the-art.},
	language = {en},
	urldate = {2019-06-28},
	author = {Pérez-Arnal, Raquel and Vilalta, Armand and Garcia-Gasulla, Dario and Cortés, Ulises and Ayguadé, Eduard and Labarta, Jesus},
	month = apr,
	year = {2018}
}

@book{seco_intrinsic_2004,
	title = {An {Intrinsic} {Information} {Content} {Metric} for {Semantic} {Similarity} in {WordNet}},
	abstract = {Information Content (IC) is an important dimension of word knowledge when assessing the similarity of two terms or word senses. The conventional way of measuring the IC of word senses is to combine knowledge of their hierarchical structure from an ontology like WordNet with statistics on their actual usage in text as derived from a large corpus. In this paper we present a wholly intrinsic measure of IC that relies on hierarchical structure alone. We report that this measure is consequently easier to calculate, yet when used as the basis of a similarity mechanism it yields judgments that correlate more closely with human assessments than other, extrinsic measures of IC that additionally employ corpus analysis.},
	author = {Seco, Nuno and Veale, Tony and Hayes, Jer},
	year = {2004}
}

@inproceedings{resnik_using_1995,
	title = {Using information content to evaluate semantic similarity in a taxonomy},
	abstract = {philip.resnikfleast.sun.com This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content. Experimental evaluation suggests that the measure performs encouragingly well (a correlation of r = 0.79 with a benchmark set of human similarity judgments, with an upper bound of r = 0.90 for human subjects performing the same task), and significantly better than the traditional edge counting approach (r = 0.66). 1},
	booktitle = {In {Proceedings} of the 14th {International} {Joint} {Conference} on {Artificial} {Intelligence} ({IJCAI}-95},
	publisher = {Morgan Kaufmann},
	author = {Resnik, Philip},
	year = {1995},
	pages = {448--453}
}

@inproceedings{papachristos_haptic_2019,
	title = {Haptic {Feedback}-{Based} {Reactive} {Navigation} for {Aerial} {Robots} {Subject} to {Localization} {Failure}},
	doi = {10.1109/AERO.2019.8741634},
	abstract = {This paper considers the problem of resilient and collision–tolerant navigation of aerial robots when the estimation of the full robot pose and the map of the environment is not possible due to sensor failure or severe degradation. Typical examples relate to GPS–denied operation in visually–degraded environments (e.g. smoke–filled tunnels, dust–filled mines) where exteroceptive sensing such as visual cameras and LiDAR becomes degraded and therefore reliable localization and mapping is not possible. A bioinspired alternative approach for resilient and collision–tolerant flight is proposed and only relies on inertial sensors, barometric readings, and force sensing on antennae integrated perimetrically to the robot's body. A reactive control scheme is implemented and enables operation within the collision–free space, as well as safe interaction with the environment objects and surfaces. Experimental results demonstrate the potential of the proposed approach especially in relation to operation within confined environments. Video-https://youtu.be/lInqtgIst8E},
	booktitle = {2019 {IEEE} {Aerospace} {Conference}},
	author = {Papachristos, C. and Khattak, S. and Alexis, K.},
	month = mar,
	year = {2019},
	keywords = {Antenna feeds, Haptic interfaces, Robot sensing systems, Unmanned aerial vehicles},
	pages = {1--7}
}

@inproceedings{hinas_multiple_2019,
	title = {Multiple {Ground} {Target} {Finding} and {Action} {Using} {UAVs}},
	doi = {10.1109/AERO.2019.8741608},
	abstract = {This paper aims to develop a generalized framework for vision-based multiple ground target finding and action using a low-cost UAV system. The framework can be effectively deployed on a variety of UAV application with the suitable detection module in fully and supervised autonomous missions such as Search and rescue, inspection of flight debris, and spot spraying application of weedicide/pesticide. The developed framework was verified using Software in the Loop (SITL) simulation and outdoor flight tests. Results show that the framework is capable to perform multiple target finding and action task in real-world conditions.},
	booktitle = {2019 {IEEE} {Aerospace} {Conference}},
	author = {Hinas, A. and Ragel, R. and Roberts, J. and Gonzalez, F.},
	month = mar,
	year = {2019},
	keywords = {Cameras, Estimation, Image color analysis, Mathematical model, Navigation, Target tracking, Task analysis},
	pages = {1--11}
}

@inproceedings{salamat_generalized_2019,
	title = {A {Generalized} {Multi}-{Objective} {Framework} for {UAV} {Mission} {Planning}},
	doi = {10.1109/AERO.2019.8741898},
	abstract = {We present a novel framework for mission/trajectory planning of electrically powered UAVs by formulating a multiobjective multi-constraints optimization problem. The problem considers a number of objectives such as, flight time, harshness and aging under maximum available energy, peak power, maximum allowed time and initial-final target state. In particular, we show that the power demand is related to the angular velocity, as well as we introduce the concept of harshness (inverse of trajectory smoothness), and aging of the mechanical structure induced by the use or by environmental effects. The multiobjective optimization problem (MOP) is solved by introducing a new decomposition approach where a number of scalar optimization sub-problems are jointly solved using an evolutionary algorithm. Numerical results are reported to both verify performance and mission feasibility as well as to determine computation time which is a key element to be considered for real time applications.},
	booktitle = {2019 {IEEE} {Aerospace} {Conference}},
	author = {Salamat, B. and Tonello, A. M.},
	month = mar,
	year = {2019},
	keywords = {Aging, Helicopters, Optimization, Planning, Real-time systems, Torque, Trajectory},
	pages = {1--6}
}

@misc{noauthor_manually_nodate,
	title = {Manually raising (throwing) an exception in {Python}},
	url = {https://stackoverflow.com/questions/2052390/manually-raising-throwing-an-exception-in-python},
	urldate = {2019-06-27},
	journal = {Stack Overflow}
}

@misc{noauthor_built-exceptions_nodate,
	title = {Built-in {Exceptions} — {Python} 3.7.4rc1 documentation},
	url = {https://docs.python.org/3/library/exceptions.html#exception-hierarchy},
	urldate = {2019-06-27}
}
@misc{shahriar_sayeed_distance_nodate,
	title = {Distance to objects using single vision camera.},
	url = {https://www.youtube.com/watch?v=Qm7vunJAtKY},
	urldate = {2019-06-26},
	author = {{Shahriar Sayeed}}
}

@misc{noauthor_collection_2019,
	title = {A collection of pre-trained, state-of-the-art models in the {ONNX} format : onnx/models},
	copyright = {MIT},
	shorttitle = {A collection of pre-trained, state-of-the-art models in the {ONNX} format},
	url = {https://github.com/onnx/models},
	urldate = {2019-06-25},
	publisher = {Open Neural Network Exchange},
	month = jun,
	year = {2019},
	note = {original-date: 2017-10-06T00:03:03Z}
}

@misc{noauthor_ros_nodate,
	title = {{ROS} {Development} {Studio} ({ROSDS})},
	url = {http://www.theconstructsim.com/rds-ros-development-studio/},
	abstract = {Online ROS Development Studio. Any Operating System · No Installation Required · Parallelize RL Training · Develop From Anywhere},
	language = {en-US},
	urldate = {2019-06-25},
	journal = {The Construct}
}

@misc{noauthor_tutorial_2018,
	title = {Tutorial on implementing {YOLO} v3 from scratch in {PyTorch}},
	url = {https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/},
	abstract = {Tutorial on building YOLO v3 detector from scratch detailing how to create the network architecture from a configuration file, load the weights and designing input/output pipelines.},
	language = {en},
	urldate = {2019-06-25},
	journal = {Hello Paperspace},
	month = apr,
	year = {2018}
}

@misc{kathuria_pytorch_2019,
	title = {A {PyTorch} implementation of the {YOLO} v3 object detection algorithm: ayooshkathuria/pytorch-yolo-v3},
	shorttitle = {A {PyTorch} implementation of the {YOLO} v3 object detection algorithm},
	url = {https://github.com/ayooshkathuria/pytorch-yolo-v3},
	urldate = {2019-06-25},
	author = {Kathuria, Ayoosh},
	month = jun,
	year = {2019},
	note = {original-date: 2018-04-06T21:55:48Z}
}

@misc{noauthor_yolo_2019,
	title = {{YOLO} {ROS}: {Real}-{Time} {Object} {Detection} for {ROS}. {Contribute} to leggedrobotics/darknet\_ros development by creating an account on {GitHub}},
	copyright = {BSD-3-Clause},
	shorttitle = {{YOLO} {ROS}},
	url = {https://github.com/leggedrobotics/darknet_ros},
	urldate = {2019-06-25},
	publisher = {ETH Zurich Legged Robotics},
	month = jun,
	year = {2019},
	note = {original-date: 2017-03-31T17:25:58Z}
}

@misc{neilnie_yolo_2018,
	title = {{YOLO} v3 {Object} {Detection} {With} {ROS} ({Robot} {Operating} {System})},
	url = {https://neilnie.com/2018/11/18/implementing-yolo-v3-object-detection-on-the-autonomous-vehicle/},
	abstract = {It has been a while since I published my last blog post. I am back! Life has been a little crazy lately. I am in the midst of my senior year in high school.  Object Detection with YOLO When we…},
	language = {en},
	urldate = {2019-06-25},
	journal = {Neil Nie},
	author = {{NeilNie}},
	month = nov,
	year = {2018}
}

@misc{ai_real-time_2019,
	title = {Real-{Time} {Object} {Detection} on {GPUs} in 10 {Minutes} - {Better} {Programming}},
	url = {https://medium.com/better-programming/real-time-object-detection-on-gpus-in-10-minutes-6e8c9b857bb3},
	abstract = {Learn how to run a high performance object detection pipeline for inference on GPUs in 10 mins.},
	language = {en},
	urldate = {2019-06-25},
	journal = {Medium},
	author = {AI, NVIDIA},
	month = jun,
	year = {2019}
}

@misc{noauthor_how_2018,
	title = {How to {Speed} {Up} {Deep} {Learning} {Inference} {Using} {TensorRT}},
	url = {https://devblogs.nvidia.com/speed-up-inference-tensorrt/},
	abstract = {Introduction to accelerated creating inference engines using TensorRT and C++ with code samples and tutorial links},
	language = {en-US},
	urldate = {2019-06-25},
	journal = {NVIDIA Developer Blog},
	month = nov,
	year = {2018}
}

@misc{ivanov_how_2019,
	title = {How to build a custom {Dataset} for {Tensorflow}},
	url = {https://towardsdatascience.com/how-to-build-a-custom-dataset-for-tensorflow-1fe3967544d8},
	abstract = {Tensorflow inspires developers to experiment with their exciting AI ideas in almost any domain that comes to mind. There are three well…},
	urldate = {2019-06-21},
	journal = {Towards Data Science},
	author = {Ivanov, Ivelin},
	month = jun,
	year = {2019}
}

@misc{noauthor_response_nodate,
	title = {Response to gazebo image stream · {Issue} \#11 · ethz-asl/rovio},
	url = {https://github.com/ethz-asl/rovio/issues/11},
	abstract = {I am trying to run the ROVIO pipeline on the Imu + Vision stream coming from the gazebo iris model\&\#39;s vi-sensor from rotorSimulator(to eventually use the pose update from ROVIO in the feedback l...},
	language = {en},
	urldate = {2019-06-19},
	journal = {GitHub}
}

@misc{noauthor_running_nodate,
	title = {Running {ROVIO} in {Gazebo} · {Issue} \#157 · ethz-asl/rovio},
	url = {https://github.com/ethz-asl/rovio/issues/157},
	abstract = {Hi, First of all, thank you for open sourcing such a great project. I have been trying to run the rovio\_node through gazebo and haven\&\#39;t been able to get any output from rovio. I have a python f...},
	language = {en},
	urldate = {2019-06-19},
	journal = {GitHub}
}

@misc{noauthor_open_2019,
	title = {An open visual-inertial mapping framework. {Contribute} to ethz-asl/maplab development by creating an account on {GitHub}},
	url = {https://github.com/ethz-asl/maplab},
	urldate = {2019-06-19},
	publisher = {ETHZ ASL},
	month = jun,
	year = {2019},
	note = {original-date: 2017-11-27T21:58:23Z}
}

@misc{noauthor_how_nodate,
	title = {How to run this package ? · {Issue} \#151 · ethz-asl/rovio},
	shorttitle = {How to run this package ?},
	url = {https://github.com/ethz-asl/rovio/issues/151},
	abstract = {Hi All, I\&\#39;m using Ubuntu 16.04 and ROS Kinetic system, and I have git cloned the package into my workspace. But I have found no documentation regarding what nodes to run, what topics to publish...},
	language = {en},
	urldate = {2019-06-19},
	journal = {GitHub}
}

@misc{noauthor_contribute_2019,
	title = {Contribute to ethz-asl/rovio development by creating an account on {GitHub}},
	url = {https://github.com/ethz-asl/rovio},
	urldate = {2019-06-19},
	publisher = {ETHZ ASL},
	month = jun,
	year = {2019},
	note = {original-date: 2015-08-06T07:43:05Z}
}

@misc{noauthor_contribute_2019-1,
	title = {Contribute to ethz-asl/rovio development by creating an account on {GitHub}},
	copyright = {View license},
	url = {https://github.com/ethz-asl/rovio},
	urldate = {2019-06-19},
	publisher = {ETHZ ASL},
	month = jun,
	year = {2019},
	note = {original-date: 2015-08-06T07:43:05Z}
}

@misc{noauthor_visual_2017,
	title = {Visual inertial odometry on a budget!!},
	url = {https://riccardogiubilato.github.io/visual/odometry/2017/12/12/Visual-Inertial-Odometry-On-A-Budget.html},
	abstract = {Hello world! Today I want to talk about Visual inertial odometry and how to build a VIO setup on a very tight budget using ROVIO.},
	language = {en},
	urldate = {2019-06-19},
	journal = {RiccardoGiubilato},
	month = dec,
	year = {2017}
}

@misc{noauthor_google_nodate,
	title = {{GooGLe} {Dataset} {Search}},
	url = {https://toolbox.google.com/datasetsearch/search?query=Drone&docid=1VLjeLZDS%2FdAk4DXAAAAAA%3D%3D},
	urldate = {2019-06-18}
}

@misc{browning_yolo_2019,
	title = {{YOLO} {Object} {Detection} in {MATLAB}, {Start} to {Finish}},
	url = {https://towardsdatascience.com/yolo-object-detection-in-matlab-start-to-finish-3f78ec80419d},
	abstract = {Downloading and implementing the YOLO object detection network in MATLAB},
	urldate = {2019-06-12},
	journal = {Towards Data Science},
	author = {Browning, James},
	month = jan,
	year = {2019}
}

@misc{dronebot_workshop_jetson_2019,
	title = {Jetson {Nano} {Developer} {Kit} - {Getting} {Started} with the {NVIDIA} {Jetson} {Nano}},
	url = {https://www.youtube.com/watch?v=BkZ1n_1F-Cg},
	urldate = {2019-06-12},
	author = {{DroneBot Workshop}},
	month = jun,
	year = {2019}
}

@misc{noauthor_how_2019,
	title = {How to change position speed in offboard mode · {Issue} \#471 · mavlink/mavros},
	url = {https://github.com/mavlink/mavros/issues/471},
	abstract = {Hello I\&\#39;m working with gazebo simulator right now (still really new to ros and mavros), and with mavros/setpoint\_position/local, I can move the copter to the desired position. However, I can\&\#3...},
	language = {en},
	urldate = {2019-06-11},
	journal = {GitHub},
	month = jun,
	year = {2019}
}

@misc{noauthor_holding_2019,
	title = {Holding altitude while controlling quadcopter with velocity commands · {Issue} \#5907 · {PX4}/{Firmware}},
	url = {https://github.com/PX4/Firmware/issues/5907},
	abstract = {Hi, I have an algorithm which gives me velocity commands (ROS geometry\_msgs/Twist type of message). Now what I want to achieve with this is to control my quadcopter using those velocity commands wi...},
	language = {en},
	urldate = {2019-06-11},
	journal = {GitHub},
	month = jun,
	year = {2019}
}

@misc{noauthor_setpoint_2019,
	title = {Setpoint raw issues {Mavros} {ROS} · {Issue} \#7068 · {PX4}/{Firmware}},
	url = {https://github.com/PX4/Firmware/issues/7068},
	abstract = {This is based off of issue (\#5907) which is closed but I still can\&\#39;t get to work. I have implemented with setpoint raw and multiple type masks (below) with no success. I get the quad rolling ar...},
	language = {en},
	urldate = {2019-06-11},
	journal = {GitHub},
	month = jun,
	year = {2019}
}

@misc{noauthor_setpoint_raw_2019,
	title = {Setpoint\_raw with bit mask 4067({VX} {VX} {PZ})not working properly. · {Issue} \#1074 · mavlink/mavros},
	url = {https://github.com/mavlink/mavros/issues/1074},
	abstract = {Issue details Dear team, I am currently using setpoint\_raw/local to control my drone indoor with a tfmini rangefinder. But when using setpoint\_raw/local to control the VX VY and PZ with bitmask4067...},
	language = {en},
	urldate = {2019-06-11},
	journal = {GitHub},
	month = jun,
	year = {2019}
}

@misc{noauthor_dronet:_2019,
	title = {{DroNet}: {Learning} to {Fly} by {Driving}},
	url = {http://rpg.ifi.uzh.ch/dronet.html},
	abstract = {Databases and ALgorithms available},
	urldate = {2019-06-11},
	month = jun,
	year = {2019}
}

@article{perez-arnal_visual_2018,
	title = {A {Visual} {Distance} for {WordNet}},
	url = {http://arxiv.org/abs/1804.09558},
	abstract = {Measuring the distance between concepts is an important field of study of Natural Language Processing, as it can be used to improve tasks related to the interpretation of those same concepts. WordNet, which includes a wide variety of concepts associated with words (i.e., synsets), is often used as a source for computing those distances. In this paper, we explore a distance for WordNet synsets based on visual features, instead of lexical ones. For this purpose, we extract the graphic features generated within a deep convolutional neural networks trained with ImageNet and use those features to generate a representative of each synset. Based on those representatives, we define a distance measure of synsets, which complements the traditional lexical distances. Finally, we propose some experiments to evaluate its performance and compare it with the current state-of-the-art.},
	urldate = {2019-06-11},
	journal = {arXiv:1804.09558 [cs, stat]},
	author = {Pérez-Arnal, Raquel and Vilalta, Armand and Garcia-Gasulla, Dario and Cortés, Ulises and Ayguadé, Eduard and Labarta, Jesus},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.09558},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}

@misc{noauthor_guide_2019,
	title = {Guide to deploying deep-learning inference networks and deep vision primitives with {TensorRT} and {NVIDIA} {Jetson}.: dusty-nv/jetson-inference},
	shorttitle = {Guide to deploying deep-learning inference networks and deep vision primitives with {TensorRT} and {NVIDIA} {Jetson}.},
	url = {https://github.com/dusty-nv/jetson-inference},
	abstract = {Image Segmentation Dataset for Aerial Ground/Sky classification},
	urldate = {2019-06-11},
	month = jun,
	year = {2019},
	note = {original-date: 2016-07-30T19:56:47Z}
}

@article{choi_unmanned_2019,
	title = {Unmanned aerial vehicles using machine learning for autonomous flight; state-of-the-art},
	volume = {33},
	issn = {0169-1864},
	url = {https://doi.org/10.1080/01691864.2019.1586760},
	doi = {10.1080/01691864.2019.1586760},
	abstract = {In recent years, since researchers began to study on Unmanned Aerial Vehicles (UAVs), UAVs have been integrated into today's everyday life, including civilian area and military area. Many researchers have tried to make use of UAVs as an ideal platform for inspection, delivery, surveillance, and so on. In particular, machine learning has been applied to UAVs for autonomous flight that enables UAVs do designated task more efficiently. In this paper, we review the history and the classification of machine learning, and discuss the state-of-the-art machine learning that has been applied to UAVs for autonomous flight. We provide control strategies including parameter tuning, adaptive control for uncertain environment, and real-time path planning, and object recognition that have been described in the literature.},
	number = {6},
	urldate = {2019-06-11},
	journal = {Advanced Robotics},
	author = {Choi, Su Yeon and Cha, Dowan},
	month = mar,
	year = {2019},
	keywords = {Unmanned aerial vehicles, autonomous flight, machine learning},
	pages = {265--277}
}

@article{perez-arnal_visual_2018-1,
	title = {A {Visual} {Distance} for {WordNet}},
	url = {http://arxiv.org/abs/1804.09558},
	abstract = {Measuring the distance between concepts is an important field of study of Natural Language Processing, as it can be used to improve tasks related to the interpretation of those same concepts. WordNet, which includes a wide variety of concepts associated with words (i.e., synsets), is often used as a source for computing those distances. In this paper, we explore a distance for WordNet synsets based on visual features, instead of lexical ones. For this purpose, we extract the graphic features generated within a deep convolutional neural networks trained with ImageNet and use those features to generate a representative of each synset. Based on those representatives, we define a distance measure of synsets, which complements the traditional lexical distances. Finally, we propose some experiments to evaluate its performance and compare it with the current state-of-the-art.},
	urldate = {2019-06-11},
	journal = {arXiv:1804.09558 [cs, stat]},
	author = {Pérez-Arnal, Raquel and Vilalta, Armand and Garcia-Gasulla, Dario and Cortés, Ulises and Ayguadé, Eduard and Labarta, Jesus},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.09558},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning}
}

@article{tian_fcos:_2019,
	title = {{FCOS}: {Fully} {Convolutional} {One}-{Stage} {Object} {Detection}},
	shorttitle = {{FCOS}},
	url = {http://arxiv.org/abs/1904.01355},
	abstract = {We propose a fully convolutional one-stage object detector (FCOS) to solve object detection in a per-pixel prediction fashion, analogue to semantic segmentation. Almost all state-of-the-art object detectors such as RetinaNet, SSD, YOLOv3, and Faster R-CNN rely on pre-defined anchor boxes. In contrast, our proposed detector FCOS is anchor-box free, as well as proposal free. By eliminating the pre-defined set of anchor boxes, FCOS completely avoids the complicated computation related to anchor boxes such as calculating overlapping during training and significantly reduces the training memory footprint. More importantly, we also avoid all hyper-parameters related to anchor boxes, which are often very sensitive to the final detection performance. With the only post-processing non-maximum suppression (NMS), our detector FCOS outperforms previous anchor-based one-stage detectors with the advantage of being much simpler. For the first time, we demonstrate a much simpler and flexible detection framework achieving improved detection accuracy. We hope that the proposed FCOS framework can serve as a simple and strong alternative for many other instance-level tasks. Code is available at: https://tinyurl.com/FCOSv1},
	urldate = {2019-06-06},
	journal = {arXiv:1904.01355 [cs]},
	author = {Tian, Zhi and Shen, Chunhua and Chen, Hao and He, Tong},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.01355},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@misc{noauthor_deep_2019,
	title = {Deep reinforcement learning {GPU} libraries for {NVIDIA} {Jetson} with {PyTorch}, {OpenAI} {Gym}, and {Gazebo} robotics simulator.: dusty-nv/jetson-reinforcement},
	copyright = {View license},
	shorttitle = {Deep reinforcement learning {GPU} libraries for {NVIDIA} {Jetson} with {PyTorch}, {OpenAI} {Gym}, and {Gazebo} robotics simulator.},
	url = {https://github.com/dusty-nv/jetson-reinforcement},
	urldate = {2019-06-06},
	month = jun,
	year = {2019},
	note = {original-date: 2016-07-31T03:21:12Z}
}

@misc{noauthor_two_2016,
	title = {Two {Days} to a {Demo}},
	url = {https://developer.nvidia.com/embedded/twodaystoademo},
	abstract = {Two Days to a Demo is our introductory series of deep learning tutorials for deploying AI and computer vision to the field with NVIDIA Jetson AGX Xavier, Jetson TX2, Jetson TX1 and Jetson Nano. This tutorial takes roughly two days to complete from start to finish, enabling you to configure and train your own neural networks. It includes all of the necessary source code, datasets, and documentation to get you started. Dive into deep learning today with Two Days to a Demo.},
	language = {en},
	urldate = {2019-06-06},
	journal = {NVIDIA Developer},
	month = nov,
	year = {2016}
}

@misc{noauthor_deep_2019-1,
	title = {Deep learning inference nodes for {ROS} with support for {NVIDIA} {Jetson} {TX1}/{TX2}/{Xavier} and {TensorRT}: dusty-nv/ros\_deep\_learning},
	shorttitle = {Deep learning inference nodes for {ROS} with support for {NVIDIA} {Jetson} {TX1}/{TX2}/{Xavier} and {TensorRT}},
	url = {https://github.com/dusty-nv/ros_deep_learning},
	urldate = {2019-06-06},
	month = jun,
	year = {2019},
	note = {original-date: 2016-10-04T02:18:28Z}
}

@misc{shah_implementation_2019,
	title = {Implementation of {YOLOv3} in {Tensorflow}},
	url = {https://medium.com/@shahkaran76/yolo-object-detection-algorithm-in-tensorflow-e080a58fa79b},
	language = {en},
	urldate = {2019-06-06},
	journal = {Medium},
	author = {Shah, Karan},
	month = jan,
	year = {2019}
}

@misc{noauthor_yolo_2019-1,
	title = {Yolo v3 {Object} {Detection} in {Tensorflow}},
	url = {https://kaggle.com/aruchomu/yolo-v3-object-detection-in-tensorflow},
	abstract = {Using data from Data for Yolo v3 kernel},
	language = {en},
	urldate = {2019-06-06},
	month = jun,
	year = {2019}
}

@misc{noauthor_how_2019-1,
	title = {How can {I} install {ROS} {Melodic} with {Python3}? - {ROS} {Answers}: {Open} {Source} {Q}\&{A} {Forum}},
	url = {http://answers.ros.org/question/295012/how-can-i-install-ros-melodic-with-python3/},
	urldate = {2019-06-06},
	month = jun,
	year = {2019}
}

@misc{ben-basst_how_2019,
	title = {How to setup {ROS} with {Python} 3},
	url = {https://medium.com/@beta_b0t/how-to-setup-ros-with-python-3-44a69ca36674},
	language = {en},
	urldate = {2019-06-06},
	journal = {Medium},
	author = {Ben-Basst, Omri},
	month = feb,
	year = {2019}
}

@misc{noauthor_installing_2019,
	title = {Installing {ROS} on {Nano} - {NVIDIA} {Developer} {Forums}},
	url = {https://devtalk.nvidia.com/default/topic/1048856/jetson-nano/installing-ros-on-nano/},
	urldate = {2019-06-06},
	month = jun,
	year = {2019}
}

@misc{noauthor_jetson_2019,
	title = {Jetson {Nano} + {Raspberry} {Pi} {Camera} - {JetsonHacks}},
	url = {https://www.jetsonhacks.com/2019/04/02/jetson-nano-raspberry-pi-camera/},
	urldate = {2019-06-06},
	month = jun,
	year = {2019}
}

@misc{noauthor_jetson_2019-1,
	title = {Jetson {Nano} {USB} camera - {NVIDIA} {Developer} {Forums}},
	url = {https://devtalk.nvidia.com/default/topic/1050271/jetson-nano-usb-camera/},
	urldate = {2019-06-06},
	month = jun,
	year = {2019}
}

@misc{allan_getting_2019,
	title = {Getting {Started} with the {NVIDIA} {Jetson} {Nano} {Developer} {Kit}},
	url = {https://blog.hackster.io/getting-started-with-the-nvidia-jetson-nano-developer-kit-43aa7c298797},
	abstract = {Getting started with NVIDIA’s GPU-based hardware},
	urldate = {2019-06-05},
	journal = {Hackster Blog},
	author = {Allan, Alasdair},
	month = apr,
	year = {2019}
}

@misc{noauthor_qut_2019,
	title = {{QUT} - {Research} {Data} {Finder}},
	url = {https://researchdatafinder.qut.edu.au/display/n6417},
	abstract = {The QUT Research Data Finder application has been developed for the aggregation of research metadata, specifically details around data collections.},
	language = {en},
	urldate = {2019-06-05},
	month = jun,
	year = {2019}
}

@misc{noauthor_jetson_2019-2,
	title = {Jetson {Nano} – {Use} {More} {Memory}! – {JetsonHacks}},
	url = {https://www.jetsonhacks.com/2019/04/14/jetson-nano-use-more-memory/},
	urldate = {2019-05-30},
	month = may,
	year = {2019}
}

@misc{noauthor_yolo_2019-2,
	title = {{YOLO} object detection with {OpenCV} - {PyImageSearch}},
	url = {https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/},
	urldate = {2019-05-30},
	month = may,
	year = {2019}
}

@misc{noauthor_practical_2018,
	title = {A {Practical} {Guide} to {Object} {Detection} using the {Popular} {YOLO} {Framework}},
	url = {https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/},
	abstract = {Object detection in a few lines of code? That's what you can do with the amazing YOLO framework and we explain all about it in this guide.},
	urldate = {2019-05-30},
	journal = {Analytics Vidhya},
	month = dec,
	year = {2018}
}

@misc{nishad_you_2019,
	title = {You {Only} {Look} {Once}({YOLO}): {Implementing} {YOLO} in less than 30 lines of {Python} {Code}},
	shorttitle = {You {Only} {Look} {Once}({YOLO})},
	url = {https://towardsdatascience.com/you-only-look-once-yolo-implementing-yolo-in-less-than-30-lines-of-python-code-97fb9835bfd2},
	abstract = {You Only Look Once is a real-time object detection algorithm, that avoids spending too much time on generating region proposals.Instead of…},
	urldate = {2019-05-30},
	journal = {Towards Data Science},
	author = {Nishad, Garima},
	month = mar,
	year = {2019}
}

@misc{noauthor_jetson_2019-3,
	title = {Jetson {Nano} {YoloV3} performance - {NVIDIA} {Developer} {Forums}},
	url = {https://devtalk.nvidia.com/default/topic/1050670/jetson-nano-yolov3-performance/},
	urldate = {2019-05-30},
	month = may,
	year = {2019}
}

@misc{noauthor_jetson_2019-4,
	title = {Jetson nano crashed when using tiny yolo v3 model - {NVIDIA} {Developer} {Forums}},
	url = {https://devtalk.nvidia.com/default/topic/1049803/jetson-nano-crashed-when-using-tiny-yolo-v3-model/},
	urldate = {2019-05-30},
	month = may,
	year = {2019}
}

@misc{noauthor_4_2019,
	title = {4 easy steps to improve your machine learning code performance},
	url = {https://towardsdatascience.com/4-easy-steps-to-improve-your-machine-learning-code-performance-88a0b0eeffa8},
	urldate = {2019-05-27},
	month = may,
	year = {2019}
}

@misc{noauthor_how_2019-2,
	title = {How to {Perform} {Object} {Detection} in {Photographs} {Using} {Mask} {R}-{CNN} with {Keras}},
	url = {https://machinelearningmastery.com/how-to-perform-object-detection-in-photographs-with-mask-r-cnn-in-keras/},
	urldate = {2019-05-27},
	month = may,
	year = {2019}
}

@misc{noauthor_moving_2019,
	title = {Moving {Camera}, {Moving} {People}: {Google} {AI}’s {Deep} {Learning} {Approach} to {Depth} {Prediction}},
	url = {https://medium.com/syncedreview/moving-camera-moving-people-google-ais-deep-learning-approach-to-depth-prediction-3c169c6ca579},
	urldate = {2019-05-27},
	month = may,
	year = {2019}
}

@misc{noauthor_jetson-inference/segnet-dataset.md_2019,
	title = {jetson-inference/segnet-dataset.md at master · dusty-nv/jetson-inference · {GitHub}},
	url = {https://github.com/dusty-nv/jetson-inference/blob/master/docs/segnet-dataset.md#downloading-aerial-drone-dataset},
	urldate = {2019-05-22},
	month = may,
	year = {2019}
}

@misc{cheung_getting_2019,
	title = {Getting started with {Jetson} {Nano} and {Autonomous} {Donkey} car},
	url = {https://medium.com/@feicheung2016/getting-started-with-jetson-nano-and-autonomous-donkey-car-d4f25bbd1c83},
	abstract = {Jetson Nano is a powerful and efficient single board computer made for (buzzword alert) AI on the edge. It is just USD 99 and it provides…},
	urldate = {2019-05-21},
	journal = {Medium},
	author = {Cheung, Fei},
	month = apr,
	year = {2019}
}

@misc{technologies_getting_2019,
	title = {Getting started with the {Jetson} {Nano}},
	url = {https://medium.com/@heldenkombinat/getting-started-with-the-jetson-nano-37af65a07aab},
	abstract = {Modern AI for everyone},
	urldate = {2019-05-21},
	journal = {Heldenkombinat Technologies},
	author = {Technologies, Heldenkombinat},
	month = may,
	year = {2019}
}

@article{dodge_understanding_2016,
	title = {Understanding {How} {Image} {Quality} {Affects} {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1604.04004},
	abstract = {Image quality is an important practical challenge that is often overlooked in the design of machine vision systems. Commonly, machine vision systems are trained and tested on high quality image datasets, yet in practical applications the input images can not be assumed to be of high quality. Recently, deep neural networks have obtained state-of-the-art performance on many machine vision tasks. In this paper we provide an evaluation of 4 state-of-the-art deep neural network models for image classification under quality distortions. We consider five types of quality distortions: blur, noise, contrast, JPEG, and JPEG2000 compression. We show that the existing networks are susceptible to these quality distortions, particularly to blur and noise. These results enable future work in developing deep neural networks that are more invariant to quality distortions.},
	urldate = {2019-05-09},
	journal = {arXiv:1604.04004 [cs]},
	author = {Dodge, Samuel and Karam, Lina},
	month = apr,
	year = {2016},
	note = {arXiv: 1604.04004},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@misc{noauthor_building_2019,
	title = {Building powerful image classification models using very little data},
	url = {https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html},
	urldate = {2019-05-09},
	month = may,
	year = {2019}
}

@misc{noauthor_faster_2018,
	title = {Faster {Neural} {Networks} {Straight} from {JPEG}},
	url = {https://eng.uber.com/neural-networks-jpeg/},
	abstract = {Uber AI Labs introduces a method for making neural networks that process images faster and more accurately by leveraging JPEG representations.},
	language = {en-US},
	urldate = {2019-05-09},
	journal = {Uber Engineering Blog},
	month = dec,
	year = {2018}
}

@misc{noauthor_eigen_2019,
	title = {Eigen},
	url = {http://eigen.tuxfamily.org/index.php?title=Main_Page},
	urldate = {2019-05-08},
	month = may,
	year = {2019}
}

@misc{noauthor_smarter_2019,
	title = {Smarter training of neural networks},
	url = {http://news.mit.edu/2019/smarter-training-neural-networks-0506},
	abstract = {MIT CSAIL project shows the neural nets we typically train contain smaller “subnetworks” that can learn just as well, and often faster.},
	urldate = {2019-05-08},
	journal = {MIT News},
	month = may,
	year = {2019}
}

@misc{noauthor_open_2019-1,
	title = {Open {Source} {Robotics}: {Getting} {Started} {With} {Gazebo} and {ROS} 2},
	shorttitle = {Open {Source} {Robotics}},
	url = {https://www.infoq.com/articles/ros-2-gazebo-tutorial},
	abstract = {Introduction to Gazebo, a powerful robot simulator that calculates physics, generates sensor data and provides convenient interfaces, and ROS 2, the latest version of the Robot Operating System, which offers familiar tools and capabilities, while expanding to new use cases. Both are open source and used by academia and industry alike.},
	urldate = {2019-05-08},
	journal = {InfoQ},
	month = may,
	year = {2019}
}

@misc{rimal_fast-scnn_2019,
	title = {Fast-{SCNN} explained and implemented using {Tensorflow} 2.0},
	url = {https://medium.com/deep-learning-journals/fast-scnn-explained-and-implemented-using-tensorflow-2-0-6bd17c17a49e},
	abstract = {Fast Segmentation Convolutional Neural Network (Fast-SCNN) is an above real-time semantic segmentation model on high resolution image data…},
	urldate = {2019-05-07},
	journal = {Medium},
	author = {Rimal, Kshitiz},
	month = may,
	year = {2019}
}

@misc{ranjan_extreme_2019,
	title = {Extreme {Rare} {Event} {Classification} using {Autoencoders} in {Keras}},
	url = {https://towardsdatascience.com/extreme-rare-event-classification-using-autoencoders-in-keras-a565b386f098},
	abstract = {In this post, we will learn how to implement an autoencoder for building a rare-event classifier. We will use a real-world rare event…},
	urldate = {2019-05-06},
	journal = {Towards Data Science},
	author = {Ranjan, Chitta},
	month = may,
	year = {2019}
}

@misc{noauthor_researchers_2019,
	title = {Researchers turn to deep learning to help enhance editing process},
	url = {https://www.microsoft.com/en-us/research/blog/beyond-spell-checkers-enhancing-the-editing-process-with-deep-learning/},
	abstract = {Spell checkers are ubiquitous. But what other, more complex classes of editorial tasks can be automated? Microsoft researchers are applying unsupervised deep learning methods to source code and natural language editing to find out},
	language = {en-US},
	urldate = {2019-05-06},
	journal = {Microsoft Research},
	month = may,
	year = {2019}
}

@article{milioto_bonnet:_2018,
	title = {Bonnet: {An} {Open}-{Source} {Training} and {Deployment} {Framework} for {Semantic} {Segmentation} in {Robotics} using {CNNs}},
	shorttitle = {Bonnet},
	url = {http://arxiv.org/abs/1802.08960},
	abstract = {The ability to interpret a scene is an important capability for a robot that is supposed to interact with its environment. The knowledge of what is in front of the robot is, for example, relevant for navigation, manipulation, or planning. Semantic segmentation labels each pixel of an image with a class label and thus provides a detailed semantic annotation of the surroundings to the robot. Convolutional neural networks (CNNs) are popular methods for addressing this type of problem. The available software for training and the integration of CNNs for real robots, however, is quite fragmented and often difficult to use for non-experts, despite the availability of several high-quality open-source frameworks for neural network implementation and training. In this paper, we propose a tool called Bonnet, which addresses this fragmentation problem by building a higher abstraction that is specific for the semantic segmentation task. It provides a modular approach to simplify the training of a semantic segmentation CNN independently of the used dataset and the intended task. Furthermore, we also address the deployment on a real robotic platform. Thus, we do not propose a new CNN approach in this paper. Instead, we provide a stable and easy-to-use tool to make this technology more approachable in the context of autonomous systems. In this sense, we aim at closing a gap between computer vision research and its use in robotics research. We provide an open-source codebase for training and deployment. The training interface is implemented in Python using TensorFlow and the deployment interface provides a C++ library that can be easily integrated in an existing robotics codebase, a ROS node, and two standalone applications for label prediction in images and videos.},
	urldate = {2019-05-06},
	journal = {arXiv:1802.08960 [cs]},
	author = {Milioto, Andres and Stachniss, Cyrill},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.08960},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics}
}

@misc{rivlin_reinforcement_2019,
	title = {Reinforcement {Learning} for {Real}-{World} {Robotics}},
	url = {https://towardsdatascience.com/reinforcement-learning-for-real-world-robotics-148c81dbdcff},
	abstract = {Ideas from the literature on RL for real-world robot control},
	urldate = {2019-05-06},
	journal = {Towards Data Science},
	author = {Rivlin, Or},
	month = may,
	year = {2019}
}

@misc{ashraf_reinforcement_2018,
	title = {Reinforcement {Learning} {Demystified}: {A} {Gentle} {Introduction}},
	shorttitle = {Reinforcement {Learning} {Demystified}},
	url = {https://towardsdatascience.com/reinforcement-learning-demystified-36c39c11ec14},
	abstract = {Episode 1, demystifying agent/environment interaction, and the components of a reinforcement learning agent.},
	urldate = {2019-05-06},
	journal = {Towards Data Science},
	author = {Ashraf, Mohammad},
	month = apr,
	year = {2018}
}

@inproceedings{ajmal_framework_2018,
	address = {Dallas, TX},
	title = {A framework for vision-based multiple target finding and action using multirotor {UAVs}},
	copyright = {2018 [please consult the author(s)]},
	isbn = {978-1-5386-1355-9},
	url = {https://eprints.qut.edu.au/120065/},
	abstract = {This paper presents a framework for vision-based target finding and action using a multirotor UAV system. The proposed framework detects and tracks a set of ground targets by using a vision-based position estimation technique. An internal map created using the relative locations of the adjacent targets is used to overcome the vision-based position estimation error and GPS noise and drift. The framework was implemented using the Robotic Operating System (ROS) and tested in the Software in the Loop (SITL) Simulation with the Gazebo robotics simulator. The test results demonstrate that the framework is robust to drift and errors, and able to perform the intended tasks successfully.},
	language = {en},
	urldate = {2019-05-06},
	booktitle = {Proceedings of the 2018 {International} {Conference} on {Unmanned} {Aircraft} {Systems} ({ICUAS} 2018)},
	publisher = {IEEE},
	author = {Ajmal, Hinas and Ragel, Roshan and Roberts, Jonathan M. and Gonzalez, Luis F.},
	month = jun,
	year = {2018},
	pages = {1320--1327}
}

@inproceedings{kangutkar_ros_2017,
	title = {{ROS} {Navigation} {Stack} for {Smart} {Indoor} {Agents}},
	doi = {10.1109/AIPR.2017.8457966},
	abstract = {Advances in compute power, sensor technology, and machine learning have facilitated a plethora of assistive and personal agents. These agents are poised to make our life more efficient, safer, feature rich, and more enjoyable. With so much activity in this area, there has been a lot of progress developing algorithms for localization, path planning, path guiding, and obstacle avoidance. Similarly, numerous frameworks for human computer interaction, obstacle recognition, object tracking, and advanced reasoning have been introduced. This research introduces a navigation stack written in Python using the Robot Operating System for modular indoor agent development. The localization system makes use of deep learning and particle filters and is easily trained to localize in new environments. The obstacle avoidance system can be changed to reflect the agents size, required safety margin, sensor properties and behavior. Different path planning algorithms can be substituted and used in the path guiding system. The created navigation stack was tested on an assistive technology wheelchair, exhibiting state of the art localization, collision avoidance, and navigation in complex scenarios.},
	booktitle = {2017 {IEEE} {Applied} {Imagery} {Pattern} {Recognition} {Workshop} ({AIPR})},
	author = {Kangutkar, R. and Lauzon, J. and Synesael, A. and Jenis, N. and Simha, K. and Ptucha, R.},
	month = oct,
	year = {2017},
	keywords = {Cameras, Collision avoidance, Navigation, Path planning, ROS navigation stack, Robot Operating System, Robot sensing systems, Wheelchairs, assistive agents, assistive technology wheelchair, collision avoidance, compute power, deep learning, handicapped aids, human computer interaction, learning (artificial intelligence), localization system, machine learning, mobile robots, modular indoor agent development, navigation, navigation stack, object tracking, obstacle avoidance system, obstacle recognition, operating systems (computers), particle filtering (numerical methods), particle filters, path guiding system, path planning, path planning algorithms, personal agents, safety margin, sensor properties, sensor technology, smart indoor agents},
	pages = {1--10}
}

@inproceedings{kangutkar_ros_2017-1,
	title = {{ROS} {Navigation} {Stack} for {Smart} {Indoor} {Agents}},
	doi = {10.1109/AIPR.2017.8457966},
	abstract = {Advances in compute power, sensor technology, and machine learning have facilitated a plethora of assistive and personal agents. These agents are poised to make our life more efficient, safer, feature rich, and more enjoyable. With so much activity in this area, there has been a lot of progress developing algorithms for localization, path planning, path guiding, and obstacle avoidance. Similarly, numerous frameworks for human computer interaction, obstacle recognition, object tracking, and advanced reasoning have been introduced. This research introduces a navigation stack written in Python using the Robot Operating System for modular indoor agent development. The localization system makes use of deep learning and particle filters and is easily trained to localize in new environments. The obstacle avoidance system can be changed to reflect the agents size, required safety margin, sensor properties and behavior. Different path planning algorithms can be substituted and used in the path guiding system. The created navigation stack was tested on an assistive technology wheelchair, exhibiting state of the art localization, collision avoidance, and navigation in complex scenarios.},
	booktitle = {2017 {IEEE} {Applied} {Imagery} {Pattern} {Recognition} {Workshop} ({AIPR})},
	author = {Kangutkar, R. and Lauzon, J. and Synesael, A. and Jenis, N. and Simha, K. and Ptucha, R.},
	month = oct,
	year = {2017},
	keywords = {Cameras, Collision avoidance, Navigation, Path planning, ROS navigation stack, Robot Operating System, Robot sensing systems, Wheelchairs, assistive agents, assistive technology wheelchair, collision avoidance, compute power, deep learning, handicapped aids, human computer interaction, learning (artificial intelligence), localization system, machine learning, mobile robots, modular indoor agent development, navigation, navigation stack, object tracking, obstacle avoidance system, obstacle recognition, operating systems (computers), particle filtering (numerical methods), particle filters, path guiding system, path planning, path planning algorithms, personal agents, safety margin, sensor properties, sensor technology, smart indoor agents},
	pages = {1--10}
}

@misc{rosebrock_getting_2019,
	title = {Getting started with the {NVIDIA} {Jetson} {Nano}},
	url = {https://www.pyimagesearch.com/2019/05/06/getting-started-with-the-nvidia-jetson-nano/},
	abstract = {In this tutorial, you will learn how to get started with your NVIDIA Jetson Nano, including installing Keras + TensorFlow, accessing the camera, and performing image classification and object detection.},
	language = {en-US},
	urldate = {2019-05-06},
	journal = {PyImageSearch},
	author = {Rosebrock, Adrian},
	month = may,
	year = {2019}
}

@misc{noauthor_pep_2019,
	title = {{PEP} 8 -- {Style} {Guide} for {Python} {Code}},
	url = {https://www.python.org/dev/peps/pep-0008/},
	abstract = {The official home of the Python Programming Language},
	language = {en},
	urldate = {2019-05-03},
	journal = {Python.org},
	month = may,
	year = {2019}
}

@misc{noauthor_how_2019-3,
	title = {How to {Program} in {C}++},
	url = {https://cs.fit.edu/~mmahoney/cse2050/how2cpp.html},
	urldate = {2019-05-03},
	month = may,
	year = {2019}
}

@book{newman_systematic_2018,
	address = {Boca Raton},
	title = {A systematic approach to learning robot programming with {ROS}},
	isbn = {978-1-4987-7787-2},
	language = {eng},
	publisher = {CRC Press},
	author = {Newman, Wyatt S.},
	year = {2018},
	keywords = {Electronic books., Operating systems (Computers), Robots Control systems., Robots Programming.}
}

@book{joseph_learning_2018,
	address = {Birmingham, UK},
	edition = {Second edition.},
	title = {Learning robotics using {Python}: design, simulate, program, and prototype an autonomous mobile robot using {ROS}, {OpenCV}, {PCL}, and {Python}},
	isbn = {978-1-78862-997-3},
	shorttitle = {Learning robotics using {Python}},
	url = {https://learning.oreilly.com/library/view/learning-robotics-using/9781788623315/?ar=#toc},
	language = {eng},
	publisher = {Packt Publishing},
	author = {Joseph, Lentin},
	year = {2018},
	keywords = {Automation., Electronic books., Python (Computer program language), Robotics.}
}

@incollection{dalmedico_gpu_2019,
	address = {Cham},
	series = {Studies in {Computational} {Intelligence}},
	title = {{GPU} and {ROS} the {Use} of {General} {Parallel} {Processing} {Architecture} for {Robot} {Perception}},
	isbn = {978-3-319-91590-6},
	url = {https://doi.org/10.1007/978-3-319-91590-6_12},
	abstract = {This chapter presents a full tutorial on how to get started on performing parallel processing with ROS. The chapter starts with a guide on how to install the complete version of ROS on the Nvidia development boards Tegra K1, Tegra X1 and Tegra X2. The tutorial includes a guide on how to update the development boards with the latest OS, and configuring CUDA, ROS and OpenCV4Tegra so that they are ready to perform the sample packages included in this chapter. The chapter follows with a description on how to install CUDA in a computer with Ubuntu operating system. After that, the integration between ROS and CUDA is covered, with many examples on how to create packages and perform parallel processing over several of the most used ROS message types. The codes and examples presented on this chapter are available in GitHub and can be found under the repository in https://github.com/air-lasca/ros-cuda.},
	language = {en},
	urldate = {2019-05-02},
	booktitle = {Robot {Operating} {System} ({ROS}): {The} {Complete} {Reference} ({Volume} 3)},
	publisher = {Springer International Publishing},
	author = {Dalmedico, Nicolas and Simões Teixeira, Marco Antônio and Barbosa, Higor Santos and de Oliveira, André Schneider and Ramos de Arruda, Lucia Valeria and Neves Jr, Flavio},
	editor = {Koubaa, Anis},
	year = {2019},
	doi = {10.1007/978-3-319-91590-6_12},
	keywords = {CUDA, GPU, Parallel processing, ROS},
	pages = {407--448}
}

@incollection{ladosz_generic_2019,
	address = {Cham},
	series = {Studies in {Computational} {Intelligence}},
	title = {A {Generic} {ROS} {Based} {System} for {Rapid} {Development} and {Testing} of {Algorithms} for {Autonomous} {Ground} and {Aerial} {Vehicles}},
	isbn = {978-3-319-91590-6},
	url = {https://doi.org/10.1007/978-3-319-91590-6_4},
	abstract = {This chapter presents a Robot Operating System (ROS) framework for development and testing of autonomous control functions. The developed system offers the user significantly reduced development times over prior methods. Previously, development of a new function from theory to flight test required a range of different test systems which offered minimal integration; this would have required great effort and expense. A generic system has been developed that can operate a large range of robotic systems. By design, a developed controller can be taken from numerical simulation, through Software/Hardware in the loop simulation to flight test, with no adjustment of code required. The flexibility and power of ROS was combined with the Robotic Systems toolbox from MATLAB/Simulink, Linux embedded systems and a commercially available autopilot. This affords the user a low cost, simple, highly flexible and reconfigurable system. Furthermore, by separating experimental controllers from the autopilot at the hardware level, flight safety is maintained as manual override is available at all times, regardless of faults in any experimental systems. This chapter details the system and demonstrates the functionality with two case studies.},
	language = {en},
	urldate = {2019-05-02},
	booktitle = {Robot {Operating} {System} ({ROS}): {The} {Complete} {Reference} ({Volume} 3)},
	publisher = {Springer International Publishing},
	author = {Ladosz, Pawel and Coombes, Matthew and Smith, Jean and Hutchinson, Michael},
	editor = {Koubaa, Anis},
	year = {2019},
	doi = {10.1007/978-3-319-91590-6_4},
	pages = {113--153}
}

@article{escobaralvarez_r-advance:_2018,
	title = {R-{ADVANCE}: {Rapid} {Adaptive} {Prediction} for {Vision}-based {Autonomous} {Navigation}, {Control}, and {Evasion}},
	volume = {35},
	issn = {1556-4967},
	shorttitle = {R-{ADVANCE}},
	url = {http://www.onlinelibrary.wiley.com/doi/abs/10.1002/rob.21744},
	doi = {10.1002/rob.21744},
	abstract = {In this article, we present a monocular visual reactive navigation system capable of navigating at high speeds, without GPS, in unknown complex cluttered environments. The system, called R-ADVANCE (Rapid Adaptive Prediction for Vision-based Autonomous Navigation, Control, and Evasion), consists of a set of biologically inspired visual perception and reactive control algorithms that provide low-computation reactive obstacle avoidance while navigating at high speeds in search of a goal object. These algorithms, along with basic planning, and augmented with low-precision visual odometry, were implemented on a micro unmanned aerial vehicle and tested in a number of challenging environments. While each of the individual algorithmic and hardware elements has been previously studied in limited environments, this work is the first time that these novel components have been integrated and flight-tested. To achieve fast flight, an NVIDIA Tegra TK1 was used as the main processor, allowing us to parallelize the system to process 1280 × 720 video streams at 40 fps, reaching flight speeds up to 19 m/s (≈68 km/h) or 42 mph.},
	language = {en},
	number = {1},
	urldate = {2019-05-02},
	journal = {Journal of Field Robotics},
	author = {Escobar‐Alvarez, Hector D. and Johnson, Neil and Hebble, Tom and Klingebiel, Karl and Quintero, Steven A. P. and Regenstein, Jacob and Browning, N. Andrew},
	year = {2018},
	keywords = {GPS-denied, High-speed, Obstacle avoidance, aerial robotics, perception},
	pages = {91--100}
}

@misc{noauthor_nlp_2019,
	title = {nlp - {How} to find distance between two synset using python nltk in wordnet hierarchy?},
	url = {https://stackoverflow.com/questions/22031968/how-to-find-distance-between-two-synset-using-python-nltk-in-wordnet-hierarchy},
	urldate = {2019-05-02},
	journal = {Stack Overflow},
	month = may,
	year = {2019}
}

@phdthesis{talbot_integrating_2018,
	type = {phd},
	title = {Integrating symbolic spatial information in robot navigation},
	url = {https://eprints.qut.edu.au/121191/},
	abstract = {Navigation cues – like labels, signs, maps, planners, spoken directions, and navigational gestures – provide humans with navigation capabilities that far surpass those of mobile robots. This thesis demonstrates how a mobile robot can use the symbolic spatial information embedded in navigation cues to proficiently navigate unseen built environments. The primary contributions of the thesis reside in the abstract map, a novel tool for grounding navigation symbols. The abstract map imagines abstract layouts and structures for unseen spaces through a mechanical analogy, then tethers the abstract spatial models with robot perceptions to inform navigation to symbolic goals in built environments.},
	language = {en},
	urldate = {2019-05-02},
	school = {Queensland University of Technology},
	author = {Talbot, Benjamin J.},
	year = {2018}
}

@article{brooks_intelligence_1991,
	title = {Intelligence without representation},
	volume = {47},
	issn = {0004-3702},
	url = {http://www.sciencedirect.com/science/article/pii/000437029190053M},
	doi = {10.1016/0004-3702(91)90053-M},
	abstract = {Artificial intelligence research has foundered on the issue of representation. When intelligence is approached in an incremental manner, with strict reliance on interfacing to the real world through perception and action, reliance on representation disappears. In this paper we outline our approach to incrementally building complete intelligent Creatures. The fundamental decomposition of the intelligent system is not into independent information processing units which must interface with each other via representations. Instead, the intelligent system is decomposed into independent and parallel activity producers which all interface directly to the world through perception and action, rather than interface to each other particularly much. The notions of central and peripheral systems evaporate—everything is both central and peripheral. Based on these principles we have built a very successful series of mobile robots which operate without supervision as Creatures in standard office environments.},
	number = {1},
	urldate = {2019-05-02},
	journal = {Artificial Intelligence},
	author = {Brooks, Rodney A.},
	month = jan,
	year = {1991},
	pages = {139--159}
}

@misc{noauthor_caffe_2019,
	title = {Caffe in {Jetson} {Nano}},
	url = {https://www.hackster.io/SeeedStudio/caffe-in-jetson-nano-9f4335},
	abstract = {We can install Caffe, a commonly used deep learning framework, onto the Jetson Nano. By Seeed.},
	language = {en},
	urldate = {2019-05-01},
	journal = {Hackster.io},
	month = may,
	year = {2019}
}

@misc{brownlee_gentle_2019,
	title = {A {Gentle} {Introduction} to the {ImageNet} {Large} {Scale} {Visual} {Recognition} {Challenge} ({ILSVRC})},
	url = {https://machinelearningmastery.com/introduction-to-the-imagenet-large-scale-visual-recognition-challenge-ilsvrc/},
	abstract = {The rise in popularity and use of deep learning neural network techniques can be traced back to the innovations in the application of convolutional neural networks to image classification tasks. Some of the most important innovations have sprung from submissions by academics and industry leaders to the ImageNet Large Scale Visual Recognition Challenge, or ILSVRC. …},
	language = {en-US},
	urldate = {2019-05-01},
	journal = {Machine Learning Mastery},
	author = {Brownlee, Jason},
	month = apr,
	year = {2019}
}

@misc{noauthor_learn_2019,
	title = {Learn {LaTeX} in 30 minutes},
	url = {https://de.overleaf.com/learn/latex/Learn_LaTeX_in_30_minutes},
	abstract = {Ein einfach bedienbarer Online-LaTeX-Editor. Keine Installation notwendig, Zusammenarbeit in Echtzeit, Versionskontrolle, Hunderte von LaTeX-Vorlagen und mehr},
	language = {de},
	urldate = {2019-05-01},
	month = may,
	year = {2019}
}

@inproceedings{luddecke_learning_2017,
	title = {Learning to {Segment} {Affordances}},
	doi = {10.1109/ICCVW.2017.96},
	abstract = {The goal of this work is to densely predict a comparatively large set of affordances given only single RGB images. We approach this task by using a convolutional neural network based on the well-known ResNet architecture, which we blend with refinement modules recently proposed in the semantic segmentation literature. A novel cost function, capable of handling incomplete data, is introduced, which is necessary because we make use of segmentations of objects and their parts to generate affordance maps. We demonstrate both, quantitatively and qualitatively, that learning a dense predictor of affordances from an object part dataset is indeed possible and show that our model outperforms several baselines.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} {Workshops} ({ICCVW})},
	author = {Lüddecke, T. and Wörgötter, F.},
	month = oct,
	year = {2017},
	keywords = {Computer architecture, Computer vision, Cost function, Image segmentation, Predictive models, RGB images, ResNet architecture, Training, affordance maps, convolutional neural network, dense predictor, image colour analysis, image segmentation, incomplete data, learning (artificial intelligence), neural nets, novel cost function, object part dataset, refinement modules, segment affordances learning, semantic segmentation literature},
	pages = {769--776}
}

@misc{darpatv_darpas_2019,
	title = {{DARPA}'s {Fast} {Lightweight} {Autonomy} ({FLA}) {Technology} {Explained}},
	url = {https://www.youtube.com/watch?v=g1HqhCiNdQU},
	urldate = {2019-04-29},
	author = {{DARPAtv}},
	month = apr,
	year = {2019}
}

@inproceedings{schulz_robot_2015,
	title = {Robot navigation using human cues: {A} robot navigation system for symbolic goal-directed exploration},
	shorttitle = {Robot navigation using human cues},
	doi = {10.1109/ICRA.2015.7139313},
	abstract = {In this paper we present for the first time a complete symbolic navigation system that performs goal-directed exploration to unfamiliar environments on a physical robot. We introduce a novel construct called the abstract map to link provided symbolic spatial information with observed symbolic information and actual places in the real world. Symbolic information is observed using a text recognition system that has been developed specifically for the application of reading door labels. In the study described in this paper, the robot was provided with a floor plan and a destination. The destination was specified by a room number, used both in the floor plan and on the door to the room. The robot autonomously navigated to the destination using its text recognition, abstract map, mapping, and path planning systems. The robot used the symbolic navigation system to determine an efficient path to the destination, and reached the goal in two different real-world environments. Simulation results show that the system reduces the time required to navigate to a goal when compared to random exploration.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Schulz, R. and Talbot, B. and Lam, O. and Dayoub, F. and Corke, P. and Upcroft, B. and Wyeth, G.},
	month = may,
	year = {2015},
	keywords = {Cameras, Navigation, Robot kinematics, Robot sensing systems, Text recognition, Transforms, abstract map, human cues, mobile robots, navigation, path planning, path planning systems, robot navigation system, robot vision, symbolic goal-directed exploration, symbolic navigation system, symbolic spatial information, text detection, text recognition system},
	pages = {1100--1105}
}

@article{meng_mobile_1993,
	title = {Mobile robot navigation using neural networks and nonmetrical environmental models},
	volume = {13},
	issn = {1066-033X},
	doi = {10.1109/37.236323},
	abstract = {A reasoning and control architecture for vision-guided navigation that makes a robot more humanlike is presented. This system, called NEURO-NAV, discards the more traditional geometrical representation of the environment, and instead uses a semantically richer nonmetrical representation in which a hallway is modeled by the order of appearance of various landmarks and by adjacency relationships. With such a representation, it becomes possible for the robot to respond to commands such as, 'follow the corridor and turn right at the second T junction'. This capability is achieved by an ensemble of neural networks whose activation and deactivation are controlled by a rule-based supervisory controller. The individual neural networks in the ensemble are trained to interpret visual information and perform primitive navigational tasks such as hallway following and landmark detection.{\textless}{\textgreater}},
	number = {5},
	journal = {IEEE Control Systems Magazine},
	author = {Meng, M. and Kak, A. C.},
	month = oct,
	year = {1993},
	keywords = {Data mining, Humans, Indoor environments, Mobile robots, NEURO-NAV, Navigation, Neural networks, Robot kinematics, Robot vision systems, Robust control, Solid modeling, adjacency relationships, computer vision, computerised navigation, hallway following, intelligent control, landmark detection, mobile robot navigation, mobile robots, neural nets, neural networks, nonmetrical environmental models, nonmetrical representation, rule-based supervisory controller},
	pages = {30--39}
}

@inproceedings{sunderhauf_place_2016,
	title = {Place categorization and semantic mapping on a mobile robot},
	doi = {10.1109/ICRA.2016.7487796},
	abstract = {In this paper we focus on the challenging problem of place categorization and semantic mapping on a robot without environment-specific training. Motivated by their ongoing success in various visual recognition tasks, we build our system upon a state-of-the-art convolutional network. We overcome its closed-set limitations by complementing the network with a series of one-vs-all classifiers that can learn to recognize new semantic classes online. Prior domain knowledge is incorporated by embedding the classification system into a Bayesian filter framework that also ensures temporal coherence. We evaluate the classification accuracy of the system on a robot that maps a variety of places on our campus in real-time. We show how semantic information can boost robotic object detection performance and how the semantic map can be used to modulate the robot's behaviour during navigation tasks. The system is made available to the community as a ROS module.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Sünderhauf, N. and Dayoub, F. and McMahon, S. and Talbot, B. and Schulz, R. and Corke, P. and Wyeth, G. and Upcroft, B. and Milford, M.},
	month = may,
	year = {2016},
	keywords = {Bayes methods, Bayesian filter framework, Benchmark testing, Computer vision, ROS module, SLAM (robots), Semantics, Training, Visualization, classification system, closed-set limitation, convolutional network, domain knowledge, image classification, image filtering, learning, learning (artificial intelligence), mobile robot, mobile robots, navigation, navigation task, neural nets, object detection, place categorization, robot behaviour, robotic object detection performance, semantic class recognition, semantic information, semantic mapping, temporal coherence, visual recognition},
	pages = {5729--5736}
}

@misc{noauthor_uc_2019,
	title = {{UC} {Berkley} - {Deep} {RL} {Course}},
	url = {http://rail.eecs.berkeley.edu/deeprlcourse/},
	urldate = {2019-04-29},
	month = apr,
	year = {2019}
}

@misc{john_software_2019,
	title = {Software development best practices in a deep learning environment},
	url = {https://towardsdatascience.com/software-development-best-practices-in-a-deep-learning-environment-a1769e9859b1},
	abstract = {Software development: best practices in a deep learning environment},
	urldate = {2019-04-24},
	journal = {Towards Data Science},
	author = {John, Per},
	month = apr,
	year = {2019}
}

@misc{noauthor_autoencoders:_2019,
	title = {Autoencoders: {Deep} {Learning} with {TensorFlow}'s {Eager} {API}},
	shorttitle = {Autoencoders},
	url = {http://www.datastuff.tech/machine-learning/autoencoder-deep-learning-tensorflow-eager-api-keras/},
	abstract = {What is an Autoencoder? Can we apply it to image compression? How well can a Deep Learning algorithm reconstruct pictures of kittens? Find out here.},
	language = {en-US},
	urldate = {2019-04-24},
	journal = {Data Stuff},
	month = apr,
	year = {2019}
}

@misc{kirschte_building_2019,
	title = {Building a {Turing} {Machine} with {Reinforcement} {Learning}},
	url = {https://towardsdatascience.com/building-a-turing-machine-with-reinforcement-learning-9d06a4f0ce6},
	abstract = {beyond manual algorithmic design},
	urldate = {2019-04-24},
	journal = {Towards Data Science},
	author = {Kirschte, Moritz},
	month = apr,
	year = {2019}
}

@misc{seif_5_2019,
	title = {5 {Advanced} {Features} of {Python} and {How} to {Use} {Them}},
	url = {https://towardsdatascience.com/5-advanced-features-of-python-and-how-to-use-them-73bffa373c84},
	abstract = {Python is a beautiful language. Simple to use yet powerfully expressive. But are you using everything that it has to offer?},
	urldate = {2019-04-24},
	journal = {Towards Data Science},
	author = {Seif, George},
	month = apr,
	year = {2019}
}

@misc{noauthor_getting_2019,
	title = {Getting started with {Jetson} {Nano} and {Autonomous} {Donkey} car},
	url = {https://medium.com/@feicheung2016/getting-started-with-jetson-nano-and-autonomous-donkey-car-d4f25bbd1c83},
	urldate = {2019-04-24},
	month = apr,
	year = {2019}
}

@misc{noauthor_ultimate_2019,
	title = {Ultimate {Guide} to {TensorFlow} 2.0 in {Python}},
	url = {https://rubikscode.net/2019/04/22/ultimate-guide-to-tensorflow-2-0-in-python/},
	urldate = {2019-04-24},
	month = apr,
	year = {2019}
}

@misc{rosebrock_segmentation:_2014,
	title = {Segmentation: {A} {SLIC} {Superpixel} {Tutorial} using {Python}},
	shorttitle = {Segmentation},
	url = {https://www.pyimagesearch.com/2014/07/28/a-slic-superpixel-tutorial-using-python/},
	abstract = {So, what's a superpixel? And how do you apply SLIC to automatically segment your images? Don't worry. This post has you covered with tons of code examples.},
	language = {en-US},
	urldate = {2019-04-24},
	journal = {PyImageSearch},
	author = {Rosebrock, Adrian},
	month = jul,
	year = {2014}
}

@inproceedings{gat_three-layer_2001,
	title = {On {Three}-{Layer} {Architectures}},
	abstract = {ion is used as a tool to isolate aspects of reality that can be tracked or predicted reliably, and ignore aspects that cannot. 3. The Anatomy of the Three Layer Architecture The three-layer architecture consists of three components: a reactive feedback control mechanism, a reactive plan execution mechanism, and a mechanism for performing time-consuming deliberative computations. These components run as separate computational processes. This is most easily accomplished by using a multi-tasking or multithreaded operating system, but can also be done my carefully coding the algorithms so they can be manually interleaved within a single computational process. In 3T the components are called the skill layer, the sequencing layer, and the planning layer respectively. In ATLANTIS these layers are called the controller, the sequencer, and the deliberator. The following discussion uses the ATLANTIS terminology, but as much as possible the description is generic to all incarnations of the three-layer architecture.},
	author = {Gat, Erann and Murphy, Robin R.},
	year = {2001},
	keywords = {Algorithm, Architecture as Topic, Biopolymer Sequencing, Categories, Computation, Computer multitasking, Feedback, Fertility, Ions, Microsequencer, Mobile robot, Nomenclature, Operating system, Programming Languages, Programming language, Programming, Linear, Retrospect (software), Robot control, Situated, Three-layer architecture, anatomical layer}
}

@misc{noauthor_structuring_2019,
	title = {Structuring {Your} {Project} — {The} {Hitchhiker}'s {Guide} to {Python}},
	url = {https://docs.python-guide.org/writing/structure},
	urldate = {2019-04-24},
	month = apr,
	year = {2019}
}

@misc{noauthor_dead_2019,
	title = {Dead {Simple} {Python}: {Project} {Structure} and {Imports}},
	shorttitle = {Dead {Simple} {Python}},
	url = {https://dev.to/codemouse92/dead-simple-python-project-structure-and-imports-38c6},
	abstract = {Any real world Python project has multiple code files...but how do you even get them to play together?},
	language = {en},
	urldate = {2019-04-24},
	journal = {The Practical Dev},
	month = apr,
	year = {2019}
}
@misc{noauthor_isaac_2019,
	title = {Isaac {SDK}},
	url = {https://developer.nvidia.com/isaac-sdk},
	abstract = {The NVIDIA® Isaac Software Development Kit (SDK) is a developer toolbox for accelerating the development and deployment of AI-powered robots. The SDK includes the Isaac Robot Engine, packages with high-performance robotics algorithms, and hardware reference applications. It will accelerate robot development for manufacturers, researchers and startups by making it easier to add AI for perception and navigation into next-generation robots.},
	language = {en},
	urldate = {2019-04-23},
	journal = {NVIDIA Developer},
	month = mar,
	year = {2019}
}

@inproceedings{perez_lqr-rrt*:_2012,
	title = {{LQR}-{RRT}*: {Optimal} sampling-based motion planning with automatically derived extension heuristics},
	shorttitle = {{LQR}-{RRT}*},
	doi = {10.1109/ICRA.2012.6225177},
	abstract = {The RRT* algorithm has recently been proposed as an optimal extension to the standard RRT algorithm [1]. However, like RRT, RRT* is difficult to apply in problems with complicated or underactuated dynamics because it requires the design of a two domain-specific extension heuristics: a distance metric and node extension method. We propose automatically deriving these two heuristics for RRT* by locally linearizing the domain dynamics and applying linear quadratic regulation (LQR). The resulting algorithm, LQR-RRT*, finds optimal plans in domains with complex or underactuated dynamics without requiring domain-specific design choices. We demonstrate its application in domains that are successively torque-limited, underactuated, and in belief space.},
	booktitle = {2012 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Perez, A. and Platt, R. and Konidaris, G. and Kaelbling, L. and Lozano-Perez, T.},
	month = may,
	year = {2012},
	keywords = {Convergence, Cost function, Heuristic algorithms, LQR-RRT, Measurement, Planning, Standards, Trajectory, automatically derived extension heuristics, distance metric, domain dynamics, domain-specific extension heuristics, linear quadratic control, linear quadratic regulation, node extension method, optimal sampling-based motion planning, path planning, sampling methods, underactuated dynamics},
	pages = {2537--2542}
}

@misc{noauthor_semantic_2019,
	title = {Semantic {Segmentation} {Using} {Deep} {Learning} - {MATLAB} \& {Simulink} - {MathWorks} {Australia}},
	url = {https://au.mathworks.com/help/vision/examples/semantic-segmentation-using-deep-learning.html},
	urldate = {2019-04-23},
	month = apr,
	year = {2019}
}

@article{hayes-roth_cognitive_1979,
	title = {A cognitive model of planning},
	volume = {3},
	issn = {0364-0213},
	url = {http://www.sciencedirect.com/science/article/pii/S0364021379800105},
	doi = {10.1016/S0364-0213(79)80010-5},
	abstract = {This paper presents a cognitive model of the planning process. The model generalizes the theoretical architecture of the Hearsay-II system. Thus, it assumes that planning comprises the activities of a variety of cognitive “specialists.” Each specialist can suggest certain kinds of decisions for incorporation into the plan in progress. These include decisions about: (a) how to approach the planning problem; (b) what knowledge bears on the problem; (c) what kinds of actions to try to plan; (d) what specific actions to plan; and (e) how to allocate cognitive resources during planning. Within each of these categories, different specialists suggest decisions at different levels of abstraction. The activities of the various specialists are not coordinated in any systematic way. Instead, the specialists operate opportunistically, suggesting decisions whenever promising opportunities arise. The paper presents a detailed account of the model and illustrates its assumptions with a “thinking aloud” protocol. It also describes the performance of a computer simulation of the model. The paper contrasts the proposed model with successive refinement models and attempts to resolve apparent differences between the two points of view.},
	number = {4},
	urldate = {2019-04-23},
	journal = {Cognitive Science},
	author = {Hayes-Roth, Barbara and Hayes-Roth, Frederick},
	month = oct,
	year = {1979},
	pages = {275--310}
}

@article{devries_learning_2018,
	title = {Learning {Confidence} for {Out}-of-{Distribution} {Detection} in {Neural} {Networks}},
	url = {https://arxiv.org/abs/1802.04865v1},
	abstract = {Modern neural networks are very powerful predictive models, but they are
often incapable of recognizing when their predictions may be wrong. Closely
related to this is the task of out-of-distribution detection, where a network
must determine whether or not an input is outside of the set on which it is
expected to safely perform. To jointly address these issues, we propose a
method of learning confidence estimates for neural networks that is simple to
implement and produces intuitively interpretable outputs. We demonstrate that
on the task of out-of-distribution detection, our technique surpasses recently
proposed techniques which construct confidence based on the network's output
distribution, without requiring any additional labels or access to
out-of-distribution examples. Additionally, we address the problem of
calibrating out-of-distribution detectors, where we demonstrate that
misclassified in-distribution examples can be used as a proxy for
out-of-distribution examples.},
	language = {en},
	urldate = {2019-04-23},
	author = {DeVries, Terrance and Taylor, Graham W.},
	month = feb,
	year = {2018}
}

@article{miller_dropout_2017,
	title = {Dropout {Sampling} for {Robust} {Object} {Detection} in {Open}-{Set} {Conditions}},
	url = {https://arxiv.org/abs/1710.06677v2},
	abstract = {Dropout Variational Inference, or Dropout Sampling, has been recently
proposed as an approximation technique for Bayesian Deep Learning and evaluated
for image classification and regression tasks. This paper investigates the
utility of Dropout Sampling for object detection for the first time. We
demonstrate how label uncertainty can be extracted from a state-of-the-art
object detection system via Dropout Sampling. We evaluate this approach on a
large synthetic dataset of 30,000 images, and a real-world dataset captured by
a mobile robot in a versatile campus environment. We show that this uncertainty
can be utilized to increase object detection performance under the open-set
conditions that are typically encountered in robotic vision. A Dropout Sampling
network is shown to achieve a 12.3\% increase in recall (for the same precision
score as a standard network) and a 15.1\% increase in precision (for the same
recall score as the standard network).},
	language = {en},
	urldate = {2019-04-23},
	author = {Miller, Dimity and Nicholson, Lachlan and Dayoub, Feras and Sünderhauf, Niko},
	month = oct,
	year = {2017}
}

@misc{noauthor_analytic_2017,
	title = {Analytic hierarchy process – car example},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Analytic_hierarchy_process_%E2%80%93_car_example&oldid=809666603},
	abstract = {This is a worked-through example showing the use of the analytic hierarchy process (AHP) in a practical decision situation.
See Analytic hierarchy process\#Practical examples for context for this example.},
	language = {en},
	urldate = {2019-04-18},
	journal = {Wikipedia},
	month = nov,
	year = {2017},
	note = {Page Version ID: 809666603}
}

@misc{noauthor_academic_2019,
	title = {Academic {Phrasebank}},
	url = {http://www.phrasebank.manchester.ac.uk/},
	urldate = {2019-04-18},
	month = apr,
	year = {2019}
}

@misc{noauthor_visualdata_2019,
	title = {{VisualData}},
	url = {https://www.visualdata.io/},
	abstract = {Search engine for computer vision datasets},
	language = {en},
	urldate = {2019-04-18},
	journal = {VisualData},
	month = apr,
	year = {2019}
}

@misc{researcher_how_2019,
	title = {How {I} planned my meals with {Reinforcement} {Learning} on a budget},
	url = {https://medium.freecodecamp.org/how-i-planned-my-meals-with-reinforcement-learning-on-a-budget-a82aac906ada},
	abstract = {Following my recent article on applying Reinforcement Learning to real life problems, I decided to demonstrate this with a small example.},
	urldate = {2019-04-17},
	journal = {freeCodeCamp.org},
	author = {Researcher, PhD, Sterling Osborne},
	month = apr,
	year = {2019}
}

@misc{noauthor_matlab_2019,
	title = {{MATLAB} and {Simulink} {Robotics} {Arena}: {Deep} {Learning} with {NVIDIA} {Jetson} and {ROS} {Video}},
	shorttitle = {{MATLAB} and {Simulink} {Robotics} {Arena}},
	url = {https://au.mathworks.com/videos/matlab-and-simulink-robotics-arena-deep-learning-with-nvidia-jetson-and-ros--1542015526909.html},
	abstract = {Learn how GPU Coder can be used to deploy deep learning algorithms from MATLAB to embedded NVIDIA GPUs, and how the deployed code can be used with the Robot Operating System (ROS).},
	language = {en},
	urldate = {2019-04-17},
	month = apr,
	year = {2019}
}

@article{brooks_robust_1986,
	title = {A robust layered control system for a mobile robot},
	volume = {2},
	issn = {0882-4967},
	doi = {10.1109/JRA.1986.1087032},
	abstract = {A new architecture for controlling mobile robots is described. Layers of control system are built to let the robot operate at increasing levels of competence. Layers are made up of asynchronous modules that communicate over low-bandwidth channels. Each module is an instance of a fairly simple computational machine. Higher-level layers can subsume the roles of lower levels by suppressing their outputs. However, lower levels continue to function as higher levels are added. The result is a robust and flexible robot control system. The system has been used to control a mobile robot wandering around unconstrained laboratory areas and computer machine rooms. Eventually it is intended to control a robot that wanders the office areas of our laboratory, building maps of its surroundings using an onboard arm to perform simple tasks.},
	number = {1},
	journal = {IEEE Journal on Robotics and Automation},
	author = {Brooks, R.},
	month = mar,
	year = {1986},
	keywords = {Acoustic sensors, Boundary conditions, Control systems, Hierarchical systems, Infrared sensors, Laboratories, Mobile robots, Robot control, Robot sensing systems, Robotics and automation, Robots, locomotion, Robust control, Robustness},
	pages = {14--23}
}

@article{andert_optical-aided_2017,
	title = {Optical-{Aided} {Aircraft} {Navigation} using {Decoupled} {Visual} {SLAM} with {Range} {Sensor} {Augmentation}},
	volume = {88},
	issn = {1573-0409},
	url = {https://doi.org/10.1007/s10846-016-0457-6},
	doi = {10.1007/s10846-016-0457-6},
	abstract = {This paper presents an optical-aided navigation method for automatic flights where satellite navigation might be disturbed. The proposed solution follows common approaches where satellite position updates are replaced with measurements from environment sensors such as a camera, lidar or radar as required. The alternative positioning is determined by a localization and mapping (SLAM) algorithm that handles 2D feature inputs from monocular camera images as well as 3D inputs from camera images that are augmented by range measurements. The method requires neither known landmarks nor a globally flat terrain. Beside the visual SLAM algorithm, the paper describes how to generate 3D feature inputs from lidar and radar sources and how to benefit from both monocular triangulation and 3D features. Regarding state estimation, the approach decouples visual SLAM from the filter updates. This allows software and hardware separation, i.e. visual SLAM computations on powerful hardware while the main filter can be installed on real-time hardware with possible lower capabilities. The localization quality in case of satellite dropouts is tested with data sets from manned and unmanned flights with different sensors while keeping all parameters constant. The tests show the applicability of this method in flat and hilly terrain and with different path lengths from few hundred meters to many kilometers. The relative navigation achieves an accumulation error of 1–6 \% of distance traveled depending on the flight scenario. In addition to the flights, the paper discusses flight profile limitations when optical navigation methods are used.},
	language = {en},
	number = {2},
	urldate = {2019-04-16},
	journal = {Journal of Intelligent \& Robotic Systems},
	author = {Andert, Franz and Ammann, Nikolaus and Krause, Stefan and Lorenz, Sven and Bratanov, Dmitry and Mejias, Luis},
	month = dec,
	year = {2017},
	keywords = {Optical-aided navigation, Sensor fusion, Simultaneous localization and mapping, Unmanned aircraft},
	pages = {547--565}
}

@misc{noauthor_bitter_2019,
	title = {The {Bitter} {Lesson}},
	url = {http://www.incompleteideas.net/IncIdeas/BitterLesson.html},
	urldate = {2019-04-16},
	month = apr,
	year = {2019}
}

@article{arkin_integrating_1990,
	series = {Designing {Autonomous} {Agents}},
	title = {Integrating behavioral, perceptual, and world knowledge in reactive navigation},
	volume = {6},
	issn = {0921-8890},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889005800314},
	doi = {10.1016/S0921-8890(05)80031-4},
	abstract = {Reactive navigation based on task decomposition is an effective means for producing robust navigation in complex domains. By incorporating various forms of knowledge, this technique can be made considerably more flexible. Behavioral and perceptual strategies which are represented in a modular form and configured to meet the robot's mission and environment add considerable versatility. A priori world knowledge, when available, can be used to configure these strategies in an efficient form. Dynamically acquired world models can be used to circumvent certain pitfalls that representationless methods are subject to. The Autonomous Robot Architecture (AuRA) is the framework within which experiments in the application of knowledge to reactive control are conducted. Actual robot experiments and simulation studies demonstrate the flexibility and feasibility of this approach over a wide range of navigational domains.},
	number = {1},
	urldate = {2019-04-16},
	journal = {Robotics and Autonomous Systems},
	author = {Arkin, Ronald C.},
	month = jun,
	year = {1990},
	keywords = {Artificial intelligence, Knowledge-based systems, Mobile robots, Reactive control, Schemas},
	pages = {105--122}
}

@inproceedings{connell_sss:_1992,
	title = {{SSS}: a hybrid architecture applied to robot navigation},
	shorttitle = {{SSS}},
	doi = {10.1109/ROBOT.1992.219995},
	abstract = {Describes a three-layer architecture, SSS, for robot control. It combines a servo-control layer, a subsumption layer, and a symbolic layer in a way that allows the advantages of each technique to be fully exploited. The key to this synergy is the interface between the individual subsystems. The design of situation recognizers that bridge the gap between the servo and subsumption layers, and event detectors that link the subsumption layers and symbolic layers are discussed. The development of such a combined system is illustrated by a fully implemented indoor navigation example. The resulting robot was able to automatically map office building environments, and smoothly navigate through them at the rapid speed of 2.6 feet per second.{\textless}{\textless}ETX{\textgreater}{\textgreater}},
	booktitle = {Proceedings 1992 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Connell, J. H.},
	month = may,
	year = {1992},
	keywords = {Bridges, Control systems, Detectors, Event detection, Navigation, Robot control, Robotics and automation, SSS, Servomechanisms, Servosystems, Space technology, computerised navigation, event detectors, hybrid architecture, indoor navigation, mobile robots, office building environments, robot navigation, servo-control layer, servomechanisms, situation recognizers, subsumption layer, symbolic layer, three-layer architecture},
	pages = {2719--2724 vol.3}
}

@article{mendonca_subsumption_2013,
	title = {A {Subsumption} {Architecture} to {Develop} {Dynamic} {Cognitive} {Network}-{Based} {Models} {With} {Autonomous} {Navigation} {Application}},
	volume = {24},
	issn = {2195-3899},
	url = {https://doi.org/10.1007/s40313-013-0008-3},
	doi = {10.1007/s40313-013-0008-3},
	abstract = {This work proposes an original approach based on subsumption architecture to build dynamic cognitive networks (DCN). Dynamic cognitive network is a soft computing technique similar to fuzzy cognitive maps (FCM) which are able to easily model cause–effect behaviors. FCMs have been applied in several areas of knowledge; however, they present some restrictions for modeling dynamic systems, specifically temporal dependencies among events. Due to these restrictions, alternative approaches based on FCM and also fuzzy networks have appeared in the literature. Dynamic cognitive networks are one of these techniques. Hence, this study presents a new type of DCN which incorporates different types of concepts and causal relations able to circumvent the main drawbacks of FCM modeling. The new approach is based on the subsumption architecture, which allows to represent, model, and implement several behaviors of a dynamic systems through a composition of hierarchical DCNs. An application of the new DCN technique in autonomous navigation is also developed in order to validate the approach.},
	language = {en},
	number = {1},
	urldate = {2019-04-16},
	journal = {Journal of Control, Automation and Electrical Systems},
	author = {Mendonça, Márcio and Angélico, Bruno Augusto and de Arruda, Lúcia Valéria Ramos and Neves, Flávio},
	month = apr,
	year = {2013},
	keywords = {Autonomous navigation, Dynamic cognitive network, Fuzzy cognitive map, Subsumption architecture},
	pages = {117--128}
}

@article{das_neural_2018,
	title = {Neural {Modular} {Control} for {Embodied} {Question} {Answering}},
	url = {http://arxiv.org/abs/1810.11181},
	abstract = {We present a modular approach for learning policies for navigation over long planning horizons from language input. Our hierarchical policy operates at multiple timescales, where the higher-level master policy proposes subgoals to be executed by specialized sub-policies. Our choice of subgoals is compositional and semantic, i.e. they can be sequentially combined in arbitrary orderings, and assume human-interpretable descriptions (e.g. 'exit room', 'find kitchen', 'find refrigerator', etc.). We use imitation learning to warm-start policies at each level of the hierarchy, dramatically increasing sample efficiency, followed by reinforcement learning. Independent reinforcement learning at each level of hierarchy enables sub-policies to adapt to consequences of their actions and recover from errors. Subsequent joint hierarchical training enables the master policy to adapt to the sub-policies.},
	urldate = {2019-04-16},
	journal = {arXiv:1810.11181 [cs]},
	author = {Das, Abhishek and Gkioxari, Georgia and Lee, Stefan and Parikh, Devi and Batra, Dhruv},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.11181},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning}
}

@inproceedings{sheppard_real-time_2017,
	title = {Real-time scene understanding for {UAV} imagery based on deep convolutional neural networks},
	doi = {10.1109/IGARSS.2017.8127435},
	abstract = {Real-time scene understanding is important for many applications of Unmanned Aerial Vehicles (UAVs) such as reconnaissance, surveillance, mapping, and infrastructure inspection. With the recent growth of computation power, it is feasible to use Deep Learning for real-time applications. Deep Convolutional Neural Networks (CNNs) have emerged as a powerful model for classifying image content, and are widely considered in the computer vision community to be the de facto standard approach for most problems. Current Deep learning approaches for image classification and object detection are designed and evaluated on lab setting human-centric photographs taken horizontally from a height of 1-2 meters. UAV images are taken vertically in high altitude; therefore the objects of interest are relatively small with a skewed vantage point which creates a real challenge in detection and classification of such images. Here we present a deep convolutional approach for classification of Aerial imagery taken by UAV. We applied our network on optical imagery taken with UAV RS-16 from Port Mansfield, TX. Experimental results in comparison with ground-truth show 93.6 \% accuracy for UAV image classification.},
	booktitle = {2017 {IEEE} {International} {Geoscience} and {Remote} {Sensing} {Symposium} ({IGARSS})},
	author = {Sheppard, C. and Rahnemoonfar, M.},
	month = jul,
	year = {2017},
	keywords = {Aerial imagery, Current Deep learning approaches, Economic indicators, UAV RS-16, UAV image classification, UAV imagery, UAV images, Unmanned Aerial Vehicles, autonomous aerial vehicles, computer vision, computer vision community, convolution, deep convolutional approach, deep convolutional neural networks, image classification, image content, learning (artificial intelligence), neural nets, object detection, optical imagery, real-time scene understanding},
	pages = {2243--2246}
}

@misc{matlab_control_2019,
	title = {Control {Systems} in {Practice}, {Part} 1: {What} {Control} {Systems} {Engineers} {Do}},
	shorttitle = {Control {Systems} in {Practice}, {Part} 1},
	url = {https://www.youtube.com/watch?v=ApMz1-MK9IQ},
	urldate = {2019-04-15},
	author = {{MATLAB}},
	month = apr,
	year = {2019}
}

@misc{gary_explains_jetson_2019,
	title = {Jetson {Nano} {Review}},
	url = {https://www.youtube.com/watch?v=RpO_a10QmLk},
	urldate = {2019-04-15},
	author = {{Gary Explains}},
	month = apr,
	year = {2019}
}

@mastersthesis{hulbert_biologically_2019,
	address = {United States -- New York},
	title = {Biologically {Inspired} {Autonomous} {Robotic} {Navigation} {Using} {High}-{Level} {Object} {Detection}},
	copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
	url = {http://search.proquest.com/pqdtglobal/docview/2117257580/abstract/734E5D100C304FB1PQ/1},
	abstract = {Caleb Hulbert B.S., Cornell University, 2016 Biologically Inspired Autonomous Robotic Navigation using High-level Object Detection Thesis advisors: Damian Lyons, Ph.D., Daniel Leeds, Ph. D. Autonomous navigation behaviors are observed in almost every animal, including humans. Neurological and behavioral studies alike seek to deconstruct biological navigation into its most basic components. In this thesis, we propose a method for autonomous navigation that makes use of high-level visual features. Namely, we focus on navigation limited to using visual input and associated semantic information. This thesis seeks to show that human-inspired object recognition, when applied in robotics, can provide an effective method for autonomous navigation. We make use of Gazebo robotic simulation software, the ROS robotic operating system, Turtlebot robot software, YOLO (You Only Look Once) object recognition, and SIFT feature extraction to compare navigation results between two methods: The proposed autonomous navigation method, referred to here as “semantic navigation” was compared to a contemporary navigational method known as average-landmark-vector (ALV) navigation using SIFT features as landmarks. The experiment consisted of simulated traversals of randomly chosen paths from a Gazebo world, each traversal consists of multiple place-to-place transitions, whose data have been recorded and analyzed. Results show that semantic navigation outperforms ALV when comparing the accuracy of the end location with respect to the goal, the number of movement iterations required to complete a transition, and the amount of extraneous distance traveled during each transition. These metrics support Semantic Navigation as a viable alternative which outperforms ALV navigation in certain goal-oriented visual homing tasks.},
	language = {English},
	urldate = {2019-04-15},
	school = {Fordham University},
	author = {Hulbert, Caleb},
	year = {2019},
	keywords = {Applied sciences, Autonomous, Biologically, Detection, High-level, Inspired, Navigation, Object, Robotic}
}

@misc{noauthor_how_2019,
	title = {How to {Configure} {Image} {Data} {Augmentation} {When} {Training} {Deep} {Learning} {Neural} {Networks}},
	url = {https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/},
	urldate = {2019-04-15},
	month = apr,
	year = {2019}
}

@misc{noauthor_will_2019,
	title = {Will the {Nvidia} {Jetson} {Nano} {Replace} the {Raspberry} {Pi}?},
	url = {https://www.makeuseof.com/tag/will-nvidia-jetson-nano-replace-raspberry-pi/},
	abstract = {Nvidia is joining the hobby board market, but is the Jetson Nano a replacement for your Raspberry Pi?},
	language = {en-US},
	urldate = {2019-04-15},
	journal = {MakeUseOf},
	month = apr,
	year = {2019}
}

@misc{noauthor_r/machinelearning_2019,
	title = {r/{MachineLearning} - [{D}]{My} {Machine} {Learning} {Journal} \#10: {First} time doing reinforcement learning and beating atari breakout with it},
	shorttitle = {r/{MachineLearning} - [{D}]{My} {Machine} {Learning} {Journal} \#10},
	url = {https://www.reddit.com/r/MachineLearning/comments/bcm681/dmy_machine_learning_journal_10_first_time_doing/},
	abstract = {156 votes and 19 comments so far on Reddit},
	language = {en},
	urldate = {2019-04-15},
	journal = {reddit},
	month = apr,
	year = {2019}
}

@misc{pierre_deep_2019,
	title = {Deep {Blue} {Sea}: {Using} {Deep} {Learning} to {Detect} {Hundreds} of {Different} {Plankton} {Species}},
	shorttitle = {Deep {Blue} {Sea}},
	url = {https://towardsdatascience.com/deep-blue-sea-using-deep-learning-to-detect-hundreds-of-different-plankton-species-dff895d3b226},
	abstract = {Unlocking the power of Keras, Transfer Learning and Ensemble Learning for contributing to the health of the world’s oceans},
	urldate = {2019-04-15},
	journal = {Towards Data Science},
	author = {Pierre, Rafael},
	month = apr,
	year = {2019}
}

@article{muller_sim4cv:_2018,
	title = {{Sim4CV}: {A} {Photo}-{Realistic} {Simulator} for {Computer} {Vision} {Applications}},
	volume = {126},
	issn = {1573-1405},
	shorttitle = {{Sim4CV}},
	url = {https://doi.org/10.1007/s11263-018-1073-7},
	doi = {10.1007/s11263-018-1073-7},
	abstract = {We present a photo-realistic training and evaluation simulator (Sim4CV) (http://www.sim4cv.org) with extensive applications across various fields of computer vision. Built on top of the Unreal Engine, the simulator integrates full featured physics based cars, unmanned aerial vehicles (UAVs), and animated human actors in diverse urban and suburban 3D environments. We demonstrate the versatility of the simulator with two case studies: autonomous UAV-based tracking of moving objects and autonomous driving using supervised learning. The simulator fully integrates both several state-of-the-art tracking algorithms with a benchmark evaluation tool and a deep neural network architecture for training vehicles to drive autonomously. It generates synthetic photo-realistic datasets with automatic ground truth annotations to easily extend existing real-world datasets and provides extensive synthetic data variety through its ability to reconfigure synthetic worlds on the fly using an automatic world generation tool.},
	language = {en},
	number = {9},
	urldate = {2019-04-15},
	journal = {International Journal of Computer Vision},
	author = {Müller, Matthias and Casser, Vincent and Lahoud, Jean and Smith, Neil and Ghanem, Bernard},
	month = sep,
	year = {2018},
	keywords = {Autonomous driving, Deep learning, Imitation learning, Object tracking, Simulator, Unreal Engine 4},
	pages = {902--919}
}

@misc{warden_why_2018,
	title = {Why you need to improve your training data, and how to do it},
	url = {https://petewarden.com/2018/05/28/why-you-need-to-improve-your-training-data-and-how-to-do-it/},
	abstract = {Photo by Lisha Li Andrej Karpathy showed this slide as part of his talk at Train AI and I loved it! It captures the difference between deep learning research and production perfectly. Academic pape…},
	language = {en},
	urldate = {2019-04-15},
	journal = {Pete Warden's blog},
	author = {Warden, Pete},
	month = may,
	year = {2018}
}

@misc{warden_what_2018,
	title = {What {Image} {Classifiers} {Can} {Do} {About} {Unknown} {Objects}},
	url = {https://petewarden.com/2018/07/06/what-image-classifiers-can-do-about-unknown-objects/},
	abstract = {Photo by Brandon Giesbrecht A few days ago I received a question from Plant Village, a team I’m collaborating with about a problem that’s emerged with a mobile app they’re develop…},
	language = {en},
	urldate = {2019-04-15},
	journal = {Pete Warden's blog},
	author = {Warden, Pete},
	month = jul,
	year = {2018}
}

@misc{noauthor_what_2019,
	title = {What {I} learned from competing against a {ConvNet} on {ImageNet}},
	url = {http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/},
	urldate = {2019-04-15},
	month = apr,
	year = {2019}
}

@misc{noauthor_state_2019,
	title = {State {Estimation} {Using} {Time}-{Varying} {Kalman} {Filter} - {MATLAB} \& {Simulink} - {MathWorks} {Australia}},
	url = {https://au.mathworks.com/help/control/getstart/estimating-states-of-time-varying-systems-using-kalman-filters.html},
	urldate = {2019-04-12},
	month = apr,
	year = {2019}
}

@misc{spruyt_geometric_2014,
	title = {A geometric interpretation of the covariance matrix},
	url = {http://www.visiondummy.com/2014/04/geometric-interpretation-covariance-matrix/},
	abstract = {In this article, we provide a geometric interpretation of the covariance matrix, exploring the relation between linear transformations and data covariance.},
	language = {en-US},
	urldate = {2019-04-12},
	journal = {Computer vision for dummies},
	author = {Spruyt, Vincent},
	month = apr,
	year = {2014}
}

@misc{nelson_intro_2019,
	title = {An {Intro} to {Git} and {GitHub} for {Beginners} ({Tutorial})},
	url = {https://product.hubspot.com/blog/git-and-github-tutorial-for-beginners},
	abstract = {Step-by-step tutorial for beginners to get started with git and GitHub.},
	language = {en-us},
	urldate = {2019-04-11},
	author = {Nelson, Meghan},
	month = apr,
	year = {2019}
}

@article{faragher_understanding_2012,
	title = {Understanding the {Basis} of the {Kalman} {Filter} {Via} a {Simple} and {Intuitive} {Derivation} [{Lecture} {Notes}]},
	volume = {29},
	issn = {1053-5888},
	doi = {10.1109/MSP.2012.2203621},
	abstract = {This article provides a simple and intuitive derivation of the Kalman filter, with the aim of teaching this useful tool to students from disciplines that do not require a strong mathematical background. The most complicated level of mathematics required to understand this derivation is the ability to multiply two Gaussian functions together and reduce the result to a compact form.},
	number = {5},
	journal = {IEEE Signal Processing Magazine},
	author = {Faragher, R.},
	month = sep,
	year = {2012},
	keywords = {Gaussian functions, Gaussian processes, Kalman filter, Kalman filters, Mathematics, intuitive derivation, mathematics, teaching},
	pages = {128--132}
}

@inproceedings{angelino_uav_2012,
	title = {{UAV} position and attitude estimation using {IMU}, {GNSS} and camera},
	abstract = {The aim of this paper is to present a method for integration of measurements provided by inertial sensors (gyroscopes and accelerometers), GPS and a video system in order to estimate position and attitude of an UAV (Unmanned Aerial Vehicle). Inertial sensors are widely used for aircraft navigation because they represent a low cost and compact solution, but their measurements suffer of several errors which cause a rapid divergence of position and attitude estimates. To avoid divergence inertial sensors are usually coupled with other systems as for example GNSS (Global Navigation Satellite System). In this paper it is examined the possibility to couple the inertial sensors also with a camera. A camera is generally installed on-board UAVs for surveillance purposes, it presents several advantages with respect to GNSS as for example great accuracy and higher data rate. Moreover, it can be used in urban area or, more in general, where multipath effects can forbid the application of GNSS. A camera, coupled with a video processing system, can provide attitude and position (up to a scale factor), but it has lower data rate than inertial sensors and its measurements have latencies which can prejudice the performances and the effectiveness of the flight control system. The integration of inertial sensors with a camera allows exploiting the better features of both the systems, providing better performances in position and attitude estimation.},
	booktitle = {2012 15th {International} {Conference} on {Information} {Fusion}},
	author = {Angelino, C. V. and Baraniello, V. R. and Cicala, L.},
	month = jul,
	year = {2012},
	keywords = {Aircraft, Cameras, Equations, Estimation, GNSS, GPS, Global Navigation Satellite System, Global Positioning System, IMU, Sensors, UAV, Vectors, accelerometers, aerospace control, aircraft navigation, attitude estimation, attitude measurement, autonomous aerial vehicles, camera, cameras, flight control system, gyroscopes, inertial sensors, position estimation, position measurement, surveillance purposes, unmanned aerial vehicle, video processing system, video system},
	pages = {735--742}
}

@inproceedings{pepperell_all-environment_2014,
	title = {All-environment visual place recognition with {SMART}},
	doi = {10.1109/ICRA.2014.6907067},
	abstract = {This paper presents Sequence Matching Across Route Traversals (SMART); a generally applicable sequence-based place recognition algorithm. SMART provides invariance to changes in illumination and vehicle speed while also providing moderate pose invariance and robustness to environmental aliasing. We evaluate SMART on vehicles travelling at highly variable speeds in two challenging environments; firstly, on an all-terrain vehicle in an off-road, forest track and secondly, using a passenger car traversing an urban environment across day and night. We provide comparative results to the current state-of-the-art SeqSLAM algorithm and investigate the effects of altering SMART's image matching parameters. Additionally, we conduct an extensive study of the relationship between image sequence length and SMART's matching performance. Our results show viable place recognition performance in both environments with short 10-metre sequences, and up to 96\% recall at 100\% precision across extreme day-night cycles when longer image sequences are used.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Pepperell, E. and Corke, P. I. and Milford, M. J.},
	month = may,
	year = {2014},
	keywords = {Cameras, Image sequences, Roads, SLAM (robots), SMART matching performance, Sensors, SeqSLAM algorithm, Trajectory, Vehicles, Visualization, all-environment visual place recognition, environmental aliasing, illumination, image matching, image matching parameters, image sequence length, image sequences, mobile robots, object recognition, pose estimation, pose invariance, robot vision, sequence matching across route traversals, sequence-based place recognition algorithm, vehicle speed},
	pages = {1612--1618}
}

@inproceedings{milford_condition-invariant_2014,
	title = {Condition-invariant, top-down visual place recognition},
	doi = {10.1109/ICRA.2014.6907678},
	abstract = {In this paper we present a novel, condition-invariant place recognition algorithm inspired by recent discoveries in human visual neuroscience. The algorithm combines intolerant but fast low resolution whole image matching with highly tolerant, sub-image patch matching processes. The approach does not require prior training and works on single images, alleviating the need for either a velocity signal or image sequence, differentiating it from current state of the art methods. We conduct an exhaustive set of experiments evaluating the relationship between place recognition performance and computational resources using part of the challenging Alderley sunny day - rainy night dataset, which has only been previously solved by integrating over 320 frame long image sequences. We achieve recall rates of up to 51\% at 100\% precision, matching places that have undergone drastic perceptual change while rejecting match hypotheses between highly aliased images of different places. Human trials demonstrate the performance is approaching human capability. The results provide a new benchmark for single image, condition-invariant place recognition.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Milford, M. and Scheirer, W. and Vig, E. and Glover, A. and Baumann, O. and Mattingley, J. and Cox, D.},
	month = may,
	year = {2014},
	keywords = {Cameras, Educational institutions, Histograms, Image recognition, Image resolution, Streaming media, Visualization, computational resources, fast low resolution whole image matching, human visual neuroscience, image matching, image resolution, image sequence, image sequences, novel condition-invariant place recognition algorithm, object recognition, place recognition performance, sub-image patch matching process},
	pages = {5571--5577}
}

@misc{noauthor_understanding_2019,
	title = {Understanding {Kalman} {Filters}, {Part} 1: {Why} {Use} {Kalman} {Filters}? - {YouTube}},
	url = {https://www.youtube.com/watch?v=mwn8xhgNpFY&t=9s},
	urldate = {2019-04-11},
	month = apr,
	year = {2019}
}

@inproceedings{suenderhauf_place_2015,
	title = {Place {Recognition} with {ConvNet} {Landmarks}: {Viewpoint}-{Robust}, {Condition}-{Robust}, {Training}-{Free}},
	volume = {11},
	isbn = {978-0-9923747-1-6},
	shorttitle = {Place {Recognition} with {ConvNet} {Landmarks}},
	url = {http://www.roboticsproceedings.org/rss11/p22.html},
	urldate = {2019-04-11},
	author = {Suenderhauf, Niko and Shirazi, Sareh and Jacobson, Adam and Dayoub, Feras and Pepperell, Edward and Upcroft, Ben and Milford, Michael},
	month = jul,
	year = {2015}
}

@misc{noauthor_cheat_2019,
	title = {Cheat {Sheets} for {AI}, {Neural} {Networks}, {Machine} {Learning}, {Deep} {Learning} \& {Big} {Data}},
	url = {https://becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-678c51b4b463},
	urldate = {2019-04-10},
	month = apr,
	year = {2019}
}

@misc{noauthor_tmux_2019,
	title = {Tmux {Cheat} {Sheet} \& {Quick} {Reference}},
	url = {https://tmuxcheatsheet.com/},
	urldate = {2019-04-10},
	month = apr,
	year = {2019}
}

@misc{noauthor_tmux_2019-1,
	title = {tmux shortcuts \& cheatsheet · {GitHub}},
	url = {https://gist.github.com/MohamedAlaa/2961058},
	urldate = {2019-04-10},
	month = apr,
	year = {2019}
}

@misc{noauthor_tensorflow_2019,
	title = {A {TensorFlow} {Glossary}/{Cheat} {Sheet} – {Google} {Cloud} {Platform} - {Community} – {Medium}},
	url = {https://medium.com/google-cloud/a-tensorflow-glossary-cheat-sheet-382583b22932},
	urldate = {2019-04-10},
	month = apr,
	year = {2019}
}

@misc{noauthor_engauge_2019,
	title = {Engauge {Digitizer}},
	url = {http://markummitchell.github.io/engauge-digitizer/},
	urldate = {2019-04-10},
	month = apr,
	year = {2019}
}

@misc{noauthor_deepfly_2019,
	title = {{DeepFly}},
	url = {https://dl.acm.org/citation.cfm?id=3010047},
	urldate = {2019-04-09},
	month = apr,
	year = {2019}
}

@misc{noauthor_cns-group-public_2019,
	title = {cns-group-public / aff-seg · {GitLab}},
	url = {https://gitlab.gwdg.de/cns-group-public/aff-seg},
	urldate = {2019-04-09},
	month = apr,
	year = {2019}
}

@misc{noauthor_github_2019,
	title = {{GitHub} - ayooshkathuria/pytorch-yolo-v3: {A} {PyTorch} implementation of the {YOLO} v3 object detection algorithm},
	url = {https://github.com/ayooshkathuria/pytorch-yolo-v3},
	urldate = {2019-04-09},
	month = apr,
	year = {2019}
}

@misc{noauthor_github_2019-1,
	title = {{GitHub} - kuangliu/torchcv: {TorchCV}: a {PyTorch} vision library mimics {ChainerCV}},
	url = {https://github.com/kuangliu/torchcv},
	urldate = {2019-04-09},
	month = apr,
	year = {2019}
}

@misc{noauthor_[learning_2019,
	title = {[{Learning} {Note}] {Single} {Shot} {MultiBox} {Detector} with {Pytorch} — {Part} 1},
	url = {https://towardsdatascience.com/learning-note-single-shot-multibox-detector-with-pytorch-part-1-38185e84bd79},
	urldate = {2019-04-09},
	month = apr,
	year = {2019}
}

@misc{noauthor_tutorial_2019,
	title = {Tutorial on implementing {YOLO} v3 from scratch in {PyTorch}},
	url = {https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/},
	urldate = {2019-04-09},
	month = apr,
	year = {2019}
}

@misc{gupta_how_2018,
	title = {How to write clean code? {Lessons} learnt from “{The} {Clean} {Code}” — {Robert} {C}. {Martin}},
	shorttitle = {How to write clean code?},
	url = {https://medium.com/mindorks/how-to-write-clean-code-lessons-learnt-from-the-clean-code-robert-c-martin-9ffc7aef870c},
	abstract = {There are two things- Programming and Good Programming. Programming is what we have all been doing. Now is the time to do good programming…},
	urldate = {2019-04-09},
	journal = {Medium},
	author = {Gupta, Shubham},
	month = feb,
	year = {2018}
}

@misc{noauthor_clean_2018,
	title = {Clean {Code} {Principles}: {Be} a {Better} {Programmer}},
	shorttitle = {Clean {Code} {Principles}},
	url = {https://simpleprogrammer.com/clean-code-principles-better-programmer/},
	abstract = {Clean code matters, and using clean code principles will go a long way toward advancing your career and making you a better programmer.},
	language = {en-US},
	urldate = {2019-04-09},
	journal = {Simple Programmer},
	month = aug,
	year = {2018}
}

@misc{deshpande_beginners_2019,
	title = {A {Beginner}'s {Guide} {To} {Understanding} {Convolutional} {Neural} {Networks} {Part} 2},
	url = {https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/},
	abstract = {ReLUs, Pooling, Dropout...(aka The Fun Stuff)},
	urldate = {2019-04-08},
	author = {Deshpande, Adit},
	month = apr,
	year = {2019}
}

@misc{noauthor_using_2018,
	title = {Using {Calibration} to {Translate} {Video} {Data} to the {Real} {World}},
	url = {https://devblogs.nvidia.com/calibration-translate-video-data/},
	abstract = {Calibration for intelligent video analytics means translating camera data into geo-locations. The DeepStream 3.0 SDK offers tools to facilitate calibration.},
	language = {en-US},
	urldate = {2019-04-05},
	journal = {NVIDIA Developer Blog},
	month = nov,
	year = {2018}
}

@misc{noauthor_even_2017,
	title = {An {Even} {Easier} {Introduction} to {CUDA}},
	url = {https://devblogs.nvidia.com/even-easier-introduction-cuda/},
	abstract = {A quick and easy introduction to CUDA programming for GPUs. This post dives into CUDA C++ with a simple, step-by-step parallel programming example.},
	language = {en-US},
	urldate = {2019-04-05},
	journal = {NVIDIA Developer Blog},
	month = jan,
	year = {2017}
}

@misc{noauthor_deep_2019,
	title = {Deep {Learning} in a {Nutshell}: {Reinforcement} {Learning}},
	url = {https://devblogs.nvidia.com/deep-learning-nutshell-reinforcement-learning/},
	urldate = {2019-04-05},
	month = apr,
	year = {2019}
}

@misc{noauthor_using_2018-1,
	title = {Using {MATLAB} and {TensorRT} on {NVIDIA} {GPUs}},
	url = {https://devblogs.nvidia.com/using-matlab-and-tensorrt-on-nvidia-gpus/},
	abstract = {Run and test algorithms in MATLAB before compiling them to CUDA and accelerating them on NVIDIA GPUs as well as exporting to CUDA applications.},
	language = {en-US},
	urldate = {2019-04-05},
	journal = {NVIDIA Developer Blog},
	month = oct,
	year = {2018}
}

@misc{noauthor_storage_2018,
	title = {Storage {Performance} {Basics} for {Deep} {Learning}},
	url = {https://devblogs.nvidia.com/storage-performance-basics-for-deep-learning/},
	abstract = {Introduction When production systems are not delivering expected levels of performance, it can be a challenging and time-consuming task to root-cause the issue(s). Especially in today’s complex environments, where the workload is comprised of many software components, libraries, etc, and rely on virtually all of the underlying hardware subsystems (CPU, memory, disk IO, network IO) …},
	language = {en-US},
	urldate = {2019-04-05},
	journal = {NVIDIA Developer Blog},
	month = mar,
	year = {2018}
}

@misc{noauthor_accelerating_2018,
	title = {Accelerating {Intelligent} {Video} {Analytics} with {Transfer} {Learning} {Toolkit}},
	url = {https://devblogs.nvidia.com/accelerating-video-analytics-tlt/},
	abstract = {NVIDIA Transfer Learning Toolkit allow users to fine tune pre-trained networks with custom data plus model pruning, scene adaptation and adding new classes.},
	language = {en-US},
	urldate = {2019-04-05},
	journal = {NVIDIA Developer Blog},
	month = nov,
	year = {2018}
}

@misc{noauthor_speeding_2019,
	title = {Speeding {Up} {Semantic} {Segmentation} {Using} {MATLAB} {Container} from {NVIDIA} {NGC}},
	url = {https://devblogs.nvidia.com/speeding-up-semantic-segmentation-matlab-nvidia-ngc/},
	abstract = {MATLAB makes it easy for engineers to train deep-learning models for semantic segmentation, taking advantage NVIDIA GPU acceleration},
	language = {en-US},
	urldate = {2019-04-05},
	journal = {NVIDIA Developer Blog},
	month = mar,
	year = {2019}
}

@misc{noauthor_pruning_2019,
	title = {Pruning {Models} with {NVIDIA} {Transfer} {Learning} {Toolkit}},
	url = {https://devblogs.nvidia.com/transfer-learning-toolkit-pruning-intelligent-video-analytics/},
	abstract = {NVIDIA Transfer Learning Toolkit is a deep learning workflow, accelerating deep learning training, deployment with DeepStream SDK 3.0 on Tesla GPUs.},
	language = {en-US},
	urldate = {2019-04-05},
	journal = {NVIDIA Developer Blog},
	month = mar,
	year = {2019}
}

@misc{noauthor_getting_2017,
	title = {Getting {Started} with {GPU} {Computing} in {Anaconda}},
	url = {https://www.anaconda.com/getting-started-with-gpu-computing-in-anaconda/},
	abstract = {Anaconda Distribution makes it easy to get started with GPU computing with several GPU-enabled packages that can be installed directly from our package repository. In this blog post, we’ll give you some pointers on where to get started with GPUs in Anaconda Distribution.},
	language = {en-US},
	urldate = {2019-04-05},
	journal = {Anaconda},
	month = oct,
	year = {2017}
}

@inproceedings{sunderhauf_performance_2015,
	title = {On the performance of {ConvNet} features for place recognition},
	doi = {10.1109/IROS.2015.7353986},
	abstract = {After the incredible success of deep learning in the computer vision domain, there has been much interest in applying Convolutional Network (ConvNet) features in robotic fields such as visual navigation and SLAM. Unfortunately, there are fundamental differences and challenges involved. Computer vision datasets are very different in character to robotic camera data, real-time performance is essential, and performance priorities can be different. This paper comprehensively evaluates and compares the utility of three state-of-the-art ConvNets on the problems of particular relevance to navigation for robots; viewpoint-invariance and condition-invariance, and for the first time enables real-time place recognition performance using ConvNets with large maps by integrating a variety of existing (locality-sensitive hashing) and novel (semantic search space partitioning) optimization techniques. We present extensive experiments on four real world datasets cultivated to evaluate each of the specific challenges in place recognition. The results demonstrate that speed-ups of two orders of magnitude can be achieved with minimal accuracy degradation, enabling real-time performance. We confirm that networks trained for semantic place categorization also perform better at (specific) place recognition when faced with severe appearance changes and provide a reference for which networks and layers are optimal for different aspects of the place recognition problem.},
	booktitle = {2015 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Sünderhauf, N. and Shirazi, S. and Dayoub, F. and Upcroft, B. and Milford, M.},
	month = sep,
	year = {2015},
	keywords = {Computer vision, ConvNet feature, Feature extraction, Real-time systems, Robustness, SLAM, SLAM (robots), Semantics, Visualization, computer vision, condition-invariance, convolutional network, locality-sensitive hashing, neural nets, object recognition, optimisation, optimization technique, place recognition, robot vision, robotic field, search problems, semantic place categorization, semantic search space partitioning, viewpoint-invariance, visual navigation},
	pages = {4297--4304}
}

@misc{noauthor_importing_2019,
	title = {Importing 3rd {Party} {Environments} in {Unreal} {Engine} for {AirSim}},
	url = {https://www.microsoft.com/en-us/research/video/importing-3rd-party-environments-in-unreal-engine-for-airsim/},
	abstract = {This video by Jim Piavis shows how you can take off-the-self environments available on websites such as TurboSquid.com or cgitrader.com and import into Unreal Engine. Once that’s done you can follow the instructions for using AirSim with that environment. Related: Autonomous car research with AirSim Microsoft shares open source system for training drones, other gadgets …},
	language = {en-US},
	urldate = {2019-04-03},
	journal = {Microsoft Research},
	month = apr,
	year = {2019}
}

@misc{noauthor_end--end_2019,
	title = {End-to-{End} {Deep} {Learning} for {Autonomous} {Driving} in {AirSim} – {AI4SIG}},
	url = {https://ai4sig.org/2018/07/airsim-e2e-deep-learning/},
	urldate = {2019-04-03},
	month = apr,
	year = {2019}
}

@inproceedings{montes_bio-inspired_2014,
	title = {Bio-inspired {Plume} {Tracking} {Algorithm} for {UAVS}},
	author = {Montes, G and Letheren, B and Villa, T and Gonzalez, F},
	month = dec,
	year = {2014}
}

@article{huang_speed/accuracy_2016,
	title = {Speed/accuracy trade-offs for modern convolutional object detectors},
	url = {https://arxiv.org/abs/1611.10012v3},
	abstract = {The goal of this paper is to serve as a guide for selecting a detection
architecture that achieves the right speed/memory/accuracy balance for a given
application and platform. To this end, we investigate various ways to trade
accuracy for speed and memory usage in modern convolutional object detection
systems. A number of successful systems have been proposed in recent years, but
apples-to-apples comparisons are difficult due to different base feature
extractors (e.g., VGG, Residual Networks), different default image resolutions,
as well as different hardware and software platforms. We present a unified
implementation of the Faster R-CNN [Ren et al., 2015], R-FCN [Dai et al., 2016]
and SSD [Liu et al., 2015] systems, which we view as "meta-architectures" and
trace out the speed/accuracy trade-off curve created by using alternative
feature extractors and varying other critical parameters such as image size
within each of these meta-architectures. On one extreme end of this spectrum
where speed and memory are critical, we present a detector that achieves real
time speeds and can be deployed on a mobile device. On the opposite end in
which accuracy is critical, we present a detector that achieves
state-of-the-art performance measured on the COCO detection task.},
	language = {en},
	urldate = {2019-04-03},
	author = {Huang, Jonathan and Rathod, Vivek and Sun, Chen and Zhu, Menglong and Korattikara, Anoop and Fathi, Alireza and Fischer, Ian and Wojna, Zbigniew and Song, Yang and Guadarrama, Sergio and Murphy, Kevin},
	month = nov,
	year = {2016}
}

@article{hu_relation_2017,
	title = {Relation {Networks} for {Object} {Detection}},
	url = {http://arxiv.org/abs/1711.11575},
	abstract = {Although it is well believed for years that modeling relations between objects would help object recognition, there has not been evidence that the idea is working in the deep learning era. All state-of-the-art object detection systems still rely on recognizing object instances individually, without exploiting their relations during learning. This work proposes an object relation module. It processes a set of objects simultaneously through interaction between their appearance feature and geometry, thus allowing modeling of their relations. It is lightweight and in-place. It does not require additional supervision and is easy to embed in existing networks. It is shown effective on improving object recognition and duplicate removal steps in the modern object detection pipeline. It verifies the efficacy of modeling object relations in CNN based detection. It gives rise to the first fully end-to-end object detector.},
	urldate = {2019-04-02},
	journal = {arXiv:1711.11575 [cs]},
	author = {Hu, Han and Gu, Jiayuan and Zhang, Zheng and Dai, Jifeng and Wei, Yichen},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.11575},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@misc{tensorflow_reinforcement_2019,
	title = {Reinforcement {Learning} in {TensorFlow} with {TF}-{Agents} ({TF} {Dev} {Summit} '19)},
	url = {https://www.youtube.com/watch?v=-TTziY7EmUA},
	urldate = {2019-04-01},
	author = {{TensorFlow}},
	month = apr,
	year = {2019}
}

@misc{noauthor_semantic_2019-1,
	title = {Semantic {Navigation} {RRT} {Planner}},
	url = {https://www.autonomousrobotslab.com/seplanner.html},
	abstract = {Dataset for download is available through this link .},
	language = {en},
	urldate = {2019-04-01},
	journal = {Autonomous Robots Lab},
	month = apr,
	year = {2019}
}

@inproceedings{cavaliere_towards_2018,
	title = {Towards an agent-driven scenario awareness in remote sensing environments},
	doi = {10.1109/SSCI.2018.8628882},
	abstract = {In dynamic environments, autonomous and unmanned vehicle systems (UVSs) represent a reliable solution, especially when the request of high performance is a stringent constraint for complex and risky tasks, such as searching survival points, multiple target monitoring, and tracking, etc. In these cases, cooperative activities among all the involved UVSs are strategic for the achievement of a collective goal. When UVS teams work collaboratively, they collect heterogeneous data from multiple sources and bring benefits through an enhanced situational awareness (SA). Multi-UVS scenarios are, by their nature, easy to be modeled as multi-agent systems. This paper presents an agent-based modeling, governing different types of unmanned vehicles that are sent ahead in an area of interest to gather environmental, sensing, image data in order to provide a complete multi-view scenario understanding. The agent model is instantiated in each vehicle, and depending on the vehicle features, encapsulates a semantic mental modeler, customized for the specific vehicle features. The agents collect raw data from the environment and translate them into high-level knowledge, i.e., a conceptualization of the data semantics (i.e., a set of pixels assumes the meaning of a car). The proposed agent-based modeling lays on a synergy between Semantic Web technologies and Fuzzy Cognitive Map (FCM) models, producing a high-level description of the evolving scenes, and then a comprehensive scenario situational awareness.},
	booktitle = {2018 {IEEE} {Symposium} {Series} on {Computational} {Intelligence} ({SSCI})},
	author = {Cavaliere, D. and Senatore, S.},
	month = nov,
	year = {2018},
	keywords = {Data models, FCM, Fuzzy Cognitive Map, Multi-agent systems, Process control, Semantic Web technologies, Semantics, Sensors, Task analysis, UVS, Unmanned vehicles, agent-based modeling, agent-driven scenario awareness, autonomous aerial vehicles, autonomous vehicle systems, control engineering computing, fuzzy set theory, image data, mobile robots, multi-agent systems, multiagent systems, remote sensing, remote sensing environments, road vehicles, semantic Web, semantic mental modeler, unmanned vehicle systems},
	pages = {1982--1989}
}

@misc{tensorflow_introducing_2019,
	title = {Introducing {TensorFlow} 2.0 and its high-level {APIs} ({TF} {Dev} {Summit} '19)},
	url = {https://www.youtube.com/watch?v=k5c-vg4rjBw&t=146s},
	urldate = {2019-04-01},
	author = {{TensorFlow}},
	month = apr,
	year = {2019}
}

@article{kuipers_robot_1991,
	title = {A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations},
	volume = {8},
	doi = {10.1016/0921-8890(91)90014-C},
	abstract = {Kuipers, B. and Byun, Y.T., A robot exploration and mapping strategy based on a sematic hierarchy of spatial representations, Robotics and Autonomous System, 8 (1991) 47-63. We have developed a robust qualitative method for robot exploration, mapping, and navigation in large-scale spatial environments. Experiments with a simulated robot in a variety of complex 2D environments have demonstrated that our qualitative method can build an accurate map of a previously unkown environment in spite of substantial random and systematic sensorimotor error. Most current approaches to robot exploration and mapping analyze sensor input to build a geometrically precise map of the environment, then extract topological structure from the geometric description. Our approach recognizes and exploits qualitative properties of large-scale before relatively error-prone geometrical properties. [sensorimotor ↔ control] → topology → geometry. At the control level, distinctive places and distinctive travel edges are identified based on the interaction between the robot's control strategies, its sensorimotor system, and the world. A distinctive place is defined as the local maximum of a distinctiveness measure appropriate to its immediate neighborhood, and is found by a hill-climbing control strategy. A distinctive travel edge, similarly, is defined by a suitable measure and a path-following control strategy. The topological network description is created by linking the distinctive places and travel edges.Metrical information is then incrementally assimilated into localgeometric descriptions of places and edges, and finally merged into a global geometric map. Topological ambiguity arising from sensorily indistinguishable places can be resolved at the topological level by the exploration strategy. With this representation, successful navigation is not critically dependent on the accuracy, or even the existence, of the geometrical description. We present examples demonstrating the process by which the robot explores and builds a map of a complex environment, including the effect of sensory errors. We also discuss new research directions that are suggested by this approach. © 1991.},
	number = {1-2},
	journal = {Robotics and Autonomous Systems},
	author = {Kuipers, B. and Byun, Y.-T.},
	year = {1991},
	keywords = {Cognitive map, Distinctive place, Environmental mapping, Large-scale space, Robot exploration, Spatial reasoning, Topological map},
	pages = {47--63}
}

@article{shah_airsim:_2017,
	title = {{AirSim}: {High}-{Fidelity} {Visual} and {Physical} {Simulation} for {Autonomous} {Vehicles}},
	shorttitle = {{AirSim}},
	url = {https://www.microsoft.com/en-us/research/publication/airsim-high-fidelity-visual-physical-simulation-autonomous-vehicles/},
	abstract = {Developing and testing algorithms for autonomous vehicles in real world is an expensive and time consuming process. Also, in order to utilize recent advances in machine intelligence and deep learning we need to collect a large amount of annotated training data in a variety of conditions and environments. We present a new simulator built on …},
	language = {en-US},
	urldate = {2019-03-27},
	journal = {Field and Service Robotics},
	author = {Shah, Shital and Kapoor, Ashish and Dey, Debadeepta and Lovett, Chris},
	month = jul,
	year = {2017}
}

@misc{noauthor_jetson_2019,
	title = {Jetson {Nano} {Brings} {AI} {Computing} to {Everyone}},
	url = {https://devblogs.nvidia.com/jetson-nano-ai-computing/},
	abstract = {Compute performance, compact footprint, and flexibility make Jetson Nano ideal for developers to create AI-powered devices and embedded systems.},
	language = {en-US},
	urldate = {2019-03-26},
	journal = {NVIDIA Developer Blog},
	month = mar,
	year = {2019}
}

@misc{noauthor_hands_2019,
	title = {Hands {On} {With} {Nvidia}'s {New} {Jetson} {Nano} - {ExtremeTech}},
	url = {https://www.extremetech.com/computing/288153-hands-on-with-nvidias-new-jetson-nano},
	urldate = {2019-03-26},
	month = mar,
	year = {2019}
}

@misc{noauthor_thesis_2019,
	title = {The {Thesis} {Whisperer}},
	url = {https://thesiswhisperer.com/},
	abstract = {Just like the horse whisperer - but with more pages},
	language = {en},
	urldate = {2019-03-26},
	journal = {The Thesis Whisperer},
	month = mar,
	year = {2019}
}

@article{kelchtermans_how_2017,
	title = {How hard is it to cross the room? -- {Training} ({Recurrent}) {Neural} {Networks} to steer a {UAV}},
	shorttitle = {How hard is it to cross the room?},
	url = {http://arxiv.org/abs/1702.07600},
	abstract = {This work explores the feasibility of steering a drone with a (recurrent) neural network, based on input from a forward looking camera, in the context of a high-level navigation task. We set up a generic framework for training a network to perform navigation tasks based on imitation learning. It can be applied to both aerial and land vehicles. As a proof of concept we apply it to a UAV (Unmanned Aerial Vehicle) in a simulated environment, learning to cross a room containing a number of obstacles. So far only feedforward neural networks (FNNs) have been used to train UAV control. To cope with more complex tasks, we propose the use of recurrent neural networks (RNN) instead and successfully train an LSTM (Long-Short Term Memory) network for controlling UAVs. Vision based control is a sequential prediction problem, known for its highly correlated input data. The correlation makes training a network hard, especially an RNN. To overcome this issue, we investigate an alternative sampling method during training, namely window-wise truncated backpropagation through time (WW-TBPTT). Further, end-to-end training requires a lot of data which often is not available. Therefore, we compare the performance of retraining only the Fully Connected (FC) and LSTM control layers with networks which are trained end-to-end. Performing the relatively simple task of crossing a room already reveals important guidelines and good practices for training neural control networks. Different visualizations help to explain the behavior learned.},
	urldate = {2019-03-25},
	journal = {arXiv:1702.07600 [cs]},
	author = {Kelchtermans, Klaas and Tuytelaars, Tinne},
	month = feb,
	year = {2017},
	note = {arXiv: 1702.07600},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@inproceedings{aznar_visual_2016,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Visual {Navigation} for {UAV} with {Map} {References} {Using} {ConvNets}},
	isbn = {978-3-319-44636-3},
	abstract = {In this paper, a visual system for helping unmanned aerial vehicles navigation, designed with a convolutional neural network, is presented. This network is trained to match on-board captured images with several previously obtained global maps, generating actions given a known global control policy. This system can be used directly for navigation or filtered, combining it with other aircraft systems. Our model will be compared with a classical map registration application, using a Scale-Invariant Feature Transform (SIFT) key point extractor. The system will be trained and evaluated with real aerial images. The results obtained show the viability of the proposed system and demonstrate its performance.},
	language = {en},
	booktitle = {Advances in {Artificial} {Intelligence}},
	publisher = {Springer International Publishing},
	author = {Aznar, Fidel and Pujol, Mar and Rizo, Ramón},
	editor = {Luaces, Oscar and Gámez, José A. and Barrenechea, Edurne and Troncoso, Alicia and Galar, Mikel and Quintián, Héctor and Corchado, Emilio},
	year = {2016},
	keywords = {Convolutional Network, Convolutional Neural Network, From Accelerate Segment Test, Unmanned Aerial Vehicle, Visual Navigation},
	pages = {13--22}
}

@inproceedings{shah_deepfly:_2016,
	address = {New York, NY, USA},
	series = {{ICVGIP} '16},
	title = {{DeepFly}: {Towards} {Complete} {Autonomous} {Navigation} of {MAVs} with {Monocular} {Camera}},
	isbn = {978-1-4503-4753-2},
	shorttitle = {{DeepFly}},
	url = {http://doi.acm.org/10.1145/3009977.3010047},
	doi = {10.1145/3009977.3010047},
	abstract = {Recently, the interest in Micro Aerial Vehicles (MAVs) and their autonomous flights has increased tremendously and significant advances have been made. The monocular camera has turned out to be most popular sensing modality for MAVs as it is light-weight, does not consume more power, and encodes rich information about the environment around. In this paper, we present DeepFly, our framework for autonomous navigation of a quadcopter equipped with monocular camera. The navigable space detection and waypoint selection are fundamental components of autonomous navigation system. They have broader meaning than just detecting and avoiding immediate obstacles. Finding the navigable space emphasizes equally on avoiding obstacles and detecting ideal regions to move next to. The ideal region can be defined by two properties: 1) All the points in the region have approximately same high depth value and 2) The area covered by the points of the region in the disparity map is considerably large. The waypoints selected from these navigable spaces assure collision-free path which is safer than path obtained from other waypoint selection methods which do not consider neighboring information. In our approach, we obtain a dense disparity map by performing a translation maneuver. This disparity map is input to a deep neural network which predicts bounding boxes for multiple navigable regions. Our deep convolutional neural network with shortcut connections regresses variable number of outputs without any complex architectural add on. Our autonomous navigation approach has been successfully tested in both indoors and outdoors environment and in range of lighting conditions.},
	urldate = {2019-03-25},
	booktitle = {Proceedings of the {Tenth} {Indian} {Conference} on {Computer} {Vision}, {Graphics} and {Image} {Processing}},
	publisher = {ACM},
	author = {Shah, Utsav and Khawad, Rishabh and Krishna, K Madhava},
	year = {2016},
	note = {event-place: Guwahati, Assam, India},
	keywords = {autonomous navigation, deep learning, micro aerial vehicles},
	pages = {59:1--59:8}
}

@article{zhang_learning_2015,
	title = {Learning {Deep} {Control} {Policies} for {Autonomous} {Aerial} {Vehicles} with {MPC}-{Guided} {Policy} {Search}},
	url = {http://arxiv.org/abs/1509.06791},
	abstract = {Model predictive control (MPC) is an effective method for controlling robotic systems, particularly autonomous aerial vehicles such as quadcopters. However, application of MPC can be computationally demanding, and typically requires estimating the state of the system, which can be challenging in complex, unstructured environments. Reinforcement learning can in principle forego the need for explicit state estimation and acquire a policy that directly maps sensor readings to actions, but is difficult to apply to unstable systems that are liable to fail catastrophically during training before an effective policy has been found. We propose to combine MPC with reinforcement learning in the framework of guided policy search, where MPC is used to generate data at training time, under full state observations provided by an instrumented training environment. This data is used to train a deep neural network policy, which is allowed to access only the raw observations from the vehicle's onboard sensors. After training, the neural network policy can successfully control the robot without knowledge of the full state, and at a fraction of the computational cost of MPC. We evaluate our method by learning obstacle avoidance policies for a simulated quadrotor, using simulated onboard sensors and no explicit state estimation at test time.},
	urldate = {2019-03-25},
	journal = {arXiv:1509.06791 [cs]},
	author = {Zhang, Tianhao and Kahn, Gregory and Levine, Sergey and Abbeel, Pieter},
	month = sep,
	year = {2015},
	note = {arXiv: 1509.06791},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics}
}

@article{levine_end--end_2015,
	title = {End-to-{End} {Training} of {Deep} {Visuomotor} {Policies}},
	url = {http://arxiv.org/abs/1504.00702},
	abstract = {Policy search methods can allow robots to learn control policies for a wide range of tasks, but practical applications of policy search often require hand-engineered components for perception, state estimation, and low-level control. In this paper, we aim to answer the following question: does training the perception and control systems jointly end-to-end provide better performance than training each component separately? To this end, we develop a method that can be used to learn policies that map raw image observations directly to torques at the robot's motors. The policies are represented by deep convolutional neural networks (CNNs) with 92,000 parameters, and are trained using a partially observed guided policy search method, which transforms policy search into supervised learning, with supervision provided by a simple trajectory-centric reinforcement learning method. We evaluate our method on a range of real-world manipulation tasks that require close coordination between vision and control, such as screwing a cap onto a bottle, and present simulated comparisons to a range of prior policy search methods.},
	urldate = {2019-03-25},
	journal = {arXiv:1504.00702 [cs]},
	author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
	month = apr,
	year = {2015},
	note = {arXiv: 1504.00702},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Robotics}
}

@misc{cmurobotics_ri_2019,
	title = {{RI} {Seminar}: {Sergey} {Levine} : {Deep} {Robotic} {Learning}},
	shorttitle = {{RI} {Seminar}},
	url = {https://www.youtube.com/watch?v=eKaYnXQUb2g},
	urldate = {2019-03-22},
	author = {{cmurobotics}},
	month = mar,
	year = {2019}
}

@misc{noauthor_pyimagesearch_2019,
	title = {{PyImageSearch} - {Be} awesome at {OpenCV}, {Python}, deep learning, and computer vision},
	url = {https://www.pyimagesearch.com/},
	abstract = {This OpenCV, deep learning, and Python blog is written by Adrian Rosebrock. Master OpenCV, deep learning, Python, and computer vision through my OpenCV and deep learning articles, tutorials, and guides.},
	language = {en-US},
	urldate = {2019-03-22},
	journal = {PyImageSearch},
	month = mar,
	year = {2019}
}

@misc{noauthor_sutton_2019,
	title = {Sutton \& {Barto} {Book}: {Reinforcement} {Learning}: {An} {Introduction}},
	url = {http://incompleteideas.net/book/the-book-2nd.html},
	urldate = {2019-03-22},
	month = mar,
	year = {2019}
}

@misc{openai_gym:_2019,
	title = {Gym: {A} toolkit for developing and comparing reinforcement learning algorithms},
	shorttitle = {Gym},
	url = {https://gym.openai.com},
	abstract = {A toolkit for developing and comparing reinforcement learning algorithms},
	urldate = {2019-03-22},
	author = {{OpenAI}},
	month = mar,
	year = {2019}
}

@misc{noauthor_survival_2019,
	title = {A {Survival} {Guide} to a {PhD}},
	url = {http://karpathy.github.io/2016/09/07/phd/},
	urldate = {2019-03-21},
	month = mar,
	year = {2019}
}

@misc{arxiv_insights_overcoming_2019,
	title = {Overcoming sparse rewards in {Deep} {RL}: {Curiosity}, hindsight \& auxiliary tasks.},
	shorttitle = {Overcoming sparse rewards in {Deep} {RL}},
	url = {https://www.youtube.com/watch?v=0Ey02HT_1Ho},
	urldate = {2019-03-21},
	author = {{Arxiv Insights}},
	month = mar,
	year = {2019}
}

@misc{vedpathak_playing_2019,
	title = {Playing {Pong} from pixels using {Reinforcement} {Learning}},
	url = {https://towardsdatascience.com/intro-to-reinforcement-learning-pong-92a94aa0f84d},
	abstract = {A gentle introduction to the key principles of Reinforcement Learning},
	urldate = {2019-03-21},
	journal = {Towards Data Science},
	author = {Vedpathak, Omkar},
	month = jan,
	year = {2019}
}

@misc{noauthor_deep_2019-1,
	title = {Deep {Reinforcement} {Learning}: {Pong} from {Pixels}},
	url = {http://karpathy.github.io/2016/05/31/rl/},
	urldate = {2019-03-21},
	month = mar,
	year = {2019}
}

@article{singla_memory-based_2018,
	title = {Memory-based {Deep} {Reinforcement} {Learning} for {Obstacle} {Avoidance} in {UAV} with {Limited} {Environment} {Knowledge}},
	url = {http://arxiv.org/abs/1811.03307},
	abstract = {This paper presents our method for enabling a UAV quadrotor, equipped with a monocular camera, to autonomously avoid collisions with obstacles in unstructured and unknown indoor environments. When compared to obstacle avoidance in ground vehicular robots, UAV navigation brings in additional challenges because the UAV motion is no more constrained to a well-defined indoor ground or street environment. Horizontal structures in indoor and outdoor environments like decorative items, furnishings, ceiling fans, sign-boards, tree branches etc., also become relevant obstacles unlike those for ground vehicular robots. Thus, methods of obstacle avoidance developed for ground robots are clearly inadequate for UAV navigation. Current control methods using monocular images for UAV obstacle avoidance are heavily dependent on environment information. These controllers do not fully retain and utilize the extensively available information about the ambient environment for decision making. We propose a deep reinforcement learning based method for UAV obstacle avoidance (OA) and autonomous exploration which is capable of doing exactly the same. The crucial idea in our method is the concept of partial observability and how UAVs can retain relevant information about the environment structure to make better future navigation decisions. Our OA technique uses recurrent neural networks with temporal attention and provides better results compared to prior works in terms of distance covered during navigation without collisions. In addition, our technique has a high inference rate (a key factor in robotic applications) and is energy-efficient as it minimizes oscillatory motion of UAV and reduces power wastage.},
	urldate = {2019-03-21},
	journal = {arXiv:1811.03307 [cs]},
	author = {Singla, Abhik and Padakandla, Sindhu and Bhatnagar, Shalabh},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.03307},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics}
}

@article{zamir_taskonomy:_2018,
	title = {Taskonomy: {Disentangling} {Task} {Transfer} {Learning}},
	shorttitle = {Taskonomy},
	url = {http://arxiv.org/abs/1804.08328},
	abstract = {Do visual tasks have a relationship, or are they unrelated? For instance, could having surface normals simplify estimating the depth of an image? Intuition answers these questions positively, implying existence of a structure among visual tasks. Knowing this structure has notable values; it is the concept underlying transfer learning and provides a principled way for identifying redundancies across tasks, e.g., to seamlessly reuse supervision among related tasks or solve many tasks in one system without piling up the complexity. We proposes a fully computational approach for modeling the structure of space of visual tasks. This is done via finding (first and higher-order) transfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D, and semantic tasks in a latent space. The product is a computational taxonomic map for task transfer learning. We study the consequences of this structure, e.g. nontrivial emerged relationships, and exploit them to reduce the demand for labeled data. For example, we show that the total number of labeled datapoints needed for solving a set of 10 tasks can be reduced by roughly 2/3 (compared to training independently) while keeping the performance nearly the same. We provide a set of tools for computing and probing this taxonomical structure including a solver that users can employ to devise efficient supervision policies for their use cases.},
	urldate = {2019-03-21},
	journal = {arXiv:1804.08328 [cs]},
	author = {Zamir, Amir and Sax, Alexander and Shen, William and Guibas, Leonidas and Malik, Jitendra and Savarese, Silvio},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.08328},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Robotics}
}

@misc{duckett_nvidia_2019,
	title = {Nvidia goes {Nano} for latest {Jetson} release},
	url = {https://www.zdnet.com/article/nvidia-goes-nano-for-latest-jetson-release/},
	abstract = {The GPU giant has released a low-powered system for AI tasks.},
	language = {en},
	urldate = {2019-03-21},
	journal = {ZDNet},
	author = {Duckett, Chris},
	month = mar,
	year = {2019}
}

@book{noauthor_robotics_2019,
	title = {Robotics and {Autonomous} {Systems}},
	url = {https://www.journals.elsevier.com/robotics-and-autonomous-systems/call-for-papers},
	abstract = {Call for Papers
SPecial Issues: Semantic Policy and Action Representations for Autonomous Robots

Competitions, Evaluation and Benchmarking of robotics and Autonomous Systems},
	urldate = {2019-03-21},
	month = mar,
	year = {2019}
}

@inproceedings{kyrkou_dronet:_2018,
	title = {{DroNet}: {Efficient} convolutional neural network detector for real-time {UAV} applications},
	shorttitle = {{DroNet}},
	doi = {10.23919/DATE.2018.8342149},
	abstract = {Unmanned Aerial Vehicles (drones) are emerging as a promising technology for both environmental and infrastructure monitoring, with broad use in a plethora of applications. Many such applications require the use of computer vision algorithms in order to analyse the information captured from an on-board camera. Such applications include detecting vehicles for emergency response and traffic monitoring. This paper therefore, explores the trade-offs involved in the development of a single-shot object detector based on deep convolutional neural networks (CNNs) that can enable UAVs to perform vehicle detection under a resource constrained environment such as in a UAV. The paper presents a holistic approach for designing such systems; the data collection and training stages, the CNN architecture, and the optimizations necessary to efficiently map such a CNN on a lightweight embedded processing platform suitable for deployment on UAVs. Through the analysis we propose a CNN architecture that is capable of detecting vehicles from aerial UAV images and can operate between 5-18 frames-per-second for a variety of platforms with an overall accuracy of 95\%. Overall, the proposed architecture is suitable for UAV applications, utilizing low-power embedded processors that can be deployed on commercial UAVs.},
	booktitle = {2018 {Design}, {Automation} {Test} in {Europe} {Conference} {Exhibition} ({DATE})},
	author = {Kyrkou, C. and Plastiras, G. and Theocharides, T. and Venieris, S. I. and Bouganis, C.},
	month = mar,
	year = {2018},
	keywords = {CNN architecture, Computer architecture, Convolutional neural networks, Detectors, Graphics processing units, Machine learning, Real-time systems, Training, Unmanned Aerial Vehicles, aerial UAV images, autonomous aerial vehicles, commercial UAVs, computer vision, computer vision algorithms, convolution, convolutional neural network detector, data collection, deep convolutional neural networks, drones, embedded systems, emergency response, environmental infrastructure monitoring, feedforward neural nets, lightweight embedded processing platform, object detection, on-board camera, plethora, real-time UAV applications, remotely operated vehicles, resource constrained environment, single-shot object detector, traffic monitoring, vehicle detection},
	pages = {967--972}
}

@misc{noauthor_critical_2019,
	type = {general},
	title = {Critical thinking - {HiQ}},
	copyright = {Copyright Queensland University of Technology 2016},
	url = {https://qutvirtual4.qut.edu.au/group/student/study/writing-and-referencing/critical-thinking},
	abstract = {The elements of critical thinking needed to read, write and learn at university.},
	language = {en},
	urldate = {2019-03-21},
	month = mar,
	year = {2019}
}

@incollection{foss_chapter_0000,
	address = {Lanham},
	title = {Chapter 4: {Developing} your itinerary: {The} preproposal pp. 35-46 and {Chapter} 5: {Advice} from other travellers: {The} literature review pp. 75-100},
	isbn = {978-0-7425-5439-9},
	shorttitle = {Chapter 4},
	url = {http://ebookcentral.proquest.com.ezp01.library.qut.edu.au/lib/qut/reader.action?docID=1040732&ppg=34},
	urldate = {2019-03-21},
	booktitle = {Destination dissertation: a traveler's guide to a done dissertation},
	publisher = {Rowman \& Littlefield Publishers},
	editor = {Foss, Sonja K. and Waters, William Joseph Condon},
	year = {0000}
}

@book{foss_destination_2007,
	address = {Lanham},
	title = {Destination dissertation: a traveler's guide to a done dissertation},
	isbn = {978-0-7425-5439-9},
	shorttitle = {Destination dissertation},
	language = {eng},
	publisher = {Rowman \& Littlefield Publishers},
	author = {Foss, Sonja K.},
	collaborator = {Waters, William Joseph Condon},
	year = {2007},
	keywords = {Academic writing Handbooks, manuals, etc., Dissertations, Academic Authorship Handbooks, manuals, etc.}
}

@article{zhao_survey_2018,
	title = {Survey on computational-intelligence-based {UAV} path planning},
	volume = {158},
	issn = {0950-7051},
	url = {http://www.sciencedirect.com/science/article/pii/S0950705118302636},
	doi = {10.1016/j.knosys.2018.05.033},
	abstract = {The key objective of unmanned aerial vehicle (UAV) path planning is to produce a flight path that connects a start state and a goal state while meeting the required constraints. Computational intelligence (CI) is a set of nature-inspired computational methodologies and approaches for addressing complex real-world problems for which mathematical or traditional modelling does not perform well. It has been applied in the field of UAVs since it can yield effective, accurate and rapid solutions. This article provides an overview of studies on UAV path planning based on CI methods published in major journals and conference proceedings. We survey relevant studies with respect to different CI algorithms utilized in UAV path planning, the types of time domain in UAV path planning, namely, offline and online, and the types of environment models, namely, 2D and 3D. It is observed that CI methods outperform traditional methods on online and 3D problems. The analysis is useful for identifying key results from UAV path planning research and is leveraged in this article to highlight trends and open issues.},
	urldate = {2019-03-20},
	journal = {Knowledge-Based Systems},
	author = {Zhao, Yijing and Zheng, Zheng and Liu, Yang},
	month = oct,
	year = {2018},
	keywords = {Computational intelligence, Learning-based algorithms, Path planning, Unmanned aerial vehicle},
	pages = {54--64}
}

@misc{carrio_review_2017,
	type = {Research article},
	title = {A {Review} of {Deep} {Learning} {Methods} and {Applications} for {Unmanned} {Aerial} {Vehicles}},
	url = {https://www.hindawi.com/journals/js/2017/3296874/},
	abstract = {Deep learning is recently showing outstanding results for solving a wide variety of robotic tasks in the areas of perception, planning, localization, and control. Its excellent capabilities for learning representations from the complex data acquired in real environments make it extremely suitable for many kinds of autonomous robotic applications. In parallel, Unmanned Aerial Vehicles (UAVs) are currently being extensively applied for several types of civilian tasks in applications going from security, surveillance, and disaster rescue to parcel delivery or warehouse management. In this paper, a thorough review has been performed on recent reported uses and applications of deep learning for UAVs, including the most relevant developments as well as their performances and limitations. In addition, a detailed explanation of the main deep learning techniques is provided. We conclude with a description of the main challenges for the application of deep learning for UAV-based solutions.},
	language = {en},
	urldate = {2019-03-20},
	journal = {Journal of Sensors},
	author = {Carrio, Adrian and Sampedro, Carlos and Rodriguez-Ramos, Alejandro and Campoy, Pascual},
	year = {2017},
	doi = {10.1155/2017/3296874}
}
@misc{noauthor_faster_2019,
	title = {Faster, {Lighter}, {Smarter}: {DARPA} {Gives} {Small} {Autonomous} {Systems} a {Tech} {Boost}},
	url = {https://www.darpa.mil/news-events/2018-07-18},
	urldate = {2019-03-20},
	month = mar,
	year = {2019}
}

@misc{darpatv_darpas_2019,
	title = {{DARPA}'s {Fast} {Lightweight} {Autonomy} ({FLA}) {Technology} {Explained}},
	url = {https://www.youtube.com/watch?v=_UFabSMuz6w},
	urldate = {2019-03-20},
	author = {{DARPAtv}},
	month = mar,
	year = {2019}
}

@misc{darpatv_fast_2019,
	title = {Fast {Lightweight} {Autonomy} ({FLA}) {Phase} 2 {Flight} {Testing}},
	url = {https://www.youtube.com/watch?v=vDYy3L9nvLk},
	urldate = {2019-03-20},
	author = {{DARPAtv}},
	month = mar,
	year = {2019}
}

@article{chen_deeplab:_2018,
	title = {{DeepLab}: {Semantic} {Image} {Segmentation} with {Deep} {Convolutional} {Nets}, {Atrous} {Convolution}, and {Fully} {Connected} {CRFs}},
	volume = {40},
	issn = {0162-8828},
	shorttitle = {{DeepLab}},
	doi = {10.1109/TPAMI.2017.2699184},
	abstract = {In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled filters, or `atrous convolution', as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with filters at multiple sampling rates and effective fields-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed “DeepLab” system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7 percent mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.},
	number = {4},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Chen, L. and Papandreou, G. and Kokkinos, I. and Murphy, K. and Yuille, A. L.},
	month = apr,
	year = {2018},
	keywords = {Computational modeling, Context, Convolution, Convolutional neural networks, Deep Convolutional Neural Networks, Deep Learning, DeepLab, Image resolution, Image segmentation, Neural networks, PASCAL VOC-2012 semantic image segmentation task, Semantics, atrous convolution, atrous spatial pyramid pooling, conditional random fields, convolution, deep convolutional nets, feature extraction, feedforward neural nets, fully connected Conditional Random Field, highlight convolution, image context, image segmentation, learning (artificial intelligence), probabilistic graphical models, random processes, semantic image segmentation, semantic segmentation},
	pages = {834--848}
}

@inproceedings{chen_sca-cnn:_2017,
	title = {{SCA}-{CNN}: {Spatial} and {Channel}-{Wise} {Attention} in {Convolutional} {Networks} for {Image} {Captioning}},
	shorttitle = {{SCA}-{CNN}},
	url = {http://openaccess.thecvf.com/content_cvpr_2017/html/Chen_SCA-CNN_Spatial_and_CVPR_2017_paper.html},
	urldate = {2019-03-19},
	author = {Chen, Long and Zhang, Hanwang and Xiao, Jun and Nie, Liqiang and Shao, Jian and Liu, Wei and Chua, Tat-Seng},
	year = {2017},
	pages = {5659--5667}
}

@article{chen_abc-cnn:_2015,
	title = {{ABC}-{CNN}: {An} {Attention} {Based} {Convolutional} {Neural} {Network} for {Visual} {Question} {Answering}},
	shorttitle = {{ABC}-{CNN}},
	url = {http://arxiv.org/abs/1511.05960},
	abstract = {We propose a novel attention based deep learning architecture for visual question answering task (VQA). Given an image and an image related natural language question, VQA generates the natural language answer for the question. Generating the correct answers requires the model's attention to focus on the regions corresponding to the question, because different questions inquire about the attributes of different image regions. We introduce an attention based configurable convolutional neural network (ABC-CNN) to learn such question-guided attention. ABC-CNN determines an attention map for an image-question pair by convolving the image feature map with configurable convolutional kernels derived from the question's semantics. We evaluate the ABC-CNN architecture on three benchmark VQA datasets: Toronto COCO-QA, DAQUAR, and VQA dataset. ABC-CNN model achieves significant improvements over state-of-the-art methods on these datasets. The question-guided attention generated by ABC-CNN is also shown to reflect the regions that are highly relevant to the questions.},
	urldate = {2019-03-19},
	journal = {arXiv:1511.05960 [cs]},
	author = {Chen, Kan and Wang, Jiang and Chen, Liang-Chieh and Gao, Haoyuan and Xu, Wei and Nevatia, Ram},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.05960},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@inproceedings{song_deep_2017,
	title = {Deep {Spatial}-{Semantic} {Attention} for {Fine}-{Grained} {Sketch}-{Based} {Image} {Retrieval}},
	url = {http://openaccess.thecvf.com/content_iccv_2017/html/Song_Deep_Spatial-Semantic_Attention_ICCV_2017_paper.html},
	urldate = {2019-03-19},
	author = {Song, Jifei and Yu, Qian and Song, Yi-Zhe and Xiang, Tao and Hospedales, Timothy M.},
	year = {2017},
	pages = {5551--5560}
}

@inproceedings{bello-cerezo_hand-designed_2018,
	series = {Smart {Innovation}, {Systems} and {Technologies}},
	title = {Hand-{Designed} {Local} {Image} {Descriptors} vs. {Off}-the-{Shelf} {CNN}-{Based} {Features} for {Texture} {Classification}: {An} {Experimental} {Comparison}},
	isbn = {978-3-319-59480-4},
	shorttitle = {Hand-{Designed} {Local} {Image} {Descriptors} vs. {Off}-the-{Shelf} {CNN}-{Based} {Features} for {Texture} {Classification}},
	abstract = {Convolutional Neural Networks have proved extremely successful in object classification applications; however, their suitability for texture analysis largely remains to be established. We investigate the use of pre-trained CNNs as texture descriptors by tapping the output of the last fully connected layer, an approach that has proved its effectiveness in other domains. Comparison with classical descriptors based on signal processing or statistics over a range of standard databases suggests that CNNs may be more effective where the intra-class variability is large. Conversely, classical approaches may be preferable where classes are well defined and homogeneous.},
	language = {en},
	booktitle = {Intelligent {Interactive} {Multimedia} {Systems} and {Services} 2017},
	publisher = {Springer International Publishing},
	author = {Bello-Cerezo, Raquel and Bianconi, Francesco and Cascianelli, Silvia and Fravolini, Mario Luca and di Maria, Francesco and Smeraldi, Fabrizio},
	editor = {De Pietro, Giuseppe and Gallo, Luigi and Howlett, Robert J. and Jain, Lakhmi C.},
	year = {2018},
	keywords = {Convolutional Neural Networks, Image classification, Local Binary Patterns, Texture},
	pages = {1--10}
}

@article{wu_scan:_2018,
	title = {{SCAN}: {Sliding} {Convolutional} {Attention} {Network} for {Scene} {Text} {Recognition}},
	shorttitle = {{SCAN}},
	url = {http://arxiv.org/abs/1806.00578},
	abstract = {Scene text recognition has drawn great attentions in the community of computer vision and artificial intelligence due to its challenges and wide applications. State-of-the-art recurrent neural networks (RNN) based models map an input sequence to a variable length output sequence, but are usually applied in a black box manner and lack of transparency for further improvement, and the maintaining of the entire past hidden states prevents parallel computation in a sequence. In this paper, we investigate the intrinsic characteristics of text recognition, and inspired by human cognition mechanisms in reading texts, we propose a scene text recognition method with sliding convolutional attention network (SCAN). Similar to the eye movement during reading, the process of SCAN can be viewed as an alternation between saccades and visual fixations. Compared to the previous recurrent models, computations over all elements of SCAN can be fully parallelized during training. Experimental results on several challenging benchmarks, including the IIIT5k, SVT and ICDAR 2003/2013 datasets, demonstrate the superiority of SCAN over state-of-the-art methods in terms of both the model interpretability and performance.},
	urldate = {2019-03-19},
	journal = {arXiv:1806.00578 [cs]},
	author = {Wu, Yi-Chao and Yin, Fei and Zhang, Xu-Yao and Liu, Li and Liu, Cheng-Lin},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.00578},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{yi_knowledge-based_2018,
	title = {Knowledge-based {Recurrent} {Attentive} {Neural} {Network} for {Small} {Object} {Detection}},
	url = {http://arxiv.org/abs/1803.05263},
	abstract = {Accurate Traffic Sign Detection (TSD) can help intelligent systems make better decisions according to the traffic regulations. TSD, regarded as a typical small object detection problem in some way, is fundamental in Advanced Driver Assistance Systems (ADAS) and self-driving. However, although deep neural networks have achieved human even superhuman performance on several tasks, due to their own limitations, small object detection is still an open question. In this paper, we proposed a brain-inspired network, named as KB-RANN, to handle this problem. Attention mechanism is an essential function of our brain, we used a novel recurrent attentive neural network to improve the detection accuracy in a fine-grained manner. Further, we combined domain specific knowledge and intuitive knowledge to improve the efficiency. Experimental result shows that our methods achieved better performance than several popular methods widely used in object detection. More significantly, we transplanted our method on our designed embedded system and deployed on our self-driving car successfully.},
	urldate = {2019-03-19},
	journal = {arXiv:1803.05263 [cs]},
	author = {Yi, Kai and Jian, Zhiqiang and Chen, Shitao and Yang, Yuedong and Zheng, Nanning},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.05263},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition}
}

@misc{noauthor_is_2019,
	title = {Is there a way to encode prior knowledge in deep neural networks? - {Quora}},
	url = {https://www.quora.com/Is-there-a-way-to-encode-prior-knowledge-in-deep-neural-networks},
	urldate = {2019-03-19},
	month = mar,
	year = {2019}
}

@misc{noauthor_deep_2019,
	title = {deep learning - {Incorporating} prior knowledge into artificial neural networks},
	url = {https://stats.stackexchange.com/questions/265497/incorporating-prior-knowledge-into-artificial-neural-networks},
	urldate = {2019-03-19},
	journal = {Cross Validated},
	month = mar,
	year = {2019}
}

@inproceedings{fattal_saliency-guided_2017,
	title = {Saliency-guided region proposal network for {CNN} based object detection},
	doi = {10.1109/ITSC.2017.8317756},
	abstract = {Robust sensing of the environment is fundamental for driver assistance systems performing safe maneuvers. While approaches to object detection have experienced tremendous improvements since the introduction and combination of region proposal and convolutional neural networks in one framework, the detection of distant objects occupying just a few pixels in images can be challenging though. The convolutional and pooling layers reduce the image information to feature maps; yet, relevant information may be lost through pooling and convolution for small objects. In order to address this challenge, a new approach to proposing regions is presented that extends the architecture of a region proposal network by incorporating priors to guide the proposals towards regions containing potential target objects. Moreover, inspired by the concept of saliency, a saliency-based prior is chosen to guide the RPN towards important regions in order to make efficient use of differences between objects and background in an unsupervised fashion. This allows the network not only to consider local information provided by the convolutional layers, but also to take into account global information provided by the saliency priors. Experimental results based on a distant vehicle dataset and different configurations including three priors show that the incorporation of saliency-inspired priors into a region proposal network can improve its performance significantly.},
	booktitle = {2017 {IEEE} 20th {International} {Conference} on {Intelligent} {Transportation} {Systems} ({ITSC})},
	author = {Fattal, A. and Karg, M. and Scharfenberger, C. and Adamy, J.},
	month = oct,
	year = {2017},
	keywords = {CNN based object detection, Computer architecture, Conferences, Feature extraction, Intelligent transportation systems, Object detection, Proposals, RPN, Visualization, convolution, convolutional layers, convolutional neural networks, distant object detection, distant vehicle dataset, driver assistance systems, driver information systems, environmental robust sensing, feedforward neural nets, global information, image information, image pixels, local information, object detection, pooling layers, proposing regions, saliency-based prior, saliency-guided region proposal network, target objects},
	pages = {1--8}
}

@article{bampis_revisiting_2019,
	title = {Revisiting the {Bag}-of-{Visual}-{Words} model: {A} hierarchical localization architecture for mobile systems},
	volume = {113},
	issn = {0921-8890},
	shorttitle = {Revisiting the {Bag}-of-{Visual}-{Words} model},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889018305293},
	doi = {10.1016/j.robot.2019.01.004},
	abstract = {In this paper, an enhanced visual place recognition system is proposed aiming to improve the localization performance of a mobile platform. Our technique takes full advantage of the continuous input image stream in order to provide additional knowledge to the matching functionality. The well-established Bag-of-Visual-Words model is adapted into a hierarchical design that derives the visual information from the full entity of a natural scene into the description, while it additionally preserves the geometric structure of the explored world. Our approach is evaluated as part of a state-of-the-art Simultaneous-Localization-and-Mapping algorithm, and parallelization techniques are exploited utilizing every available hardware module in a low-power device. The implemented algorithm has been tested on several publicly available datasets offering consistently accurate localization results and preventing the majority of redundant computations that the additional geometrical verifications can induce.},
	urldate = {2019-03-18},
	journal = {Robotics and Autonomous Systems},
	author = {Bampis, Loukas and Gasteratos, Antonios},
	month = mar,
	year = {2019},
	keywords = {Localization, Mobile systems, Parallel programming, Visual place recognition},
	pages = {104--119}
}

@article{selvaraju_grad-cam:_2016,
	title = {Grad-{CAM}: {Visual} {Explanations} from {Deep} {Networks} via {Gradient}-based {Localization}},
	shorttitle = {Grad-{CAM}},
	url = {http://arxiv.org/abs/1610.02391},
	abstract = {We propose a technique for producing "visual explanations" for decisions from a large class of CNN-based models, making them more transparent. Our approach - Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept, flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Unlike previous approaches, GradCAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g. VGG), (2) CNNs used for structured outputs (e.g. captioning), (3) CNNs used in tasks with multimodal inputs (e.g. VQA) or reinforcement learning, without any architectural changes or re-training. We combine GradCAM with fine-grained visualizations to create a high-resolution class-discriminative visualization and apply it to off-the-shelf image classification, captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classification models, our visualizations (a) lend insights into their failure modes (showing that seemingly unreasonable predictions have reasonable explanations), (b) are robust to adversarial images, (c) outperform previous methods on weakly-supervised localization, (d) are more faithful to the underlying model and (e) help achieve generalization by identifying dataset bias. For captioning and VQA, our visualizations show that even non-attention based models can localize inputs. Finally, we conduct human studies to measure if GradCAM explanations help users establish trust in predictions from deep networks and show that GradCAM helps untrained users successfully discern a "stronger" deep network from a "weaker" one. Our code is available at https://github.com/ramprs/grad-cam. A demo and a video of the demo can be found at http://gradcam.cloudcv.org and youtu.be/COjUB9Izk6E.},
	urldate = {2019-03-15},
	journal = {arXiv:1610.02391 [cs]},
	author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	month = oct,
	year = {2016},
	note = {arXiv: 1610.02391},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning}
}

@article{sadeghi_cad2rl:_2016,
	title = {{CAD2RL}: {Real} {Single}-{Image} {Flight} without a {Single} {Real} {Image}},
	shorttitle = {{CAD2RL}},
	url = {http://arxiv.org/abs/1611.04201},
	abstract = {Deep reinforcement learning has emerged as a promising and powerful technique for automatically acquiring control policies that can process raw sensory inputs, such as images, and perform complex behaviors. However, extending deep RL to real-world robotic tasks has proven challenging, particularly in safety-critical domains such as autonomous flight, where a trial-and-error learning process is often impractical. In this paper, we explore the following question: can we train vision-based navigation policies entirely in simulation, and then transfer them into the real world to achieve real-world flight without a single real training image? We propose a learning method that we call CAD\${\textasciicircum}2\$RL, which can be used to perform collision-free indoor flight in the real world while being trained entirely on 3D CAD models. Our method uses single RGB images from a monocular camera, without needing to explicitly reconstruct the 3D geometry of the environment or perform explicit motion planning. Our learned collision avoidance policy is represented by a deep convolutional neural network that directly processes raw monocular images and outputs velocity commands. This policy is trained entirely on simulated images, with a Monte Carlo policy evaluation algorithm that directly optimizes the network's ability to produce collision-free flight. By highly randomizing the rendering settings for our simulated training set, we show that we can train a policy that generalizes to the real world, without requiring the simulator to be particularly realistic or high-fidelity. We evaluate our method by flying a real quadrotor through indoor environments, and further evaluate the design choices in our simulator through a series of ablation studies on depth prediction. For supplementary video see: https://youtu.be/nXBWmzFrj5s},
	urldate = {2019-03-14},
	journal = {arXiv:1611.04201 [cs]},
	author = {Sadeghi, Fereshteh and Levine, Sergey},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.04201},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Robotics}
}

@article{muller_teaching_2017,
	title = {Teaching {UAVs} to {Race}: {End}-to-{End} {Regression} of {Agile} {Controls} in {Simulation}},
	shorttitle = {Teaching {UAVs} to {Race}},
	url = {http://arxiv.org/abs/1708.05884},
	abstract = {Automating the navigation of unmanned aerial vehicles (UAVs) in diverse scenarios has gained much attention in recent years. However, teaching UAVs to fly in challenging environments remains an unsolved problem, mainly due to the lack of training data. In this paper, we train a deep neural network to predict UAV controls from raw image data for the task of autonomous UAV racing in a photo-realistic simulation. Training is done through imitation learning with data augmentation to allow for the correction of navigation mistakes. Extensive experiments demonstrate that our trained network (when sufficient data augmentation is used) outperforms state-of-the-art methods and flies more consistently than many human pilots. Additionally, we show that our optimized network architecture can run in real-time on embedded hardware, allowing for efficient on-board processing critical for real-world deployment. From a broader perspective, our results underline the importance of extensive data augmentation techniques to improve robustness in end-to-end learning setups.},
	urldate = {2019-03-14},
	journal = {arXiv:1708.05884 [cs]},
	author = {Müller, Matthias and Casser, Vincent and Smith, Neil and Michels, Dominik L. and Ghanem, Bernard},
	month = aug,
	year = {2017},
	note = {arXiv: 1708.05884},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{kaufmann_deep_2018,
	title = {Deep {Drone} {Racing}: {Learning} {Agile} {Flight} in {Dynamic} {Environments}},
	shorttitle = {Deep {Drone} {Racing}},
	url = {http://arxiv.org/abs/1806.08548},
	abstract = {Autonomous agile flight brings up fundamental challenges in robotics, such as coping with unreliable state estimation, reacting optimally to dynamically changing environments, and coupling perception and action in real time under severe resource constraints. In this paper, we consider these challenges in the context of autonomous, vision-based drone racing in dynamic environments. Our approach combines a convolutional neural network (CNN) with a state-of-the-art path-planning and control system. The CNN directly maps raw images into a robust representation in the form of a waypoint and desired speed. This information is then used by the planner to generate a short, minimum-jerk trajectory segment and corresponding motor commands to reach the desired goal. We demonstrate our method in autonomous agile flight scenarios, in which a vision-based quadrotor traverses drone-racing tracks with possibly moving gates. Our method does not require any explicit map of the environment and runs fully onboard. We extensively test the precision and robustness of the approach in simulation and in the physical world. We also evaluate our method against state-of-the-art navigation approaches and professional human drone pilots.},
	urldate = {2019-03-14},
	journal = {arXiv:1806.08548 [cs]},
	author = {Kaufmann, Elia and Loquercio, Antonio and Ranftl, Rene and Dosovitskiy, Alexey and Koltun, Vladlen and Scaramuzza, Davide},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.08548},
	keywords = {Computer Science - Robotics}
}

@inproceedings{gandhi_learning_2017,
	title = {Learning to fly by crashing},
	doi = {10.1109/IROS.2017.8206247},
	abstract = {How do you learn to navigate an Unmanned Aerial Vehicle (UAV) and avoid obstacles? One approach is to use a small dataset collected by human experts: however, high capacity learning algorithms tend to overfit when trained with little data. An alternative is to use simulation. But the gap between simulation and real world remains large especially for perception problems. The reason most research avoids using large-scale real data is the fear of crashes! In this paper, we propose to bite the bullet and collect a dataset of crashes itself! We build a drone whose sole purpose is to crash into objects: it samples naive trajectories and crashes into random objects. We crash our drone 11,500 times to create one of the biggest UAV crash dataset. This dataset captures the different ways in which a UAV can crash. We use all this negative flying data in conjunction with positive data sampled from the same trajectories to learn a simple yet powerful policy for UAV navigation. We show that this simple self-supervised model is quite effective in navigating the UAV even in extremely cluttered environments with dynamic obstacles including humans. For supplementary video see:.},
	booktitle = {2017 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Gandhi, D. and Pinto, L. and Gupta, A.},
	month = sep,
	year = {2017},
	keywords = {Cameras, Computer crashes, Data collection, Drones, Navigation, Trajectory, UAV crash dataset, UAV navigation, Unmanned Aerial Vehicle, aerospace navigation, autonomous aerial vehicles, collision avoidance, drone, dynamic obstacles, flying data, motion control, naive trajectories, obstacle avoidance, trajectory control},
	pages = {3948--3955}
}

@article{yosinski_understanding_2015,
	title = {Understanding {Neural} {Networks} {Through} {Deep} {Visualization}},
	url = {http://arxiv.org/abs/1506.06579},
	abstract = {Recent years have produced great advances in training large, deep neural networks (DNNs), including notable successes in training convolutional neural networks (convnets) to recognize natural images. However, our understanding of how these models work, especially what computations they perform at intermediate layers, has lagged behind. Progress in the field will be further accelerated by the development of better tools for visualizing and interpreting neural nets. We introduce two such tools here. The first is a tool that visualizes the activations produced on each layer of a trained convnet as it processes an image or video (e.g. a live webcam stream). We have found that looking at live activations that change in response to user input helps build valuable intuitions about how convnets work. The second tool enables visualizing features at each layer of a DNN via regularized optimization in image space. Because previous versions of this idea produced less recognizable images, here we introduce several new regularization methods that combine to produce qualitatively clearer, more interpretable visualizations. Both tools are open source and work on a pre-trained convnet with minimal setup.},
	urldate = {2019-03-14},
	journal = {arXiv:1506.06579 [cs]},
	author = {Yosinski, Jason and Clune, Jeff and Nguyen, Anh and Fuchs, Thomas and Lipson, Hod},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.06579},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing}
}

@article{zaheer_deep_2017,
	title = {Deep {Sets}},
	url = {http://arxiv.org/abs/1703.06114},
	abstract = {We study the problem of designing models for machine learning tasks defined on {\textbackslash}emph\{sets\}. In contrast to traditional approach of operating on fixed dimensional vectors, we consider objective functions defined on sets that are invariant to permutations. Such problems are widespread, ranging from estimation of population statistics {\textbackslash}cite\{poczos13aistats\}, to anomaly detection in piezometer data of embankment dams {\textbackslash}cite\{Jung15Exploration\}, to cosmology {\textbackslash}cite\{Ntampaka16Dynamical,Ravanbakhsh16ICML1\}. Our main theorem characterizes the permutation invariant functions and provides a family of functions to which any permutation invariant objective function must belong. This family of functions has a special structure which enables us to design a deep network architecture that can operate on sets and which can be deployed on a variety of scenarios including both unsupervised and supervised learning tasks. We also derive the necessary and sufficient conditions for permutation equivariance in deep models. We demonstrate the applicability of our method on population statistic estimation, point cloud classification, set expansion, and outlier detection.},
	urldate = {2019-03-13},
	journal = {arXiv:1703.06114 [cs, stat]},
	author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan and Smola, Alexander},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.06114},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{howard_mobilenets:_2017,
	title = {{MobileNets}: {Efficient} {Convolutional} {Neural} {Networks} for {Mobile} {Vision} {Applications}},
	shorttitle = {{MobileNets}},
	url = {http://arxiv.org/abs/1704.04861},
	abstract = {We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.},
	urldate = {2019-03-13},
	journal = {arXiv:1704.04861 [cs]},
	author = {Howard, Andrew G. and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
	month = apr,
	year = {2017},
	note = {arXiv: 1704.04861},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{hong_virtual--real:_2018,
	title = {Virtual-to-{Real}: {Learning} to {Control} in {Visual} {Semantic} {Segmentation}},
	shorttitle = {Virtual-to-{Real}},
	url = {http://arxiv.org/abs/1802.00285},
	abstract = {Collecting training data from the physical world is usually time-consuming and even dangerous for fragile robots, and thus, recent advances in robot learning advocate the use of simulators as the training platform. Unfortunately, the reality gap between synthetic and real visual data prohibits direct migration of the models trained in virtual worlds to the real world. This paper proposes a modular architecture for tackling the virtual-to-real problem. The proposed architecture separates the learning model into a perception module and a control policy module, and uses semantic image segmentation as the meta representation for relating these two modules. The perception module translates the perceived RGB image to semantic image segmentation. The control policy module is implemented as a deep reinforcement learning agent, which performs actions based on the translated image segmentation. Our architecture is evaluated in an obstacle avoidance task and a target following task. Experimental results show that our architecture significantly outperforms all of the baseline methods in both virtual and real environments, and demonstrates a faster learning curve than them. We also present a detailed analysis for a variety of variant configurations, and validate the transferability of our modular architecture.},
	urldate = {2019-03-13},
	journal = {arXiv:1802.00285 [cs]},
	author = {Hong, Zhang-Wei and Yu-Ming, Chen and Su, Shih-Yang and Shann, Tzu-Yun and Chang, Yi-Hsiang and Yang, Hsuan-Kung and Ho, Brian Hsi-Lin and Tu, Chih-Chieh and Chang, Yueh-Chuan and Hsiao, Tsu-Ching and Hsiao, Hsin-Wei and Lai, Sih-Pin and Lee, Chun-Yi},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.00285},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics, Computer Science - Systems and Control}
}

@misc{noauthor_welcome_2019,
	title = {Welcome to {Spinning} {Up} in {Deep} {RL}! — {Spinning} {Up} documentation},
	url = {https://spinningup.openai.com/en/latest/},
	urldate = {2019-03-13},
	month = mar,
	year = {2019}
}

@article{nicholson_quadricslam:_2019,
	title = {{QuadricSLAM}: {Dual} {Quadrics} {From} {Object} {Detections} as {Landmarks} in {Object}-{Oriented} {SLAM}},
	volume = {4},
	issn = {2377-3766},
	shorttitle = {{QuadricSLAM}},
	doi = {10.1109/LRA.2018.2866205},
	abstract = {In this letter, we use two-dimensional (2-D) object detections from multiple views to simultaneously estimate a 3-D quadric surface for each object and localize the camera position. We derive a simultaneous localization and mapping (SLAM) formulation that uses dual quadrics as 3-D landmark representations, exploiting their ability to compactly represent the size, position and orientation of an object, and show how 2-D object detections can directly constrain the quadric parameters via a novel geometric error formulation. We develop a sensor model for object detectors that addresses the challenge of partially visible objects, and demonstrate how to jointly estimate the camera pose and constrained dual quadric parameters in factor graph based SLAM with a general perspective camera.},
	number = {1},
	journal = {IEEE Robotics and Automation Letters},
	author = {Nicholson, L. and Milford, M. and Sünderhauf, N.},
	month = jan,
	year = {2019},
	keywords = {2-D object detections, 3-D landmark representations, 3-D quadric surface, Cameras, Detectors, Ellipsoids, Object detection, SLAM, SLAM (robots), SLAM formulation, Semantics, Simultaneous localization and mapping, Three-dimensional displays, camera position, cameras, dual quadric parameters, factor graph based SLAM, general perspective camera, geometric error formulation, graph theory, mobile robots, object detection, object detectors, object-oriented SLAM, partially visible objects, robot vision, semantic scene understanding, simultaneous localization and mapping},
	pages = {1--8}
}

@article{he_mask_2018,
	title = {Mask {R}-{CNN}},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2018.2844175},
	abstract = {We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, {\textbackslash}eg, allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without bells and whistles, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code has been made available at: https://github.com/facebookresearch/Detectron.},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {He, K. and Gkioxari, G. and Dollar, P. and Girshick, R.},
	year = {2018},
	keywords = {Convolutional Neural Network, Feature extraction, Image segmentation, Instance Segmentation, Object Detection, Object detection, Pose Estimation, Proposals, Quantization (signal), Semantics, Task analysis},
	pages = {1--1}
}

@article{dubey_investigating_2018,
	title = {Investigating {Human} {Priors} for {Playing} {Video} {Games}},
	url = {http://arxiv.org/abs/1802.10217},
	abstract = {What makes humans so good at solving seemingly complex video games? Unlike computers, humans bring in a great deal of prior knowledge about the world, enabling efficient decision making. This paper investigates the role of human priors for solving video games. Given a sample game, we conduct a series of ablation studies to quantify the importance of various priors on human performance. We do this by modifying the video game environment to systematically mask different types of visual information that could be used by humans as priors. We find that removal of some prior knowledge causes a drastic degradation in the speed with which human players solve the game, e.g. from 2 minutes to over 20 minutes. Furthermore, our results indicate that general priors, such as the importance of objects and visual consistency, are critical for efficient game-play. Videos and the game manipulations are available at https://rach0012.github.io/humanRL\_website/},
	urldate = {2019-03-13},
	journal = {arXiv:1802.10217 [cs]},
	author = {Dubey, Rachit and Agrawal, Pulkit and Pathak, Deepak and Griffiths, Thomas L. and Efros, Alexei A.},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.10217},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning}
}

@article{redmon_yolov3:_2018,
	title = {{YOLOv3}: {An} {Incremental} {Improvement}},
	shorttitle = {{YOLOv3}},
	url = {https://arxiv.org/abs/1804.02767v1},
	abstract = {We present some updates to YOLO! We made a bunch of little design changes to
make it better. We also trained this new network that's pretty swell. It's a
little bigger than last time but more accurate. It's still fast though, don't
worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but
three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3
is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5
mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always,
all the code is online at https://pjreddie.com/yolo/},
	language = {en},
	urldate = {2019-03-13},
	author = {Redmon, Joseph and Farhadi, Ali},
	month = apr,
	year = {2018}
}

@inproceedings{kouris_learning_2018,
	title = {Learning to {Fly} by {MySelf}: {A} {Self}-{Supervised} {CNN}-{Based} {Approach} for {Autonomous} {Navigation}},
	shorttitle = {Learning to {Fly} by {MySelf}},
	doi = {10.1109/IROS.2018.8594204},
	abstract = {Nowadays, Unmanned Aerial Vehicles (UAVs)are becoming increasingly popular facilitated by their extensive availability. Autonomous navigation methods can act as an enabler for the safe deployment of drones on a wide range of real-world civilian applications. In this work, we introduce a self-supervised CNN-based approach for indoor robot navigation. Our method addresses the problem of real-time obstacle avoidance, by employing a regression CNN that predicts the agent's distance-to-collision in view of the raw visual input of its on-board monocular camera. The proposed CNN is trained on our custom indoor-flight dataset which is collected and annotated with real-distance labels, in a self-supervised manner using external sensors mounted on an UAV. By simultaneously processing the current and previous input frame, the proposed CNN extracts spatio-temporal features that encapsulate both static appearance and motion information to estimate the robot's distance to its closest obstacle towards multiple directions. These predictions are used to modulate the yaw and linear velocity of the UAV, in order to navigate autonomously and avoid collisions. Experimental evaluation demonstrates that the proposed approach learns a navigation policy that achieves high accuracy on real-world indoor flights, outperforming previously proposed methods from the literature.},
	booktitle = {2018 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Kouris, A. and Bouganis, C.},
	month = oct,
	year = {2018},
	keywords = {Cameras, Drones, Navigation, Robots, Sensors, Task analysis, Trajectory, UAV, agent distance-to-collision prediction, autonomous aerial vehicles, autonomous navigation methods, civilian applications, collision avoidance, convolutional neural nets, drone safe deployment, external sensors, feature extraction, indoor flights, indoor navigation, indoor robot navigation, indoor-flight dataset, learning (artificial intelligence), learning systems, linear velocity, mobile robots, motion control, motion information, navigation policy, navigation policy learning, neurocontrollers, on-board monocular camera, raw visual input, real-distance labels, real-time obstacle avoidance, regression CNN, regression analysis, robot distance estimation, robot vision, self-supervised CNN-based approach, sensor fusion, spatio-temporal feature extraction, static appearance information, unmanned aerial vehicles, velocity control},
	pages = {1--9}
}

@inproceedings{modasshir_deep_2018,
	title = {Deep {Neural} {Networks}: {A} {Comparison} on {Different} {Computing} {Platforms}},
	shorttitle = {Deep {Neural} {Networks}},
	doi = {10.1109/CRV.2018.00060},
	abstract = {Deep Neural Networks (DNN) have gained tremendous popularity over the last years for several computer vision tasks, including classification and object detection. Such techniques have been able to achieve human-level performance in many tasks and have produced results of unprecedented accuracy. As DNNs have intense computational requirements in the majority of applications, they utilize a cluster of computers or a cutting edge Graphical Processing Unit (GPU), often having excessive power consumption and generating a lot of heat. In many robotics applications the above requirements prove to be a challenge, as there is limited power on-board and heat dissipation is always a problem. In particular in underwater robotics with limited space, the above two requirements have been proven prohibitive. As first of this kind, this paper aims at analyzing and comparing the performance of several state-of-the-art DNNs on different platforms. With a focus on the underwater domain, the capabilities of the Jetson TX2 from NVIDIA and the Neural Compute Stick from Intel are of particular interest. Experiments on standard datasets show how different platforms are usable on an actual robotic system, providing insights on the current state-of-the-art embedded systems. Based on such results, we propose some guidelines in choosing the appropriate platform and network architecture for a robotic system.},
	booktitle = {2018 15th {Conference} on {Computer} and {Robot} {Vision} ({CRV})},
	author = {Modasshir, M. and Li, A. Quattrini and Rekleitis, I.},
	month = may,
	year = {2018},
	keywords = {Comparison, Deep Neural Networks, Embedded Systems, Embedded systems, GPU, Graphics processing units, Neural networks, Object detection, Portable computers, Robots, Task analysis, computer clusters, computer vision, computer vision tasks, computing platforms, cooling, deep neural networks, embedded systems, graphical processing unit, graphics processing units, heat dissipation, human-level performance, image classification, mobile robots, neural nets, object detection, power consumption, power on-board dissipation, robotic system network architecture, underwater robotics application},
	pages = {383--389}
}

@inproceedings{silano_crazys:_2018,
	title = {{CrazyS}: {A} {Software}-{In}-{The}-{Loop} {Platform} for the {Crazyflie} 2.0 {Nano}-{Quadcopter}},
	shorttitle = {{CrazyS}},
	doi = {10.1109/MED.2018.8442759},
	abstract = {In this paper we propose CrazyS, an extension of the ROS (Robot Operating System) package RotorS, aimed to modeling, developing and integrating the Crazyflie 2.0 nano-quadcopter in the physics based simulation environment Gazebo. Such simulation platform allows to understand quickly the behavior of the flight control system by comparing and evaluating different indoor and outdoor scenarios, with a details level quite close to reality. The proposed extension expands RotorS capabilities by considering the Crazyflie 2.0 physical model and its flight control system, as well. A simple case study has been considered in order to show how the package works. The use of open-source software makes the platform available for scientific and educational activities.},
	booktitle = {2018 26th {Mediterranean} {Conference} on {Control} and {Automation} ({MED})},
	author = {Silano, G. and Aucone, E. and Iannelli, L.},
	month = jun,
	year = {2018},
	keywords = {Aircraft, Atmospheric modeling, Crazyflie 2.0 nanoquadcopter, Crazyflie 2.0 physical model, Drones, Mathematical model, ROS package, Robot Operating System, Robot sensing systems, Rotors, Software-In-The-Loop Platform, Vehicle dynamics, aircraft control, control engineering computing, flight control system, helicopters, industrial robots, multi-robot systems, public domain software},
	pages = {1--6}
}

@inproceedings{bengio_curriculum_2009,
	address = {Montreal, Quebec, Canada},
	title = {Curriculum learning},
	isbn = {978-1-60558-516-1},
	url = {http://portal.acm.org/citation.cfm?doid=1553374.1553380},
	doi = {10.1145/1553374.1553380},
	abstract = {Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them “curriculum learning”. In the context of recent research studying the diﬃculty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that signiﬁcant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an eﬀect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).},
	language = {en},
	urldate = {2019-03-12},
	booktitle = {Proceedings of the 26th {Annual} {International} {Conference} on {Machine} {Learning} - {ICML} '09},
	publisher = {ACM Press},
	author = {Bengio, Yoshua and Louradour, Jérôme and Collobert, Ronan and Weston, Jason},
	year = {2009},
	pages = {1--8}
}

@article{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2019-03-12},
	journal = {arXiv:1512.03385 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.03385},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{mur-artal_orb-slam2:_2017,
	title = {{ORB}-{SLAM2}: {An} {Open}-{Source} {SLAM} {System} for {Monocular}, {Stereo}, and {RGB}-{D} {Cameras}},
	volume = {33},
	issn = {1552-3098},
	shorttitle = {{ORB}-{SLAM2}},
	doi = {10.1109/TRO.2017.2705103},
	abstract = {We present ORB-SLAM2, a complete simultaneous localization and mapping (SLAM) system for monocular, stereo and RGB-D cameras, including map reuse, loop closing, and relocalization capabilities. The system works in real time on standard central processing units in a wide variety of environments from small hand-held indoors sequences, to drones flying in industrial environments and cars driving around a city. Our back-end, based on bundle adjustment with monocular and stereo observations, allows for accurate trajectory estimation with metric scale. Our system includes a lightweight localization mode that leverages visual odometry tracks for unmapped regions and matches with map points that allow for zero-drift localization. The evaluation on 29 popular public sequences shows that our method achieves state-of-the-art accuracy, being in most cases the most accurate SLAM solution. We publish the source code, not only for the benefit of the SLAM community, but with the aim of being an out-of-the-box SLAM solution for researchers in other fields.},
	number = {5},
	journal = {IEEE Transactions on Robotics},
	author = {Mur-Artal, R. and Tardós, J. D.},
	month = oct,
	year = {2017},
	keywords = {Cameras, Feature extraction, Kalman filters, Localization, ORB-SLAM, Optimization, RGB-D, RGB-D cameras, SLAM (robots), SLAM community, Simultaneous localization and mapping, Tracking loops, Trajectory, cameras, distance measurement, lightweight localization mode, map points, mapping, mobile robots, monocular cameras, motion estimation, open-source SLAM system, path planning, robot vision, simultaneous localization and mapping (SLAM), simultaneous localization and mapping system, stereo, stereo cameras, zero-drift localization},
	pages = {1255--1262}
}

@inproceedings{mccormac_semanticfusion:_2017,
	address = {Singapore, Singapore},
	title = {{SemanticFusion}: {Dense} {3D} semantic mapping with convolutional neural networks},
	isbn = {978-1-5090-4633-1},
	shorttitle = {{SemanticFusion}},
	url = {http://ieeexplore.ieee.org/document/7989538/},
	doi = {10.1109/ICRA.2017.7989538},
	abstract = {Ever more robust, accurate and detailed mapping using visual sensing has proven to be an enabling factor for mobile robots across a wide variety of applications. For the next level of robot intelligence and intuitive user interaction, maps need to extend beyond geometry and appearance — they need to contain semantics. We address this challenge by combining Convolutional Neural Networks (CNNs) and a state-of-the-art dense Simultaneous Localisation and Mapping (SLAM) system, ElasticFusion, which provides long-term dense correspondences between frames of indoor RGB-D video even during loopy scanning trajectories. These correspondences allow the CNN’s semantic predictions from multiple view points to be probabilistically fused into a map. This not only produces a useful semantic 3D map, but we also show on the NYUv2 dataset that fusing multiple predictions leads to an improvement even in the 2D semantic labelling over baseline single frame predictions. We also show that for a smaller reconstruction dataset with larger variation in prediction viewpoint, the improvement over single frame segmentation increases. Our system is efﬁcient enough to allow real-time interactive use at frame-rates of ≈25Hz.},
	language = {en},
	urldate = {2019-03-12},
	booktitle = {2017 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	publisher = {IEEE},
	author = {McCormac, John and Handa, Ankur and Davison, Andrew and Leutenegger, Stefan},
	month = may,
	year = {2017},
	pages = {4628--4635}
}

@inproceedings{toudeshki_robust_2018,
	title = {Robust {UAV} {Visual} {Teach} and {Repeat} {Using} {Only} {Sparse} {Semantic} {Object} {Features}},
	doi = {10.1109/CRV.2018.00034},
	abstract = {We demonstrate the use of semantic object detections as robust features for Visual Teach and Repeat (VTR). Recent CNN-based object detectors are able to reliably detect objects of tens or hundreds of categories in video at frame rates. We show that such detections are repeatable enough to use as landmarks for VTR, without any low-level image features. Since object detections are highly invariant to lighting and surface appearance changes, our VTR can cope with global lighting changes and local movements of the landmark objects. In the teaching phase we build extremely compact scene descriptors: a list of detected object labels and their image-plane locations. In the repeating phase, we use Seq-SLAM-like relocalization to identify the most similar learned scene, then use a motion control algorithm based on the funnel lane theory to navigate the robot along the previously piloted trajectory. We evaluate the method on a commodity UAV, examining the robustness of the algorithm to new viewpoints, lighting conditions, and movements of landmark objects. The results suggest that semantic object features could be useful due to their invariance to superficial appearance changes compared to low-level image features.},
	booktitle = {2018 15th {Conference} on {Computer} and {Robot} {Vision} ({CRV})},
	author = {Toudeshki, A. G. and Shamshirdar, F. and Vaughan, R.},
	month = may,
	year = {2018},
	keywords = {CNN based object detector, CNN-based object detectors, Detectors, Feature extraction, Lighting, Robots, SLAM (robots), Semantics, Trajectory, VTR, Video recording, autonomous aerial vehicles, commodity UAV, detected object labels, extremely compact scene descriptors, feature extraction, funnel lane theory, global lighting changes, image sensors, image-plane locations, landmark objects, learning (artificial intelligence), low-level image features, mobile robots, motion control, motion control algorithm, object detection, path planning, repeating phase, robot navigation, robot vision, robust UAV visual teach and repeat, robust features, semantic navigation, semantic object detections, sparse semantic object features, superficial appearance changes, surface appearance changes, teaching phase, trajectory control, visual teach and repeat},
	pages = {182--189}
}

@inproceedings{murali_utilizing_2017,
	address = {Yokohama},
	title = {Utilizing semantic visual landmarks for precise vehicle navigation},
	isbn = {978-1-5386-1526-3},
	url = {http://ieeexplore.ieee.org/document/8317859/},
	doi = {10.1109/ITSC.2017.8317859},
	urldate = {2019-03-12},
	booktitle = {2017 {IEEE} 20th {International} {Conference} on {Intelligent} {Transportation} {Systems} ({ITSC})},
	publisher = {IEEE},
	author = {Murali, Varun and Chiu, Han-Pang and Samarasekera, Supun and Kumar, Rakesh Teddy},
	month = oct,
	year = {2017},
	pages = {1--8}
}

@inproceedings{tenorth_knowrob-map_2010,
	title = {{KNOWROB}-{MAP} - knowledge-linked semantic object maps},
	doi = {10.1109/ICHR.2010.5686350},
	abstract = {Autonomous household robots are supposed to accomplish complex tasks like cleaning the dishes which involve both navigation and manipulation within the environment. For navigation, spatial information is mostly sufficient, but manipulation tasks raise the demand for deeper knowledge about objects, such as their types, their functions, or the way how they can be used. We present KNOWROB-MAP, a system for building environment models for robots by combining spatial information about objects in the environment with encyclopedic knowledge about the types and properties of objects, with common-sense knowledge describing what the objects can be used for, and with knowledge derived from observations of human activities by learning statistical relational models. In this paper, we describe the concept and implementation of KNOWROB-MAP and present several examples demonstrating the range of information the system can provide to autonomous robots.},
	booktitle = {2010 10th {IEEE}-{RAS} {International} {Conference} on {Humanoid} {Robots}},
	author = {Tenorth, M. and Kunze, L. and Jain, D. and Beetz, M.},
	month = dec,
	year = {2010},
	keywords = {Containers, Data structures, KNOWROB-MAP, Knowledge based systems, Knowledge representation, Robot sensing systems, Semantics, autonomous household robots, common-sense knowledge, encyclopaedias, encyclopedic knowledge, knowledge engineering, knowledge-linked semantic object maps, manipulation tasks, mobile robots, service robots, statistical analysis, statistical relational models},
	pages = {430--435}
}

@inproceedings{katsura_view-based_2003,
	title = {A view-based outdoor navigation using object recognition robust to changes of weather and seasons},
	volume = {3},
	doi = {10.1109/IROS.2003.1249323},
	abstract = {This paper describes a view-based outdoor navigation method. In the method, a user first guides a robot along a route. During this guided movement, the robot learns a sequence of images and a rough geometry of the route. The robot then moves autonomously along the route with localizing itself based on the comparison between the learned images and input images. Since appearances of objects in images may vary much according to changes of seasons and weather in outdoor scenes, a simple image comparison does not work. We, therefore, propose a comparison method in which the robot first recognizes objects in images using object models which allow for appearance variations, and then compares recognition results of learned and input images. We also developed a method which automatically selects key images used for the comparison from an image sequence. Successful autonomous navigation experiments in our campus under various conditions show the feasibility of the method.},
	booktitle = {Proceedings 2003 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS} 2003) ({Cat}. {No}.{03CH37453})},
	author = {Katsura, H. and Miura, J. and Hild, M. and Shirai, Y.},
	month = oct,
	year = {2003},
	keywords = {Global Positioning System, Image recognition, Image sequences, Layout, Mobile robots, Navigation, Object recognition, Robot vision systems, Robotics and automation, Robustness, autonomous navigation, image sequence, image sequences, input images, learned images, mobile robots, object recognition, outdoor scenes, path planning, robot, robot vision, rough geometry, view based outdoor navigation, weather},
	pages = {2974--2979 vol.3}
}

@article{meger_curious_2008,
	series = {From {Sensors} to {Human} {Spatial} {Concepts}},
	title = {Curious {George}: {An} attentive semantic robot},
	volume = {56},
	issn = {0921-8890},
	shorttitle = {Curious {George}},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889008000316},
	doi = {10.1016/j.robot.2008.03.008},
	abstract = {State-of-the-art methods have recently achieved impressive performance for recognising the objects present in large databases of pre-collected images. There has been much less focus on building embodied systems that recognise objects present in the real world. This paper describes an intelligent system that attempts to perform robust object recognition in a realistic scenario, where a mobile robot moving through an environment must use the images collected from its camera directly to recognise objects. To perform successful recognition in this scenario, we have chosen a combination of techniques including a peripheral-foveal vision system, an attention system combining bottom-up visual saliency with structure from stereo, and a localisation and mapping technique. The result is a highly capable object recognition system that can be easily trained to locate the objects of interest in an environment, and subsequently build a spatial-semantic map of the region. This capability has been demonstrated during the Semantic Robot Vision Challenge, and is further illustrated with a demonstration of semantic mapping. We also empirically verify that the attention system outperforms an undirected approach even with a significantly lower number of foveations.},
	number = {6},
	urldate = {2019-03-12},
	journal = {Robotics and Autonomous Systems},
	author = {Meger, David and Forssén, Per-Erik and Lai, Kevin and Helmer, Scott and McCann, Sancho and Southey, Tristram and Baumann, Matthew and Little, James J. and Lowe, David G.},
	month = jun,
	year = {2008},
	keywords = {Object permanence, Object recognition, Saliency, Semantic robot vision, Visual attention},
	pages = {503--511}
}

@article{zhong_continuous_2017,
	title = {Continuous learning route map for robot navigation using a growing-on-demand self-organizing neural network},
	volume = {14},
	doi = {10.1177/1729881417743612},
	abstract = {This article proposes an experience-based route map continuous learning method and applies it into robot planning and navigation. First of all, the framework for robot route map learning and navigation is designed, which incorporates the four cyclic processes of planning, motion, perception, and extraction, enabling robot to constantly learn the information of the road experience and to obtain and improve the route map of the environment. Besides, a growing-on-demand self-organizing neural network learning algorithm is also proposed. This algorithm is based on growing neural gas algorithm, but it does not require presetting of network scale, and under the condition of dynamically growing input data, it can regulate the increase scale of network online in a self-adaptive and self-organized manner to obtain stable learning results. Finally, with robot roaming in an environment, this algorithm is used to conduct continuous learning of dynamically increasing route information, extract the topological structure of the raw road data in feature space, and ultimately obtain the route map of the environment. Mobile robot utilizes the route map to plan a suitable route and guides robot to move to the destination along the route and complete navigation task. Through physical experiments in outdoor environment, its feasibility and validity are verified. © The Author(s) 2017.},
	number = {6},
	journal = {International Journal of Advanced Robotic Systems},
	author = {Zhong, C. and Liu, S. and Lu, Q. and Zhang, B.},
	year = {2017},
	keywords = {Route-based navigation, continuous learning, growing neural gas, route map, self-organizing neural network}
}

@article{piasco_survey_2018,
	title = {A survey on {Visual}-{Based} {Localization}: {On} the benefit of heterogeneous data},
	volume = {74},
	shorttitle = {A survey on {Visual}-{Based} {Localization}},
	doi = {10.1016/j.patcog.2017.09.013},
	abstract = {We are surrounded by plenty of information about our environment. From these multiple sources, numerous data could be extracted: set of images, 3D model, coloured points cloud. When classical localization devices failed (e.g. GPS sensor in cluttered environments), aforementioned data could be used within a localization framework. This is called Visual Based Localization (VBL). Due to numerous data types that can be collected from a scene, VBL encompasses a large amount of different methods. This paper presents a survey about recent methods that localize a visual acquisition system according to a known environment. We start by categorizing VBL methods into two distinct families: indirect and direct localization systems. As the localization environment is almost always dynamic, we pay special attention to methods designed to handle appearances changes occurring in a scene. Thereafter, we highlight methods exploiting heterogeneous types of data. Finally, we conclude the paper with a discussion on promising trends that could permit to a localization system to reach high precision pose estimation within an area as large as possible. © 2017 Elsevier Ltd},
	journal = {Pattern Recognition},
	author = {Piasco, N. and Sidibé, D. and Demonceaux, C. and Gouet-Brunet, V.},
	year = {2018},
	keywords = {Camera relocalisation, Image-based localization, Pose estimation, Visual geo-localization},
	pages = {90--109}
}

@article{li_robocloud:_2018,
	title = {{RoboCloud}: augmenting robotic visions for open environment modeling using {Internet} knowledge},
	volume = {61},
	shorttitle = {{RoboCloud}},
	doi = {10.1007/s11432-017-9380-5},
	abstract = {Modeling an open environment that contains unpredictable objects is a challenging problem in the field of robotics. In traditional approaches, when a robot encounters an unknown object, a mistake will inevitably be added to the robot’s environmental model, severely constraining the robot’s autonomy, and possibly leading to disastrous consequences in certain settings. The abundant knowledge accumulated on the Internet has the potential to remedy the uncertainties that result from encountering with unknown objects. However, robotic applications generally pay considerable attention to quality of service (QoS). For this reason, directly accessing the Internet, which can be unpredictable, is generally not acceptable. RoboCloud is proposed as a novel approach to environment modeling that takes advantage of the Internet without sacrificing the critical properties of QoS. RoboCloud is a “mission cloud–public cloud” layered cloud organization model in which the mission cloud provides QoS-available environment modeling capability with built-in prior knowledge while the public cloud is the existing services provided by the Internet. The “cloud phase transition” mechanism seeks help from the public cloud only when a request is outside the knowledge of the mission cloud and the QoS cost is acceptable. We have adopted semantic mapping, a typical robotic environment modeling task, to illustrate and substantiate our approach and key mechanism. Experiments using open 2D and 3D datasets with real robots have demonstrated that RoboCloud is able to augment robotic visions for open environment modeling. © 2018, Science China Press and Springer-Verlag GmbH Germany, part of Springer Nature.},
	number = {5},
	journal = {Science China Information Sciences},
	author = {Li, Y. and Wang, H. and Ding, B. and Zhou, W.},
	year = {2018},
	keywords = {Internet-augmented, cloud robotics, environment modeling, robotic software, robotic visions, semantic mapping, uncertainty}
}

@inproceedings{sousa_incremental_2018,
	title = {Incremental {Semantic} {Mapping} with {Unsupervised} {On}-line {Learning}},
	volume = {2018-July},
	doi = {10.1109/IJCNN.2018.8489430},
	abstract = {This paper introduces an incremental semantic mapping approach, with on-line unsupervised learning, based on Self-Organizing Maps (SOM) for robotic agents. The method includes a mapping module, which incrementally creates a topological map of the environment, enriched with objects recognized around each topological node, and a module of places categorization, endowed with an incremental unsupervised learning SOM with on-line training. The proposed approach was tested in experiments with real-world data, in which it demonstrates promising capabilities of incremental acquisition of topological maps enriched with semantic information, and for clustering together similar places based on this information. The approach was also able to continue learning from newly visited environments without degrading the information previously learned. © 2018 IEEE.},
	author = {Sousa, Y.C.N. and Bassani, H.F.},
	year = {2018}
}

@inproceedings{figurowski_hybrid_2018,
	title = {Hybrid path planning for mobile robot using known environment model with semantic layer},
	volume = {2029},
	doi = {10.1063/1.5066476},
	abstract = {This paper presents a path planning algorithm using multiple models derived from known environment map. Each model is generated on a different abstraction level leading to a hierarchical structure; its layers include a semantic description, world topology, and metrical layer. This approach yields several benefits in control, planning and interaction aspects of the affected mobile robot. Control for the end-user is simplified as it is focused on task execution allowing for more abstract commands to be issued, which leads to a more user-friendly interface for interacting with the mobile robot. Planning process benefits from the hierarchy structure as the search space is narrowed in subsequent abstraction levels. As a consequence, less computing power is required for finding a valid route. Conducted simulations are compared with other solutions and the results demonstrate that the presented algorithm shows good performance in complicated environments. © 2018 Author(s).},
	author = {Figurowski, D. and Jain, A.},
	year = {2018}
}

@article{moon_view-point_2018,
	title = {View-point {Invariant} {3D} {Classification} for {Mobile} {Robots} {Using} a {Convolutional} {Neural} {Network}},
	volume = {16},
	doi = {10.1007/s12555-018-0182-y},
	abstract = {3D object classification is an important component in semantic scene understanding for mobile robots. However, many current systems do not consider the practical issues such as object representation from different viewing positions of mobile robots. A novel 3D object representation is introduced using cylindrical occupancy grid and 3D convolutional neural network with row-wise max pooling layer. Due to the rotationally invariant characteristics of this method, robots can successfully classify 3D objects regardless of starting positions of object modelling. Experimental results on publicly available benchmark dataset show the significantly improved performance compared with other conventional algorithms. © 2018, Institute of Control, Robotics and Systems and The Korean Institute of Electrical Engineers and Springer-Verlag GmbH Germany, part of Springer Nature.},
	number = {6},
	journal = {International Journal of Control, Automation and Systems},
	author = {Moon, J. and Kim, H. and Lee, B.},
	year = {2018},
	keywords = {3D object classification, cylindrical CNN, mobile robots, view-point invariant},
	pages = {2888--2895}
}

@article{balaska_graph-based_2019,
	title = {Graph-based semantic segmentation},
	volume = {67},
	doi = {10.1007/978-3-030-00232-9_60},
	abstract = {This work deals with the graph-based semantic segmentation of a robot’s traversed environment using the Louvain algorithm. In recent years, semantic segmentation has been the focus of several researchers’ interest and is applied to a variety of robotic applications. The Louvain method for community detection is a novel technique for extracting communities from large networks. The method is a greedy optimization one with a complexity of O(nlogn). We first assessed the Louvain algorithm with the COLD-Freiburg dataset to create the semantic map and compute the communities. We demonstrate that lighting conditions do not affect the system’s ability to categorize places. In particular, we train the system with COLD Freiburg seg1cloudy1 and we query images from seg1sunny1 and seg1night1. The results exhibit that the system is capable of categorizing the evaluated frames into the correct community. © Springer Nature Switzerland AG 2019.},
	journal = {Mechanisms and Machine Science},
	author = {Balaska, V. and Bampis, L. and Gasteratos, A.},
	year = {2019},
	keywords = {Community detection, Illumination invariance, Robot localization, Semantic segmentation},
	pages = {572--579}
}

@article{ruiz-sarmiento_building_2017,
	title = {Building {Multiversal} {Semantic} {Maps} for {Mobile} {Robot} {Operation}},
	volume = {119},
	issn = {0950-7051},
	url = {http://www.sciencedirect.com/science/article/pii/S0950705116305184},
	doi = {10.1016/j.knosys.2016.12.016},
	abstract = {Semantic maps augment metric-topological maps with meta-information, i.e. l semantic knowledge aimed at the planning and execution of high-level robotic tasks. Semantic knowledge typically encodes human-like concepts, like types of objects and rooms, which are connected to sensory data when symbolic representations of percepts from the robot workspace are grounded to those concepts. Such a symbol grounding is usually carried out by algorithms that individually categorize each symbol and provide a crispy outcome – a symbol is either a member of a category or not. Such approach is valid for a variety of tasks, but it fails at: (i) dealing with the uncertainty inherent to the grounding process, and (ii) jointly exploiting the contextual relations among concepts (e.g. microwaves are usually in kitchens). This work provides a solution for probabilistic symbol grounding that overcomes these limitations. Concretely, we rely on Conditional Random Fields (CRFs) to model and exploit contextual relations, and to provide measurements about the uncertainty coming from the possible groundings in the form of beliefs (e.g. an object can be categorized (grounded) as a microwave or as a nightstand with beliefs 0.6 and 0.4, respectively). Our solution is integrated into a novel semantic map representation called Multiversal Semantic Map (MvSmap), which keeps the sets of different groundings, or universes, as instances of ontologies annotated with the obtained beliefs for their posterior exploitation. The suitability of our proposal has been proven with the Robot@Home dataset, a repository that contains challenging multi-modal sensory information gathered by a mobile robot in home environments.},
	urldate = {2019-03-11},
	journal = {Knowledge-Based Systems},
	author = {Ruiz-Sarmiento, Jose-Raul and Galindo, Cipriano and Gonzalez-Jimenez, Javier},
	month = mar,
	year = {2017},
	keywords = {Conditional random fields, Mobile robots, Ontologies, Semantic maps, Symbol grounding, Uncertainty handling},
	pages = {257--272}
}

@inproceedings{posada_visual_2014,
	title = {Visual {Semantic} {Robot} {Navigation} in {Indoor} {Environments}},
	abstract = {This work proposes a robot navigation framework based on semantic information extracted from visual data. The robot rather than navigating by following a sequence of metric poses, is able to reach its targets by activating behaviors described by natural language (e.g. get out of the room, follow the corridor, and then enter the room at the right). The system operates without prior map knowledge or a metric representation. This type of navigation is inspired from humans, where places are not described in terms of a global map but with semantic information. One of the advantages of this representation is that the system is able to recover from errors occurring in case of conflicts with the current context. E.g. a corridor-centering behavior activated inside a room.},
	booktitle = {{ISR}/{Robotik} 2014; 41st {International} {Symposium} on {Robotics}},
	author = {Posada, L. F. and Hoffmann, F. and Bertram, T.},
	month = jun,
	year = {2014},
	pages = {1--7}
}

@article{wang_visual_2018,
	title = {Visual {Semantic} {Navigation} {Based} on {Deep} {Learning} for {Indoor} {Mobile} {Robots}},
	volume = {2018},
	copyright = {Copyright © 2018 Li Wang et al.; This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
	issn = {10762787},
	url = {http://search.proquest.com/docview/2035224685/abstract/E8F2BAAD17F74B77PQ/1},
	doi = {http://dx.doi.org.ezp01.library.qut.edu.au/10.1155/2018/1627185},
	abstract = {In order to improve the environmental perception ability of mobile robots during semantic navigation, a three-layer perception framework based on transfer learning is proposed, including a place recognition model, a rotation region recognition model, and a “side” recognition model. The first model is used to recognize different regions in rooms and corridors, the second one is used to determine where the robot should be rotated, and the third one is used to decide the walking side of corridors or aisles in the room. Furthermore, the “side” recognition model can also correct the motion of robots in real time, according to which accurate arrival to the specific target is guaranteed. Moreover, semantic navigation is accomplished using only one sensor (a camera). Several experiments are conducted in a real indoor environment, demonstrating the effectiveness and robustness of the proposed perception framework.},
	language = {English},
	urldate = {2019-03-11},
	journal = {Complexity; Hoboken},
	author = {Wang, Li and Zhao, Lijun and Link to external site, this link will open in a new window and Huo, Guanglei and Li, Ruifeng and Hou, Zhenghua and Luo, Pan and Sun, Zhenye and Wang, Ke and Yang, Chenguang and Link to external site, this link will open in a new window},
	editor = {Floquet, Thierry},
	year = {2018},
	keywords = {Automation, Cameras, Computers--Computer Simulation, Corridors, Indoor environments, International conferences, Labeling, Machine learning, Mapping, Mathematics, Navigation, Pattern recognition, Perception, Planning, Recognition, Robotics, Robots, Semantics}
}

@inproceedings{crespo_reasoning_2018,
	title = {Reasoning {Systems} for {Semantic} {Navigation} in {Mobile} {Robots}},
	doi = {10.1109/IROS.2018.8594271},
	abstract = {Semantic navigation is the navigation paradigm in which environmental semantic concepts and their relationships are taken into account to plan the route of a mobile robot. This paradigm facilitates the interaction with humans and the understanding of human environments in terms of navigation goals and tasks. At the high level, a semantic navigation system requires two main components: a semantic representation of the environment, and a reasoning system. This paper is focused on develop a model of the environment using semantic concepts. This paper presents two solutions for the semantic navigation paradigm. Both systems implement an ontological model. Whilst the first one uses a relational database, the second one is based on KnowRob. Both systems have been integrated in a semantic navigator. We compare both systems at the qualitative and quantitative levels, and present an implementation on a mobile robot as a proof of concept.},
	booktitle = {2018 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Crespo, J. and Barber, R. and Mozos, O. M. and BeBler, D. and Beetz, M.},
	month = oct,
	year = {2018},
	keywords = {Cognition, KnowRob, Mobile robots, Navigation, Ontologies, Relational databases, Semantics, control engineering computing, environmental semantic concepts, inference mechanisms, mobile robot, mobile robots, navigation, ontological model, ontologies (artificial intelligence), path planning, reasoning system, relational database, semantic navigation paradigm, semantic navigation system, semantic representation},
	pages = {5654--5659}
}

@article{sanchez-rodriguez_survey_2018,
	title = {A survey on stereo vision-based autonomous navigation for multi-rotor {MUAVs}},
	volume = {36},
	doi = {10.1017/S0263574718000358},
	abstract = {This paper presents an overview of the most recent vision-based multi-rotor micro unmanned aerial vehicles (MUAVs) intended for autonomous navigation using a stereoscopic camera. Drone operation is difficult because pilots need the expertise to fly the drones. Pilots have a limited field of view, and unfortunate situations, such as loss of line of sight or collision with objects such as wires and branches, can happen. Autonomous navigation is an even more difficult challenge than remote control navigation because the drones must make decisions on their own in real time and simultaneously build maps of their surroundings if none is available. Moreover, MUAVs are limited in terms of useful payload capability and energy consumption. Therefore, a drone must be equipped with small sensors, and it must carry low weight. In addition, a drone requires a sufficiently powerful onboard computer so that it can understand its surroundings and navigate accordingly to achieve its goal safely. A stereoscopic camera is considered a suitable sensor because of its three-dimensional (3D) capabilities. Hence, a drone can perform vision-based navigation through object recognition and self-localise inside a map if one is available; otherwise, its autonomous navigation creates a simultaneous localisation and mapping problem. Copyright © Cambridge University Press 2018.},
	number = {8},
	journal = {Robotica},
	author = {Sanchez-Rodriguez, J.-P. and Aceves-Lopez, A.},
	year = {2018},
	keywords = {Autonomous navigation, Computer vision, Multi-rotor micro unmanned aerial vehicle (MUAV), Simultaneous localisation and mapping (SLAM), Stereoscopic vision},
	pages = {1225--1243}
}

@article{maravall_vision-based_2015,
	title = {Vision-based anticipatory controller for the autonomous navigation of an {UAV} using artificial neural networks},
	volume = {151},
	doi = {10.1016/j.neucom.2014.09.077},
	abstract = {A vision-based anticipatory controller for the autonomous indoor navigation of an unmanned aerial vehicle (UAV) is the topic of this paper. A dual Feedforward/Feedback architecture has been used as the UAV's controller and the K-NN classifier using the gray level image histogram as discriminant variables has been applied for landmarks recognition. After a brief description of the UAV, we first identify the two main components of its autonomous navigation, namely, the landmark recognition and the dual controller based on cerebellar system of living beings, then we focus on the anticipatory module that has been implemented by an artificial neural network. Afterwards, the paper describes the experimental setup and discusses the experimental results centered mainly on the basic UAV's behavior of landmark approximation maneuver, which in topological navigation is known as the beaconing or homing problem. © 2014 Elsevier B.V.},
	number = {P1},
	journal = {Neurocomputing},
	author = {Maravall, D. and de Lope, J. and Pablo Fuentes, J.},
	year = {2015},
	keywords = {Nearest neighbors methods, Neural networks, Topological maps, Unmanned aerial vehicles, Vision-based dual anticipatory reactive controllers},
	pages = {101--107}
}

@article{kurniawati_motion_2011,
	title = {Motion planning under uncertainty for robotic tasks with long time horizons},
	volume = {30},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364910386986},
	doi = {10.1177/0278364910386986},
	abstract = {Motion planning with imperfect state information is a crucial capability for autonomous robots to operate reliably in uncertain and dynamic environments. Partially observable Markov decision processes (POMDPs) provide a principled general framework for planning under uncertainty. Using probabilistic sampling, point-based POMDP solvers have drastically improved the speed of POMDP planning, enabling us to handle moderately complex robotic tasks. However, robot motion planning tasks with long time horizons remains a severe obstacle for even the fastest point-based POMDP solvers today. This paper proposes Milestone Guided Sampling (MiGS), a new point-based POMDP solver, which exploits state space information to reduce effective planning horizons. MiGS samples a set of points, called milestones, from a robot’s state space and constructs a simplified representation of the state space from the sampled milestones. It then uses this representation of the state space to guide sampling in the belief space and tries to capture the essential features of the belief space with a small number of sampled points. Preliminary results are very promising. We tested MiGS in simulation on several difficult POMDPs that model distinct robotic tasks with long time horizons in both 2-D and 3-D environments. These POMDPs are impossible to solve with the fastest point-based solvers today, but MiGS solved them in a few minutes.},
	language = {en},
	number = {3},
	urldate = {2019-03-08},
	journal = {The International Journal of Robotics Research},
	author = {Kurniawati, Hanna and Du, Yanzhu and Hsu, David and Lee, Wee Sun},
	month = mar,
	year = {2011},
	pages = {308--323}
}

@inproceedings{chen_only_2017,
	title = {Only look once, mining distinctive landmarks from {ConvNet} for visual place recognition},
	doi = {10.1109/IROS.2017.8202131},
	abstract = {Recently, image representations derived from Convolutional Neural Networks (CNNs) have been demonstrated to achieve impressive performance on a wide variety of tasks, including place recognition. In this paper, we take a step deeper into the internal structure of CNNs and propose novel CNN-based image features for place recognition by identifying salient regions and creating their regional representations directly from the convolutional layer activations. A range of experiments is conducted on challenging datasets with varied conditions and viewpoints. These reveal superior precision-recall characteristics and robustness against both viewpoint and appearance variations for the proposed approach over the state of the art. By analyzing the feature encoding process of our approach, we provide insights into what makes an image presentation robust against external variations.},
	booktitle = {2017 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Chen, Z. and Maffra, F. and Sa, I. and Chli, M.},
	month = sep,
	year = {2017},
	keywords = {CNN-based image features, ConvNet, Convolutional Neural Networks, Feature extraction, Image recognition, Image representation, Image retrieval, Robustness, Visualization, appearance variations, convolutional layer activations, distinctive landmarks mining, feature encoding process, feature extraction, feedforward neural nets, image presentation, image recognition, image representation, image representations, image retrieval, place recognition, precision-recall characteristics, regional representations, salient regions, viewpoint variations, visual place recognition},
	pages = {9--16}
}

@article{lowry_visual_2016,
	title = {Visual {Place} {Recognition}: {A} {Survey}},
	volume = {32},
	issn = {1552-3098},
	shorttitle = {Visual {Place} {Recognition}},
	doi = {10.1109/TRO.2015.2496823},
	abstract = {Visual place recognition is a challenging problem due to the vast range of ways in which the appearance of real-world places can vary. In recent years, improvements in visual sensing capabilities, an ever-increasing focus on long-term mobile robot autonomy, and the ability to draw on state-of-the-art research in other disciplines-particularly recognition in computer vision and animal navigation in neuroscience-have all contributed to significant advances in visual place recognition systems. This paper presents a survey of the visual place recognition research landscape. We start by introducing the concepts behind place recognition-the role of place recognition in the animal kingdom, how a “place” is defined in a robotics context, and the major components of a place recognition system. Long-term robot operations have revealed that changing appearance can be a significant factor in visual place recognition failure; therefore, we discuss how place recognition solutions can implicitly or explicitly account for appearance change within the environment. Finally, we close with a discussion on the future of visual place recognition, in particular with respect to the rapid advances being made in the related fields of deep learning, semantic scene understanding, and video description.},
	number = {1},
	journal = {IEEE Transactions on Robotics},
	author = {Lowry, S. and Sünderhauf, N. and Newman, P. and Leonard, J. J. and Cox, D. and Corke, P. and Milford, M. J.},
	month = feb,
	year = {2016},
	keywords = {Animals, Computer vision, Conferences, Navigation, Robot sensing systems, Visual place recognition, Visualization, animal kingdom, animal navigation, computer vision, deep learning, learning (artificial intelligence), long-term mobile robot autonomy, mobile robots, object recognition, place recognition, robot vision, robotics context, semantic scene understanding, video description, video signal processing, visual place recognition research landscape, visual place recognition system, visual sensing capabilities},
	pages = {1--19}
}

@article{xin_real-time_2018,
	title = {Real-{Time} {Visual} {Place} {Recognition} {Based} on {Analyzing} {Distribution} of {Multi}-scale {CNN} {Landmarks}},
	issn = {1573-0409},
	url = {https://doi.org/10.1007/s10846-018-0804-x},
	doi = {10.1007/s10846-018-0804-x},
	abstract = {What makes visual place recognition difficult to solve is the variation of the real-world places. In this work, an effective similarity measurement is proposed for visual place recognition in changing environments, based on Convolutional Neural Networks (CNNs) and content-based multi-scale landmarks. The image is firstly segmented into multi-scale landmarks with content information in order to adapt variations of viewpoint, then highly representative features of landmarks are derived from Convolutional Neural Networks (CNNs), which are robust against appearance variations. In the similarity measurement, the similarity between images is determined by analyzing both spatial and scale distributions of matched landmarks. Moreover, an efficient feature extraction and reduction strategy are proposed to generate all features of landmarks at one time. The efficiency of the proposed method makes it suitable for real-time applications. The proposed method is evaluated on two widespread datasets with varied viewpoint and appearance conditions and achieves superior performance against four other state-of-the-art methods, such as the bag-of-words model DBoW3 and the CNN-based Edge Boxes landmarks. Extensive experimentation demonstrates that integrating global and local information can provide more invariance in severe appearance changes, and considering the spatial distribution of landmarks can improve the robustness against viewpoint changes.},
	language = {en},
	urldate = {2019-03-07},
	journal = {Journal of Intelligent \& Robotic Systems},
	author = {Xin, Zhe and Cui, Xiaoguang and Zhang, Jixiang and Yang, Yiping and Wang, Yanqing},
	month = mar,
	year = {2018},
	keywords = {68T45, 92B20, Changing environments, Convolutional neural networks, Landmark distribution, Localization, Visual place recognition}
}

@article{kober_reinforcement_2013,
	title = {Reinforcement learning in robotics: {A} survey},
	volume = {32},
	issn = {0278-3649},
	shorttitle = {Reinforcement learning in robotics},
	url = {https://doi.org/10.1177/0278364913495721},
	doi = {10.1177/0278364913495721},
	abstract = {Reinforcement learning offers to robotics a framework and set of tools for the design of sophisticated and hard-to-engineer behaviors. Conversely, the challenges of robotic problems provide both inspiration, impact, and validation for developments in reinforcement learning. The relationship between disciplines has sufficient promise to be likened to that between physics and mathematics. In this article, we attempt to strengthen the links between the two research communities by providing a survey of work in reinforcement learning for behavior generation in robots. We highlight both key challenges in robot reinforcement learning as well as notable successes. We discuss how contributions tamed the complexity of the domain and study the role of algorithms, representations, and prior knowledge in achieving these successes. As a result, a particular focus of our paper lies on the choice between model-based and model-free as well as between value-function-based and policy-search methods. By analyzing a simple problem in some detail we demonstrate how reinforcement learning approaches may be profitably applied, and we note throughout open questions and the tremendous potential for future research.},
	language = {en},
	number = {11},
	urldate = {2019-03-06},
	journal = {The International Journal of Robotics Research},
	author = {Kober, Jens and Bagnell, J. Andrew and Peters, Jan},
	month = sep,
	year = {2013},
	pages = {1238--1274}
}

@article{loianno_cooperative_2018,
	title = {Cooperative {Transportation} {Using} {Small} {Quadrotors} {Using} {Monocular} {Vision} and {Inertial} {Sensing}},
	volume = {3},
	issn = {2377-3766},
	doi = {10.1109/LRA.2017.2778018},
	abstract = {Micro aerial vehicles have the potential to assist humans in tasks such as manipulation and transportation for construction and humanitarian missions, beyond simply acquiring data and building maps. In this letter, we address the state estimation, control, and trajectory planning in cooperative transportation of structures, which are either too heavy or too big to be carried by small microvehicles. Specifically, we consider small quadrotors, each equipped only with a single camera and inertial measurement unit as a sensor. The key contributions are 1) a new approach to coordinated control, which allows independent control of each vehicle while guaranteeing the system's stability and 2) a new cooperative localization scheme that allows each vehicle to benefit from measurements acquired by other vehicles. The latter relies on the vehicles exploiting the inherent rigid structure information to infer additional constraints between the vehicles' poses allowing us to formulate the pose estimation problem as an optimization problem on the Lie group SE(3). The proposed approach is validated through experimental results with multiple quadrotors grasping and transporting a rigid structure.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Loianno, G. and Kumar, V.},
	month = apr,
	year = {2018},
	keywords = {Aerial systems, Cameras, Lie group SE(3), Lie groups, Optimization, Payloads, Periodic structures, Robot sensing systems, Transportation, autonomous aerial vehicles, cameras, cooperative localization scheme, coordinated control, helicopters, humanitarian missions, independent control, inertial measurement unit, inertial sensing, inherent rigid structure information, key contributions, map building, microaerial vehicles, mobile robots, monocular vision, multi-robot systems, multiple quadrotors, optimization and optimal control, path planning, perception and autonomy, pose estimation, pose estimation problem, robot vision, sensor-based control, single camera, small quadrotors, state estimation, system stability, trajectory planning, transportation},
	pages = {680--687}
}

@inproceedings{svacha_improving_2017,
	title = {Improving quadrotor trajectory tracking by compensating for aerodynamic effects},
	doi = {10.1109/ICUAS.2017.7991501},
	abstract = {In this work, we demonstrate that the position tracking performance of a quadrotor may be significantly improved for forward and vertical flight by incorporating simple lumped parameter models for induced drag and thrust, respectively, into the quadrotor dynamics and modifying the controller to compensate for these terms. We further show that the parameters for these models may be easily and accurately identified offline from forward and vertical flight data. We demonstrate that the simple drag compensating controller can reduce the position error in the direction of forward flight in steady state by 75\%, and that the controller using a more accurate thrust model, dubbed the “refined” thrust model, can improve the position error by 72\% in the vertical direction.},
	booktitle = {2017 {International} {Conference} on {Unmanned} {Aircraft} {Systems} ({ICUAS})},
	author = {Svacha, J. and Mohta, K. and Kumar, V.},
	month = jun,
	year = {2017},
	keywords = {Acceleration, Aerodynamics, Blades, Data models, Drag, Linear regression, Propellers, aerodynamic effects compensation, aerodynamics, drag, drag compensating controller, forward flight, helicopters, lumped parameter models, position control, position error reduction, position tracking performance, quadrotor dynamics, quadrotor trajectory tracking, refined thrust model, trajectory optimisation (aerospace)},
	pages = {860--866}
}

@article{liu_search-based_2018,
	title = {Search-{Based} {Motion} {Planning} for {Aggressive} {Flight} in {SE}(3)},
	volume = {3},
	issn = {2377-3766},
	doi = {10.1109/LRA.2018.2795654},
	abstract = {Quadrotors with large thrust-to-weight ratios are able to track aggressive trajectories with sharp turns and high accelerations. In this letter, we develop a search-based trajectory planning algorithm that exploits the quadrotor maneuverability to generate sequences of motion primitives in cluttered environments. We model the quadrotor body as an ellipsoid and compute its flight attitude along trajectories in order to check for collisions against obstacles. The ellipsoid model allows the quadrotor to pass through gaps that are smaller than its diameter with nonzero pitch or roll angles. Without any prior information about the location of gaps and associated attitude constraints, our algorithm is able to find a safe and optimal trajectory that guides the robot to its goal as fast as possible. To accelerate planning, we first perform a lower dimensional search and use it as a heuristic to guide the generation of a final dynamically feasible trajectory. We analyze critical discretization parameters of motion primitive planning and demonstrate the feasibility of the generated trajectories in various simulations and real-world experiments.},
	number = {3},
	journal = {IEEE Robotics and Automation Letters},
	author = {Liu, S. and Mohta, K. and Atanasov, N. and Kumar, V.},
	month = jul,
	year = {2018},
	keywords = {Acceleration, Angular velocity, Collision avoidance, Motion and path planning, Planning, Robots, SE(3), Trajectory, Vehicle dynamics, aerial systems: applications, aggressive flight, aggressive trajectories tracking, aircraft control, attitude constraints, attitude control, autonomous aerial vehicles, autonomous vehicle navigation, cluttered environments, ellipsoid model, final dynamically feasible trajectory, flight attitude, helicopters, lower dimensional search, mobile robots, motion primitive planning, optimal trajectory, optimisation, path planning, quadrotor body, quadrotor maneuverability, safe trajectory, search problems, search-based motion planning, search-based trajectory planning algorithm, thrust-to-weight ratios, trajectories generation, trajectory control},
	pages = {2439--2446}
}

@article{bonatti_autonomous_2018,
	title = {Autonomous drone cinematographer: {Using} artistic principles to create smooth, safe, occlusion-free trajectories for aerial filming},
	shorttitle = {Autonomous drone cinematographer},
	url = {http://arxiv.org/abs/1808.09563},
	abstract = {Autonomous aerial cinematography has the potential to enable automatic capture of aesthetically pleasing videos without requiring human intervention, empowering individuals with the capability of high-end film studios. Current approaches either only handle off-line trajectory generation, or offer strategies that reason over short time horizons and simplistic representations for obstacles, which result in jerky movement and low real-life applicability. In this work we develop a method for aerial filming that is able to trade off shot smoothness, occlusion, and cinematography guidelines in a principled manner, even under noisy actor predictions. We present a novel algorithm for real-time covariant gradient descent that we use to efficiently find the desired trajectories by optimizing a set of cost functions. Experimental results show that our approach creates attractive shots, avoiding obstacles and occlusion 65 times over 1.25 hours of flight time, re-planning at 5 Hz with a 10 s time horizon. We robustly film human actors, cars and bicycles performing different motion among obstacles, using various shot types.},
	urldate = {2019-03-05},
	journal = {arXiv:1808.09563 [cs]},
	author = {Bonatti, Rogerio and Zhang, Yanfu and Choudhury, Sanjiban and Wang, Wenshan and Scherer, Sebastian},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.09563},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics}
}

@article{falanga_pampc:_2018,
	title = {{PAMPC}: {Perception}-{Aware} {Model} {Predictive} {Control} for {Quadrotors}},
	shorttitle = {{PAMPC}},
	url = {http://arxiv.org/abs/1804.04811},
	abstract = {We present the first perception-aware model predictive control framework for quadrotors that unifies control and planning with respect to action and perception objectives. Our framework leverages numerical optimization to compute trajectories that satisfy the system dynamics and require control inputs within the limits of the platform. Simultaneously, it optimizes perception objectives for robust and reliable sens- ing by maximizing the visibility of a point of interest and minimizing its velocity in the image plane. Considering both perception and action objectives for motion planning and control is challenging due to the possible conflicts arising from their respective requirements. For example, for a quadrotor to track a reference trajectory, it needs to rotate to align its thrust with the direction of the desired acceleration. However, the perception objective might require to minimize such rotation to maximize the visibility of a point of interest. A model-based optimization framework, able to consider both perception and action objectives and couple them through the system dynamics, is therefore necessary. Our perception-aware model predictive control framework works in a receding-horizon fashion by iteratively solving a non-linear optimization problem. It is capable of running in real-time, fully onboard our lightweight, small-scale quadrotor using a low-power ARM computer, to- gether with a visual-inertial odometry pipeline. We validate our approach in experiments demonstrating (I) the contradiction between perception and action objectives, and (II) improved behavior in extremely challenging lighting conditions.},
	urldate = {2019-03-05},
	journal = {arXiv:1804.04811 [cs]},
	author = {Falanga, Davide and Foehn, Philipp and Lu, Peng and Scaramuzza, Davide},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.04811},
	keywords = {Computer Science - Robotics}
}

@article{loquercio_dronet:_2018,
	title = {{DroNet}: {Learning} to {Fly} by {Driving}},
	volume = {3},
	issn = {2377-3766},
	shorttitle = {{DroNet}},
	doi = {10.1109/LRA.2018.2795643},
	abstract = {Civilian drones are soon expected to be used in a wide variety of tasks, such as aerial surveillance, delivery, or monitoring of existing architectures. Nevertheless, their deployment in urban environments has so far been limited. Indeed, in unstructured and highly dynamic scenarios, drones face numerous challenges to navigate autonomously in a feasible and safe way. In contrast to traditional “map-localize-plan” methods, this letter explores a data-driven approach to cope with the above challenges. To accomplish this, we propose DroNet: a convolutional neural network that can safely drive a drone through the streets of a city. Designed as a fast eight-layers residual network, DroNet produces two outputs for each single input image: A steering angle to keep the drone navigating while avoiding obstacles, and a collision probability to let the UAV recognize dangerous situations and promptly react to them. The challenge is however to collect enough data in an unstructured outdoor environment such as a city. Clearly, having an expert pilot providing training trajectories is not an option given the large amount of data required and, above all, the risk that it involves for other vehicles or pedestrians moving in the streets. Therefore, we propose to train a UAV from data collected by cars and bicycles, which, already integrated into the urban environment, would not endanger other vehicles and pedestrians. Although trained on city streets from the viewpoint of urban vehicles, the navigation policy learned by DroNet is highly generalizable. Indeed, it allows a UAV to successfully fly at relative high altitudes and even in indoor environments, such as parking lots and corridors. To share our findings with the robotics community, we publicly release all our datasets, code, and trained networks.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Loquercio, A. and Maqueda, A. I. and del-Blanco, C. R. and Scaramuzza, D.},
	month = apr,
	year = {2018},
	keywords = {Automobiles, DroNet, Drones, Learning from demonstration, Navigation, Robots, Training, UAV, Urban areas, aerial surveillance, aerial systems: perception and autonomy, aerospace computing, autonomous aerial vehicles, bicycles, cars, city streets, civilian drones, collision avoidance, collision probability, control engineering computing, convolutional neural network, dangerous situation recognition, data-driven approach, deep learning in robotics and automation, drone navigation, eight-layers residual network, feedforward neural nets, highly dynamic scenarios, image sensors, indoor environments, learning (artificial intelligence), mobile robots, navigation policy, obstacle avoidance, pedestrians, relative high altitudes, robot vision, single input image, steering angle, surveillance, traditional map-localize-plan method, trained networks, training trajectories, unstructured outdoor environment, unstructured scenarios, urban environment, urban vehicles},
	pages = {1088--1095}
}

@inproceedings{blosch_vision_2010,
	title = {Vision based {MAV} navigation in unknown and unstructured environments},
	doi = {10.1109/ROBOT.2010.5509920},
	abstract = {Within the research on Micro Aerial Vehicles (MAVs), the field on flight control and autonomous mission execution is one of the most active. A crucial point is the localization of the vehicle, which is especially difficult in unknown, GPS-denied environments. This paper presents a novel vision based approach, where the vehicle is localized using a downward looking monocular camera. A state-of-the-art visual SLAM algorithm tracks the pose of the camera, while, simultaneously, building an incremental map of the surrounding region. Based on this pose estimation a LQG/LTR based controller stabilizes the vehicle at a desired setpoint, making simple maneuvers possible like take-off, hovering, setpoint following or landing. Experimental data show that this approach efficiently controls a helicopter while navigating through an unknown and unstructured environment. To the best of our knowledge, this is the first work describing a micro aerial vehicle able to navigate through an unexplored environment (independently of any external aid like GPS or artificial beacons), which uses a single camera as only exteroceptive sensor.},
	booktitle = {2010 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Blösch, M. and Weiss, S. and Scaramuzza, D. and Siegwart, R.},
	month = may,
	year = {2010},
	keywords = {Aerospace control, Aircraft navigation, Attitude control, Cameras, GPS-denied environments, Global Positioning System, Helicopters, LQG-LTR based controller, Remotely operated vehicles, Robotics and automation, SLAM (robots), Sliding mode control, Unmanned aerial vehicles, aerospace robotics, aircraft control, autonomous mission execution, downward looking monocular camera, exteroceptive sensor, flight control, image sensors, linear quadratic Gaussian control, micro aerial vehicles, microrobots, mobile robots, path planning, pose estimation, robot vision, vision based MAV navigation, visual SLAM algorithm},
	pages = {21--28}
}

@inproceedings{monajjemi_uav_2015,
	title = {{UAV}, do you see me? {Establishing} mutual attention between an uninstrumented human and an outdoor {UAV} in flight},
	shorttitle = {{UAV}, do you see me?},
	doi = {10.1109/IROS.2015.7353882},
	abstract = {We present the first demonstration of establishing mutual attention between an outdoor UAV in autonomous normal flight and an uninstrumented human user. We use the familiar periodic waving gesture as a signal to attract the UAV's attention. The UAV can discriminate this gesture from human walking and running that appears similarly periodic. Once a signaling person is observed and tracked, the UAV acknowledges that the user has its attention by hovering and performing a “wobble” behavior. Both parties are now ready for further interaction. The system works on-board the UAV using a single camera for input and is demonstrated working reliably in real-robot trials.},
	booktitle = {2015 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Monajjemi, M. and Bruce, J. and Sadat, S. A. and Wawerla, J. and Vaughan, R.},
	month = sep,
	year = {2015},
	keywords = {Cameras, Computer vision, Feature extraction, Motion estimation, Real-time systems, Tracking, UAV wobble behavior, autonomous aerial vehicles, autonomous normal flight, gesture recognition, human-robot interaction, mobile robots, outdoor UAV, periodic waving gesture, uninstrumented human user},
	pages = {3614--3620}
}

@article{bruce_one-shot_2017,
	title = {One-{Shot} {Reinforcement} {Learning} for {Robot} {Navigation} with {Interactive} {Replay}},
	url = {http://arxiv.org/abs/1711.10137},
	abstract = {Recently, model-free reinforcement learning algorithms have been shown to solve challenging problems by learning from extensive interaction with the environment. A significant issue with transferring this success to the robotics domain is that interaction with the real world is costly, but training on limited experience is prone to overfitting. We present a method for learning to navigate, to a fixed goal and in a known environment, on a mobile robot. The robot leverages an interactive world model built from a single traversal of the environment, a pre-trained visual feature encoder, and stochastic environmental augmentation, to demonstrate successful zero-shot transfer under real-world environmental variations without fine-tuning.},
	urldate = {2019-03-05},
	journal = {arXiv:1711.10137 [cs]},
	author = {Bruce, Jake and Suenderhauf, Niko and Mirowski, Piotr and Hadsell, Raia and Milford, Michael},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.10137},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics}
}

@inproceedings{anderson_vision-and-language_2018,
	title = {Vision-and-{Language} {Navigation}: {Interpreting} {Visually}-{Grounded} {Navigation} {Instructions} in {Real} {Environments}},
	shorttitle = {Vision-and-{Language} {Navigation}},
	url = {http://openaccess.thecvf.com/content_cvpr_2018/html/Anderson_Vision-and-Language_Navigation_Interpreting_CVPR_2018_paper.html},
	urldate = {2019-03-05},
	author = {Anderson, Peter and Wu, Qi and Teney, Damien and Bruce, Jake and Johnson, Mark and Sünderhauf, Niko and Reid, Ian and Gould, Stephen and van den Hengel, Anton},
	year = {2018},
	pages = {3674--3683}
}

@article{garg_lost?_2018,
	title = {{LoST}? {Appearance}-{Invariant} {Place} {Recognition} for {Opposite} {Viewpoints} using {Visual} {Semantics}},
	shorttitle = {{LoST}?},
	url = {http://arxiv.org/abs/1804.05526},
	abstract = {Human visual scene understanding is so remarkable that we are able to recognize a revisited place when entering it from the opposite direction it was first visited, even in the presence of extreme variations in appearance. This capability is especially apparent during driving: a human driver can recognize where they are when travelling in the reverse direction along a route for the first time, without having to turn back and look. The difficulty of this problem exceeds any addressed in past appearance- and viewpoint-invariant visual place recognition (VPR) research, in part because large parts of the scene are not commonly observable from opposite directions. Consequently, as shown in this paper, the precision-recall performance of current state-of-the-art viewpoint- and appearance-invariant VPR techniques is orders of magnitude below what would be usable in a closed-loop system. Current engineered solutions predominantly rely on panoramic camera or LIDAR sensing setups; an eminently suitable engineering solution but one that is clearly very different to how humans navigate, which also has implications for how naturally humans could interact and communicate with the navigation system. In this paper we develop a suite of novel semantic- and appearance-based techniques to enable for the first time high performance place recognition in this challenging scenario. We first propose a novel Local Semantic Tensor (LoST) descriptor of images using the convolutional feature maps from a state-of-the-art dense semantic segmentation network. Then, to verify the spatial semantic arrangement of the top matching candidates, we develop a novel approach for mining semantically-salient keypoint correspondences.},
	urldate = {2019-03-05},
	journal = {arXiv:1804.05526 [cs]},
	author = {Garg, Sourav and Suenderhauf, Niko and Milford, Michael},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.05526},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics}
}

@inproceedings{aydemir_what_2012,
	title = {What can we learn from 38,000 rooms? {Reasoning} about unexplored space in indoor environments},
	shorttitle = {What can we learn from 38,000 rooms?},
	doi = {10.1109/IROS.2012.6386110},
	abstract = {Many robotics tasks require the robot to predict what lies in the unexplored part of the environment. Although much work focuses on building autonomous robots that operate indoors, indoor environments are neither well understood nor analyzed enough in the literature. In this paper, we propose and compare two methods for predicting both the topology and the categories of rooms given a partial map. The methods are motivated by the analysis of two large annotated floor plan data sets corresponding to the buildings of the MIT and KTH campuses. In particular, utilizing graph theory, we discover that local complexity remains unchanged for growing global complexity in real-world indoor environments, a property which we exploit. In total, we analyze 197 buildings, 940 floors and over 38,000 real-world rooms. Such a large set of indoor places has not been investigated before in the previous work. We provide extensive experimental results and show the degree of transferability of spatial knowledge between two geographically distinct locations. We also contribute the KTH data set and the software tools to with it.},
	booktitle = {2012 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Aydemir, A. and Jensfelt, P. and Folkesson, J.},
	month = oct,
	year = {2012},
	keywords = {Buildings, Databases, Indoor environments, Power grids, Prediction algorithms, Robots, Topology, annotated floor plan data set, autonomous robot, graph theory, indoor environment, mobile robots, robotic task, software tools, spatial knowledge transferability, unexplored space},
	pages = {4675--4682}
}

@inproceedings{liu_online_2012,
	title = {Online semantic exploration of indoor maps},
	doi = {10.1109/ICRA.2012.6224871},
	abstract = {In this paper we propose a method to extract an abstracted floor plan from typical grid maps using Bayesian reasoning. The result of this procedure is a probabilistic generative model of the environment defined over abstract concepts. It is well suited for higher-level reasoning and communication purposes. We demonstrate the effectiveness of the approach through real-world experiments.},
	booktitle = {2012 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Liu, Z. and Chen, D. and Wichert, G. von},
	month = may,
	year = {2012},
	keywords = {Bayes methods, Bayesian reasoning, Image color analysis, Kernel, Markov processes, Proposals, Robot kinematics, Semantics, abstracted floor plan extraction, grid maps, higher-level communication, higher-level reasoning, indoor maps, inference mechanisms, mobile robots, online semantic exploration, probabilistic generative model, robot vision},
	pages = {4361--4366}
}

@article{loncomilla_bayesian_2018,
	title = {A {Bayesian} based {Methodology} for {Indirect} {Object} {Search}},
	volume = {90},
	doi = {10.1007/s10846-017-0643-1},
	abstract = {The main goal of this paper is to propose a Bayesian based methodology for implementing robot informed search for objects. The methodology uses convolutions between observation likelihoods of secondary objects and spatial relation masks for estimating the probability map of the object being searched for, and also a search procedure that uses this probability map. A method for computing complex spatial relation masks by using a basis composed of basic relation masks and a database of co-occurrences of objects is used. Each basic relation mask corresponds to a qualitative spatial relation (QSR), such as: ‘very near’, ‘near’, or ‘far’. The search procedure takes into account the probability that the main object can be in different regions on the map and the distance to those regions. Also, the object search procedure is able to detect objects and generate new plans while moving. The proposed methodology is compared with uninformed and alternative informed search approaches using simulations and real-world experiments with a service robot. In simulations, the use of the proposed methodology increases the detection rate from 28\% (direct uninformed search) to 79\%, when the main object can be detected within a maximum distance of 1 meter. In the real world experiments, the use of the proposed methodology increases the detection rate from 40\% (direct uninformed search) to 87\% when using convolutions with soft masks, global search, and information on the positive detection of secondary objects. The detection rates obtained when using the proposed methodology are also much higher than those obtained by alternative informed search methods, both in the simulated and in the real-world experiments. © 2017, Springer Science+Business Media B.V.},
	number = {1-2},
	journal = {Journal of Intelligent and Robotic Systems: Theory and Applications},
	author = {Loncomilla, P. and Ruiz-del-Solar, J. and Saavedra A, M.},
	year = {2018},
	keywords = {Active search, Informed search, Robot indirect search for objects, Semantic search},
	pages = {45--63}
}

@inproceedings{li_learning_2016,
	title = {Learning to generalize {3D} spatial relationships},
	volume = {2016-June},
	doi = {10.1109/ICRA.2016.7487798},
	abstract = {This paper presents an approach to learn meaningful spatial relationships in an unsupervised fashion from the distribution of 3D object poses in the real world. Our approach begins by extracting an over-complete set of features to describe the relative geometry of two objects. Each relationship type is modeled using a relevance-weighted distance over this feature space. This effectively ignores irrelevant feature dimensions. Our algorithm RAnSEM for determining subsets of data that share a relationship as well as the model to describe each relationship is based on robust sample-based clustering. This approach combines the search for consistent groups of data with the extraction of models that precisely capture the geometry of those groups. An iterative refinement scheme has shown to be an effective approach for finding concepts of differing degrees of geometric specificity. Our results show that the models learned by our approach correlate strongly with the English labels that have been given by a human annotator to a set of validation data drawn from the nYUv2 real-world Kinect dataset, demonstrating that these concepts can be automatically acquired given sufficient experience. Additionally, the results of our method significantly out-perform K-means, a standard baseline for unsupervised cluster extraction. © 2016 IEEE.},
	author = {Li, J. and Meger, D. and Dudek, G.},
	year = {2016},
	pages = {5744--5749}
}

@inproceedings{goeddel_learning_2016,
	title = {Learning semantic place labels from occupancy grids using {CNNs}},
	volume = {2016-November},
	doi = {10.1109/IROS.2016.7759589},
	abstract = {The goal of this paper is to develop a robot with a grounded spatial vocabulary. Such a vocabulary would allow it to give and follow directions, and would give it valuable additional information in aiding localization and navigation. We approach the problem by defining an ontology of space (including corridor, doorway, and room) and by creating a Convolutional Neural Network (CNN) that allows the robot to classify LIDAR sensor data accordingly. In particular, we propose a CNN architecture that performs comparably or better than existing methods based on engineered features. Training CNNs can be fickle; we describe several specific aspects of our approach that are important for good performance in this task. © 2016 IEEE.},
	author = {Goeddel, R. and Olson, E.},
	year = {2016},
	pages = {3999--4004}
}

@article{vasudevan_cognitive_2007,
	series = {From {Sensors} to {Human} {Spatial} {Concepts}},
	title = {Cognitive maps for mobile robots—an object based approach},
	volume = {55},
	issn = {0921-8890},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889006002004},
	doi = {10.1016/j.robot.2006.12.008},
	abstract = {Robots are rapidly evolving from factory work-horses to robot-companions. The future of robots, as our companions, is highly dependent on their abilities to understand, interpret and represent the environment in an efficient and consistent fashion, in a way that is comprehensible to humans. The work presented here is oriented in this direction. It suggests a hierarchical probabilistic representation of space that is based on objects. A global topological representation of places with object graphs serving as local maps is proposed. The work also details the first efforts towards conceptualizing space on the basis of the human compatible representation so formed. Such a representation and the resulting conceptualization would be useful for enabling robots to be cognizant of their surroundings. Experiments on place classification and place recognition are reported in order to demonstrate the applicability of such a representation towards understanding space and thereby performing spatial cognition. Further, relevant results from user studies validating the proposed representation are also reported. Thus, the theme of the work is — representation for spatial cognition.},
	number = {5},
	urldate = {2019-03-05},
	journal = {Robotics and Autonomous Systems},
	author = {Vasudevan, Shrihari and Gächter, Stefan and Nguyen, Viet and Siegwart, Roland},
	month = may,
	year = {2007},
	keywords = {Cognitive spatial representation, Conceptualization of space, Robot mapping, Spatial cognition},
	pages = {359--371}
}

@inproceedings{viswanathan_automated_2009,
	title = {Automated {Spatial}-{Semantic} {Modeling} with {Applications} to {Place} {Labeling} and {Informed} {Search}},
	doi = {10.1109/CRV.2009.49},
	abstract = {This paper presents a spatial-semantic modeling system featuring automated learning of object-place relations from an online annotated database, and the application of these relations to a variety of real-world tasks. The system is able to label novel scenes with place information, as we demonstrate on test scenes drawn from the same source as our training set. We have designed our system for future enhancement of a robot platform that performs state-of-the-art object recognition and creates object maps of realistic environments. In this context, we demonstrate the use of spatial-semantic information to perform clustering and place labeling of object maps obtained from real homes.This place information is fed back into the robot system to inform an object search planner about likely locations of a query object. As a whole, this system represents a new level in spatial reasoning and semantic understanding for a physical platform.},
	booktitle = {2009 {Canadian} {Conference} on {Computer} and {Robot} {Vision}},
	author = {Viswanathan, P. and Meger, D. and Southey, T. and Little, J. J. and Mackworth, A. K.},
	month = may,
	year = {2009},
	keywords = {Cognitive robotics, Computer vision, Informed Search, Intelligent robots, LabelMe, Labeling, Layout, Mobile robots, Object recognition, Place Labeling, Robot kinematics, Robot vision systems, Robotics and automation, automated learning, automated spatial-semantic modeling system, learning (artificial intelligence), object maps place labeling, object recognition, online annotated database, robot platform, robot vision, spatial reasoning},
	pages = {284--291}
}

@article{wilson_good_2017,
	title = {Good enough practices in scientific computing},
	volume = {13},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510},
	doi = {10.1371/journal.pcbi.1005510},
	abstract = {Author summary Computers are now essential in all branches of science, but most researchers are never taught the equivalent of basic lab skills for research computing. As a result, data can get lost, analyses can take much longer than necessary, and researchers are limited in how effectively they can work with software and data. Computing workflows need to follow the same practices as lab projects and notebooks, with organized data, documented steps, and the project structured for reproducibility, but researchers new to computing often don't know where to start. This paper presents a set of good computing practices that every researcher can adopt, regardless of their current level of computational skill. These practices, which encompass data management, programming, collaborating with colleagues, organizing projects, tracking work, and writing manuscripts, are drawn from a wide variety of published sources from our daily lives and from our work with volunteer organizations that have delivered workshops to over 11,000 people since 2010.},
	language = {en},
	number = {6},
	urldate = {2019-03-04},
	journal = {PLOS Computational Biology},
	author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K.},
	month = jun,
	year = {2017},
	keywords = {Computer software, Control systems, Data management, Data processing, Programming languages, Reproducibility, Software tools, Source code},
	pages = {e1005510}
}

@inproceedings{xia_gibson_2018,
	address = {Salt Lake City, UT},
	title = {Gibson {Env}: {Real}-{World} {Perception} for {Embodied} {Agents}},
	isbn = {978-1-5386-6420-9},
	shorttitle = {Gibson {Env}},
	url = {https://ieeexplore.ieee.org/document/8579043/},
	doi = {10.1109/CVPR.2018.00945},
	language = {en},
	urldate = {2019-03-04},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Xia, Fei and Zamir, Amir R. and He, Zhiyang and Sax, Alexander and Malik, Jitendra and Savarese, Silvio},
	month = jun,
	year = {2018},
	pages = {9068--9079}
}

@article{perk_motion_2006,
	title = {Motion {Primitives} for {Robotic} {Flight} {Control}},
	url = {http://arxiv.org/abs/cs/0609140},
	abstract = {We introduce a simple framework for learning aggressive maneuvers in flight control of UAVs. Having inspired from biological environment, dynamic movement primitives are analyzed and extended using nonlinear contraction theory. Accordingly, primitives of an observed movement are stably combined and concatenated. We demonstrate our results experimentally on the Quanser Helicopter, in which we first imitate aggressive maneuvers and then use them as primitives to achieve new maneuvers that can fly over an obstacle.},
	urldate = {2019-03-04},
	journal = {arXiv:cs/0609140},
	author = {Perk, Baris E. and Slotine, J. J. E.},
	month = sep,
	year = {2006},
	note = {arXiv: cs/0609140},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics}
}

@article{lu_survey_2018,
	title = {A survey on vision-based {UAV} navigation},
	volume = {21},
	issn = {1009-5020},
	url = {https://doi.org/10.1080/10095020.2017.1420509},
	doi = {10.1080/10095020.2017.1420509},
	abstract = {Research on unmanned aerial vehicles (UAV) has been increasingly popular in the past decades, and UAVs have been widely used in industrial inspection, remote sensing for mapping \& surveying, rescuing, and so on. Nevertheless, the limited autonomous navigation capability severely hampers the application of UAVs in complex environments, such as GPS-denied areas. Previously, researchers mainly focused on the use of laser or radar sensors for UAV navigation. With the rapid development of computer vision, vision-based methods, which utilize cheaper and more flexible visual sensors, have shown great advantages in the field of UAV navigation. The purpose of this article is to present a comprehensive literature review of the vision-based methods for UAV navigation. Specifically on visual localization and mapping, obstacle avoidance and path planning, which compose the essential parts of visual navigation. Furthermore, throughout this article, we will have an insight into the prospect of the UAV navigation and the challenges to be faced.},
	number = {1},
	urldate = {2019-03-01},
	journal = {Geo-spatial Information Science},
	author = {Lu, Yuncheng and Xue, Zhucun and Xia, Gui-Song and Zhang, Liangpei},
	month = jan,
	year = {2018},
	keywords = {Unmanned aerial vehicles (UAV), obstacle avoidance, path planning, visual SLAM},
	pages = {21--32}
}

@inproceedings{balamurugan_survey_2016,
	title = {Survey on {UAV} navigation in {GPS} denied environments},
	doi = {10.1109/SCOPES.2016.7955787},
	abstract = {In the Unmanned Air Vehicle (UAV) navigation the main challenge is estimating and maintaining the accurate values of UAVs position and orientation. The onboard Inertial Measurement Unit (IMU) provide the measurements but it is mainly affected from the accumulated error due to drift in measurements. Traditionally the Global Position System (GPS) measurements of vehicles position data can be fused with IMU measurements to compensate the accumulated error, But the GPS signals is not available everywhere and it will be degraded or fully not available in hostile areas, building structures and water bodies. Researchers already evolved methods to handle the UAV navigation in GPS denied environment by using Vision based navigation like Visual Odometry (VO) and Simultaneous Localisation and Mapping (SLAM). In this survey paper we attempted to understand the existing research towards vision based navigation and finally proposed a Modular Multi-Sensor Data Fusion technique for UAV navigation in the GPS denied environment.},
	booktitle = {2016 {International} {Conference} on {Signal} {Processing}, {Communication}, {Power} and {Embedded} {System} ({SCOPES})},
	author = {Balamurugan, G. and Valarmathi, J. and Naidu, V. P. S.},
	month = oct,
	year = {2016},
	keywords = {Cameras, GPS denied environments, Global Positioning System, Inertial Measurement Unit (IMU), Pose estimation, SLAM (robots), Simultaneous Localisation and Mapping (SLAM), Simultaneous localization and mapping, UAV navigation, Unmanned Air Vehicle (UAV), Unmanned aerial vehicles, Visual Odometry (VO), Visualization, autonomous aerial vehicles, global position system measurements, inertial measurement unit, inertial navigation, modular multisensor data fusion technique, sensor fusion, simultaneous localisation and mapping, unmanned air vehicle, vision based navigation, visual odometry},
	pages = {198--204}
}

@article{zhang_geometric_2015,
	title = {Geometric {Reinforcement} {Learning} for {Path} {Planning} of {UAVs}},
	volume = {77},
	issn = {1573-0409},
	url = {https://doi.org/10.1007/s10846-013-9901-z},
	doi = {10.1007/s10846-013-9901-z},
	abstract = {We proposed a new learning algorithm, named Geometric Reinforcement Learning (GRL), for path planning of Unmanned Aerial Vehicles (UAVs). The contributions of GRL are as: (1) GRL exploits a specific reward matrix, which is simple and efficient for path planning of multiple UAVs. The candidate points are selected from the region along the Geometric path from the current point to the target point. (2) The convergence of calculating the reward matrix is theoretically proven, and the path in terms of path length and risk measure can be calculated. (3) In GRL, the reward matrix is adaptively updated based on the Geometric distance and risk information shared by other UAVs. Extensive experimental results validate the effectiveness and feasibility of GRL on the navigation of UAVs.},
	language = {en},
	number = {2},
	urldate = {2019-02-28},
	journal = {Journal of Intelligent \& Robotic Systems},
	author = {Zhang, Baochang and Mao, Zhili and Liu, Wanquan and Liu, Jianzhuang},
	month = feb,
	year = {2015},
	keywords = {Geometric, Path planning, UAV},
	pages = {391--409}
}

@inproceedings{cavaliere_empowering_2018,
	title = {Empowering {UAV} scene perception by semantic spatio-temporal features},
	doi = {10.1109/EE1.2018.8385272},
	abstract = {The use of unmanned aerial vehicles (UAVs) is becoming a key asset in different application domains: from the military to surveillance tasks; to filming and journalism to shipping and delivery; to disaster monitoring to rescue operation and healthcare. One of the most desirable UAV capabilities is a human-like scenario understanding, i.e., the object recognition and interactions with other objects and with the environment, through the scene evolution, in order to get a high-view scenario description. The paper presents a semantic-enhanced approach for UAV-based surveillance systems. The video analysis is extended and enriched with semantic high level data to provide a global view of the video scenes. Semantic Web technologies provide the expressive power to describe semantically scenes appearing in the videos. The synergy between the video tracking methods and the semantic web technologies provides a new high-level human-like interpretation of the scenario. The approach focuses on the event understanding at semantic level: it is coded as spatio-temporal relation which joins fixed or mobile objects, with respect to a given temporal sequence of video frames. The system is composed of two macro components: one devoted to the tracking activities, i.e., the object identification and classification, the other enriches tracking data semantically, where the ontology-based scenario model is the bridge between the components. A reasoning component applied to the semantic knowledge, extracted from the scenario, infers new statements that describe the detected events occurring in the video.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Environmental} {Engineering} ({EE})},
	author = {Cavaliere, D. and Saggese, A. and Senatore, S. and Vento, M. and Loia, V.},
	month = mar,
	year = {2018},
	keywords = {Cognition, Event detection, Object recognition, Ontologies, Semantics, Task analysis, UAV scene perception, UAV-based surveillance systems, Unmanned aerial vehicles, autonomous aerial vehicles, classification, disaster monitoring, filming journalism, healthcare, human-like scenario interpretation, mobile objects, mobile robots, object detection, object identification, object recognition, ontologies (artificial intelligence), ontology-based scenario model, rescue operation, scene evolution, semantic Web, semantic Web technologies, semantic high level data, semantic knowledge, semantic spatio-temporal features, semantic-enhanced approach, shipping delivery, spatio-temporal relation, surveillance tasks, temporal sequence, unmanned aerial vehicles, video analysis, video frames, video scenes, video signal processing, video surveillance, video tracking methods},
	pages = {1--6}
}

@inproceedings{drouilly_semantic_2015,
	title = {Semantic representation for navigation in large-scale environments},
	doi = {10.1109/ICRA.2015.7139314},
	abstract = {Mimicking human navigation is a challenging goal for autonomous robots. This requires to explicitly take into account not only geometric representation but also high-level interpretation of the environment. In this paper, we demonstrate the capability to infer a route in a global map by using semantics. Our approach relies on an object-based representation of the world automatically built by robots from spherical images. In addition, we propose a new approach to specify paths in terms of high-level robot actions. This path description provides robots with the ability to interact with humans in an intuitive way. We perform experiments on simulated and real-world data, demonstrating the ability of our approach to deal with complex large-scale outdoor environments whilst dealing with labelling errors.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Drouilly, R. and Rives, P. and Morisset, B.},
	month = may,
	year = {2015},
	keywords = {Buildings, Navigation, Observability, Planning, Robot sensing systems, Semantics, mobile robots, object-based representation, path planning, semantic navigation representation},
	pages = {1106--1111}
}

@inproceedings{dang_autonomous_2018,
	title = {Autonomous exploration and simultaneous object search using aerial robots},
	doi = {10.1109/AERO.2018.8396632},
	abstract = {In this paper, a strategy for autonomous exploration of unknown environments and simultaneous object search using aerial robots is proposed. An aerial robot is initially armed with the capacity to autonomously explore unknown environments, detect objects that belong to certain semantic classes of interest and relate these detections to the respective location on the map. Provided this information, a sampling-based semantically-enhanced exploration path planning algorithm is designed such that in its every iteration it identifies a finite-depth collision free path that maximizes a gain related to exploring new space, as well as a gain related to the resolution of the observation of the previously mapped parts of the environment that relate to detected objects of interest. Through this ability to explore the unknown space, while accounting for the resolution of observation of viewpoints perceiving objects of interest, online 3D mapping that is focused on the subsets of the map most relevant with object search missions is achieved. The proposed algorithm is evaluated, verified and demonstrated in both simulation, as well as experimental studies using an autonomous aerial robot capable of GPS-denied visual-inertial localization and mapping operation.},
	booktitle = {2018 {IEEE} {Aerospace} {Conference}},
	author = {Dang, T. and Papachristos, C. and Alexis, K.},
	month = mar,
	year = {2018},
	keywords = {Cameras, Path planning, Robot vision systems, Semantics, Unmanned aerial vehicles, aerospace robotics, autonomous exploration, collision avoidance, finite-depth collision free path, mapping operation, mobile robots, object detection, object search missions, robot vision, semantically-enhanced exploration path, simultaneous object search, visual-inertial localization},
	pages = {1--7}
}

@article{adler_autonomous_2014,
	title = {Autonomous {Exploration} of {Urban} {Environments} using {Unmanned} {Aerial} {Vehicles}},
	volume = {31},
	copyright = {© 2014 Wiley Periodicals, Inc.},
	issn = {1556-4967},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21526},
	doi = {10.1002/rob.21526},
	abstract = {This paper introduces a custom-built unmanned aerial vehicle that is capable of autonomous exploration in urban environments. It consists of a multicopter, an inertial navigation system, and two two-dimensional laser range finders. In addition to a description of the hardware architecture and individual components being used, the authors also discuss challenges and problems that arose during its construction, as well as optimizations and workarounds applied in the course of its development. Also presented is the software architecture, with a focus on a novel algorithm capable of generating multiple next best views, sorted by achievable information gain. Although the vehicle was designed for application on airborne platforms in urban environments, it works directly on raw point clouds and thus can be used with any sensor generating spatial occupancy information (e.g., LIDAR, RGBD, or time-of-flight-cameras). To satisfy constraints introduced by real-time operation on unmanned aerial vehicles, the algorithm is implemented on a highly parallel single-instruction multiple-data architecture and benchmarked using graphics processing units from multiple hardware generations, using data from real flights. It is also compared with the previous, CPU-based proof of concept. As the underlying hardware imposes limitations with regard to memory access and concurrency, necessary data structures and further performance considerations are explained in detail. The Open-source code for this paper is available at http://www.github.com/benadler/octocopter/.},
	language = {en},
	number = {6},
	urldate = {2019-02-27},
	journal = {Journal of Field Robotics},
	author = {Adler, Benjamin and Xiao, Junhao and Zhang, Jianwei},
	year = {2014},
	pages = {912--939}
}

@inproceedings{pham_reinforcement_2018,
	title = {Reinforcement {Learning} for {Autonomous} {UAV} {Navigation} {Using} {Function} {Approximation}},
	doi = {10.1109/SSRR.2018.8468611},
	abstract = {Unmanned aerial vehicles (UAV) are commonly used for search and rescue missions in unknown environments, where an exact mathematical model of the environment may not be available. This paper proposes a framework for the UAV to locate a missing human after a natural disaster in such environment, using a reinforcement learning (RL) algorithm. A function approximation based RL algorithm is proposed to deal with a large number of states representation and to obtain a faster convergence time. We conducted both simulated and real implementations to show how the UAVs can successfully learn to carry out the task without colliding with obstacles. Technical aspects for applying RL algorithm to a UAV system and UAV flight control were also addressed.},
	booktitle = {2018 {IEEE} {International} {Symposium} on {Safety}, {Security}, and {Rescue} {Robotics} ({SSRR})},
	author = {Pham, H. X. and La, H. M. and Feil-Seifer, D. and Nguyen, L. Van},
	month = aug,
	year = {2018},
	keywords = {Approximation algorithms, Function approximation, Laser radar, Learning (artificial intelligence), NASA, Navigation, UAV system, Unmanned aerial vehicles, autonomous UAV navigation, autonomous aerial vehicles, collision avoidance, function approximation, learning (artificial intelligence), reinforcement learning algorithm, robot programming, search and rescue missions, unmanned aerial vehicles},
	pages = {1--6}
}

@article{christie_semantics_2016,
	title = {Semantics for {UGV} {Registration} in {GPS}-denied {Environments}},
	url = {http://arxiv.org/abs/1609.04794},
	abstract = {Localization in a global map is critical to success in many autonomous robot missions. This is particularly challenging for multi-robot operations in unknown and adverse environments. Here, we are concerned with providing a small unmanned ground vehicle (UGV) the ability to localize itself within a 2.5D aerial map generated from imagery captured by a low-flying unmanned aerial vehicle (UAV). We consider the scenario where GPS is unavailable and appearance-based scene changes may have occurred between the UAV's flight and the start of the UGV's mission. We present a GPS-free solution to this localization problem that is robust to appearance shifts by exploiting high-level, semantic representations of image and depth data. Using data gathered at an urban test site, we empirically demonstrate that our technique yields results within five meters of a GPS-based approach.},
	urldate = {2019-02-27},
	journal = {arXiv:1609.04794 [cs]},
	author = {Christie, Gordon and Warnell, Garrett and Kochersberger, Kevin},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.04794},
	keywords = {Computer Science - Robotics}
}

@inproceedings{alirezaie_exploiting_2017,
	title = {Exploiting context and semantics for {UAV} {Path}-finding in an urban setting},
	volume = {1935},
	abstract = {In this paper we propose an ontology pattern that represents paths in a geo-representation model to be used in an aerial path planning processes. This pattern provides semantics related to constraints (i.e., flight forbidden zones) in a path planning problem in order to generate collision free paths. Our proposed approach has been applied on an ontology containing geo-regions extracted from satellite imagery data from a large urban city as an illustrative example.},
	author = {Alirezaie, M. and Kiselev, A. and Klügl, F. and Längkvist, M. and Loutfi, A.},
	year = {2017},
	keywords = {Ontology Design Pattern, Path Planning, Representation and reasoning for Robotics, Semantic Web for Robotics},
	pages = {11--20}
}

@inproceedings{cavaliere_towards_2016,
	title = {Towards semantic context-aware drones for aerial scenes understanding},
	doi = {10.1109/AVSS.2016.7738062},
	abstract = {Visual object tracking with unmanned aerial vehicles (UAVs) plays a central role in the aerial surveillance. Reliable object detection depends on many factors such as large displacements, occlusions, image noise, illumination and pose changes or image blur that may compromise the object labeling. The paper presents a proposal for a hybrid solution that adds semantic information to the video tracking processing: along with the tracked objects, the scene is completely depicted by data from places, natural features, or in general Points of Interest (POIs). Each scene from a video sequence is semantically described by ontological statements which, by inference, support the object identification which often suffers from some weakness in the object tracking methods. The synergy between the tracking methods and semantic technologies seems to bridge the object labeling gap, enhance the understanding of the situation awareness, as well as critical alarming situations.},
	booktitle = {2016 13th {IEEE} {International} {Conference} on {Advanced} {Video} and {Signal} {Based} {Surveillance} ({AVSS})},
	author = {Cavaliere, D. and Senatore, S. and Vento, M. and Loia, V.},
	month = aug,
	year = {2016},
	keywords = {Drones, Google, Labeling, Object tracking, Ontologies, POI, Semantics, UAV, Video sequences, aerial surveillance, autonomous aerial vehicles, general points of interest, natural features, object detection, object identification, object labeling gap, object tracking, ontological statements, ontologies (artificial intelligence), reliable object detection, semantic information, semantic networks, semantic technologies, unmanned aerial vehicles, video sequence, video tracking processing, visual object tracking},
	pages = {115--121}
}

@inproceedings{milford_ratslam_2004,
	address = {Hilton New Orleans Riverside Hotel, New Orleans, LA},
	title = {{RatSLAM} : a hippocampal model for simultaneous localization and mapping},
	copyright = {Copyright 2004 IEEE},
	isbn = {978-0-7803-8232-9},
	shorttitle = {{RatSLAM}},
	url = {https://eprints.qut.edu.au/37593/},
	abstract = {The work presents a new approach to the problem of simultaneous localization and mapping - SLAM - inspired by computational models of the hippocampus of rodents. The rodent hippocampus has been extensively studied with respect to navigation tasks, and displays many of the properties of a desirable SLAM solution. RatSLAM is an implementation of a hippocampal model that can perform SLAM in real time on a real robot. It uses a competitive attractor network to integrate odometric information with landmark sensing to form a consistent representation of the environment. Experimental results show that RatSLAM can operate with ambiguous landmark information and recover from both minor and major path integration errors.},
	language = {en},
	urldate = {2019-02-26},
	booktitle = {Proceedings of {IEEE} {International} {Conference} on {Robotics} and {Automation}, 2004},
	publisher = {IEEE},
	author = {Milford, Michael J. and Wyeth, Gordon F. and Prasser, David},
	month = jul,
	year = {2004}
}

@article{moon_scene_2018,
	title = {Scene understanding using natural language description based on {3D} semantic graph map},
	volume = {11},
	issn = {1861-2784},
	url = {https://doi.org/10.1007/s11370-018-0257-x},
	doi = {10.1007/s11370-018-0257-x},
	abstract = {A natural language description for working environment understanding is an important component in human–robot communication. Although 3D semantic graph mappings are widely studied for perceptual aspects of the environment, these approaches hardly apply to the communication issues such as natural language descriptions for a semantic graph map. There are many researches on workspace understanding over images in the field of computer vision, which automatically generate sentences while they usually never utilize multiple scenes and 3D information. In this paper, we introduce a novel natural language description method using 3D semantic graph map. An object-oriented semantic graph map is first constructed using 3D information. A graph convolutional neural network and a recurrent neural network are then used to generate a description of the map. A natural language sentence focusing on objects over 3D semantic graph map can be eventually generated consisting of a single scene or multiple scenes. We validate the proposed method using publicly available dataset and compare it with conventional methods.},
	language = {en},
	number = {4},
	urldate = {2019-02-26},
	journal = {Intelligent Service Robotics},
	author = {Moon, Jiyoun and Lee, Beomhee},
	month = oct,
	year = {2018},
	keywords = {3D semantic graph map, Natural language description, Scene understanding},
	pages = {347--354}
}

@inproceedings{kunze_searching_2012,
	title = {Searching objects in large-scale indoor environments: {A} decision-theoretic approach},
	shorttitle = {Searching objects in large-scale indoor environments},
	doi = {10.1109/ICRA.2012.6224965},
	abstract = {Many of today's mobile robots are supposed to perform everyday manipulation tasks autonomously. However, in large-scale environments, a task-related object might be out of the robot's reach. Hence, the robot first has to search for the object in its environment before it can perform the task. In this paper, we present a decision-theoretic approach for searching objects in large-scale environments using probabilistic environment models and utilities associated with object locations. We demonstrate the feasibility of our approach by integrating it into a robot system and by conducting experiments where the robot is supposed to search different objects with various strategies in the context of fetch-and-delivery tasks within a multi-level building.},
	booktitle = {2012 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Kunze, L. and Beetz, M. and Saito, M. and Azuma, H. and Okada, K. and Inaba, M.},
	month = may,
	year = {2012},
	keywords = {Databases, Elevators, Probabilistic logic, Robots, Search problems, Semantics, decision theory, decision-theoretic approach, fetch-and-delivery task, large-scale indoor environment, manipulation task, mobile robot, mobile robots, multilevel building, object location, object search, probabilistic environment model, probability, robot system, task-related object},
	pages = {4385--4390}
}

@inproceedings{anati_robot_2012,
	title = {Robot localization using soft object detection},
	doi = {10.1109/ICRA.2012.6225216},
	abstract = {In this paper, we give a new double twist to the robot localization problem. We solve the problem for the case of prior maps which are semantically annotated perhaps even sketched by hand. Data association is achieved not through the detection of visual features but the detection of object classes used in the annotation of the prior maps. To avoid the caveats of general object recognition, we propose a new representation of the query images that consists of a vector of the detection scores for each object class. Given such soft object detections we are able to create hypotheses about pose and to refine them through particle filtering. As opposed to small confined office and kitchen spaces, our experiment takes place in a large open urban rail station with multiple semantically ambiguous places. The success of our approach shows that our new representation is a robust way to exploit the plethora of existing prior maps for GPS-denied environments avoiding the data association problems when matching point clouds or visual features.},
	booktitle = {2012 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Anati, R. and Scaramuzza, D. and Derpanis, K. G. and Daniilidis, K.},
	month = may,
	year = {2012},
	keywords = {Cameras, Heating, Histograms, Image color analysis, Object detection, Robot kinematics, data association, object detection, object recognition, particle filtering, path planning, robot localization problem, robot vision, sensor fusion, soft object detection, urban rail station},
	pages = {4992--4999}
}

@inproceedings{bowman_probabilistic_2017,
	title = {Probabilistic data association for semantic {SLAM}},
	doi = {10.1109/ICRA.2017.7989203},
	abstract = {Traditional approaches to simultaneous localization and mapping (SLAM) rely on low-level geometric features such as points, lines, and planes. They are unable to assign semantic labels to landmarks observed in the environment. Furthermore, loop closure recognition based on low-level features is often viewpoint-dependent and subject to failure in ambiguous or repetitive environments. On the other hand, object recognition methods can infer landmark classes and scales, resulting in a small set of easily recognizable landmarks, ideal for view-independent unambiguous loop closure. In a map with several objects of the same class, however, a crucial data association problem exists. While data association and recognition are discrete problems usually solved using discrete inference, classical SLAM is a continuous optimization over metric information. In this paper, we formulate an optimization problem over sensor states and semantic landmark positions that integrates metric information, semantic information, and data associations, and decompose it into two interconnected problems: an estimation of discrete data association and landmark class probabilities, and a continuous optimization over the metric states. The estimated landmark and robot poses affect the association and class distributions, which in turn affect the robot-landmark pose optimization. The performance of our algorithm is demonstrated on indoor and outdoor datasets.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Bowman, S. L. and Atanasov, N. and Daniilidis, K. and Pappas, G. J.},
	month = may,
	year = {2017},
	keywords = {Feature extraction, Measurement, Optimization, SLAM (robots), Semantics, Simultaneous localization and mapping, discrete data association, indoor datasets, landmark class probabilities, low-level geometric features, object recognition, optimisation, optimization problem, outdoor datasets, pose estimation, probabilistic data association, robot-landmark pose optimization, semantic SLAM, semantic information, semantic landmark positions, sensor fusion, simultaneous localization-and-mapping, view-independent unambiguous loop closure recognition},
	pages = {1722--1729}
}

@inproceedings{li_incorporating_2014,
	title = {Incorporating extrinsic object properties in robotic semantic mapping},
	doi = {10.1109/ROBIO.2014.7090528},
	abstract = {Most robot semantic mapping methods only consider the intrinsic properties of landmarks and objects inside a scene, by detecting them with their appearances, and some other methods include extrinsic properties with manually designed object relations. In this work, we use relational operators to capture the extrinsic property values, and adopt conditional random field to integrate intrinsic and extrinsic property values into semantic mapping. We compare our approach with three types of semantic maps, and show that our approach allows the robot to find designated objects more accurately.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Robotics} and {Biomimetics} ({ROBIO} 2014)},
	author = {Li, K. and Meng, M.},
	month = dec,
	year = {2014},
	keywords = {Feature extraction, Markov random fields, Measurement, Robot sensing systems, Semantics, Visualization, extrinsic object property, object detection, object recognition, relational operator, robot vision, robotic semantic mapping},
	pages = {1392--1397}
}

@inproceedings{lang_definition_2014,
	title = {Definition of semantic maps for outdoor robotic tasks},
	doi = {10.1109/ROBIO.2014.7090724},
	abstract = {In recent years, a lot of work was conducted in order to give robots the ability to gather semantic information about their environment, store it, represent it for the user and to perform high-level tasks based on the semantic information. Most of the systems use internal representations of the gathered information that is not intuitively understandable by humans and that is inadequate for learning from commonly available sources. The combination of object/place classification and common-sense knowledge to semantic maps found its way into indoor semantic mapping approaches to improve human-robot interaction. The aim is to assign complex task settings to the robot allowing it to guide the search for the solution by itself. In this paper, we present a formal common definition of semantic maps. We discuss different criteria for designing and classifying semantic maps and their appropriate challenges. Furthermore, we present an outdoor semantic mapping approach incorporating common-sense knowledge into the classification process and a suitable map representation for high-level tasks.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Robotics} and {Biomimetics} ({ROBIO} 2014)},
	author = {Lang, D. and Friedmann, S. and Häselich, M. and Paulus, D.},
	month = dec,
	year = {2014},
	keywords = {Cameras, Cognition, Robot sensing systems, Semantics, Three-dimensional displays, classification process, common-sense knowledge, control engineering computing, formal common definition, gathered information, high-level task, human-robot interaction, indoor semantic mapping approach, internal representation, map representation, mobile robots, object/place classification, outdoor robotic task, outdoor semantic mapping approach, pattern classification, semantic information, semantic maps},
	pages = {2547--2552}
}

@inproceedings{ruiz-del-solar_bayesian_2013,
	title = {A {Bayesian} framework for informed search using convolutions between observation likelihoods and spatial relation masks},
	doi = {10.1109/ICAR.2013.6766593},
	abstract = {In this work, a novel methodology for robots executing informed object search is proposed. The methodology is based mainly on a Bayesian framework that uses convolutions between observation likelihoods and spatial relation masks for estimating the probability map of the object being search for. By using spatial relation masks, complex spatial relations between objects can be defined as weighted sums of basic spatial relations using co-occurrence matrices as weights. The methodology is validated in an office environment in which four object classes (“monitor,” “keyboard,” “system unit,” and “router”) and four basic spatial relations (“very near,” “near,” “far,” and “very far”) are considered. Experiments combine statistics about object's coocurrence and about object detection in real environments, and search trials using a realistic simulation tool in which extensive tests comparing six object search algorithms are carried out. Results show that the use of the proposed methodology increases the object detection rate in a search task from 27.5\% up to 53.2\%.},
	booktitle = {2013 16th {International} {Conference} on {Advanced} {Robotics} ({ICAR})},
	author = {Ruiz-del-Solar, J. and Loncomilla, P. and Saavedra, M.},
	month = nov,
	year = {2013},
	keywords = {Active search, Bayes methods, Bayesian framework, Cameras, Co-occurrence matrix, Informed search, Object detection, Robot vision systems, Search problems, Semantic search, Semantics, Spatial relations, Three-dimensional displays, cooccurrence matrices, matrix algebra, mobile robots, object detection, object search, object search algorithms, observation likelihoods, office environment, probability map estimation, realistic simulation tool, robot vision, search problems, spatial relation masks, weighted sums},
	pages = {1--8}
}

@incollection{al-moadhen_improving_2015,
	address = {Cham},
	series = {Smart {Innovation}, {Systems} and {Technologies}},
	title = {Improving the {Efficiency} of {Robot} {Task} {Planning} by {Automatically} {Integrating} {Its} {Planner} and {Common}-{Sense} {Knowledge} {Base}},
	isbn = {978-3-319-13545-8},
	url = {https://doi.org/10.1007/978-3-319-13545-8_11},
	abstract = {This chapter presents a newly developed approach for intelligently generating symbolic plans for mobile robots acting in domestic environments, such as offices and houses. The significance of this approach lies in its novel framework which consists of new modelling of high-level robot actions and their integration with common-sense knowledge in order to support robotic task planner. This framework will enable direct interactions between the task planner and the semantic knowledge base. By using common-sense domain knowledge, the task planner will take into consideration the properties and relations of objects and places in its environment, before creating semantically related actions that will represent a plan. A new module has been appended to the framework which is called Semantic Realization and Refreshment Module (SRRM). This module has the ability to discover and select entities in the robot’s world (entities related to robot plan) which are semantically equivalent or have a degree of similarity (where they don’t exceed a predefined threshold) by using techniques and standards (metrics) for similarities. SRRM supports robotic task planning to generate approximate plans to solve its tasks when there is no exact plan can be generated according to initial and goal state by extending initial state and action details with similar or equivalent objects. The extended framework enables direct interactions between task planner, Semantic Action Models (SAMs) and knowledge-base through creating planning domain (or extended planning domain) with predicates (or semantically equivalent or similar predicates) which specify domain features. The proposed framework and approach are tested on some scenarios that cover most aspects of robot planning system.},
	language = {en},
	urldate = {2019-02-26},
	booktitle = {Knowledge-{Based} {Information} {Systems} in {Practice}},
	publisher = {Springer International Publishing},
	author = {Al-Moadhen, Ahmed and Packianather, Michael and Qiu, Renxi and Setchi, Rossi and Ji, Ze},
	editor = {Tweedale, Jeffrey W. and Jain, Lakhmi C. and Watada, Junzo and Howlett, Robert J.},
	year = {2015},
	doi = {10.1007/978-3-319-13545-8_11},
	keywords = {Common-Sense Knowledge Base, Semantic Action Model, Semantic Realization and Refreshment Module},
	pages = {185--199}
}

@article{al-moadhen_integrating_2013,
	series = {17th {International} {Conference} in {Knowledge} {Based} and {Intelligent} {Information} and {Engineering} {Systems} - {KES2013}},
	title = {Integrating {Robot} {Task} {Planner} with {Common}-sense {Knowledge} {Base} to {Improve} the {Efficiency} of {Planning}},
	volume = {22},
	issn = {1877-0509},
	url = {http://www.sciencedirect.com/science/article/pii/S1877050913008909},
	doi = {10.1016/j.procs.2013.09.097},
	abstract = {This paper presents a developed approach for intelligently generating symbolic plans by mobile robots acting in domestic environments, such as offices and houses. The significance of the approach lies in developing a new framework that consists of the new modeling of high-level robot actions and then their integration with common-sense knowledge in order to support a robotic task planner. This framework will enable interactions between the task planner and the semantic knowledge base directly. By using common-sense domain knowledge, the task planner will take into consideration the properties and relations of objects and places in its environment, before creating semantically related actions that will represent a plan. This plan will accomplish the user order. The robot task planner will use the available domain knowledge to check the next related actions to the current one and the action's conditions met will be chosen. Then the robot will use the immediately available knowledge information to check whether the plan outcomes are met or violated.},
	urldate = {2019-02-26},
	journal = {Procedia Computer Science},
	author = {Al-Moadhen, Ahmed and Qiu, Renxi and Packianather, Michael and Ji, Ze and Setchi, Rossi},
	month = jan,
	year = {2013},
	keywords = {Common-Sense knowledge, ConceptNet., Semantic Action Model, Semantic Network, Task Planner},
	pages = {211--220}
}
@inproceedings{galindo_multi-hierarchical_2005,
	title = {Multi-hierarchical semantic maps for mobile robotics},
	doi = {10.1109/IROS.2005.1545511},
	abstract = {The success of mobile robots, and particularly of those interfacing with humans in daily environments (e.g., assistant robots), relies on the ability to manipulate information beyond simple spatial relations. We are interested in semantic information, which gives meaning to spatial information like images or geometric maps. We present a multi-hierarchical approach to enable a mobile robot to acquire semantic information from its sensors, and to use it for navigation tasks. In our approach, the link between spatial and semantic information is established via anchoring. We show experiments on a real mobile robot that demonstrate its ability to use and infer new semantic information from its environment, improving its operation.},
	booktitle = {2005 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Galindo, C. and Saffiotti, A. and Coradeschi, S. and Buschka, P. and Fernandez-Madrigal, J. A. and Gonzalez, J.},
	month = aug,
	year = {2005},
	keywords = {Abstraction, Anchoring, Home automation, Humans, Knowledge representation, Mobile robots, Navigation, Orbital robotics, Robot sensing systems, Robotics and automation, Semantic maps, Sensor systems, Symbol grounding, Systems engineering and theory, knowledge acquisition, knowledge representation, mobile robot, mobile robots, multihierarchical semantic map, navigation, path planning, semantic information acquisition, symbol grounding},
	pages = {2278--2283}
}

@inproceedings{bouguerra_semantic_2007,
	title = {Semantic {Knowledge}-{Based} {Execution} {Monitoring} for {Mobile} {Robots}},
	doi = {10.1109/ROBOT.2007.364044},
	abstract = {We describe a novel intelligent execution monitoring approach for mobile robots acting in indoor environments such as offices and houses. Traditionally, monitoring execution in mobile robotics amounted to looking for discrepancies between the model-based predicted state of executing an action and the real world state as computed from sensing data. We propose to employ semantic knowledge as a source of information to monitor execution. The key idea is to compute implicit expectations, from semantic domain information, that can be observed at run time by the robot to make sure actions are executed correctly. We present the semantic knowledge representation formalism, and how semantic knowledge is used in monitoring. We also describe experiments run in an indoor environment using a real mobile robot.},
	booktitle = {Proceedings 2007 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Bouguerra, A. and Karlsson, L. and Saffiotti, A.},
	month = apr,
	year = {2007},
	keywords = {Computerized monitoring, Indoor environments, Intelligent robots, Logic, Mobile computing, Mobile robots, Orbital robotics, Predictive models, Robot sensing systems, Robotics and automation, indoor environment, intelligent execution monitoring, intelligent robots, mobile robots, semantic domain information, semantic knowledge representation, semantic networks},
	pages = {3693--3698}
}

@article{banino_vector-based_2018,
	title = {Vector-based navigation using grid-like representations in artificial agents},
	volume = {557},
	copyright = {2018 Macmillan Publishers Ltd., part of Springer Nature},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-018-0102-6},
	doi = {10.1038/s41586-018-0102-6},
	abstract = {Grid-like representations emerge spontaneously within a neural network trained to self-localize, enabling the agent to take shortcuts to destinations using vector-based navigation.},
	language = {En},
	number = {7705},
	urldate = {2019-02-24},
	journal = {Nature},
	author = {Banino, Andrea and Barry, Caswell and Uria, Benigno and Blundell, Charles and Lillicrap, Timothy and Mirowski, Piotr and Pritzel, Alexander and Chadwick, Martin J. and Degris, Thomas and Modayil, Joseph and Wayne, Greg and Soyer, Hubert and Viola, Fabio and Zhang, Brian and Goroshin, Ross and Rabinowitz, Neil and Pascanu, Razvan and Beattie, Charlie and Petersen, Stig and Sadik, Amir and Gaffney, Stephen and King, Helen and Kavukcuoglu, Koray and Hassabis, Demis and Hadsell, Raia and Kumaran, Dharshan},
	month = may,
	year = {2018},
	pages = {429}
}

@misc{noauthor_shared_2019,
	title = {Shared grounding of event descriptions by autonomous robots - {ScienceDirect}},
	url = {https://www-sciencedirect-com.ezp01.library.qut.edu.au/science/article/pii/S0921889002003573},
	urldate = {2019-02-19},
	month = feb,
	year = {2019}
}

@article{tenorth_web-enabled_2011,
	title = {Web-{Enabled} {Robots}},
	volume = {18},
	issn = {1070-9932},
	doi = {10.1109/MRA.2011.940993},
	abstract = {In this article, we describe and discuss the use of information that is available in the World Wide Web and intended for human use as a knowledge resource for autonomous service robots. To this end, we introduce several categories of Web sites that can serve as information sources and explain which kinds of information they provide. We then investigate several information processing methods that can access these Web sites to provide robots with necessary knowledge for performing everyday manipulation tasks. The use of the Web as a knowledge resource is a promising alternative to the hard and tedious task of coding comprehensive specific knowledge bases for robots.},
	language = {eng},
	number = {2},
	journal = {IEEE Robotics \& Automation Magazine},
	author = {Tenorth, M. and Klank, U. and Pangercic, D. and Beetz, M.},
	year = {2011},
	keywords = {Engineering, Human Factors, Knowledge Based Systems, Knowledge Engineering, Robot Programmig, Semantic Web, Solid Modeling, Web Sites},
	pages = {58--68}
}

@inproceedings{spexard_biron_2006,
	title = {{BIRON}, where are you? {Enabling} a robot to learn new places in a real home environment by integrating spoken dialog and visual localization},
	isbn = {978-1-4244-0258-8},
	shorttitle = {{BIRON}, where are you?},
	doi = {10.1109/IROS.2006.281770},
	abstract = {An ambitious goal in modern robotic science is to build mobile robots that are able to interact as companions in real world environments. Especially for caretaking of elderly people a system robustly working at private homes is essential, requiring a very natural and human oriented way of communication. Since home environments are usually very individual a first task for a newly acquired robot is to get familiar with its new environment. This paper gives a short overview on how we integrated a vision based localization using the advantages of a very modular architecture and extending a spoken dialog system for online labeling and interaction about different locations. We present results from the integrated system working in a real, fully furnished home environment where it was able to learn the names of different rooms. This system enables us to perform real user studies in future without the need to fall back to Wizard-of-Oz experiments. Ongoing work aims at enabling the robot to take initiative by asking for unknown locations. A future extension is the ability to generalize over features of known rooms to make predictions when encountering unknown rooms},
	language = {eng},
	publisher = {IEEE},
	author = {Spexard, T. and {Shuyin Li} and Wrede, B. and Fritsch, J. and Sagerer, G. and Booij, O. and Zivkovic, Z. and Terwijn, B. and Krose, B.},
	year = {2006},
	keywords = {Artificial Intelligence, Cognitive Robotics, Computer Architecture, Engineering, Human Robot Interaction, Intelligent Robots, Mobile Robots, Orbital Robotics, Performance Evaluation, Robustness, System Testing},
	pages = {934--940}
}

@inproceedings{hemachandra_learning_2014,
	title = {Learning spatial-semantic representations from natural language descriptions and scene classifications},
	doi = {10.1109/ICRA.2014.6907235},
	abstract = {We describe a semantic mapping algorithm that learns human-centric environment models by interpreting natural language utterances. Underlying the approach is a coupled metric, topological, and semantic representation of the environment that enables the method to fuse information from natural language descriptions with low-level metric and appearance data. We extend earlier work with a novel formulation that incorporates spatial layout into a topological representation of the environment. We also describe a factor graph formulation of the semantic properties that encodes human-centric concepts such as type and colloquial name for each mapped region. The algorithm infers these properties by combining the user's natural language descriptions with image- and laser-based scene classification. We also propose a mechanism to more effectively ground natural language descriptions of distant regions using semantic cues from other modalities. We describe how the algorithm employs this learned semantic information to propose valid topological hypotheses, leading to more accurate topological and metric maps. We demonstrate that integrating language with other sensor data increases the accuracy of the achieved spatial-semantic representation of the environment.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Hemachandra, S. and Walter, M. R. and Tellex, S. and Teller, S.},
	month = may,
	year = {2014},
	keywords = {Laser modes, Measurement, Natural languages, Robot sensing systems, Semantics, Topology, appearance data, control engineering computing, factor graph formulation, graph theory, human-centric environment models, human-robot interaction, image classification, image-based scene classification, laser-based scene classification, learning, learning (artificial intelligence), low-level metric data, mapped region, metric representation, natural language descriptions, natural language processing, natural language utterances, robot vision, semantic cues, semantic mapping algorithm, semantic networks, semantic properties, spatial layout, spatial-semantic representations, topological hypotheses, topological representation},
	pages = {2623--2630}
}

@book{barnard_computational_2016,
	address = {San Rafael, California (1537 Fourth Street, San Rafael, CA  94901 USA)},
	series = {Synthesis lectures on computer vision, \# 7},
	title = {Computational methods for integrating vision and language},
	isbn = {978-1-60845-113-5},
	abstract = {Modeling data from visual and linguistic modalities together creates opportunities for better understanding of both, and supports many useful applications. Examples of dual visual-linguistic data includes images with keywords, video with narrative, and figures in documents. We consider two key task-driven themes: translating from one modality to another (e.g., inferring annotations for images) and understanding the data using all modalities, where one modality can help disambiguate information in another. The multiple modalities can either be essentially semantically redundant (e.g., keywords provided by a person looking at the image), or largely complementary (e.g., meta data such as the camera used). Redundancy and complementarity are two endpoints of a scale, and we observe that good performance on translation requires some redundancy, and that joint inference is most useful where some information is complementary. Computational methods discussed are broadly organized into ones for simple keywords, ones going beyond keywords toward natural language, and ones considering sequential aspects of natural language. Methods for keywords are further organized based on localization of semantics, going from words about the scene taken as whole, to words that apply to specific parts of the scene, to relationships between parts. Methods going beyond keywords are organized by the linguistic roles that are learned, exploited, or generated. These include proper nouns, adjectives, spatial and comparative prepositions, and verbs. More recent developments in dealing with sequential structure include automated captioning of scenes and video, alignment of video and text, and automated answering of questions about scenes depicted in images.},
	language = {eng},
	publisher = {Morgan \& Claypool},
	author = {Barnard, Kobus},
	year = {2016},
	keywords = {Closed captioning Technological innovations., Computer vision Mathematical models., Electronic books., Information visualization., Keyword searching Technological innovations., Natural language processing (Computer science), affective visual attributes, aligning visual and linguistic data, auto-annotation, auto-illustration, correspondence ambiguity, cross-modal disambiguation, image captioning, language, loosely labeled data, multimodal translation, region labeling, video captioning, vision, visual question answering}
}

@article{matuszek_joint_nodate,
	title = {A {Joint} {Model} of {Language} and {Perception} for {Grounded} {Attribute} {Learning}},
	url = {http://arxiv.org/abs/1206.6423},
	abstract = {As robots become more ubiquitous and capable, it becomes ever more important to enable untrained users to easily interact with them. Recently, this has led to study of the language grounding problem, where the goal is to extract representations of the meanings of natural language tied to perception and actuation in the physical world. In this paper, we present an approach for joint learning of language and perception models for grounded attribute induction. Our perception model includes attribute classifiers, for example to detect object color and shape, and the language model is based on a probabilistic categorial grammar that enables the construction of rich, compositional meaning representations. The approach is evaluated on the task of interpreting sentences that describe sets of objects in a physical workspace. We demonstrate accurate task performance and effective latent-variable concept induction in physical grounded scenes. Comment: Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)},
	urldate = {2019-02-19},
	author = {Matuszek, Cynthia and Fitzgerald, Nicholas and Zettlemoyer, Luke and Bo, Liefeng and Fox, Dieter},
	keywords = {Computer Science - Computation and Language, Computer Science - Learning, Computer Science - Robotics}
}

@article{liu_context-specific_2016,
	title = {Context-{Specific} grounding of web natural descriptions to human-centered situations},
	volume = {111},
	issn = {0950-7051},
	doi = {10.1016/j.knosys.2016.07.037},
	abstract = {•This novel W2S method is effective in grounding web natural descriptions into human-centered situations. With the grounded knowledge, human-centered situations could be effectively understood.•The influence of environmental context towards humans’ activities could be measured. The context involvements in situation representation could improve the accuracy of situation understanding.•The proposed semantic analysis method could evaluate the situation-involvement degree of the knowledge entities (i.e., objects and environmental context) and their relations. Based on the involvement degree, the key features including objects, environmental context, and their mutual relations could be extracted to accurately represent a situation. Human-centered situation, which describes the surrounding world of a person, indicates his undergoing activities. Understanding of human-centered situations helps an assistive robot with its decision making. Existing methods, such as learning from human demonstration, are economically expensive, time-consuming, and have limited scalability. To address this problem, we developed a web-to-situation (W2S) method with which web natural descriptions are grounded into human-centered situations in a context-specific manner. By comparing the learned knowledge from the web and the survey, we proved that W2S is effective in extracting reliable knowledge in an efficient and low-cost manner. By implementing the W2S-retrieved knowledge in 60 web-collected situations and 60 real life situations, we proved that W2S is effective in situation understanding. Given that the web contains huge amounts of information, W2S is expected to effectively scale up a robot's knowledge.},
	language = {eng},
	journal = {Knowledge-Based Systems},
	author = {Liu, Rui and Zhang, Xiaoli},
	year = {2016},
	keywords = {Assistive Robot, Decision Making, Environmental Context, Human-Centered Situation, Web Information Retrieval},
	pages = {1--16}
}

@inproceedings{taniguchi_online_2017,
	address = {Vancouver, BC},
	title = {Online spatial concept and lexical acquisition with simultaneous localization and mapping},
	isbn = {978-1-5386-2682-5},
	url = {http://ieeexplore.ieee.org/document/8202243/},
	doi = {10.1109/IROS.2017.8202243},
	urldate = {2019-02-19},
	booktitle = {2017 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	publisher = {IEEE},
	author = {Taniguchi, Akira and Hagiwara, Yoshinobu and Taniguchi, Tadahiro and Inamura, Tetsunari},
	month = sep,
	year = {2017},
	pages = {811--818}
}

@article{cosgun_context-aware_2018,
	title = {Context-aware robot navigation using interactively built semantic maps},
	volume = {9},
	issn = {2081-4836},
	url = {http://www.degruyter.com/view/j/pjbr.2018.9.issue-1/pjbr-2018-0020/pjbr-2018-0020.xml},
	doi = {10.1515/pjbr-2018-0020},
	number = {1},
	urldate = {2019-02-19},
	journal = {Paladyn, Journal of Behavioral Robotics},
	author = {Cosgun, Akansel and Christensen, Henrik I.},
	month = aug,
	year = {2018},
	pages = {254--276}
}

@article{deeken_grounding_2018,
	title = {Grounding semantic maps in spatial databases},
	volume = {105},
	issn = {0921-8890},
	doi = {10.1016/j.robot.2018.03.011},
	abstract = {Semantic maps add to classic robot maps spatially grounded object instances anchored in a suitable way for knowledge representation and reasoning. They enable a robot to solve reasoning problems of geometrical, topological, ontological and logical nature in addition to localization and path planning. Recent literature on semantic mapping lacks effective and efficient approaches for grounding qualitative spatial relations through analysis of the quantitative geometric data of the mapped entities. Yet, such qualitative relations are essential to perform spatial and ontological reasoning about objects in the robot’s surroundings.This article contributes a framework for semantic map representation, called SEMAP, to overcome this missing aspect. It is able to manage full 3D maps with geometric object models and the corresponding semantic annotations as well as their relative spatial relations. For that, spatial database technology is used to solve the representational and querying problems efficiently. This article describes the extensions necessary to make a spatial database suitable for robotic applications. Especially, we add 3D spatial operators and a tree of transformations to represent relative position information. We evaluate the implemented capabilities and present real life use cases of SEMAP in different application domains. •Automatic grounding of spatial relations as factual knowledge.•Qualitative spatial reasoning and geometric qualification.•Integration of PostGIS into a semantic mapping framework.•Addition of 3D spatial relation operators to PostGIS.•Dynamic topology extraction between entities.},
	language = {eng},
	journal = {Robotics and Autonomous Systems},
	author = {Deeken, Henning and Wiemann, Thomas and Hertzberg, Joachim},
	year = {2018},
	keywords = {Knowledge Representation, Semantic Mapping, Spatial Analysis},
	pages = {146--165}
}

@article{landsiedel_review_2017,
	title = {A review of spatial reasoning and interaction for real-world robotics},
	volume = {31},
	issn = {0169-1864},
	doi = {10.1080/01691864.2016.1277554},
	abstract = {Truly universal helper robots capable of coping with unknown, unstructured environments must be capable of spatial reasoning, i.e. establishing geometric relations between objects and locations, expressing those in terms understandable by humans. It is therefore desirable that spatial and semantic environment representations are tightly interlinked. 3D robotic mapping and the generation of consistent metric representations of space are highly useful for navigation and exploration, but they do not capture symbol-level information about the environment. This is, however, essential for reasoning, and enables interaction via natural language, which is arguably the most common and natural communication channel used and understood by humans. This article presents a review of research in three major fields relevant for this discussion of spatial reasoning and interaction. Firstly, dialogue systems are an integral part of modern approaches to situated human–robot interaction. Secondly, interactive robots must be equipped with environment representations and reasoning methods that are suitable for both navigation and task fulfillment, as well as for interaction with human partners. Thirdly, at the interface between these domains are systems that ground language in systemic environment representation and which allow the integration of information from natural language descriptions into robotic maps. For each of these areas, important approaches are outlined and relations between the fields are highlighted, and challenging applications as well as open problems are discussed.},
	language = {eng},
	number = {5},
	journal = {Advanced Robotics},
	author = {Landsiedel, C. and Rieser, V. and Walter, M. and Wollherr, D.},
	year = {2017},
	keywords = {Article, Environment Modelling, Natural Language Grounding, Semantic Mapping, Situated Human–Robot Interaction, Spatial Reasoning},
	pages = {222--242}
}

@inproceedings{guadarrama_grounding_2013,
	title = {Grounding spatial relations for human-robot interaction},
	doi = {10.1109/IROS.2013.6696569},
	abstract = {We propose a system for human-robot interaction that learns both models for spatial prepositions and for object recognition. Our system grounds the meaning of an input sentence in terms of visual percepts coming from the robot's sensors in order to send an appropriate command to the PR2 or respond to spatial queries. To perform this grounding, the system recognizes the objects in the scene, determines which spatial relations hold between those objects, and semantically parses the input sentence. The proposed system uses the visual and spatial information in conjunction with the semantic parse to interpret statements that refer to objects (nouns), their spatial relationships (prepositions), and to execute commands (actions). The semantic parse is inherently compositional, allowing the robot to understand complex commands that refer to multiple objects and relations such as: “Move the cup close to the robot to the area in front of the plate and behind the tea box”. Our system correctly parses 94\% of the 210 online test sentences, correctly interprets 91\% of the correctly parsed sentences, and correctly executes 89\% of the correctly interpreted sentences.},
	booktitle = {2013 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Guadarrama, S. and Riano, L. and Golland, D. and Go¨hring, D. and Jia, Y. and Klein, D. and Abbeel, P. and Darrell, T.},
	month = nov,
	year = {2013},
	keywords = {Adaptation models, Grounding, Natural languages, PR2, Robot sensing systems, Semantics, Three-dimensional displays, complex commands, human-robot interaction, image sensors, input sentence, intelligent robots, natural language interfaces, object recognition, online test sentences, robot sensors, robot vision, semantic parse, sentence interpretation, spatial information, spatial prepositions, spatial queries, spatial relations grounding, spatial relationships, visual information, visual perception, visual percepts},
	pages = {1640--1647}
}

@inproceedings{tan_grounding_2014,
	title = {Grounding spatial relations in natural language by fuzzy representation for human-robot interaction},
	doi = {10.1109/FUZZ-IEEE.2014.6891797},
	abstract = {This paper addresses the issue of grounding spatial relations in natural language for human-robot interaction and robot control. The problem is approached by identifying two set of spatial relations, the image space-based and object-centered, and expressing them as fuzzy sets to capture the ambiguity inherent to the linguistic expressions for the relations. The sizes and shades of the scene objects have also been modeled as fuzzy sets for conditioning the spatial relations. To verify the validity of our approach and test its feasibility in a natural language-based interface, we have considered the typical scenarios of using the spatial relations in simple declarative and imperative sentences and designed simple grammars for parsing such sentences. Our experiment has shown that fuzzy spatial relation analysis provides a useful way for modeling the ambiguity or imprecision of the natural language in describing spatial relations and that it is possible to use the spatial relation models to support robot control and human-robot interaction in a natural language-based interface.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Fuzzy} {Systems} ({FUZZ}-{IEEE})},
	author = {Tan, J. and Ju, Z. and Liu, H.},
	month = jul,
	year = {2014},
	keywords = {Cognition, Grounding, Human-robot interaction, Natural languages, Pragmatics, Robots, Shape, ambiguity modeling, artificial intelligence, computational linguistics, declarative sentences, fuzzy representation, fuzzy set, fuzzy set theory, fuzzy sets, fuzzy spatial relation analysis, grammars, human-robot interaction, image space-based spatial relation, imperative sentences, imprecision modeling, linguistic expressions, natural language interfaces, natural language-based interface, object-centered spatial relation, robot control, robot vision, scene object shades, scene object sizes, sentence parsing, spatial relation conditioning, spatial relations},
	pages = {1743--1750}
}

@misc{noauthor_grounding_2019,
	title = {Grounding spatial relations for human-robot interaction - {IEEE} {Conference} {Publication}},
	url = {https://ieeexplore-ieee-org.ezp01.library.qut.edu.au/document/6696569},
	urldate = {2019-02-19},
	month = feb,
	year = {2019}
}

@inproceedings{dodge_parsing_2017,
	title = {Parsing floor plan images},
	doi = {10.23919/MVA.2017.7986875},
	abstract = {This paper introduces a method for analyzing floor plan images using wall segmentation, object detection, and optical character recognition. We introduce a challenging new real-estate floor plan dataset, R-FP, evaluate different wall segmentation methods, and propose fully convolutional networks (FCN) for this task. We explore architectures with different pixel-stride values and more compact ones with skipped pooling layers. An FCN-2s with a 2-pixel stride layer achieves state-of-the-art performance, obtaining a mean Intersection-over-Union score of 89.9\% on R-FP, and 94.4\% on the public CVC-FP data set. Using OCR and object detection, we estimate room sizes. Finally, we show applications in automatic 3D model building and interactive furniture fitting.},
	booktitle = {2017 {Fifteenth} {IAPR} {International} {Conference} on {Machine} {Vision} {Applications} ({MVA})},
	author = {Dodge, S. and Xu, J. and Stenger, B.},
	month = may,
	year = {2017},
	keywords = {2-pixel stride layer, Character recognition, Image segmentation, OCR, Object detection, Optical character recognition software, R-FP, Solid modeling, Three-dimensional displays, Training, architecture, automatic 3D model building, feedforward neural nets, floor plan image analysis, floor plan image parsing, fully convolutional networks, furniture, image segmentation, interactive furniture fitting, interactive systems, mean intersection-over-union score, object detection, optical character recognition, pixel-stride values, public CVC-FP data set, real estate data processing, real-estate floor plan dataset, room size estimation, skipped pooling layers, solid modelling, wall segmentation, walls},
	pages = {358--361}
}

@inproceedings{ziran_object_2018,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Object {Detection} in {Floor} {Plan} {Images}},
	isbn = {978-3-319-99978-4},
	abstract = {In this work we investigate the use of deep neural networks for object detection in floor plan images. Object detection is important for understanding floor plans and is a preliminary step for their conversion into other representations.In particular, we evaluate the use of object detection architectures, originally designed and trained to recognize objects in images, for recognizing furniture objects as well as doors and windows in floor plans. Even if the problem is somehow easier than the original one in the case of this research the datasets available are extremely small and therefore the training of deep architectures can be problematic. In addition to the use of object detection architectures for floor plan images, another contribution of this paper is the creation of two datasets that have been used for performing the experiments covering different types of floor plans with different peculiarities.},
	language = {en},
	booktitle = {Artificial {Neural} {Networks} in {Pattern} {Recognition}},
	publisher = {Springer International Publishing},
	author = {Ziran, Zahra and Marinai, Simone},
	editor = {Pancioni, Luca and Schwenker, Friedhelm and Trentin, Edmondo},
	year = {2018},
	keywords = {Convolutional neural networks, Floor plan analysis, Object detection, Transfer learning},
	pages = {383--394}
}

@article{pintore_3d_2018,
	title = {{3D} floor plan recovery from overlapping spherical images},
	volume = {4},
	issn = {2096-0662},
	url = {https://doi.org/10.1007/s41095-018-0125-9},
	doi = {10.1007/s41095-018-0125-9},
	abstract = {We present a novel approach to automatically recover, from a small set of partially overlapping spherical images, an indoor structure representation in terms of a 3D floor plan registered with a set of 3D environment maps. We introduce several improvements over previous approaches based on color and spatial reasoning exploiting Manhattan world priors. In particular, we introduce a new method for geometric context extraction based on a 3D facet representation, which combines color distribution analysis of individual images with sparse multi-view clues. We also introduce an efficient method to combine the facets from different viewpoints in a single consistent model, taking into the reliability of the facet information. The resulting capture and reconstruction pipeline automatically generates 3D multi-room environments in cases where most previous approaches fail, e.g., in the presence of hidden corners and large clutter, without the need for additional dense 3D data or tools. We demonstrate the effectiveness and performance of our approach on different real-world indoor scenes. Our test data is available to allow further studies and comparisons.},
	language = {en},
	number = {4},
	urldate = {2019-02-12},
	journal = {Computational Visual Media},
	author = {Pintore, Giovanni and Ganovelli, Fabio and Pintus, Ruggero and Scopigno, Roberto and Gobbetti, Enrico},
	month = dec,
	year = {2018},
	keywords = {360 degree photography, indoor reconstruction, multi-room environments, spherical panoramic cameras},
	pages = {367--383}
}

@misc{rosebrock_gentle_2018,
	title = {A gentle guide to deep learning object detection},
	url = {https://www.pyimagesearch.com/2018/05/14/a-gentle-guide-to-deep-learning-object-detection/},
	abstract = {Deep learning object detection can be challenging to understand, but in this tutorial I'll break it down and give you a strong deep learning object detection foundation.},
	language = {en-US},
	urldate = {2019-02-12},
	journal = {PyImageSearch},
	author = {Rosebrock, Adrian},
	month = may,
	year = {2018}
}

@misc{noauthor_models_2019,
	title = {Models},
	url = {https://aiyprojects.withgoogle.com/},
	abstract = {Machine learning is a technique for building software models that can make predictions based on patterns and relationships that have been discovered in data. Experiment with these models to see machine learning in action.},
	language = {en\_US},
	urldate = {2019-02-12},
	journal = {Models},
	month = feb,
	year = {2019}
}

@book{kevitt_integration_1995,
	title = {Integration of {Natural} {Language} and {Vision} {Processing}: {Computational} {Models} and {Systems}},
	isbn = {978-0-7923-3379-1},
	shorttitle = {Integration of {Natural} {Language} and {Vision} {Processing}},
	url = {https://www.springer.com/de/book/9780792333791},
	abstract = {Although there has been much progress in developing theories, models and systems in the areas of Natural Language Processing (NLP) and Vision Processing (VP) there has heretofore been little progress on integrating these subareas of Artificial Intelligence (AI). This book contains a set of edited papers addressing computational models and systems for the integration of NLP and VP. The papers focus on site descriptions such as that of the large Japanese \$500 million Real World Computing (RWC) project, on historical philosophical issues, on systems which have been built and which integrate the processing of visual scenes together with language about them, and on spatial relations which appear to be the key to integration. The U.S.A., Japan and the EU are well reflected, showing up the fact that integration is a truly international issue. There is no doubt that all of this will be necessary for the InformationSuperHighways of the future.},
	language = {en},
	urldate = {2019-02-07},
	publisher = {Springer Netherlands},
	editor = {Kevitt, Paul Mc},
	year = {1995}
}

@article{saffiotti_robots_2011,
	title = {Robots that change their world: {Inferring} {Goals} from {Semantic} {Knowledge}},
	shorttitle = {Robots that change their world},
	url = {https://www.academia.edu/27738972/Robots_that_change_their_world_Inferring_Goals_from_Semantic_Knowledge},
	abstract = {Robots that change their world: Inferring Goals from Semantic Knowledge},
	language = {en},
	urldate = {2019-02-07},
	author = {Saffiotti, Alessandro},
	year = {2011}
}

@incollection{nuallain_investigation_1995,
	address = {Dordrecht},
	title = {An {Investigation} into the {Common} {Semantics} of {Language} and {Vision}},
	isbn = {978-94-011-0273-5},
	url = {https://doi.org/10.1007/978-94-011-0273-5_2},
	abstract = {This paper describes a project currently being undertaken at the National Research Council. The project addresses itself to two much-discussed topics: • the relation between the semantics of language and vision • the notion of symbol-grounding. We discuss some of the parallels and differences between the linguistic and visual channels of perception, and then describe a computer system we are designing that exploits both. This system accepts verbal scene descriptions and re-constructs a three-dimensional display of the virtual model of the world that it builds up in the process of interpreting the input.},
	language = {en},
	urldate = {2019-02-07},
	booktitle = {Integration of {Natural} {Language} and {Vision} {Processing}: {Computational} {Models} and {Systems}},
	publisher = {Springer Netherlands},
	author = {Nualláin, Seán Ó and Smith, Arnold G.},
	editor = {Mc Kevitt, Paul},
	year = {1995},
	doi = {10.1007/978-94-011-0273-5_2},
	keywords = {graphics, grounding, natural language, vision, visualisation},
	pages = {21--30}
}

@article{liu_review_2017,
	title = {A {Review} of {Methodologies} for {Natural}-{Language}-{Facilitated} {Human}-{Robot} {Cooperation}},
	url = {http://arxiv.org/abs/1701.08756},
	abstract = {Natural-language-facilitated human-robot cooperation (NLC) refers to using natural language (NL) to facilitate interactive information sharing and task executions with a common goal constraint between robots and humans. Recently, NLC research has received increasing attention. Typical NLC scenarios include robotic daily assistance, robotic health caregiving, intelligent manufacturing, autonomous navigation, and robot social accompany. However, a thorough review, that can reveal latest methodologies to use NL to facilitate human-robot cooperation, is missing. In this review, a comprehensive summary about methodologies for NLC is presented. NLC research includes three main research focuses: NL instruction understanding, NL-based execution plan generation, and knowledge-world mapping. In-depth analyses on theoretical methods, applications, and model advantages and disadvantages are made. Based on our paper review and perspective, potential research directions of NLC are summarized.},
	urldate = {2019-02-05},
	journal = {arXiv:1701.08756 [cs]},
	author = {Liu, Rui and Zhang, Xiaoli},
	month = jan,
	year = {2017},
	note = {arXiv: 1701.08756},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, Computer Science - Robotics}
}

@inproceedings{fraundorfer_topological_2007,
	title = {Topological mapping, localization and navigation using image collections},
	doi = {10.1109/IROS.2007.4399123},
	abstract = {In this paper we present a highly scalable vision-based localization and mapping method using image collections. A topological world representation is created online during robot exploration by adding images to a database and maintaining a link graph. An efficient image matching scheme allows real-time mapping and global localization. The compact image representation allows us to create image collections containing millions of images, which enables mapping of very large environments. A path planning method using graph search is proposed and local geometric information is used to navigate in the topological map. Experiments show the good performance of the image matching for global localization and demonstrate path planning and navigation.},
	booktitle = {2007 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Fraundorfer, F. and Engels, C. and Nister, D.},
	month = oct,
	year = {2007},
	keywords = {Cameras, Image databases, Image matching, Image representation, Legged locomotion, Navigation, Path planning, Robot vision systems, Spatial databases, USA Councils, graph search, image collection, image database, image matching, image matching scheme, image representation, mobile robots, navigation, path planning, path planning method, real-time mapping, real-time systems, search problems, topological mapping, topological world representation, vision-based localization, visual databases},
	pages = {3872--3877}
}

@misc{noauthor_pdf_2019,
	title = {({PDF}) {Linking} {ImageNet} {WordNet} {Synsets} with {Wikidata}},
	url = {https://www.researchgate.net/publication/323723121_Linking_ImageNet_WordNet_Synsets_with_Wikidata},
	abstract = {PDF {\textbar} The linkage of ImageNet WordNet synsets to Wikidata items will leverage deep learning algorithm with access to a rich multilingual knowledge graph. Here I will describe our on-going efforts in linking the two resources and issues faced in matching the Wikidata and WordNet...},
	language = {en},
	urldate = {2019-02-05},
	journal = {ResearchGate},
	month = feb,
	year = {2019}
}

@misc{noauthor_pdf_2019-1,
	title = {({PDF}) {Visualizing} {WordNet} structure},
	url = {https://www.researchgate.net/publication/228729013_Visualizing_WordNet_structure},
	abstract = {PDF {\textbar} Representations in WordNet are not on the level of individual words or word forms, but on the level of word meanings (lexemes). A word meaning, in turn, is characterized by simply listing the word forms that can be used to express it in a synonym set (synset). As a result,...},
	language = {en},
	urldate = {2019-02-05},
	journal = {ResearchGate},
	month = feb,
	year = {2019}
}

@misc{noauthor_visualizing_2019,
	title = {Visualizing {WordNet} relationships as graphs {\textbar} {Random} {Hacks}},
	url = {http://www.randomhacks.net/2009/12/29/visualizing-wordnet-relationships-as-graphs/},
	urldate = {2019-02-05},
	month = feb,
	year = {2019}
}

@inproceedings{duvallet_imitation_2013,
	title = {Imitation learning for natural language direction following through unknown environments},
	doi = {10.1109/ICRA.2013.6630702},
	abstract = {The use of spoken instructions in human-robot teams holds the promise of enabling untrained users to effectively control complex robotic systems in a natural and intuitive way. Providing robots with the capability to understand natural language directions would enable effortless coordination in human robot teams that operate in non-specialized unknown environments. However, natural language direction following through unknown environments requires understanding the meaning of language, using a partial semantic world model to generate actions in the world, and reasoning about the environment and landmarks that have not yet been detected. We address the problem of robots following natural language directions through complex unknown environments. By exploiting the structure of spatial language, we can frame direction following as a problem of sequential decision making under uncertainty. We learn a policy which predicts a sequence of actions that follow the directions by exploring the environment and discovering landmarks, backtracking when necessary, and explicitly declaring when it has reached the destination. We use imitation learning to train the policy, using demonstrations of people following directions. By training explicitly in unknown environments, we can generalize to situations that have not been encountered previously.},
	booktitle = {2013 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Duvallet, F. and Kollar, T. and Stentz, A.},
	month = may,
	year = {2013},
	keywords = {Elevators, Equations, Natural languages, Robot kinematics, Semantics, Training, action generation, backtracking, effective complex robotic system control, effortless coordination, human robot teams, human-robot interaction, human-robot teams, imitation learning, inference mechanisms, landmark discovery, language meaning understanding, learning (artificial intelligence), multi-robot systems, natural language direction following, natural language directions, natural language processing, nonspecialized unknown environment, partial semantic world model, policy learning, reasoning, sequential decision making under uncertainty, spatial language, spoken instruction},
	pages = {1047--1053}
}

@incollection{pauls_preclinical_2017,
	title = {Preclinical {Evaluation}},
	isbn = {978-0-12-810492-7},
	url = {https://books.telegraph.co.uk/Product/Shaun-Gregory/Mechanical-Circulatory-and-Respiratory-Support/21430261},
	language = {en-gb},
	urldate = {2018-09-15},
	booktitle = {Mechanical {Circulatory} and {Respiratory} {Support}},
	publisher = {Academic Press},
	author = {Pauls, J P and Bartnikowski, N and Jansen, S and Einly, L and Dasse, K},
	collaborator = {Gregory, S. and Stevens, M and Fraser, J},
	month = sep,
	year = {2017},
	pages = {407--438}
}

@incollection{smith_hydraulic_2017,
	title = {Hydraulic {Design}},
	isbn = {978-0-12-810492-7},
	url = {https://books.telegraph.co.uk/Product/Shaun-Gregory/Mechanical-Circulatory-and-Respiratory-Support/21430261},
	language = {en-gb},
	urldate = {2018-09-15},
	booktitle = {Mechanical {Circulatory} and {Respiratory} {Support}},
	publisher = {Academic Press},
	author = {Smith, A and Wang, Y and Groß-Hardt, S and Graefe, R},
	collaborator = {Gregory, S. and Stevens, M and Fraser, J},
	month = sep,
	year = {2017},
	pages = {301--334}
}

@incollection{gregory_biventricular_2017,
	title = {Biventricular {Assist} {Devices}},
	isbn = {978-0-12-810492-7},
	url = {https://books.telegraph.co.uk/Product/Shaun-Gregory/Mechanical-Circulatory-and-Respiratory-Support/21430261},
	language = {en-gb},
	urldate = {2018-09-15},
	booktitle = {Mechanical {Circulatory} and {Respiratory} {Support}},
	publisher = {Academic Press},
	author = {Gregory, S. and Boon Chiang, Ng and Nadeem, K},
	collaborator = {Gregory, S. and Stevens, M and Fraser, J},
	month = sep,
	year = {2017},
	pages = {187--214}
}

@article{sahle_prevalence_2016,
	title = {Prevalence of heart failure in {Australia}: a systematic review},
	volume = {16},
	issn = {1471-2261},
	shorttitle = {Prevalence of heart failure in {Australia}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4744379/},
	doi = {10.1186/s12872-016-0208-4},
	abstract = {Background
In the absence of a systematic collection of data pertaining to heart failure, summarizing the data available from individual studies provides an opportunity to estimate the burden of heart failure. The present study systematically reviewed the literature to estimate the incidence and prevalence rates of heart failure in Australia.

Methods
Studies reporting on prevalence or incidence of heart failure published between 1990 and 2015 were identified through a systematic search of Embase, PubMed, Ovid Medline, MeSH, Scopus and websites of the Australian Institute of Health, and Welfare and Australian Bureau of Statistics.

Results
The search yielded a total of 4978 records, of which thirteen met the inclusion criteria. There were no studies reporting on the incidence of heart failure. The prevalence of heart failure in the Australian population ranged between 1.0 \% and 2.0 \%, with a significant proportion of cases being previously undiagnosed. The burden of heart failure was higher among Indigenous than non-Indigenous Australians (age-standardized prevalence rate ratio of 1.7). Heart failure was prevalent in women than men, and in rural and remote regions than in the metropolitan and capital territories.

Conclusion
This systematic review highlights the limited available data on the epidemiology of heart failure in Australia. Population level studies, using standardized approaches, are needed in order to precisely describe the burden of HF in the population.

Electronic supplementary material
The online version of this article (doi:10.1186/s12872-016-0208-4) contains supplementary material, which is available to authorized users.},
	urldate = {2018-09-21},
	journal = {BMC Cardiovascular Disorders},
	author = {Sahle, Berhe W. and Owen, Alice J. and Mutowo, Mutsa P. and Krum, Henry and Reid, Christopher M.},
	month = feb,
	year = {2016},
	pmid = {26852410},
	pmcid = {PMC4744379}
}

@article{takeda_outcome_2014,
	title = {Outcome of unplanned right ventricular assist device support for severe right heart failure after implantable left ventricular assist device insertion},
	volume = {33},
	issn = {1557-3117},
	doi = {10.1016/j.healun.2013.06.025},
	abstract = {BACKGROUND: The use of a right ventricular assist device (RVAD) becomes necessary for severe right ventricular (RV) failure after left ventricular assist device (LVAD) insertion. Although temporary support could lead to successful RVAD weaning in certain patients, the data remain scarce.
METHODS: We retrospectively reviewed 398 patients who underwent implantable LVAD insertion between January 2000 and December 2012. Of these patients, 44 (11\%) required unplanned RVAD support due to severe RV failure after LVAD insertion. For comparison, 37 patients who underwent planned biventricular assist device (BiVAD) insertion were identified during the same study period. We analyzed the early and late outcomes in these patients.
RESULTS: The mean duration of RVAD support was 21 ± 23 days. Of the 44 patients, 21 (49\%) were weaned from the RVAD (weaning group), whereas 23 (51\%) required continued biventricular support (failure group). The failure group had ongoing end-organ dysfunction after RVAD insertion. Hospital mortality was significantly lower in the weaning group (24\%) and in the planned BiVAD group (30\%) as compared to the failure group (74\%, p = 0.0009). The 6-month actuarial survival rate was 75\% in the weaning group, 62\% in the planned BiVAD group and 13\% in the failure group (p {\textless} 0.0001). Successful bridge to transplant was achieved in 14 patients (67\%) in the weaning group as compared with 8 patients (35\%) in the failure group (p = 0.03). On multivariate logistic regression analyses, pre-operative white blood cell (odds ratio [OR] 1.3, 95\% confidence interval [CI] 1.04 to 1.50, p = 0.016) and creatinine (OR 0.26, 95\% CI 0.079 to 0.88, p = 0.03) levels were significant predictors for RVAD removal.
CONCLUSIONS: Among patients who developed acute RV failure after LVAD insertion, only half could be weaned from the temporary RVAD support. An alternative strategy is necessary in patients who require continuous RVAD support.},
	language = {eng},
	number = {2},
	journal = {The Journal of Heart and Lung Transplantation: The Official Publication of the International Society for Heart Transplantation},
	author = {Takeda, Koji and Naka, Yoshifumi and Yang, Jonathan A. and Uriel, Nir and Colombo, Paolo C. and Jorde, Ulrich P. and Takayama, Hiroo},
	month = feb,
	year = {2014},
	pmid = {23932442},
	keywords = {Adult, Female, Heart Failure, Heart-Assist Devices, Humans, LVAD, Logistic Models, Male, Middle Aged, RVAD, Retrospective Studies, Severity of Illness Index, Survival Rate, Treatment Outcome, Ventricular Dysfunction, Left, Ventricular Dysfunction, Right, heart failure, heart transplant, right ventricle, ventricular assist device},
	pages = {141--148}
}

@article{matthews_right_2008,
	title = {The {Right} {Ventricular} {Failure} {Risk} {Score}: {A} {Pre}-{Operative} {Tool} for {Assessing} the {Risk} of {Right} {Ventricular} {Failure} in {Left} {Ventricular} {Assist} {Device} {Candidates}},
	volume = {51},
	issn = {0735-1097},
	shorttitle = {The {Right} {Ventricular} {Failure} {Risk} {Score}},
	url = {http://www.sciencedirect.com/science/article/pii/S0735109708010280},
	doi = {10.1016/j.jacc.2008.03.009},
	abstract = {Objectives
This study sought to develop a model that estimates the post-operative risk of right ventricular (RV) failure in left ventricular assist device (LVAD) candidates.
Background
Right ventricular failure after LVAD surgery is associated with increased morbidity and mortality, but identifying LVAD candidates at risk for RV failure remains difficult.
Methods
A prospectively collected LVAD database was evaluated for pre-operative clinical, laboratory, echocardiographic, and hemodynamic predictors of RV failure. Right ventricular failure was defined as the need for post-operative intravenous inotrope support for {\textgreater}14 days, inhaled nitric oxide for ≥48 h, right-sided circulatory support, or hospital discharge on an inotrope. An RV failure risk score (RVFRS) was created from multivariable logistic regression model coefficients, and a receiver-operating characteristic curve of the score was generated.
Results
Of 197 LVADs implanted, 68 (35\%) were complicated by post-operative RV failure. A vasopressor requirement (4 points), aspartate aminotransferase ≥80 IU/l (2 points), bilirubin ≥2.0 mg/dl (2.5 points), and creatinine ≥2.3 mg/dl (3 points) were independent predictors of RV failure. The odds ratio for RV failure for patients with an RVFRS ≤3.0, 4.0 to 5.0, and ≥5.5 were 0.49 (95\% confidence interval [CI] 0.37 to 0.64), 2.8 (95\% CI 1.4 to 5.9), and 7.6 (95\% CI 3.4 to 17.1), respectively, and 180-day survivals were 90 ± 3\%, 80 ± 8\%, and 66 ± 9\%, respectively (log rank for linear trend p = 0.0045). The area under the receiver-operating characteristic curve for the RVFRS (0.73 ± 0.04) was superior to that of other commonly used predictors of RV failure (all p {\textless} 0.05).
Conclusions
The RVFRS, composed of routinely collected, noninvasive pre-operative clinical data, effectively stratifies the risk of RV failure and death after LVAD implantation.},
	number = {22},
	urldate = {2018-09-20},
	journal = {Journal of the American College of Cardiology},
	author = {Matthews, Jennifer Cowger and Koelling, Todd M. and Pagani, Francis D. and Aaronson, Keith D.},
	month = jun,
	year = {2008},
	pages = {2163--2172}
}

@misc{noauthor_right_2018,
	title = {The {Right} {Ventricular} {Failure} {Risk} {Score}: {A} {Pre}-{Operative} {Tool} for {Assessing} the {Risk} of {Right} {Ventricular} {Failure} in {Left} {Ventricular} {Assist} {Device} {Candidates} - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S0735109708010280},
	urldate = {2018-09-20},
	month = sep,
	year = {2018}
}

@article{kormos_right_2010,
	title = {Right ventricular failure in patients with the {HeartMate} {II} continuous-flow left ventricular assist device: {Incidence}, risk factors, and effect on outcomes},
	volume = {139},
	issn = {0022-5223},
	shorttitle = {Right ventricular failure in patients with the {HeartMate} {II} continuous-flow left ventricular assist device},
	url = {http://www.sciencedirect.com/science/article/pii/S0022522309014755},
	doi = {10.1016/j.jtcvs.2009.11.020},
	abstract = {Objective
The aim of this study was to evaluate the incidence, risk factors, and effect on outcomes of right ventricular failure in a large population of patients implanted with continuous-flow left ventricular assist devices.
Methods
Patients (n = 484) enrolled in the HeartMate II left ventricular assist device (Thoratec, Pleasanton, Calif) bridge-to-transplantation clinical trial were examined for the occurrence of right ventricular failure. Right ventricular failure was defined as requiring a right ventricular assist device, 14 or more days of inotropic support after implantation, and/or inotropic support starting more than 14 days after implantation. Demographics, along with clinical, laboratory, and hemodynamic data, were compared between patients with and without right ventricular failure, and risk factors were identified.
Results
Overall, 30 (6\%) patients receiving left ventricular assist devices required a right ventricular assist device, 35 (7\%) required extended inotropes, and 33 (7\%) required late inotropes. A significantly greater percentage of patients without right ventricular failure survived to transplantation, recovery, or ongoing device support at 180 days compared with patients with right ventricular failure (89\% vs 71\%, P {\textless} .001). Multivariate analysis revealed that a central venous pressure/pulmonary capillary wedge pressure ratio of greater than 0.63 (odds ratio, 2.3; 95\% confidence interval, 1.2–4.3; P = .009), need for preoperative ventilator support (odds ratio, 5.5; 95\% confidence interval, 2.3–13.2; P {\textless} .001), and blood urea nitrogen level of greater than 39 mg/dL (odds ratio, 2.1; 95\% confidence interval, 1.1–4.1; P = .02) were independent predictors of right ventricular failure after left ventricular assist device implantation.
Conclusions
The incidence of right ventricular failure in patients with a HeartMate II ventricular assist device is comparable or less than that of patients with pulsatile-flow devices. Its occurrence is associated with worse outcomes than seen in patients without right ventricular failure. Patients at risk for right ventricular failure might benefit from preoperative optimization of right heart function or planned biventricular support.},
	number = {5},
	urldate = {2018-09-20},
	journal = {The Journal of Thoracic and Cardiovascular Surgery},
	author = {Kormos, Robert L. and Teuteberg, Jeffrey J. and Pagani, Francis D. and Russell, Stuart D. and John, Ranjit and Miller, Leslie W. and Massey, Todd and Milano, Carmelo A. and Moazami, Nader and Sundareswaran, Kartik S. and Farrar, David J.},
	month = may,
	year = {2010},
	pages = {1316--1324}
}

@article{santambrogio_right_2006,
	title = {Right ventricular failure after left ventricular assist device insertion: preoperative risk factors},
	volume = {5},
	issn = {1569-9293},
	shorttitle = {Right ventricular failure after left ventricular assist device insertion},
	url = {https://academic.oup.com/icvts/article/5/4/379/672314},
	doi = {10.1510/icvts.2006.128322},
	abstract = {Abstract.  Right ventricular failure after left ventricular assist device placement is the major concern on weaning from cardiopulmonary bypass and it is one of},
	language = {en},
	number = {4},
	urldate = {2018-09-20},
	journal = {Interactive CardioVascular and Thoracic Surgery},
	author = {Santambrogio, Luisa and Bianchi, Tiziana and Fuardo, Marinella and Gazzoli, Fabrizio and Veronesi, Roberto and Braschi, Antonio and Maurelli, Marco},
	month = aug,
	year = {2006},
	pages = {379--382}
}

@article{shah_multicenter_2018,
	title = {Multicenter experience with durable biventricular assist devices},
	volume = {37},
	issn = {1053-2498, 1557-3117},
	url = {https://www.jhltonline.org/article/S1053-2498(18)31473-6/fulltext},
	doi = {10.1016/j.healun.2018.05.001},
	abstract = {BACKGROUND
Severe right ventricular failure necessitating a right ventricular assist device (RVAD) complicates 6\% to 11\% of left ventricular assist device (LVAD) implants. Patient outcomes for those receiving durable continuous-flow VADs in a biventricular configuration (i.e., BiVAD) have been reported in limited case series.
METHODS
Data from United States centers with ≥ 6 BiVAD implants were collected. Characteristics and outcomes of patients receiving contemporaneous (i.e., same surgery) vs staged implantation of the HVAD as a BiVAD were compared.
RESULTS
From 2011 to 2017, 46 patients received durable BiVADs and had the following characteristics: median age, 46 years (interquartile range [IQR], 19–67 years), non-ischemic cardiomyopathy (80\%), bridge to transplant (83\%), Interagency Registry for Mechanically Assisted Circulatory Support Profile 1 or 2 (92\%), use of temporary circulatory support (37\%), right atrial pressure 19 mm Hg (IQR, 14–23 mm Hg), and cardiac index of 1.6 liters/min/m2 (IQR, 1.2–2.1 liters/min/m2). Operative mortality was 33\%. Equal numbers of patients received a right atrial or right ventricular implant. Contemporaneous BiVAD implantation occurred in 31 patients (67\%), and compared with 15 patients (33\%) with staged implants, these patients had a shorter intensive care unit length of stay of 12 days (IQR, 7–23 days) vs 42 days (IQR, 28–48 days, p = 0.035) and were more likely to be discharged from the hospital on BiVAD support (61\% vs 27\%, p = 0.04). RVAD thrombosis developed in 17 patients (37\%). Patients with contemporaneous BiVAD implants had a 1-year survival of 74\% compared with 40\% in staged BiVAD patients (p = 0.11).
CONCLUSIONS
Patients receiving durable BiVADs represent a critically ill patient population with severe biventricular failure who have high operative mortality and RVAD thrombosis rates. The 1-year survival for patients receiving contemporaneous BiVADs in experienced centers mirrors other contemporary durable biventricular support strategies.},
	language = {English},
	number = {9},
	urldate = {2018-09-20},
	journal = {The Journal of Heart and Lung Transplantation},
	author = {Shah, Palak and Ha, Richard and Singh, Ramesh and Cotts, William and Adler, Eric and Kiernan, Michael and Brambatti, Michela and Meehan, Karen and Phillips, Sheila and Kidambi, Sumanth and Macaluso, Gregory P. and Banerjee, Dipanjan and Mooney, Dierdre and Pham, Duc and Pretorius, Victor D.},
	month = sep,
	year = {2018},
	pmid = {30173824},
	keywords = {biventricular assist device, cardiogenic shock, heart failure, right heart failure, ventricular assist device},
	pages = {1093--1101}
}

@article{estep_overview_2015,
	title = {Overview of the {Current} {Benefits} and {Risks} of {Continuous}-{Flow} {Left} {Ventricular} {Assist} {Devices}},
	volume = {11},
	issn = {1947-6094},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4362060/},
	doi = {10.14797/mdcj-11-1-2},
	number = {1},
	urldate = {2018-09-16},
	journal = {Methodist DeBakey Cardiovascular Journal},
	author = {Estep, Jerry D. and Loebe, Matthias},
	year = {2015},
	pmid = {25793021},
	pmcid = {PMC4362060},
	pages = {2--3}
}

@article{smith_preliminary_2018,
	title = {Preliminary design of the internal geometry in a minimally invasive left ventricular assist device under pulsatile-flow conditions},
	volume = {41},
	issn = {0391-3988},
	url = {https://doi.org/10.1177/0391398817752291},
	doi = {10.1177/0391398817752291},
	abstract = {Purpose:A minimally invasive, partial-assist, intra-atrial blood pump has been proposed, which would unload the left ventricle with a flow path from the left atrium to the arterial system. Flow modulation is a common strategy for ensuring washout in the pump, but it can increase power consumption because it is typically achieved through motor-speed variation. However, if a pump?s performance curve had the proper gradient, flow modulation could be realized passively. To achieve this goal, we propose a pump performance operating curve as an alternative to the more standard operating point.Methods and results:Mean-line theory was employed to generate an initial set of geometries that were then tested on a hydraulic test rig at {\textasciitilde}20,000?r/min. Experimental results show that the intra-atrial blood pump performed below the operating region; however, it was determined that smaller hub diameter and longer chord length bring the performance of the intra-atrial blood pump device closer to the operating curve.Conclusion:We found that it is possible to shape the pump performance curve for specifically targeted gradients over the operating region through geometric variations inside the pump.},
	language = {en},
	number = {3},
	urldate = {2018-09-16},
	journal = {The International Journal of Artificial Organs},
	author = {Smith, P Alex and Wang, Yaxin and Metcalfe, Ralph W and Sampaio, Luiz C and Timms, Daniel L and Cohn, William E and Frazier, OH},
	month = mar,
	year = {2018},
	pages = {144--151}
}

@misc{foundation_heart_2018,
	title = {Heart disease in {Australia}},
	url = {https://www.heartfoundation.org.au/about-us/what-we-do/heart-disease-in-australia},
	abstract = {The Heart Foundation saves lives and improves health through funding world-class cardiovascular research, guidelines for health professionals, informing the},
	language = {en},
	urldate = {2018-09-16},
	journal = {The Heart Foundation},
	author = {Foundation, The Heart},
	month = sep,
	year = {2018}
}

@misc{noauthor_heart_2018,
	title = {Heart disease in {Australia} {\textbar} {The} {Heart} {Foundation}},
	url = {https://www.heartfoundation.org.au/about-us/what-we-do/heart-disease-in-australia},
	urldate = {2018-09-16},
	month = sep,
	year = {2018}
}

@article{kirklin_eighth_2017,
	title = {Eighth annual {INTERMACS} report: {Special} focus on framing the impact of adverse events},
	volume = {36},
	issn = {1557-3117},
	shorttitle = {Eighth annual {INTERMACS} report},
	doi = {10.1016/j.healun.2017.07.005},
	abstract = {BACKGROUND: The Interagency Registry for Mechanically Assisted Circulatory Support (INTERMACS) database now includes {\textgreater}20,000 patients from {\textgreater}180 hospitals.
METHODS: The eighth annual report of INTERMACS updates the first decade of patient enrollment.
RESULTS: In the current era, {\textgreater}95\% of implants are continuous flow devices. Overall survival continues to remain {\textgreater}80\% at 1 year and 70\% at 2 years. Review of major adverse events shows minimal advantage for patients with ambulatory heart failure pre-implant. Stroke, major infection, and continued inotrope requirement during the first 3 months have a major effect on subsequent survival.
CONCLUSIONS: Greater application of durable devices to patients with ambulatory heart failure will mandate more effective neutralization or prevention of major adverse events.},
	language = {eng},
	number = {10},
	journal = {The Journal of Heart and Lung Transplantation: The Official Publication of the International Society for Heart Transplantation},
	author = {Kirklin, James K. and Pagani, Francis D. and Kormos, Robert L. and Stevenson, Lynne W. and Blume, Elizabeth D. and Myers, Susan L. and Miller, Marissa A. and Baldwin, J. Timothy and Young, James B. and Naftel, David C.},
	month = oct,
	year = {2017},
	pmid = {28942782},
	keywords = {Databases, Factual, Global Health, Heart Failure, Heart-Assist Devices, Humans, INTERMACS, Morbidity, Registries, Survival Rate, advanced heart failure, destination therapy, mechanical support, ventricular assist device},
	pages = {1080--1086}
}

@book{gregory_mechanical_2017,
	title = {Mechanical {Circulatory} and {Respiratory} {Support}},
	isbn = {978-0-12-810492-7},
	url = {https://books.telegraph.co.uk/Product/Shaun-Gregory/Mechanical-Circulatory-and-Respiratory-Support/21430261},
	abstract = {s},
	language = {en-gb},
	urldate = {2018-09-15},
	publisher = {Academic Press},
	author = {Gregory, S. and Stevens, M and Fraser, J},
	month = sep,
	year = {2017}
}

@phdthesis{matschkur_biomechanic-kinemetric_2002,
	address = {Munich},
	type = {{PhD} {Dissertation}},
	title = {Biomechanic-kinemetric motion analysis and elektromyographical case studies of the muscle activity in surfing},
	url = {https://mediatum.ub.tum.de/603155},
	abstract = {This Dissertation is about biomechanic-kinemetric motion analysis of selected turns as well as elektromyographical case studies of the muscle activity of the bodies lower extremity while surfing. The results of both surveys lead to conclusions about a particular training in surfing. A historical and scientific overview of surfing introduces the topic and calls the readers attention to the specific starting-situation due to the social and cultural significance of surfing for the surfers. The creation and acceptance of a training plan in surfing is only successful if the coach is aware of that. The focus of this dissertation lies on the sports-scientific recording and discussion of surfing in principle, with threedimensional and elektromyographical parameters which have not been carried out before},
	language = {German},
	urldate = {2018-03-15},
	school = {TU Munich},
	author = {Matschkur, T.},
	month = may,
	year = {2002}
}

@misc{noauthor_surf_2018,
	title = {Surf {Snowdonia} {\textbar} {What} {Is} {The} {Wave} {Garden}},
	url = {https://www.surfsnowdonia.com/what-is-the-wave-garden/},
	abstract = {Wavegarden, industry leader in the design and manufacture of wave generation systems, has built a full-sized demo center in Northern Spain. This first of its},
	language = {en-GB},
	urldate = {2018-03-15},
	month = mar,
	year = {2018}
}

@misc{noauthor_wavegarden_2018,
	title = {Wavegarden {\textbar} {Wavegarden} {Cove}®},
	url = {http://wavegarden.com/wavegarden-cove/},
	language = {en-US},
	urldate = {2018-03-15},
	month = mar,
	year = {2018}
}

@inproceedings{groh_wearable_2016,
	title = {Wearable trick classification in freestyle snowboarding},
	doi = {10.1109/BSN.2016.7516238},
	abstract = {Digital motion analysis in freestyle snowboarding requires a stable trick detection and accurate classification. Freestyle snowboarding contains several trick categories that all have to be recognized for an application in training sessions or competitions. While previous work already addressed the classification of specific tricks or turns, there is no known method that contains a full pipeline for detection and classification of tricks from multiple categories. In this paper, we suggest a classification pipeline containing the detection, categorization and classification of tricks of two major freestyle trick categories. We evaluated our algorithm based on data from two different acquisitions with a total number of eleven athletes and 275 trick events. Tricks of both categories were categorized with recall results of 96.6\% and 97.4\%. The classification of the tricks was evaluated to an accuracy of 90.3 \% for the first and 93.3\% for the second category.},
	booktitle = {2016 {IEEE} 13th {International} {Conference} on {Wearable} and {Implantable} {Body} {Sensor} {Networks} ({BSN})},
	author = {Groh, B. H. and Fleckenstein, M. and Eskofier, B. M.},
	month = jun,
	year = {2016},
	keywords = {Accelerometers, Calibration, Event detection, Feature extraction, Gyroscopes, Magnetometers, Pattern recognition, classification pipeline, digital motion analysis, freestyle snowboarding, image motion analysis, wearable trick classification},
	pages = {89--93}
}

@patent{lokshin_distributed_2015,
	title = {Distributed systems and methods to measure and process sport motions},
	url = {https://patents.google.com/patent/US9060682B2/en},
	abstract = {A distributed, multi-stage, intelligent system is configured to determine user action performance characteristics parameters in action sports. Ruggedness, complexity, and cost are unevenly distributed among components across the stages for improved overall performance and reduced cost. The system includes stage-one, wearable devices configured to use sensors to collect initial data and transfer the initial data to stage-two devices which may temporally store the initial data and/or perform further data processing to generate intermediate data for communication to one or more stage-three devices configured for long term data storage, further processing and presentation.},
	nationality = {US},
	language = {en},
	assignee = {ALPINEREPLAY Inc},
	urldate = {2018-03-15},
	author = {Lokshin, David J.},
	month = jun,
	year = {2015},
	keywords = {data, device, devices, sensor, stage}
}

@patent{lokshin_method_2013,
	title = {Method and apparatus for determining sportsman jumps using fuzzy logic},
	url = {https://patents.google.com/patent/WO2013191727A1/zh-cn},
	nationality = {WO},
	language = {en},
	assignee = {Alpine Replay, Inc.},
	urldate = {2018-03-15},
	author = {Lokshin, Anatole M. and Kuzkin, Vitaly},
	month = dec,
	year = {2013},
	keywords = {data, jump, membership, set, sportsman}
}

@misc{baird_like_2016,
	title = {Like it or not, the {Brazilian} {Storm} {Has} {Taken} {Over} {Pro} {Surfing}},
	url = {https://sports.vice.com/en_us/article/bmqxkd/like-it-or-not-the-brazilian-storm-has-taken-over-pro-surfing},
	abstract = {Once considered fringe competitors, the new crop of Brazilian surfers is now poised to own the WSL. And not everyone is psyched about it.},
	language = {en},
	urldate = {2018-03-15},
	journal = {Sports},
	author = {Baird, Saxon},
	month = mar,
	year = {2016}
}

@misc{noauthor_surfing_2018,
	title = {Surfing {Market} {Trends}},
	url = {http://www.strategyr.com/MarketResearch/infographTemplate.asp?code=MCP-6536},
	urldate = {2018-03-15},
	month = mar,
	year = {2018}
}

@misc{noauthor_socioeconomic_2018,
	title = {A {Socioeconomic} \& {Recreational} {Profile} of {Surfers} in the {U}.{S}.},
	url = {https://www.surfrider.org/coastal-blog/entry/a-socioeconomic-and-recreational-profile-of-surfers-in-the-united-states},
	abstract = {The Surfrider Foundation, with support from Surfing Magazine, created the Surf-First Surfer Survey to collect a national dataset on the recreational, demographic and economic characteristics of surfers.},
	language = {en},
	urldate = {2018-03-15},
	journal = {Surfrider Foundation},
	month = mar,
	year = {2018}
}

@article{groh_classification_2017,
	title = {Classification and visualization of skateboard tricks using wearable sensors},
	volume = {40},
	issn = {1574-1192},
	url = {http://www.sciencedirect.com/science/article/pii/S1574119217302833},
	doi = {10.1016/j.pmcj.2017.05.007},
	abstract = {The application of wearables and customized signal processing methods offers new opportunities for motion analysis and visualization in skateboarding. In this work, we propose an automatic trick analysis and visualization application based on inertial–magnetic data. Skateboard tricks are detected and classified in real-time and visualized by means of an animated 3D-graphic. We achieved a trick detection recall of 96.4\%, a classification accuracy of 89.1\% (considering correctly performed tricks) and an error of the board orientation visualization of 2.2° ± 1.9°. The system is extendable in its application and can be incorporated as support for skateboard training and competitions.},
	urldate = {2018-03-15},
	journal = {Pervasive and Mobile Computing},
	author = {Groh, Benjamin H. and Fleckenstein, Martin and Kautz, Thomas and Eskofier, Bjoern M.},
	month = sep,
	year = {2017},
	keywords = {Board sports, Classification, Visualization, Wearable computing},
	pages = {42--55}
}

@article{groh_wearable_2016-1,
	title = {Wearable {Real}-{Time} {Skateboard} {Trick} {Visualization} and {Its} {Community} {Perception}},
	volume = {36},
	issn = {0272-1716},
	doi = {10.1109/MCG.2016.95},
	abstract = {Motion visualization is an attractive way to provide support for a range of recreational and competitive sports. In skateboarding, sensor technology in particular can help visualization systems capture the motion of athletes to provide relevant information to athletes, judges, and spectators. This article describes the authors' proposed application of a 9D inertial-magnetic measurement unit (IMMU) based real-time trick classification and visualization system. It also reports on a survey they conducted with skateboarders that asked about the usefulness, acceptance, and future ideas of such a system.},
	number = {5},
	journal = {IEEE Computer Graphics and Applications},
	author = {Groh, B. H. and Flaschka, J. and Wirth, M. and Kautz, T. and Fleckenstein, M. and Eskofier, B. M.},
	month = sep,
	year = {2016},
	keywords = {Computer graphics, IMMU, Motion control, Pattern recognition, Real-time systems, Sensors, Visualization, Wearable computing, athlete motion, community perception, competitive sport, computer graphics, computer graphics applications, data visualisation, inertial magnetic measurement unit, motion visualization, pattern classification, pattern recognition algorithms, real time trick classification, real-time systems, recreational sport, sensor technology, sensors, sport, sports data visualization, visualization system, visualization systems},
	pages = {12--18}
}

@misc{groh_imu-based_2015,
	address = {Sydney, Australia},
	title = {{IMU}-based {Trick} {Classification} in {Skateboarding}},
	language = {English},
	urldate = {2018-03-15},
	author = {Groh, B.},
	collaborator = {Schuldhaus, D. and Kautz, T. and Eskofier, B.},
	month = oct,
	year = {2015}
}

@incollection{harding_classification_2008,
	title = {Classification of {Aerial} {Acrobatics} in {Elite} {Half}-{Pipe} {Snowboarding} {Using} {Body} {Mounted} {Inertial} {Sensors} ({P237})},
	isbn = {978-2-287-09412-5 978-2-287-09413-2},
	url = {https://link.springer.com/chapter/10.1007/978-2-287-09413-2_55},
	abstract = {We have previously presented data indicating that the two most important objective performance variables in elite half-pipe snowboarding competition are air-time and degree of rotation. Furthermore, we have documented that air-time can be accurately quantified by signal processing of tri-axial accelerometer data obtained from body mounted inertial sensors. This paper adds to our initial findings by describing how body mounted inertial sensors (specifically tri-axial rate gyroscopes) and basic signal processing can be used to automatically classify aerial acrobatic manoeuvres into four rotational groups (180, 360, 540 or 720 degree rotations). Classification of aerial acrobatics is achieved using integration by summation. Angular velocity (ω i, j, k ) quantified by tri-axial rate gyroscopes was integrated over time (t = 0.01s) to provide discrete angular displacements (θ i, j, k ). Absolute angular displacements for each orthogonal axes (i, j, k) were then accumulated over the duration of an aerial acrobatic manoeuvre to provide the total angular displacement achieved in each axis over that time period. The total angular displacements associated with each orthogonal axes were then summed to calculate a composite rotational parameter called Air Angle (AA). We observed a statistically significant difference between AA across four half-pipe snowboarding acrobatic groups which involved increasing levels of rotational complexity (P {\textless} 0.001, n = 216). The signal processing technique documented in this paper provides sensitive automatic classification of aerial acrobatics into terminology used by the snowboarding community and subsequently has the potential to allow coaches and judges to focus on the more subjective and stylistic aspects of half-pipe snowboarding during either training or elite-level competition.},
	language = {en},
	urldate = {2018-03-15},
	booktitle = {The {Engineering} of {Sport} 7},
	publisher = {Springer, Paris},
	author = {Harding, Jason W. and Mackintosh, Colin G. and Hahn, Allan G. and James, Daniel A.},
	year = {2008},
	doi = {10.1007/978-2-287-09413-2_55},
	pages = {447--456}
}

@inproceedings{bona_monitoring_2014,
	title = {Monitoring of plantar forces and surfboard's movement: {Alternative} to understand the injuries mechanism},
	isbn = {978-1-4799-2921-4},
	shorttitle = {Monitoring of plantar forces and surfboard's movement},
	doi = {10.1109/MeMeA.2014.6860063},
	abstract = {The concern about injuries in sport are evident due to the implications it carries. To have the knowledge of the mechanisms of injuries is important either to prevent and recovery. This context generates the appropriate scenario to develop an electronic solution to measure dynamically the Center of Pressure (CoP) and surfboard's movement and support the understanding of the mechanisms responsible for the occurrence of injuries. Two matrices composed by 24 force sensors and Inertial Measurement Unit (IMU) controlled by ATEMEGA1280 microcontroller were developed. This system was tested using a dynamic protocol using one unstable structure at the bottom of the surfboard. The results have shown that the CoP displacement was largest during the tests that presented great rotation changes. Furthermore, the power oscillations were greater during transition moments. The proposed system is able to measure biomechanical variables dynamically, i.e, force, and surfboard's angle pitch and roll. This report reviews the surf injuries in literature and describes the electronic device used beyond to present the results of the tests performed.},
	booktitle = {{IEEE} {MeMeA} 2014 - {IEEE} {International} {Symposium} on {Medical} {Measurements} and {Applications}, {Proceedings}},
	author = {Bona, Daniel and Marques, Maria and Borgonovo-Santos, Marcio and Correia, Miguel},
	month = jun,
	year = {2014},
	pages = {1--4}
}

@misc{noauthor_rules_2018,
	title = {Rules and {Regulations}},
	url = {http://www.worldsurfleague.com/pages/rules-and-regulations},
	abstract = {World Surf League - The global home of surfing.},
	language = {en},
	urldate = {2018-03-14},
	journal = {World Surf League},
	month = mar,
	year = {2018}
}

@article{lestrade_biomechanics_2016,
	title = {{BIOMECHANICS} {OF} {SURFING}: {DEVELOPMENT} {AND} {VALIDATION} {OF} {AN} {INSTRUMENTED} {SURFBOARD} {TO} {MEASURE} {SURFBOARD} {KINETICS}},
	volume = {33},
	copyright = {Copyright (c) 2016 ISBS - Conference Proceedings Archive},
	issn = {1999-4168},
	shorttitle = {{BIOMECHANICS} {OF} {SURFING}},
	url = {https://ojs.ub.uni-konstanz.de/cpa/article/view/6478},
	abstract = {The purpose of this study was to investigate the different relations between the actions of a surfer and the kinematic behaviour of his surfboard. An instrumented surfboard has been designed with a force platform synchronized with an inertial measurement unit and acquisition system. An experimental campaign has been carried out in situ, where different waves have been surfed to validate the device. Results revealed that measured efforts of the surfer and kinematics of his surfboard are consistent regarding the expected behaviour. Instrumented surfboards will help coaches by giving them a new performance analysis tool. It will also provide an experimental database for the development of numerical models about interactions Surfer/Surfboard/Wave.},
	language = {en},
	number = {1},
	urldate = {2018-03-14},
	journal = {ISBS - Conference Proceedings Archive},
	author = {Lestrade, K. and Guérard, S. and Lanusse, P. and Viot, Ph},
	month = may,
	year = {2016},
	keywords = {Dynamic solicitation, Instrumented Surfboard, Motion analysis}
}

@misc{noauthor_trace_2018,
	title = {Trace - {The} {World}'s {Most} {Advanced} {Action} {Sports} {Tracker} - {Trace}},
	url = {http://www.traceup.com/action},
	abstract = {Trace is a small, waterproof GPS + sensors device that attaches directly to your surfboard, skis, snowboard and tracks detailed stats about your activity. Trace syncs with your iPhone, Android, or computer where you can check your stats and compare against others. Bonus for GoPro fans: Trace auto-edits your entire day of GoPro footage down into an action-filled highlight video.},
	language = {en},
	urldate = {2018-03-14},
	month = mar,
	year = {2018}
}

@misc{noauthor_3x_2018,
	title = {3x {World} {Champion} {Mick} {Fanning} {Announces} {Retirement}},
	url = {http://www.worldsurfleague.com/posts/308361/3x-world-champion-mick-fanning-announces-retirement},
	abstract = {After 17 years, the Australian icon is hanging up the competition jersey.},
	language = {en},
	urldate = {2018-03-14},
	journal = {World Surf League},
	month = mar,
	year = {2018}
}

@misc{noauthor_surf_2018-1,
	title = {Surf {Ranch} {Announced} as 2018 {Championship} {Tour} {Venue}},
	url = {http://www.worldsurfleague.com/posts/283223/surf-ranch-announced-as-2018-championship-tour-venue},
	abstract = {Full 2018 schedule coming soon.},
	language = {en},
	urldate = {2018-03-14},
	journal = {World Surf League},
	month = mar,
	year = {2018}
}

@misc{noauthor_australias_2018,
	title = {Australia's {First} {Surf} {Parks} - {URBNSURF}},
	url = {http://www.urbnsurf.co/},
	urldate = {2018-03-14},
	month = mar,
	year = {2018}
}

@misc{noauthor_welcome_2017,
	title = {Welcome to the wonderful world of surfing},
	url = {https://www.olympic.org/news/welcome-to-the-wonderful-world-of-surfing},
	abstract = {Fernando Aguerre, president of the International Surfing Association (ISA), has dedicated much of the past two decades of his life to securing surfing a spot at the Tokyo 2020 Olympic Games. Here, the Argentinean re-lives the extraordinary journey to achieving his dream.},
	language = {en},
	urldate = {2018-03-14},
	journal = {International Olympic Committee},
	month = aug,
	year = {2017}
}

@article{maravall_navigation_2017,
	title = {Navigation and {Self}-{Semantic} {Location} of {Drones} in {Indoor} {Environments} by {Combining} the {Visual} {Bug} {Algorithm} and {Entropy}-{Based} {Vision}},
	volume = {11},
	issn = {1662-5218},
	url = {https://www.frontiersin.org/articles/10.3389/fnbot.2017.00046/full},
	doi = {10.3389/fnbot.2017.00046},
	abstract = {We introduce a hybrid algorithm for the self-semantic location and autonomous navigation of robots using entropy-based vision and visual topological maps. In visual topological maps the visual landmarks are considered as leave points for guiding the robot to reach a target point (robot homing) in indoor environments. These visual landmarks are defined from images of relevant objects or characteristic scenes in the environment. The entropy of an image is directly related to the presence of a unique object or the presence of several different objects inside it: the lower the entropy the higher the probability of containing a single object inside it and, conversely, the higher the entropy the higher the probability of containing several objects inside it. Consequently, we propose the use of the entropy of images captured by the robot not only for the landmark searching and detection but also for obstacle avoidance. If the detected object corresponds to a landmark, the robot uses the suggestions stored in the visual topological map to reach the next landmark or to finish the mission. Otherwise, the robot considers the object as an obstacle and starts a collision avoidance maneuver. In order to validate the proposal we have defined an experimental framework in which the visual bug algorithm is used by an Unmanned Aerial Vehicle (UAV) in typical indoor navigation tasks.},
	language = {English},
	urldate = {2018-03-14},
	journal = {Frontiers in Neurorobotics},
	author = {Maravall, Darío and de Lope, Javier and Fuentes, Juan P.},
	year = {2017},
	keywords = {Entropy search, Visual Topological maps, Visual bug algorithm, internal models, unmanned aerial vehicles}
}

@inproceedings{saux_rapid_2013,
	title = {Rapid semantic mapping: {Learn} environment classifiers on the fly},
	shorttitle = {Rapid semantic mapping},
	doi = {10.1109/IROS.2013.6696888},
	abstract = {We propose solutions to provide unmanned aerial vehicles (UAV) with features to understand the scene below and help the operational planning. First, using a visual mapping of the environnement, interactive learning of specific targets of interest is performed on the ground control station to build semantic maps useful for planning. Then, the learned target detectors are transformed to be applied to new images captured by the UAV. On the technical side, we present: (i) an online gradient boost algorithm to interactively design context-dependent detectors; (ii) a video-domain adaptation method to use object detectors on on-board-camera images. We verify our approach on challenging data captured in real-world conditions.},
	booktitle = {2013 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Saux, B. Le and Sanfourche, M.},
	month = nov,
	year = {2013},
	keywords = {Buildings, Cameras, Detectors, Feature extraction, Semantics, Training, UAV, Videos, autonomous aerial vehicles, context-dependent detectors, environment classifiers, ground control station, image classification, interactive learning, learning (artificial intelligence), object detection, object detectors, on-board-camera images, online gradient boost algorithm, rapid semantic mapping, robot vision, target detectors, unmanned aerial vehicles, video signal processing, video-domain adaptation method, visual mapping},
	pages = {3725--3730}
}

@inproceedings{guerry_snapnet-r:_2017,
	title = {{SnapNet}-{R}: {Consistent} {3D} {Multi}-view {Semantic} {Labeling} for {Robotics}},
	isbn = {978-1-5386-1034-3},
	shorttitle = {{SnapNet}-{R}},
	url = {doi.ieeecomputersociety.org/10.1109/ICCVW.2017.85},
	doi = {10.1109/ICCVW.2017.85},
	abstract = {In this paper we present a new approach for semantic recognition in the context of robotics. When a robot evolves in its environment, it gets 3D information given either by its sensors or by its own motion through 3D reconstruction. Our approach uses (i) 3D-coherent synthesis of scene observations and (ii) mix them in a multi-view framework for 3D labeling. (iii) This is efficient locally (for 2D semantic segmentation) and globally (for 3D structure labeling). This allows to add semantics to the observed scene that goes beyond simple image classification, as shown on challenging datasets such as SUNRGBD or the 3DRMS Reconstruction Challenge.},
	urldate = {2018-03-14},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} {Workshop} ({ICCVW})},
	author = {Guerry, J. and Boulch, A. and Saux, B. L. and Moras, J. and Plyer, A. and Filliat, D.},
	month = oct,
	year = {2017},
	keywords = {Labeling, Robot sensing systems, Semantics, Three-dimensional displays, Training, Two dimensional displays},
	pages = {669--678}
}

@inproceedings{zhang_integrated_2017,
	title = {An integrated {UAV} navigation system based on geo-registered {3D} point cloud},
	doi = {10.1109/MFI.2017.8170396},
	abstract = {The autonomous navigation of unmanned aerial vehicles (UAVs) require a lot of sensing modalities to improve their cruise efficiency. This paper presents a system for autonomous navigation and path planning of UAVs in GPS-denied environment based on the fusion of geo-registered 3D point clouds with proprioceptive sensors (IMU, odometry and barometer) and the 2D Google maps. The contributions of this paper are illustrated as follows: 1) combination of 2D map and geo-registered 3D point clouds; 2) registration of local point cloud to global geo-registered 3D point clouds; 3) integration of visual odometry, IMU, GPS and barometer. Experiment and simulation results demonstrate the efficacy and robustness of the proposed system.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Multisensor} {Fusion} and {Integration} for {Intelligent} {Systems} ({MFI})},
	author = {Zhang, S. and Wang, S. and Li, C. and Liu, G. and Hao, Q.},
	month = nov,
	year = {2017},
	keywords = {2D Google maps, Databases, GPS-denied environment, Global Positioning System, IMU, Kalman filters, Path planning, Sensors, Three-dimensional displays, aerospace computing, autonomous aerial vehicles, autonomous navigation, barometer, control engineering computing, cruise efficiency, distance measurement, geo-registered 3D point cloud, image registration, integrated UAV navigation system, local point cloud, mobile robots, path planning, proprioceptive sensors, robot vision, sensing modalities, unmanned aerial vehicles, visual odometry},
	pages = {650--655}
}

@article{kostavelis_semantic_2015,
	title = {Semantic mapping for mobile robotics tasks: {A} survey},
	volume = {66},
	issn = {0921-8890},
	shorttitle = {Semantic mapping for mobile robotics tasks},
	url = {http://www.sciencedirect.com/science/article/pii/S0921889014003030},
	doi = {10.1016/j.robot.2014.12.006},
	abstract = {The evolution of contemporary mobile robotics has given thrust to a series of additional conjunct technologies. Of such is the semantic mapping, which provides an abstraction of space and a means for human–robot communication. The recent introduction and evolution of semantic mapping motivated this survey, in which an explicit analysis of the existing methods is sought. The several algorithms are categorized according to their primary characteristics, namely scalability, inference model, temporal coherence and topological map usage. The applications involving semantic maps are also outlined in the work at hand, emphasizing on human interaction, knowledge representation and planning. The existence of publicly available validation datasets and benchmarking, suitable for the evaluation of semantic mapping techniques is also discussed in detail. Last, an attempt to address open issues and questions is also made.},
	urldate = {2018-03-14},
	journal = {Robotics and Autonomous Systems},
	author = {Kostavelis, Ioannis and Gasteratos, Antonios},
	month = apr,
	year = {2015},
	keywords = {Human–robot interaction, Knowledge representation, Mobile robots, Object recognition, Place recognition, Planning, Semantic map, Temporal coherence, Topological map},
	pages = {86--103}
}

@misc{noauthor_abaqus_2016,
	title = {Abaqus {Analysis} {User}'s {Guide} (6.14)},
	url = {http://50.16.225.63/v6.14/books/usb/default.htm},
	urldate = {2016-12-13},
	month = dec,
	year = {2016},
	keywords = {Abaqus, Adhesion, Bonding, Cohesive, Contact, FEM, Failuer, Mechanics, Modelling}
}

@article{dominguez_actin_2011,
	title = {Actin structure and function},
	volume = {40},
	issn = {1936-1238},
	doi = {10.1146/annurev-biophys-042910-155359},
	abstract = {Actin is the most abundant protein in most eukaryotic cells. It is highly conserved and participates in more protein-protein interactions than any known protein. These properties, along with its ability to transition between monomeric (G-actin) and filamentous (F-actin) states under the control of nucleotide hydrolysis, ions, and a large number of actin-binding proteins, make actin a critical player in many cellular functions, ranging from cell motility and the maintenance of cell shape and polarity to the regulation of transcription. Moreover, the interaction of filamentous actin with myosin forms the basis of muscle contraction. Owing to its central role in the cell, the actin cytoskeleton is also disrupted or taken over by numerous pathogens. Here we review structures of G-actin and F-actin and discuss some of the interactions that control the polymerization and disassembly of actin.},
	language = {eng},
	journal = {Annual Review of Biophysics},
	author = {Dominguez, Roberto and Holmes, Kenneth C.},
	year = {2011},
	pmid = {21314430},
	pmcid = {PMC3130349},
	keywords = {Actins, Binding Sites, Computer Simulation, Models, Biological, Models, Chemical, Models, Molecular, Protein Binding, Protein Conformation, Structure-Activity Relationship},
	pages = {169--186}
}

@misc{noauthor_oasis_2016,
	title = {{OASIS}},
	url = {http://www.abstractsonline.com/Plan/ViewAbstract.aspx?mID=3541&sKey=9d203404-cbcd-4af2-af8c-3e16d7a5f7b7&cKey=c3cc1e0b-e2db-4bf3-bb82-707f29b21f09&mKey=0d04d93f-3cbf-4352-9f47-e1e75f25e684},
	urldate = {2016-12-14},
	month = dec,
	year = {2016}
}

@misc{noauthor_oasis_2016-1,
	title = {{OASIS}},
	url = {http://www.abstractsonline.com/Plan/ViewAbstract.aspx?mID=3541&sKey=9d203404-cbcd-4af2-af8c-3e16d7a5f7b7&cKey=1ad8b34a-a950-4254-8e14-aa8e55815f65&mKey=0d04d93f-3cbf-4352-9f47-e1e75f25e684},
	urldate = {2016-12-14},
	month = dec,
	year = {2016}
}

@misc{noauthor_mechanotransduction_2016,
	title = {Mechanotransduction at the {Focal} {Adhesions}},
	url = {http://www.abstractsonline.com/Plan/ViewSession.aspx?sKey=9d203404-cbcd-4af2-af8c-3e16d7a5f7b7&mKey=%7b0D04D93F-3CBF-4352-9F47-E1E75F25E684%7d},
	urldate = {2016-12-14},
	month = dec,
	year = {2016}
}

@article{marquez_fourier_2006,
	title = {Fourier analysis and automated measurement of cell and fiber angular orientation distributions},
	volume = {43},
	issn = {0020-7683},
	url = {http://www.sciencedirect.com/science/article/pii/S0020768305006207},
	doi = {10.1016/j.ijsolstr.2005.11.003},
	abstract = {This paper studies the application of the discrete Fourier transform (DFT) to predict angular orientation distributions from images of fibers and cells. Angular distributions of fibers in composites define their material properties. In biological tissues, cell and fiber orientation distributions are important since they define their mechanical properties and function.

We developed a filtering scheme for the DFT to predict angular distributions accurately. The errors involved in this DFT technique and their sources were quantified through Monte Carlo simulation of computer-generated images. The knowledge of these errors allows one to verify the suitability of the method for a particular application. We found that the DFT method is most accurate for slender fibers, and propose a means to minimize errors by optimizing parameters. This method was applied to predict orientation distribution of cells and actin fibers in bio-artificial tissue constructs.},
	number = {21},
	urldate = {2016-12-15},
	journal = {International Journal of Solids and Structures},
	author = {Marquez, J. Pablo},
	month = oct,
	year = {2006},
	keywords = {Angular orientation distributions, Fourier analysis},
	pages = {6413--6423}
}

@article{verdier_review._2009,
	title = {Review. {Rheological} properties of biological materials},
	volume = {10},
	url = {https://hal.archives-ouvertes.fr/hal-00415166},
	abstract = {Eucaryotic cells and biological materials are described from a rheological point of view. Single cell properties give rise to typical microrheological properties which can aect cell behaviour, in close connection with their adhesion properties. Single cell properties are also important in the context of multicellular systems, i.e. in biological tissues. Results from experiments are analyzed and models proposed both at the cellular scale and the macroscopic scale.},
	urldate = {2016-12-16},
	journal = {Comptes rendus de l'Académie des sciences. Série IV, Physique, astrophysique},
	author = {Verdier, Claude and Etienne, Jocelyn and Duperray, Alain and Preziosi, Luigi},
	month = dec,
	year = {2009},
	keywords = {Rheology, cell mechanics, tissues, viscoelastic},
	pages = {790--811}
}

@misc{noauthor_how_2016,
	title = {How do {I} assign viscoelastic material properties into {Abaqus}?},
	url = {https://www.researchgate.net/post/How_do_I_assign_viscoelastic_material_properties_into_Abaqus},
	abstract = {i am simulating the behavior of tissue on Abaqus
i want to assign those material properties please:
time-dependent viscoelastic properties were assigned to the cytoplasm using this model (E0 = 6.5...},
	urldate = {2016-12-16},
	month = dec,
	year = {2016},
	keywords = {Cell, cytoplasm, viscoelastic, young's modulus}
}

@article{song_computational_2012,
	title = {Computational {Modeling} of {Tissue} {Engineering} {Scaffolds} as {Delivery} {Devices} for {Mechanical} and {Mechanically} {Modulated} {Signals}},
	url = {https://www.researchgate.net/publication/278709467_Computational_Modeling_of_Tissue_Engineering_Scaffolds_as_Delivery_Devices_for_Mechanical_and_Mechanically_Modulated_Signals},
	doi = {10.1007/8415_2012_138},
	abstract = {In this chapter, we outline the use of computational modeling and novel experimental methods to develop tissue engineering scaffolds as delivery devices for exogenous and endogenous cues,...},
	urldate = {2016-12-16},
	journal = {ResearchGate},
	author = {Song, Min Jae and Dean, David and Tate, Melissa L. Knothe},
	month = jan,
	year = {2012},
	keywords = {CFD, PU, Scaffold},
	pages = {127--143}
}

@article{caliari_practical_2016,
	title = {A practical guide to hydrogels for cell culture},
	volume = {13},
	copyright = {© 2016 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1548-7091},
	url = {http://www.nature.com/nmeth/journal/v13/n5/full/nmeth.3839.html},
	doi = {10.1038/nmeth.3839},
	abstract = {There is growing appreciation of the role that the extracellular environment plays in regulating cell behavior. Mechanical, structural, and compositional cues, either alone or in concert, can drastically alter cell function. Biomaterials, and particularly hydrogels, have been developed and implemented to present defined subsets of these cues for investigating countless cellular processes as a means of understanding morphogenesis, aging, and disease. Although most scientists concede that standard cell culture materials (tissue culture plastic and glass) do a poor job of recapitulating native cellular milieus, there is currently a knowledge barrier for many researchers in regard to the application of hydrogels for cell culture. Here, we introduce hydrogels to those who may be unfamiliar with procedures to culture and study cells with these systems, with a particular focus on commercially available hydrogels.},
	language = {en},
	number = {5},
	urldate = {2016-12-16},
	journal = {Nature Methods},
	author = {Caliari, Steven R. and Burdick, Jason A.},
	month = may,
	year = {2016},
	keywords = {Biological techniques, Biomaterials, ECM, Hydrogel, material, overview, properties, review},
	pages = {405--414}
}

@article{cox_remodeling_2011,
	title = {Remodeling and homeostasis of the extracellular matrix: implications for fibrotic diseases and cancer},
	volume = {4},
	copyright = {© 2011. Published by The Company of Biologists Ltd.  This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial Share Alike License (http://creativecommons.org/licenses/by-nc-sa/3.0), which permits unrestricted non-commercial use, distribution and reproduction in any medium provided that the original work is properly cited and all further distributions of the work or adaptation are subject to the same Creative Commons License terms.},
	issn = {1754-8403, 1754-8411},
	shorttitle = {Remodeling and homeostasis of the extracellular matrix},
	url = {http://dmm.biologists.org/content/4/2/165},
	doi = {10.1242/dmm.004077},
	abstract = {Skip to Next Section
Dynamic remodeling of the extracellular matrix (ECM) is essential for development, wound healing and normal organ homeostasis. Life-threatening pathological conditions arise when ECM remodeling becomes excessive or uncontrolled. In this Perspective, we focus on how ECM remodeling contributes to fibrotic diseases and cancer, which both present challenging obstacles with respect to clinical treatment, to illustrate the importance and complexity of cell-ECM interactions in the pathogenesis of these conditions. Fibrotic diseases, which include pulmonary fibrosis, systemic sclerosis, liver cirrhosis and cardiovascular disease, account for over 45\% of deaths in the developed world. ECM remodeling is also crucial for tumor malignancy and metastatic progression, which ultimately cause over 90\% of deaths from cancer. Here, we discuss current methodologies and models for understanding and quantifying the impact of environmental cues provided by the ECM on disease progression, and how improving our understanding of ECM remodeling in these pathological conditions is crucial for uncovering novel therapeutic targets and treatment strategies. This can only be achieved through the use of appropriate in vitro and in vivo models to mimic disease, and with technologies that enable accurate monitoring, imaging and quantification of the ECM.},
	language = {en},
	number = {2},
	urldate = {2016-12-16},
	journal = {Disease Models \& Mechanisms},
	author = {Cox, Thomas R. and Erler, Janine T.},
	month = mar,
	year = {2011},
	pmid = {21324931},
	keywords = {Collagen, ECM, Elastin, Focal Adhesion, Hydrogel, properties},
	pages = {165--178}
}

@article{abdalrahman_cellular_2016,
	title = {Cellular mechanosensitivity to substrate stiffness decreases with increasing dissimilarity to cell stiffness},
	author = {Abdalrahman, T. and Dubuis, L. and Green, J. and Davies, N. and Franz, T.},
	year = {2016}
}

@article{sun_regulation_2006,
	title = {Regulation of mesenchymal stem cell adhesion and orientation in {3D} collagen scaffold by electrical stimulus},
	volume = {69},
	issn = {1567-5394},
	url = {http://www.sciencedirect.com/science/article/pii/S156753940500143X},
	doi = {10.1016/j.bioelechem.2005.11.007},
	abstract = {Cell adhesion and orientation are important for both natural and engineered tissues to fully achieve physiologic functions. Based on diverse cellular responses induced by electrical stimulus on 2D substrate, we applied non-invasive electrical stimulus to regulate cell adhesion and orientation of bone marrow-derived mesenchymal stem cells (MSCs) and fibroblasts in a reconstituted 3D collagen-based scaffold. While fibroblasts were induced to reorient perpendicularly in response to direct current electrical stimulus, rat MSCs showed only slight changes in cell reorientation. Multiphoton microscopy revealed that rat MSCs exhibited much stronger 3D adhesion, which appears to resist cell reorientation. Only in response to a large electrical stimulus (e.g., 10 V/cm), collagen fibers around rat MSCs became disconnected and loosely reorganized. In contrast, the collagen fibers surrounding the fibroblasts were entangled in a random network and became preferentially aligned in the direction of the electrical stimulus. When incubated with integrin antibodies, both fibroblasts and rat MSCs failed to respond to electrical stimulus, providing evidence that integrin-dependent molecular mechanisms are involved in 3D cell adhesion and orientation. Elucidation of physical regulation of 3D cell adhesion and orientation may offer a novel approach in controlling cell growth and differentiation and could be useful for stem cell-based therapeutic application and engineering tissue constructs.},
	number = {2},
	urldate = {2016-12-21},
	journal = {Bioelectrochemistry},
	author = {Sun, Shan and Titushkin, Igor and Cho, Michael},
	month = oct,
	year = {2006},
	keywords = {Adhesion, Electrical stimulus, Integrin, Laser optical tweezers, Mesenchymal stem cells, Multiphoton microscopy, Orientation},
	pages = {133--141}
}

@article{macqueen_mesenchymal_2013,
	title = {Mesenchymal stem cell mechanobiology and emerging experimental platforms},
	volume = {10},
	copyright = {© 2013 The Author(s) Published by the Royal Society. All rights reserved.},
	issn = {1742-5689, 1742-5662},
	url = {http://rsif.royalsocietypublishing.org/content/10/84/20130179},
	doi = {10.1098/rsif.2013.0179},
	abstract = {Experimental control over progenitor cell lineage specification can be achieved by modulating properties of the cell's microenvironment. These include physical properties of the cell adhesion substrate, such as rigidity, topography and deformation owing to dynamic mechanical forces. Multipotent mesenchymal stem cells (MSCs) generate contractile forces to sense and remodel their extracellular microenvironments and thereby obtain information that directs broad aspects of MSC function, including lineage specification. Various physical factors are important regulators of MSC function, but improved understanding of MSC mechanobiology requires novel experimental platforms. Engineers are bridging this gap by developing tools to control mechanical factors with improved precision and throughput, thereby enabling biological investigation of mechanics-driven MSC function. In this review, we introduce MSC mechanobiology and review emerging cell culture platforms that enable new insights into mechanobiological control of MSCs. Our main goals are to provide engineers and microtechnology developers with an up-to-date description of MSC mechanobiology that is relevant to the design of experimental platforms and to introduce biologists to these emerging platforms.},
	language = {en},
	number = {84},
	urldate = {2016-12-21},
	journal = {Journal of The Royal Society Interface},
	author = {MacQueen, Luke and Sun, Yu and Simmons, Craig A.},
	month = jul,
	year = {2013},
	pmid = {23635493},
	keywords = {3d, Geometry, Hydrogel, IMPORTANT, MSC, Morphology},
	pages = {20130179}
}
@article{cukierman_cell_2002,
	title = {Cell interactions with three-dimensional matrices},
	volume = {14},
	issn = {0955-0674},
	url = {http://www.sciencedirect.com/science/article/pii/S0955067402003642},
	doi = {10.1016/S0955-0674(02)00364-2},
	abstract = {Signaling and other cellular functions differ in three-dimensional compared with two-dimensional systems. Cell adhesion structures can evolve in vitro towards in-vivo-like adhesions with distinct biological activities. In this review, we examine recent advances in studies of interactions of fibroblasts with collagen gels and fibronectin-containing matrices that mimic in vivo three-dimensional microenvironments. These three-dimensional systems are illuminating mechanisms of cell–matrix interactions in living organisms.},
	number = {5},
	urldate = {2016-12-21},
	journal = {Current Opinion in Cell Biology},
	author = {Cukierman, Edna and Pankov, Roumen and Yamada, Kenneth M},
	month = oct,
	year = {2002},
	keywords = {3D substrates, 3Dsignalling, Adhesion, cell-derived 3D matrix, cell-matrix interactions, collagen gel, fibronectin, mechanotransudction},
	pages = {633--640}
}

@article{wang_cell_2013,
	title = {Cell adhesion and mechanical stimulation in the regulation of mesenchymal stem cell differentiation},
	volume = {17},
	issn = {1582-1838},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3741348/},
	doi = {10.1111/jcmm.12061},
	abstract = {Stem cells have been shown to have the potential to provide a source of cells for applications to tissue engineering and organ repair. The mechanisms that regulate stem cell fate, however, mostly remain unclear. Mesenchymal stem cells (MSCs) are multipotent progenitor cells that are isolated from bone marrow and other adult tissues, and can be differentiated into multiple cell lineages, such as bone, cartilage, fat, muscles and neurons. Although previous studies have focused intensively on the effects of chemical signals that regulate MSC commitment, the effects of physical/mechanical cues of the microenvironment on MSC fate determination have long been neglected. However, several studies provided evidence that mechanical signals, both direct and indirect, played important roles in regulating a stem cell fate. In this review, we summarize a number of recent studies on how cell adhesion and mechanical cues influence the differentiation of MSCs into specific lineages. Understanding how chemical and mechanical cues in the microenvironment orchestrate stem cell differentiation may provide new insights into ways to improve our techniques in cell therapy and organ repair.},
	number = {7},
	urldate = {2016-12-21},
	journal = {Journal of Cellular and Molecular Medicine},
	author = {Wang, Yang-Kao and Chen, Christopher S},
	month = jul,
	year = {2013},
	pmid = {23672518},
	pmcid = {PMC3741348},
	keywords = {Differentiation, Lineage, Mesenchymal stem cells, mechanotransudction},
	pages = {823--832}
}

@article{huang_mesenchymal_2008,
	title = {Mesenchymal stem cells for vascular regeneration},
	volume = {3},
	issn = {1746-0751},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2596657/},
	doi = {10.2217/17460751.3.6.877},
	abstract = {Mesenchymal stem cells (MSCs) have tremendous potential for regenerative medicine, and have been researched for the treatment of cardiovascular diseases. MSCs are a promising cell type because of their ease of isolation and expansion, their multipotency and their low immunogenicity. However, in order to fully utilize the therapeutic potential of MSCs, it is important to understand the intrinsic property of MSCs and the role of the microenvironment in modulating MSC behavior and function. Microenvironmental factors such as mechanical cues, soluble factors and matrix properties not only regulate MSC differentiation, but also modulate MSC signaling to the surrounding environment. Understanding the properties of MSCs and the role of the microenvironment will be beneficial for developing in vivo therapies for the construction of tissue-engineered vascular grafts and the treatment of ischemic cardiac tissues.},
	number = {6},
	urldate = {2016-12-21},
	journal = {Regenerative medicine},
	author = {Huang, Ngan F and Li, Song},
	month = nov,
	year = {2008},
	pmid = {18947310},
	pmcid = {PMC2596657},
	keywords = {ECM, Hydrogel, IMPORTANT, MSC, Modelling, Myocardial Infarct, grafts, patch, vascular},
	pages = {877--892}
}

@article{krishnan_modeling_2008,
	title = {Modeling and simulation of chemomechanics at the cell-matrix interface},
	volume = {2},
	issn = {1933-6918},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2634991/},
	abstract = {Chemomechanical characteristics of the extracellular materials with which cells interact can have a profound impact on cell adhesion and migration. To understand and modulate such complex multiscale processes, a detailed understanding of the feedback between a cell and the adjacent microenvironment is crucial. Here, we use computational modeling and simulation to examine the cell-matrix interaction at both the molecular and continuum lengthscales. Using steered molecular dynamics, we consider how extracellular matrix (ECM) stiffness and extracellular pH influence the interaction between cell surface adhesion receptors and extracellular matrix ligands, and we predict potential consequences for focal adhesion formation and dissolution. Using continuum level finite element simulations and analytical methods to model cell-induced ECM deformation as a function of ECM stiffness and thickness, we consider the implications toward design of synthetic substrata for cell biology experiments that intend to decouple chemical and mechanical cues.},
	number = {2},
	urldate = {2016-12-21},
	journal = {Cell Adhesion \& Migration},
	author = {Krishnan, Ranjani and Oommen, Binu and Walton, Emily B and Maloney, John M and Van Vliet, Krystyn J},
	year = {2008},
	pmid = {19262102},
	pmcid = {PMC2634991},
	keywords = {IMPORTANT},
	pages = {83--94}
}

@phdthesis{petrova_cell_2016,
	address = {Knoxville},
	title = {Cell {Contraction}, {De}-adhesion, and {Shape} {Effects} {Investigated} by {Cohesive} {Model} with {Finite} {Element} {Simulations}},
	url = {http://trace.tennessee.edu/cgi/viewcontent.cgi?article=5068&context=utk_gradthes},
	language = {English},
	urldate = {2016-12-21},
	school = {University of Tennessee},
	author = {Petrova, M.},
	month = may,
	year = {2016},
	keywords = {IMPORTANT}
}

@article{slomka_confocal_2010,
	title = {Confocal microscopy-based three-dimensional cell-specific modeling for large deformation analyses in cellular mechanics},
	volume = {43},
	issn = {1873-2380},
	doi = {10.1016/j.jbiomech.2010.02.011},
	abstract = {This study introduces a new confocal microscopy-based three-dimensional cell-specific finite element (FE) modeling methodology for simulating cellular mechanics experiments involving large cell deformations. Three-dimensional FE models of undifferentiated skeletal muscle cells were developed by scanning C2C12 myoblasts using a confocal microscope, and then building FE model geometries from the z-stack images. Strain magnitudes and distributions in two cells were studied when the cells were subjected to compression and stretching, which are used in pressure ulcer and deep tissue injury research to induce large cell deformations. Localized plasma membrane and nuclear surface area (NSA) stretches were observed for both the cell compression and stretching simulation configurations. It was found that in order to induce large tensile strains ({\textgreater}5\%) in the plasma membrane and NSA, one needs to apply more than approximately 15\% of global cell deformation in cell compression tests, or more than approximately 3\% of tensile strains in the elastic plate substrate in cell stretching experiments. Utilization of our modeling can substantially enrich experimental cellular mechanics studies in classic cell loading designs that typically involve large cell deformations, such as static and cyclic stretching, cell compression, micropipette aspiration, shear flow and hydrostatic pressure, by providing magnitudes and distributions of the localized cellular strains specific to each setup and cell type, which could then be associated with the applied stimuli.},
	language = {eng},
	number = {9},
	journal = {Journal of Biomechanics},
	author = {Slomka, Noa and Gefen, Amit},
	month = jun,
	year = {2010},
	pmid = {20188374},
	keywords = {Abaqus, Cell Line, Cell Size, Cellular, Cellular Geometry, Compressive Strength, Computer Simulation, Elastic Modulus, FEM, Hardness, IMPORTANT, Imaging, Three-Dimensional, Microscopy, Confocal, Models, Biological, Stress, Mechanical, Tensile Strength},
	pages = {1806--1816}
}

@article{or-tzadikario_confocal-based_2011,
	title = {Confocal-based cell-specific finite element modeling extended to study variable cell shapes and intracellular structures: {The} example of the adipocyte},
	volume = {44},
	issn = {0021-9290},
	shorttitle = {Confocal-based cell-specific finite element modeling extended to study variable cell shapes and intracellular structures},
	url = {http://www.sciencedirect.com/science/article/pii/S0021929010004987},
	doi = {10.1016/j.jbiomech.2010.09.012},
	abstract = {This communication extends the recently reported cell-specific finite element (FE) method in Slomka and Gefen (2010) in which geometrically realistic FE cell models are created from confocal microscopy scans for large deformation analyses. The cell-specific FE method is extended here in the following aspects: (i) we demonstrate that cell-specific FE is versatile enough to deal with cells of substantially different geometrical shapes. The examples of an “elongated” pre-adipocyte and a “round” mature adipocyte are used to demonstrate this feature. (ii) We demonstrate that cell-specific FE can be used to analyze the mechanical behavior of cells that incorporate complex intracellular structures and are subjected to large deformations—again through the example of an adipocyte which contains a multitude of lipid droplets, each having a different size and shape. By demonstrating feasibility of inclusion of such inhomogeneities in the cytoplasm, the present work paves the way for modeling cellular organelles such as Golgi bodies, lysosomes and mitochondria in mechanically loaded cells using cell-specific FE.},
	number = {3},
	urldate = {2016-12-22},
	journal = {Journal of Biomechanics},
	author = {Or-Tzadikario, Shira and Gefen, Amit},
	month = feb,
	year = {2011},
	keywords = {Abaqus, Cell organelles, Cellular Geometry, Cellular mechanics, Confocal laser microscopy imaging, FEM, Fibroblast, Lipid droplets, Models, Biological},
	pages = {567--573}
}

@article{huang_cell_2004,
	title = {Cell mechanics and mechanotransduction: pathways, probes, and physiology},
	volume = {287},
	copyright = {Copyright © 2004 the American Physiological Society},
	issn = {0363-6143, 1522-1563},
	shorttitle = {Cell mechanics and mechanotransduction},
	url = {http://ajpcell.physiology.org/content/287/1/C1},
	doi = {10.1152/ajpcell.00559.2003},
	abstract = {Cells face not only a complex biochemical environment but also a diverse biomechanical environment. How cells respond to variations in mechanical forces is critical in homeostasis and many diseases. The mechanisms by which mechanical forces lead to eventual biochemical and molecular responses remain undefined, and unraveling this mystery will undoubtedly provide new insight into strengthening bone, growing cartilage, improving cardiac contractility, and constructing tissues for artificial organs. In this article we review the physical bases underlying the mechanotransduction process, techniques used to apply controlled mechanical stresses on living cells and tissues to probe mechanotransduction, and some of the important lessons that we are learning from mechanical stimulation of cells with precisely controlled forces.},
	language = {en},
	number = {1},
	urldate = {2016-12-22},
	journal = {American Journal of Physiology - Cell Physiology},
	author = {Huang, Hayden and Kamm, Roger D. and Lee, Richard T.},
	month = jul,
	year = {2004},
	pmid = {15189819},
	keywords = {Adhesion, Biologic, Cell, FEM, Focal Adhesion, Force, Measurement},
	pages = {C1--C11}
}

@article{barreto_multi-structural_2013,
	title = {A multi-structural single cell model of force-induced interactions of cytoskeletal components},
	volume = {34},
	issn = {0142-9612},
	url = {http://www.sciencedirect.com/science/article/pii/S0142961213004663},
	doi = {10.1016/j.biomaterials.2013.04.022},
	abstract = {Several computational models based on experimental techniques and theories have been proposed to describe cytoskeleton (CSK) mechanics. Tensegrity is a prominent model for force generation, but it cannot predict mechanics of individual CSK components, nor explain the discrepancies from the different single cell stimulating techniques studies combined with cytoskeleton-disruptors. A new numerical concept that defines a multi-structural 3D finite element (FE) model of a single-adherent cell is proposed to investigate the biophysical and biochemical differences of the mechanical role of each cytoskeleton component under loading. The model includes prestressed actin bundles and microtubule within cytoplasm and nucleus surrounded by the actin cortex. We performed numerical simulations of atomic force microscopy (AFM) experiments by subjecting the cell model to compressive loads. The numerical role of the CSK components was corroborated with AFM force measurements on U2OS-osteosarcoma cells and NIH-3T3 fibroblasts exposed to different cytoskeleton-disrupting drugs. Computational simulation showed that actin cortex and microtubules are the major components targeted in resisting compression. This is a new numerical tool that explains the specific role of the cortex and overcomes the difficulty of isolating this component from other networks in vitro. This illustrates that a combination of cytoskeletal structures with their own properties is necessary for a complete description of cellular mechanics.},
	number = {26},
	urldate = {2016-12-22},
	journal = {Biomaterials},
	author = {Barreto, Sara and Clausen, Casper H. and Perrault, Cecile M. and Fletcher, Daniel A. and Lacroix, Damien},
	month = aug,
	year = {2013},
	keywords = {AFM (atomic force microscopy), Actin bundles, Actin cortex, Cytoskeleton, Finite element modeling, Microtubules},
	pages = {6119--6126}
}

@article{pfeiler_finite_2008,
	title = {Finite element modeling of {3D} human mesenchymal stem cell-seeded collagen matrices exposed to tensile strain},
	volume = {41},
	issn = {0021-9290},
	url = {http://www.sciencedirect.com/science/article/pii/S0021929008001863},
	doi = {10.1016/j.jbiomech.2008.04.007},
	abstract = {The use of human mesenchymal stem cells (hMSCs) in tissue engineering is attractive due to their ability to extensively self-replicate and differentiate into a multitude of cell lineages. It has been experimentally established that hMSCs are influenced by chemical and mechanical signals. However, the combined chemical and mechanical in vitro culture conditions that lead to functional tissue require greater understanding. In this study, finite element models were created to evaluate the local loading conditions on bone marrow-derived hMSCs seeded in three-dimensional collagen matrices exposed to cyclic tensile strain. Mechanical property and geometry data used in the models were obtained experimentally from a previous study in our laboratory and from mechanical testing. Eight finite element models were created to simulate three-dimensional hMSC-seeded collagen matrices exposed to different levels of cyclic tensile strain (10\% and 12\%), culture media (complete growth and osteogenic differentiating), and durations of culture (7 and 14 days). Through finite element analysis, it was determined that globally applied uniaxial tensile strains of 10\% and 12\% resulted in local strains up to 18.3\% and 21.8\%, respectively. Model results were also compared to experimental studies in an attempt to explain observed differences between hMSC response to 10\% and 12\% cyclic tensile strain.},
	number = {10},
	urldate = {2016-12-22},
	journal = {Journal of Biomechanics},
	author = {Pfeiler, T. Wayne and Sumanasinghe, Ruwan D. and Loboa, Elizabeth G.},
	month = jul,
	year = {2008},
	keywords = {Bioreactor, Collagen, Collagen Matrix, FEM, Finite element modeling, HMSCs, MSC, Uniaxial tensile strain},
	pages = {2289--2296}
}

@article{darling_viscoelastic_2008,
	title = {Viscoelastic properties of human mesenchymally-derived stem cells and primary osteoblasts, chondrocytes, and adipocytes},
	volume = {41},
	issn = {0021-9290},
	url = {http://www.sciencedirect.com/science/article/pii/S0021929007003028},
	doi = {10.1016/j.jbiomech.2007.06.019},
	abstract = {The mechanical properties of single cells play important roles in regulating cell-matrix interactions, potentially influencing the process of mechanotransduction. Recent studies also suggest that cellular mechanical properties may provide novel biological markers, or “biomarkers,” of cell phenotype, reflecting specific changes that occur with disease, differentiation, or cellular transformation. Of particular interest in recent years has been the identification of such biomarkers that can be used to determine specific phenotypic characteristics of stem cells that separate them from primary, differentiated cells. The goal of this study was to determine the elastic and viscoelastic properties of three primary cell types of mesenchymal lineage (chondrocytes, osteoblasts, and adipocytes) and to test the hypothesis that primary differentiated cells exhibit distinct mechanical properties compared to adult stem cells (adipose-derived or bone marrow-derived mesenchymal stem cells). In an adherent, spread configuration, chondrocytes, osteoblasts, and adipocytes all exhibited significantly different mechanical properties, with osteoblasts being stiffer than chondrocytes and both being stiffer than adipocytes. Adipose-derived and mesenchymal stem cells exhibited similar properties to each other, but were mechanically distinct from primary cells, particularly when comparing a ratio of elastic to relaxed moduli. These findings will help more accurately model the cellular mechanical environment in mesenchymal tissues, which could assist in describing injury thresholds and disease progression or even determining the influence of mechanical loading for tissue engineering efforts. Furthermore, the identification of mechanical properties distinct to stem cells could result in more successful sorting procedures to enrich multipotent progenitor cell populations.},
	number = {2},
	urldate = {2016-12-22},
	journal = {Journal of Biomechanics},
	author = {Darling, Eric M. and Topel, Matthew and Zauscher, Stefan and Vail, Thomas P. and Guilak, Farshid},
	year = {2008},
	keywords = {ADAS cell, Adipocyte, Atomic force microscopy, Cell, Chondrocyte, IMPORTANT, MSC, Mechanical Properties, Mechanotransduction, Osteoblast, cell mechanics},
	pages = {454--464}
}

@article{slomka_membrane-stretch-induced_2009,
	title = {Membrane-{Stretch}-{Induced} {Cell} {Death} in {Deep} {Tissue} {Injury}: {Computer} {Model} {Studies}},
	volume = {2},
	issn = {1865-5025, 1865-5033},
	shorttitle = {Membrane-{Stretch}-{Induced} {Cell} {Death} in {Deep} {Tissue} {Injury}},
	url = {http://link.springer.com/article/10.1007/s12195-009-0046-x},
	doi = {10.1007/s12195-009-0046-x},
	abstract = {Deep tissue injury (DTI) is a serious pressure ulcer, involving a mass of necrotic soft tissue under bony prominences as a consequence of sustained tissue deformations. Though several processes are thought to participate in the onset and development of DTI (e.g., cellular deformation, ischemia, and ischemia-reperfusion), the specific mechanisms responsible for it are currently unknown. Recent work indicated that pathological processes at the cell level, which relate to cell deformation, are involved in the etiology. We hypothesized that sustained tissue deformations can lead to elevated intracellular concentration of cell metabolites, e.g., calcium ion (Ca2+), due to a stretch-induced increase in the local permeability of plasma membranes. This may ultimately lead to cell death due to intracellular cytotoxic concentrations of metabolites. In order to investigate this hypothesis, computational models were developed, for determining compression-induced membrane stretches and trends of times for reaching intracellular cytotoxic Ca2+ levels due to uncontrolled Ca2+ influx through stretched membranes. The simulations indicated that elevated compressive cell deformations exceeding 25\% induce large tensional strains ({\textgreater}5\%, and up to 11.5\%) in membranes. These are likely to increase Ca2+ influx from the extracellular space into the cytosol through the stretched sites. Consistent with this assumption, the Ca2+ transport model showed high sensitivity of times for cell death to changes in membrane resistance. These results may open a new path in pressure ulcer research, by indicating how global tissue deformations are transformed to plasma membrane deformations, which in turn, affect transport properties and eventually, cell viability.},
	language = {en},
	number = {1},
	urldate = {2016-12-23},
	journal = {Cellular and Molecular Bioengineering},
	author = {Slomka, Noa and Or-Tzadikario, Shira and Sassun, Dan and Gefen, Amit},
	month = mar,
	year = {2009},
	keywords = {Adhesion, FEM},
	pages = {118}
}

@article{shoham_deformations_2012,
	title = {Deformations, mechanical strains and stresses across the different hierarchical scales in weight-bearing soft tissues},
	volume = {21},
	issn = {0965-206X},
	url = {http://www.sciencedirect.com/science/article/pii/S0965206X12000046},
	doi = {10.1016/j.jtv.2012.03.001},
	abstract = {Sustained internal tissue loads (deformations, mechanical strains and stresses) which develop during immobile weight-bearing postures such as while in bed or in a chair were identified as a fundamental cause for the onset and progression of pressure ulcers (PUs), particularly of the deep tissue injury (DTI) type. The sustained loading may compromise tissue viability either directly, by geometrically distorting cells, or indirectly, by distorting the vasculature or lymphatic networks or, at the micro-scale, by distorting cellular organelles involved in regulating transport, e.g. the plasma membrane, since transport-control-mechanisms are essential for adequate biological function of cells. In this article we provide a comprehensive, rigorous review of the up-to-date published computational-modeling-work as well as relevant experimental studies concerning tissue deformations, strains and stresses across the different hierarchical scales: tissue-scale [cm], meso-scale [mm] and cell-scale [μm]. Viability of tissues exposed to sustained loading should be investigated in all dimensional scales, from the macro to micro, in order to provide complete understanding of the etiology of PUs and DTIs and in particular, for identifying individuals for whom and conditions at which the susceptibility to these injuries might be greater. Emerging relevant bioengineering methods of computer simulation such as multiscale and multiphysics modeling will undoubtedly contribute to the aetiological research in this field in the near future.},
	number = {2},
	urldate = {2016-12-23},
	journal = {Journal of Tissue Viability},
	author = {Shoham, Naama and Gefen, Amit},
	month = may,
	year = {2012},
	keywords = {Biomechanics, Deep tissue injury, Finite element method, Models, Biological, Multiscale modeling, Pressure ulcer, Scale},
	pages = {39--46}
}

@article{ronan_numerical_2012,
	title = {Numerical investigation of the active role of the actin cytoskeleton in the compression resistance of cells},
	volume = {14},
	issn = {1751-6161},
	url = {http://www.sciencedirect.com/science/article/pii/S175161611200166X},
	doi = {10.1016/j.jmbbm.2012.05.016},
	abstract = {Numerous in-vitro studies have established that cells react to their physical environment and to applied mechanical loading. However, the mechanisms underlying such phenomena are poorly understood. Previous modelling of cell compression considered the cell as a passive homogenous material, requiring an artificial increase in the stiffness of spread cells to replicate experimentally measured forces. In this study, we implement a fully 3D active constitutive formulation that predicts the distribution, remodelling, and contractile behaviour of the cytoskeleton. Simulations reveal that polarised and axisymmetric spread cells contain stress fibres which form dominant bundles that are stretched during compression. These dominant fibres exert tension; causing an increase in computed compression forces compared to round cells. In contrast, fewer stress fibres are computed for round cells and a lower resistance to compression is predicted. The effect of different levels of cellular contractility associated with different cell phenotypes is also investigated. Highly contractile cells form more dominant circumferential stress fibres and hence provide greater resistance to compression. Computed predictions correlate strongly with published experimentally observed trends of compression resistance as a function of cellular contractility and offer an insight into the link between cell geometry, stress fibre distribution and contractility, and cell deformability. Importantly, it is possible to capture the behaviour of both round and spread cells using a given, unchanged set of material parameters for each cell type. Finally, it is demonstrated that stress distributions in the cell cytoplasm and nucleus computed using the active formulation differ significantly from those computed using passive material models.},
	urldate = {2016-12-23},
	journal = {Journal of the Mechanical Behavior of Biomedical Materials},
	author = {Ronan, William and Deshpande, Vikram S. and McMeeking, Robert M. and McGarry, J. Patrick},
	month = oct,
	year = {2012},
	keywords = {Active contractility, Cell, Cell compression, Constitutive formulation, Models, Biological, Spherical, Stress fibre},
	pages = {143--157}
}

@article{deshpande_bio-mechanical_2008,
	title = {A bio-mechanical model for coupling cell contractility with focal adhesion formation},
	volume = {56},
	issn = {0022-5096},
	url = {https://www.researchgate.net/publication/241491472_A_bio-mechanical_model_for_coupling_cell_contractility_with_focal_adhesion_formation},
	doi = {10.1016/j.jmps.2007.08.006},
	abstract = {Official Full-Text Publication: A bio-mechanical model for coupling cell contractility with focal adhesion formation on ResearchGate, the professional network for scientists.},
	number = {4},
	urldate = {2016-12-23},
	journal = {ResearchGate},
	author = {Deshpande, Vikram S. and Mrksich, Milan and McMeeking, Robert M. and Evans, Anthony G.},
	month = apr,
	year = {2008},
	keywords = {Biomechanics, FEM, Focal Adhesion, Models, Chemical},
	pages = {1484--1510}
}

@article{peeters_mechanical_2005,
	title = {Mechanical and failure properties of single attached cells under compression},
	volume = {38},
	issn = {0021-9290},
	url = {http://www.sciencedirect.com/science/article/pii/S0021929004003616},
	doi = {10.1016/j.jbiomech.2004.07.018},
	abstract = {Eukaryotic cells are continuously subjected to mechanical forces under normal physiological conditions. These forces and associated cellular deformations induce a variety of biological processes. The degree of deformation depends on the mechanical properties of the cell. As most cells are anchorage dependent for normal functioning, it is important to study the mechanical properties of cells in their attached configuration. The goal of the present study was to obtain the mechanical and failure properties of attached cells. Individual, attached C2C12 mouse myoblasts were subjected to unconfined compression experiments using a recently developed loading device. The device allows global compression of the cell until cell rupture and simultaneously measures the associated forces. Cell bursting was characterized by a typical reduction in the force, referred to as the bursting force. Mean bursting forces were calculated as 8.7 ± 2.5 μ N at an axial strain of 72 ± 4 \%. Visualization of the cell using confocal microscopy revealed that cell bursting was preceded by the formation of bulges at the cell membrane, which eventually led to rupturing of the cell membrane. Finite element calculations were performed to simulate the obtained force–deformation curves. A finite element mesh was built for each cell to account for its specific geometrical features. Using an axisymmetric approximation of the cell geometry, and a Neo–Hookean constitutive model, excellent agreement between predicted and measured force–deformation curves was obtained, yielding an average Young's modulus of 1.14 ± 0.32 kPa .},
	number = {8},
	urldate = {2016-12-23},
	journal = {Journal of Biomechanics},
	author = {Peeters, E. A. G. and Oomens, C. W. J. and Bouten, C. V. C. and Bader, D. L. and Baaijens, F. P. T.},
	month = aug,
	year = {2005},
	keywords = {Compression, Confocal microscopy, Elastic properties, Muscle cells, cell mechanics},
	pages = {1685--1693}
}

@article{randolph_guide_2009,
	title = {A {Guide} to {Writing} the {Dissertation} {Literature} {Review}},
	volume = {14},
	issn = {1531-7714},
	abstract = {Writing a faulty literature review is one of many ways to derail a dissertation. This article summarizes some pivotal information on how to write a high-quality dissertation literature review. It begins with a discussion of the purposes of a review, presents taxonomy of literature reviews, and then discusses the steps in conducting a quantitative or qualitative literature review. The article concludes with a discussion of common mistakes and a framework for the self-evaluation of a literature review. (Contains 1 figure and 4 tables.)},
	language = {en},
	number = {13},
	urldate = {2016-12-23},
	journal = {Practical Assessment, Research \& Evaluation},
	author = {Randolph, Justus J.},
	month = jun,
	year = {2009},
	keywords = {Classification, Doctoral Dissertations, Literature Reviews, Qualitative Research, Statistical Analysis}
}

@article{hakkinen_direct_2010,
	title = {Direct {Comparisons} of the {Morphology}, {Migration}, {Cell} {Adhesions}, and {Actin} {Cytoskeleton} of {Fibroblasts} in {Four} {Different} {Three}-{Dimensional} {Extracellular} {Matrices}},
	volume = {17},
	issn = {1937-3341},
	url = {http://online.liebertpub.com/doi/abs/10.1089/ten.tea.2010.0273},
	doi = {10.1089/ten.tea.2010.0273},
	abstract = {Interactions between cells and the extracellular matrix are at the core of tissue engineering and biology. However, most studies of these interactions have used traditional two-dimensional (2D) tissue culture, which is less physiological than three-dimensional (3D) tissue culture. In this study, we compared cell behavior in four types of commonly used extracellular matrix under 2D and 3D conditions. Specifically, we quantified parameters of cell adhesion and migration by human foreskin fibroblasts in cell-derived matrix or hydrogels of collagen type I, fibrin, or basement membrane extract (BME). Fibroblasts in 3D were more spindle shaped with fewer lateral protrusions and substantially reduced actin stress fibers than on 2D matrices; cells failed to spread in 3D BME. Cell–matrix adhesion structures were detected in all matrices. Although the shapes of these cell adhesions differed, the total area per cell occupied by cell–matrix adhesions in 2D and 3D was nearly identical. Fibroblasts migrated most rapidly in cell-derived 3D matrix and collagen and migrated minimally in BME, with highest migration directionality in cell-derived matrix. This identification of quantitative differences in cellular responses to different matrix composition and dimensionality should help guide the development of customized 3D tissue culture and matrix scaffolds for tissue engineering.},
	number = {5-6},
	urldate = {2016-12-23},
	journal = {Tissue Engineering Part A},
	author = {Hakkinen, Kirsi M. and Harunaga, Jill S. and Doyle, Andrew D. and Yamada, Kenneth M.},
	month = oct,
	year = {2010},
	keywords = {3d, Adhesion, Cell, Fibroblast, Hydrogel, IMPORTANT, Morphology},
	pages = {713--724}
}

@article{lee_cell_2015,
	title = {Cell {Adhesion} and {Long}-{Term} {Survival} of {Transplanted} {Mesenchymal} {Stem} {Cells}: {A} {Prerequisite} for {Cell} {Therapy}},
	volume = {2015},
	issn = {1942-0900},
	shorttitle = {Cell {Adhesion} and {Long}-{Term} {Survival} of {Transplanted} {Mesenchymal} {Stem} {Cells}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4333334/},
	doi = {10.1155/2015/632902},
	abstract = {The literature provides abundant evidence that mesenchymal stem cells (MSCs) are an attractive resource for therapeutics and have beneficial effects in regenerating injured tissues due to their self-renewal ability and broad differentiation potential. Although the therapeutic potential of MSCs has been proven in both preclinical and clinical studies, several questions have not yet been addressed. A major limitation to the use of MSCs in clinical applications is their poor viability at the site of injury due to the harsh microenvironment and to anoikis driven by the loss of cell adhesion. To improve the survival of the transplanted MSCs, strategies to regulate apoptotic signaling and enhance cell adhesion have been developed, such as pretreatment with cytokines, growth factors, and antiapoptotic molecules, genetic modifications, and hypoxic preconditioning. More appropriate animal models and a greater understanding of the therapeutic mechanisms of MSCs will be required for their successful clinical application. Nevertheless, the development of stem cell therapies using MSCs has the potential to treat degenerative diseases. This review discusses various approaches to improving MSC survival by inhibiting anoikis.},
	urldate = {2016-12-26},
	journal = {Oxidative Medicine and Cellular Longevity},
	author = {Lee, Seahyoung and Choi, Eunhyun and Cha, Min-Ji and Hwang, Ki-Chul},
	year = {2015},
	pmid = {25722795},
	pmcid = {PMC4333334},
	keywords = {Adhesion, MSC, importance, stem cells}
}

@article{mozaffarian_heart_2016,
	title = {Heart {Disease} and {Stroke} {Statistics}—2016 {Update}},
	volume = {133},
	copyright = {© 2015 American Heart Association, Inc.},
	issn = {0009-7322, 1524-4539},
	url = {http://circ.ahajournals.org/content/133/4/e38},
	doi = {10.1161/CIR.0000000000000350},
	abstract = {Each year, the American Heart Association (AHA), in conjunction with the Centers for Disease Control and Prevention, the National Institutes of Health, and other government agencies, brings together the most up-to-date statistics related to heart disease, stroke, and other cardiovascular and metabolic diseases and presents them in its Heart Disease and Stroke Statistical Update. The Statistical Update represents a critical resource for the lay public, policy makers, media professionals, clinicians, healthcare administrators, researchers, and others seeking the best available data on these conditions. Together, cardiovascular disease (CVD) and stroke produce immense health and economic burdens in the United States and globally. The Statistical Update brings together in a single document up-to-date information on the core health behaviors (including diet, physical activity [PA], smoking, and energy balance) and health factors (including blood pressure, cholesterol, and glucose) that define cardiovascular health; a range of …},
	language = {en},
	number = {4},
	urldate = {2016-12-26},
	journal = {Circulation},
	author = {Mozaffarian, Dariush and Benjamin, Emelia J. and Go, Alan S. and Arnett, Donna K. and Blaha, Michael J. and Cushman, Mary and Das, Sandeep R. and Ferranti, Sarah de and Després, Jean-Pierre and Fullerton, Heather J. and Howard, Virginia J. and Huffman, Mark D. and Isasi, Carmen R. and Jiménez, Monik C. and Judd, Suzanne E. and Kissela, Brett M. and Lichtman, Judith H. and Lisabeth, Lynda D. and Liu, Simin and Mackey, Rachel H. and Magid, David J. and McGuire, Darren K. and Mohler, Emile R. and Moy, Claudia S. and Muntner, Paul and Mussolino, Michael E. and Nasir, Khurram and Neumar, Robert W. and Nichol, Graham and Palaniappan, Latha and Pandey, Dilip K. and Reeves, Mathew J. and Rodriguez, Carlos J. and Rosamond, Wayne and Sorlie, Paul D. and Stein, Joel and Towfighi, Amytis and Turan, Tanya N. and Virani, Salim S. and Woo, Daniel and Yeh, Robert W. and Turner, Melanie B.},
	month = jan,
	year = {2016},
	pmid = {26673558},
	keywords = {AHA Scientific Statements, cardiovascular diseases, epidemiology, risk factors, statistics, stroke},
	pages = {e38--e360}
}

@phdthesis{masithulela_computational_2016,
	type = {Thesis},
	title = {Computational biomechanics in the remodelling rat heart post myocardial infarction},
	url = {https://open.uct.ac.za/handle/11427/20555},
	abstract = {Cardiovascular diseases account for one third of all deaths worldwide, more than 33\% of which are related to ischemic heart disease, including myocardial infarction (MI). This thesis seeks to provide insight and understanding of mechanisms during different stages of MI by utilizing finite element (FE) modelling.  Three-dimensional biventricular rat heart geometries were developed from cardiac magnetic resonance images of a healthy heart and a heart with left ventricular (LV) infarction two weeks and four weeks after infarct induction. From these geometries, FE models were established. To represent the myocardium, a structure-based constitutive model and a rule-based myofibre distribution were developed to simulate both passive mechanics and active contraction.},
	language = {eng},
	urldate = {2016-12-26},
	school = {University of Cape Town},
	author = {Masithulela, Fulufhelo James},
	year = {2016}
}

@article{sart_three-dimensional_2014,
	title = {Three-{Dimensional} {Aggregates} of {Mesenchymal} {Stem} {Cells}: {Cellular} {Mechanisms}, {Biological} {Properties}, and {Applications}},
	volume = {20},
	issn = {1937-3368},
	shorttitle = {Three-{Dimensional} {Aggregates} of {Mesenchymal} {Stem} {Cells}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4185975/},
	doi = {10.1089/ten.teb.2013.0537},
	abstract = {Mesenchymal stem cells (MSCs) are primary candidates in cell therapy and tissue engineering and are being tested in clinical trials for a wide range of diseases. Originally isolated and expanded as plastic adherent cells, MSCs have intriguing properties of in vitro self-assembly into three-dimensional (3D) aggregates reminiscent of skeletal condensation in vivo. Recent studies have shown that MSC 3D aggregation improved a range of biological properties, including multilineage potential, secretion of therapeutic factors, and resistance against ischemic condition. Hence, the formation of 3D MSC aggregates has been explored as a novel strategy to improve cell delivery, functional activation, and in vivo retention to enhance therapeutic outcomes. This article summarizes recent reports of MSC aggregate self-assembly, characterization of biological properties, and their applications in preclinical models. The cellular and molecular mechanisms underlying MSC aggregate formation and functional activation are discussed, and the areas that warrant further investigation are highlighted. These analyses are combined to provide perspectives for identifying the controlling mechanisms and refining the methods of aggregate fabrication and expansion for clinical applications.},
	number = {5},
	urldate = {2016-12-26},
	journal = {Tissue Engineering. Part B, Reviews},
	author = {Sart, Sébastien and Tsai, Ang-Chen and Li, Yan and Ma, Teng},
	month = oct,
	year = {2014},
	pmid = {24168395},
	pmcid = {PMC4185975},
	pages = {365--380}
}

@article{grayson_human_2004,
	title = {Human mesenchymal stem cells tissue development in {3D} {PET} matrices},
	volume = {20},
	issn = {8756-7938},
	doi = {10.1021/bp034296z},
	abstract = {Human mesenchymal stem cells (hMSCs) are attractive cell sources for engineered tissue constructs with broad therapeutic potential. Three-dimensional (3D) hMSC tissue development in nonwoven poly(ethylene terephthalate) (PET) fibrous matrices was investigated. HMSCs were seeded onto 3D PET scaffolds and were cultured for over 1 month. Their proliferation rates were affected by seeding density but remained much lower than those of 2D controls. Compared to 2D surfaces, hMSCs grown in 3D scaffolds secreted and embedded themselves in an extensive ECM network composed of collagen I, collagen IV, fibronectin, and laminin. HMSCs were influenced by the orientation of adjacent PET fibers to organize the ECM proteins into highly aligned fibrils. We observed the increased expressions of alpha(2)beta(1) integrin but a slight decrease in the expression of alpha(5)beta(1) integrin in 3D compared to 2D culture and found that alpha(V)beta(3) was expressed only in 2D. Paxillin expression was down-regulated in 3D culture with a concomitant change in its localization patterns. We demonstrated the multi-lineage potentials of the 3D tissue constructs by differentiating the cells grown in the scaffolds into osteoblasts and adipocytes. Taken together, these results showed that hMSCs grown in 3D scaffolds display tissue development patterns distinct from their 2D counterparts and provide important clues for designing 3D scaffolds for developing tissue engineered constructs.},
	language = {eng},
	number = {3},
	journal = {Biotechnology Progress},
	author = {Grayson, Warren L. and Ma, Teng and Bunnell, Bruce},
	month = jun,
	year = {2004},
	pmid = {15176898},
	keywords = {Adipocytes, Biocompatible Materials, Cell Adhesion Molecules, Cell Culture Techniques, Cell Differentiation, Cell Proliferation, Cell Survival, Cell adhesion, Cells, Cultured, Extracellular Matrix, Extracellular Matrix Proteins, Humans, Materials Testing, Mesenchymal Stromal Cells, Osteoblasts, Polyethylene Terephthalates, Tissue Engineering},
	pages = {905--912}
}

@article{xiao_mechanical_2013,
	title = {Mechanical {Testing} of {Hydrogels} in {Cartilage} {Tissue} {Engineering}: {Beyond} the {Compressive} {Modulus}},
	volume = {19},
	issn = {1937-3368},
	shorttitle = {Mechanical {Testing} of {Hydrogels} in {Cartilage} {Tissue} {Engineering}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3752504/},
	doi = {10.1089/ten.teb.2012.0461},
	abstract = {Injuries to articular cartilage result in significant pain to patients and high medical costs. Unfortunately, cartilage repair strategies have been notoriously unreliable and/or complex. Biomaterial-based tissue-engineering strategies offer great promise, including the use of hydrogels to regenerate articular cartilage. Mechanical integrity is arguably the most important functional outcome of engineered cartilage, although mechanical testing of hydrogel-based constructs to date has focused primarily on deformation rather than failure properties. In addition to deformation testing, as the field of cartilage tissue engineering matures, this community will benefit from the addition of mechanical failure testing to outcome analyses, given the crucial clinical importance of the success of engineered constructs. However, there is a tremendous disparity in the methods used to evaluate mechanical failure of hydrogels and articular cartilage. In an effort to bridge the gap in mechanical testing methods of articular cartilage and hydrogels in cartilage regeneration, this review classifies the different toughness measurements for each. The urgency for identifying the common ground between these two disparate fields is high, as mechanical failure is ready to stand alongside stiffness as a functional design requirement. In comparing toughness measurement methods between hydrogels and cartilage, we recommend that the best option for evaluating mechanical failure of hydrogel-based constructs for cartilage tissue engineering may be tensile testing based on the single edge notch test, in part because specimen preparation is more straightforward and a related American Society for Testing and Materials (ASTM) standard can be adopted in a fracture mechanics context.},
	number = {5},
	urldate = {2016-12-27},
	journal = {Tissue Engineering. Part B, Reviews},
	author = {Xiao, Yinghua and Friis, Elizabeth A. and Gehrke, Stevin H. and Detamore, Michael S.},
	month = oct,
	year = {2013},
	pmid = {23448091},
	pmcid = {PMC3752504},
	keywords = {Behaviour, Hydrogel, material, properties},
	pages = {403--412}
}

@article{guilak_biomechanics_2014,
	title = {Biomechanics and mechanobiology in functional tissue engineering},
	volume = {47},
	issn = {0021-9290},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4051419/},
	doi = {10.1016/j.jbiomech.2014.04.019},
	abstract = {The field of tissue engineering continues to expand and mature, and several products are now in clinical use, with numerous other preclinical and clinical studies underway. However, specific challenges still remain in the repair or regeneration of tissues that serve a predominantly biomechanical function. Furthermore, it is now clear that mechanobiological interactions between cells and scaffolds can critically influence cell behavior, even in tissues and organs that do not serve an overt biomechanical role. Over the past decade, the field of “functional tissue engineering” has grown as a subfield of tissue engineering to address the challenges and questions on the role of biomechanics and mechanobiology in tissue engineering. Originally posed as a set of principles and guidelines for engineering of load-bearing tissues, functional tissue engineering has grown to encompass several related areas that have proven to have important implications for tissue repair and regeneration. These topics include measurement and modeling of the in vivo biomechanical environment; quantitative analysis of the mechanical properties of native tissues, scaffolds, and repair tissues; development of rationale criteria for the design and assessment of engineered tissues; investigation of the effects biomechanical factors on native and repair tissues, in vivo and in vitro; and development and application of computational models of tissue growth and remodeling. Here we further expand this paradigm and provide examples of the numerous advances in the field over the past decade. Consideration of these principles in the design process will hopefully improve the safety, efficacy, and overall success of engineered tissue replacements.},
	number = {9},
	urldate = {2016-12-27},
	journal = {Journal of biomechanics},
	author = {Guilak, Farshid and Butler, David L. and Goldstein, Steven A. and Baaijens, Frank P.T.},
	month = jun,
	year = {2014},
	pmid = {24818797},
	pmcid = {PMC4051419},
	pages = {1933--1940}
}

@article{cukierman_taking_2001,
	title = {Taking cell-matrix adhesions to the third dimension},
	volume = {294},
	issn = {0036-8075},
	doi = {10.1126/science.1064829},
	abstract = {Adhesions between fibroblastic cells and extracellular matrix have been studied extensively in vitro, but little is known about their in vivo counterparts. Here, we characterized the composition and function of adhesions in three-dimensional (3D) matrices derived from tissues or cell culture. "3D-matrix adhesions" differ from focal and fibrillar adhesions characterized on 2D substrates in their content of alpha5beta1 and alphavbeta3 integrins, paxillin, other cytoskeletal components, and tyrosine phosphorylation of focal adhesion kinase (FAK). Relative to 2D substrates, 3D-matrix interactions also display enhanced cell biological activities and narrowed integrin usage. These distinctive in vivo 3D-matrix adhesions differ in structure, localization, and function from classically described in vitro adhesions, and as such they may be more biologically relevant to living organisms.},
	language = {eng},
	number = {5547},
	journal = {Science (New York, N.Y.)},
	author = {Cukierman, E. and Pankov, R. and Stevens, D. R. and Yamada, K. M.},
	month = nov,
	year = {2001},
	pmid = {11721053},
	keywords = {3T3 Cells, Animals, Cell Culture Techniques, Cell Division, Cell Movement, Cell Size, Cell adhesion, Cells, Cultured, Culture Techniques, Cycloheximide, Cytoskeletal Proteins, Extracellular Matrix, Fibroblasts, Fibronectins, Fluorescent Antibody Technique, Indirect, Focal Adhesion Kinase 1, Focal Adhesion Protein-Tyrosine Kinases, Focal Adhesions, Glutaral, Humans, Imaging, Three-Dimensional, Integrins, Mice, Mitogen-Activated Protein Kinases, Molecular Conformation, Phosphorylation, Protein-Tyrosine Kinases, Time Factors},
	pages = {1708--1712}
}

@article{mierke_contractile_2008,
	title = {Contractile forces in tumor cell migration},
	volume = {87},
	issn = {0171-9335},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2566782/},
	doi = {10.1016/j.ejcb.2008.01.002},
	abstract = {Cancer is a deadly disease primarily because of the ability of tumor cells to spread from the primary tumor, to invade into the connective tissue, and to form metastases at distant sites. In contrast to cell migration on a planar surface where large cell tractions and contractile forces are not essential, tractions and forces are thought to be crucial for overcoming the resistance and steric hindrance of a dense 3-dimensional connective tissue matrix. In this review, we describe recently developed biophysical tools including 2-D and 3-D traction microscopy to measure contractile forces of cells. We discuss evidence indicating that tumor cell invasiveness is associated with increased contractile force generation.},
	number = {8-9},
	urldate = {2016-12-27},
	journal = {European journal of cell biology},
	author = {Mierke, Claudia Tanja and Rösel, Daniel and Fabry, Ben and Brábek, Jan},
	month = sep,
	year = {2008},
	pmid = {18295931},
	pmcid = {PMC2566782},
	pages = {669--676}
}

@article{chauviere_modeling_2007,
	title = {Modeling cell movement in anisotropic and heterogeneous network tissues},
	volume = {2},
	issn = {1556-181X},
	url = {https://www.researchgate.net/publication/224010778_Modeling_cell_movement_in_anisotropic_and_heterogeneous_network_tissues},
	doi = {10.3934/nhm.2007.2.333},
	abstract = {Official Full-Text Publication: Modeling cell movement in anisotropic and heterogeneous network tissues on ResearchGate, the professional network for scientists.},
	urldate = {2016-12-27},
	journal = {ResearchGate},
	author = {Chauvière, A. and Hillen, T. and Preziosi, L.},
	month = jun,
	year = {2007},
	pages = {333--357}
}

@article{zielinski_finite_2013,
	title = {Finite element analysis of traction force microscopy: influence of cell mechanics, adhesion, and morphology},
	volume = {135},
	issn = {1528-8951},
	shorttitle = {Finite element analysis of traction force microscopy},
	doi = {10.1115/1.4024467},
	abstract = {The interactions between adherent cells and their extracellular matrix (ECM) have been shown to play an important role in many biological processes, such as wound healing, morphogenesis, differentiation, and cell migration. Cells attach to the ECM at focal adhesion sites and transmit contractile forces to the substrate via cytoskeletal actin stress fibers. This contraction results in traction stresses within the substrate/ECM. Traction force microscopy (TFM) is an experimental technique used to quantify the contractile forces generated by adherent cells. In TFM, cells are seeded on a flexible substrate and displacements of the substrate caused by cell contraction are tracked and converted to a traction stress field. The magnitude of these traction stresses are normally used as a surrogate measure of internal cell contractile force or contractility. We hypothesize that in addition to contractile force, other biomechanical properties including cell stiffness, adhesion energy density, and cell morphology may affect the traction stresses measured by TFM. In this study, we developed finite element models of the 2D and 3D TFM techniques to investigate how changes in several biomechanical properties alter the traction stresses measured by TFM. We independently varied cell stiffness, cell-ECM adhesion energy density, cell aspect ratio, and contractility and performed a sensitivity analysis to determine which parameters significantly contribute to the measured maximum traction stress and net contractile moment. Results suggest that changes in cell stiffness and adhesion energy density can significantly alter measured tractions, independent of contractility. Based on a sensitivity analysis, we developed a correction factor to account for changes in cell stiffness and adhesion and successfully applied this correction factor algorithm to experimental TFM measurements in invasive and noninvasive cancer cells. Therefore, application of these types of corrections to TFM measurements can yield more accurate estimates of cell contractility.},
	language = {eng},
	number = {7},
	journal = {Journal of Biomechanical Engineering},
	author = {Zielinski, Rachel and Mihai, Cosmin and Kniss, Douglas and Ghadiali, Samir N.},
	month = jul,
	year = {2013},
	pmid = {23720059},
	pmcid = {PMC3705880},
	keywords = {Animals, Cell Movement, Cell Physiological Phenomena, Cell Size, Cell adhesion, Computer Simulation, Elastic Modulus, Extracellular Matrix, Finite Element Analysis, Focal Adhesions, Humans, Mechanotransduction, Cellular, Microscopy, Models, Biological, Stress, Mechanical},
	pages = {71009}
}

@article{guvendiren_stiffening_2012,
	title = {Stiffening hydrogels to probe short- and long-term cellular responses to dynamic mechanics},
	volume = {3},
	copyright = {© 2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
	issn = {2041-1723},
	url = {http://www.nature.com/ncomms/journal/v3/n4/full/ncomms1792.html},
	doi = {10.1038/ncomms1792},
	abstract = {Studying the effects of extracellular matrix stiffening has been impeded because mostin vitromodels are static. Here, dynamic hydrogels are developed that stiffen in the presence of cells and are used to investigate the short-term (minutes-to-hours) and long-term (days-to-weeks) cellular responses to dynamic stiffening.},
	language = {en},
	urldate = {2017-01-02},
	journal = {Nature Communications},
	author = {Guvendiren, Murat and Burdick, Jason A.},
	month = apr,
	year = {2012},
	keywords = {3d, Adhesion, FIGURE, Forces, MSC, Stem Cell, Traction, young's modulus},
	pages = {792}
}

@article{khetan_degradation-mediated_2013,
	title = {Degradation-mediated cellular traction directs stem cell fate in covalently crosslinked three-dimensional hydrogels},
	volume = {12},
	copyright = {© 2013 Nature Publishing Group},
	issn = {1476-1122},
	url = {http://www.nature.com/nmat/journal/v12/n5/full/nmat3586.html},
	doi = {10.1038/nmat3586},
	abstract = {Although cell–matrix adhesive interactions are known to regulate stem cell differentiation, the underlying mechanisms, in particular for direct three-dimensional encapsulation within hydrogels, are poorly understood. Here, we demonstrate that in covalently crosslinked hyaluronic acid (HA) hydrogels, the differentiation of human mesenchymal stem cells (hMSCs) is directed by the generation of degradation-mediated cellular traction, independently of cell morphology or matrix mechanics. hMSCs within HA hydrogels of equivalent elastic moduli that permit (restrict) cell-mediated degradation exhibited high (low) degrees of cell spreading and high (low) tractions, and favoured osteogenesis (adipogenesis). Moreover, switching the permissive hydrogel to a restrictive state through delayed secondary crosslinking reduced further hydrogel degradation, suppressed traction, and caused a switch from osteogenesis to adipogenesis in the absence of changes to the extended cellular morphology. Furthermore, inhibiting tension-mediated signalling in the permissive environment mirrored the effects of delayed secondary crosslinking, whereas upregulating tension induced osteogenesis even in the restrictive environment.},
	language = {en},
	number = {5},
	urldate = {2017-01-02},
	journal = {Nature Materials},
	author = {Khetan, Sudhir and Guvendiren, Murat and Legant, Wesley R. and Cohen, Daniel M. and Chen, Christopher S. and Burdick, Jason A.},
	month = may,
	year = {2013},
	keywords = {3d, Adhesion, FIGURE, Gels and hydrogels, MSC, Morphology, Stem cells, Traction},
	pages = {458--465}
}

@article{huebsch_harnessing_2010,
	title = {Harnessing traction-mediated manipulation of the cell/matrix interface to control stem-cell fate},
	volume = {9},
	copyright = {© 2010 Nature Publishing Group},
	issn = {1476-1122},
	url = {http://www.nature.com/nmat/journal/v9/n6/abs/nmat2732.html},
	doi = {10.1038/nmat2732},
	abstract = {Stem cells sense and respond to the mechanical properties of the extracellular matrix. However, both the extent to which extracellular-matrix mechanics affect stem-cell fate in three-dimensional microenvironments and the underlying biophysical mechanisms are unclear. We demonstrate that the commitment of mesenchymal stem-cell populations changes in response to the rigidity of three-dimensional microenvironments, with osteogenesis occurring predominantly at 11–30 kPa. In contrast to previous two-dimensional work, however, cell fate was not correlated with morphology. Instead, matrix stiffness regulated integrin binding as well as reorganization of adhesion ligands on the nanoscale, both of which were traction dependent and correlated with osteogenic commitment of mesenchymal stem-cell populations. These findings suggest that cells interpret changes in the physical properties of adhesion substrates as changes in adhesion-ligand presentation, and that cells themselves can be harnessed as tools to mechanically process materials into structures that feed back to manipulate their fate.
View full text},
	language = {en},
	number = {6},
	urldate = {2017-01-02},
	journal = {Nature Materials},
	author = {Huebsch, Nathaniel and Arany, Praveen R. and Mao, Angelo S. and Shvartsman, Dmitry and Ali, Omar A. and Bencherif, Sidi A. and Rivera-Feliciano, José and Mooney, David J.},
	month = jun,
	year = {2010},
	keywords = {3d, Adhesion, Biological physics, Biomedical materials, Differentiation, Fate, Hydrogel, MSC, Polymers, Traction},
	pages = {518--526}
}

@article{passier_stem-cell-based_2008,
	title = {Stem-cell-based therapy and lessons from the heart},
	volume = {453},
	copyright = {© 2008 Nature Publishing Group},
	issn = {0028-0836},
	url = {http://www.nature.com/nature/journal/v453/n7193/full/nature07040.html},
	doi = {10.1038/nature07040},
	abstract = {The potential usefulness of human embryonic stem cells for therapy derives from their ability to form any cell in the body. This potential has been used to justify intensive research despite some ethical concerns. In parallel, scientists have searched for adult stem cells that can be used as an alternative to embryonic cells, and, for the heart at least, these efforts have led to promising results. However, most adult cardiomyocytes are unable to divide and form new cardiomyocytes and would therefore be unable to replace those lost as a result of disease. Basic questions — for example, whether cardiomyocyte replacement or alternatives, such as providing the damaged heart with new blood vessels or growth factors to activate resident stem cells, are the best approach — remain to be fully addressed. Despite this, preclinical studies on cardiomyocyte transplantation in animals and the first clinical trials with adult stem cells have recently been published with mixed results.},
	language = {en},
	number = {7193},
	urldate = {2017-01-02},
	journal = {Nature},
	author = {Passier, Robert and van Laake, Linda W. and Mummery, Christine L.},
	month = may,
	year = {2008},
	keywords = {Cardiac, MSC, Regeneration, Remodelling, Treatment},
	pages = {322--329}
}

@article{ge_size_2014,
	title = {The {Size} of {Mesenchymal} {Stem} {Cells} is a {Significant} {Cause} of {Vascular} {Obstructions} and {Stroke}},
	volume = {10},
	issn = {1550-8943, 1558-6804},
	url = {http://link.springer.com/article/10.1007/s12015-013-9492-x},
	doi = {10.1007/s12015-013-9492-x},
	abstract = {Background and PurposeIntravascular injection of mesenchymal stem cells (MSCs) has been found to cause considerable vascular obstructions which may lead to serious outcomes, particularly after intra-arterial injection. However, the underlying mechanisms have been poorly understood.MethodsIn this study, we fractionated MSCs that had been cultured in monolayer for six passages into small (average diameter = 17.9 μm) and large (average diameter 30.4 μm) populations according to their sizes, and examined their vascular obstructions after intra-internal carotid artery injection in rats and mice in comparison with MSCs derived from 3D spheroids which were uniformly smaller in size (average diameter 12.6 μm).ResultsWe found that 3D MSCs did not cause detectable infarct in the brain as evidenced by MRI scan and TTC stain, 2D MSCs in small size caused a microinfarct in one of five animals, which was co-localized to the area of entrapped MSCs (labeled with DiI), while 2D MSCs in large size caused much larger infarcts in all five animals, and substantial amounts of DiI-positive MSCs were found in the infarct. Meanwhile, corresponding neurological defects were observed in the animals with stroke. In consistence, injection of 2D MSCs (average diameter 26.5) caused a marked loss of cortical neurons and their axons in Thy1-GFP transgenic mice and the activation of microglia in CX3CR1-GFP transgenic mice in the area with MSC entrapment.ConclusionsOur results suggest that the size of MSCs is a significant cause of MSC caused vascular obstructions and stroke.},
	language = {en},
	number = {2},
	urldate = {2017-01-02},
	journal = {Stem Cell Reviews and Reports},
	author = {Ge, Jianfeng and Guo, Ling and Wang, Shan and Zhang, Yiling and Cai, Ting and Zhao, Robert C. H. and Wu, Yaojiong},
	month = apr,
	year = {2014},
	keywords = {3d, MSC, Morphology},
	pages = {295--303}
}

@article{lulevich_cell_2009,
	title = {Cell tracing dyes significantly change single cell mechanics},
	volume = {113},
	issn = {1520-6106},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2698996/},
	doi = {10.1021/jp8103358},
	abstract = {Cell tracing dyes are very frequently utilized in cellular biology research because they provide highly sensitive fluorescent tags that do not compromise cellular functions such as growth and proliferation. In many investigations concerning cellular adhesion and mechanics, fluorescent dyes have been employed with the assumption of little impact on the results. Using the single-cell compression technique developed by our team, the single-cell mechanics of MDA-MB-468 and MLC-SV40 cells were investigated as a function of dye uptake. Cell tracing dyes increase living cell stiffness 3-6 times and cell-to-probe adhesion up to 7 times. These results suggest a more significant effect than toxins, such as Thrombin. A simple analytical model was derived to enable the extraction of the Young’s moduli of the cell membrane and cytoskeleton from the force-deformation profiles measured for individual cells. The increase in Young’s modulus of the membrane is 3-7 times, which is more significant than that of the cytoskeleton (1.1-3.4 times). We propose that changes in cell mechanics upon the addition of fluorescent tracing dye are primarily due to incorporation of amphiphilic dye molecules into the cellular plasma membrane, which increases the lateral interaction among phospholipid chains and thus enhances their rigidity and adhesion.},
	number = {18},
	urldate = {2017-01-03},
	journal = {The journal of physical chemistry. B},
	author = {Lulevich, Valentin and Shih, Yi-Ping and Lo, Su Hao and Liu, Gang-yu},
	month = may,
	year = {2009},
	pmid = {19366241},
	pmcid = {PMC2698996},
	pages = {6511--6519}
}

@article{bao_cell_2003,
	title = {Cell and molecular mechanics of biological materials},
	volume = {2},
	copyright = {© 2003 Nature Publishing Group},
	issn = {1476-1122},
	url = {http://www.nature.com/nmat/journal/v2/n11/abs/nmat1001.html},
	doi = {10.1038/nmat1001},
	abstract = {Living cells can sense mechanical forces and convert them into biological responses. Similarly, biological and biochemical signals are known to influence the abilities of cells to sense, generate and bear mechanical forces. Studies into the mechanics of single cells, subcellular components and biological molecules have rapidly evolved during the past decade with significant implications for biotechnology and human health. This progress has been facilitated by new capabilities for measuring forces and displacements with piconewton and nanometre resolutions, respectively, and by improvements in bio-imaging. Details of mechanical, chemical and biological interactions in cells remain elusive. However, the mechanical deformation of proteins and nucleic acids may provide key insights for understanding the changes in cellular structure, response and function under force, and offer new opportunities for the diagnosis and treatment of disease. This review discusses some basic features of the deformation of single cells and biomolecules, and examines opportunities for further research.},
	language = {en},
	number = {11},
	urldate = {2017-01-03},
	journal = {Nature Materials},
	author = {Bao, G. and Suresh, S.},
	month = nov,
	year = {2003},
	pages = {715--725}
}

@article{dahl_power-law_2005,
	title = {Power-{Law} {Rheology} of {Isolated} {Nuclei} with {Deformation} {Mapping} of {Nuclear} {Substructures}},
	volume = {89},
	issn = {0006-3495},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1366783/},
	doi = {10.1529/biophysj.105.062554},
	abstract = {Force-induced changes in genome expression as well as remodeling of nuclear architecture in development and disease motivate a deeper understanding of nuclear mechanics. Chromatin and green fluorescent protein-lamin B dynamics were visualized in a micropipette aspiration of isolated nuclei, and both were shown to contribute to viscoelastic properties of the somatic cell nucleus. Reversible swelling by almost 200\% in volume, with changes in salt, demonstrates the resilience and large dilational capacity of the nuclear envelope, nucleoli, and chromatin. Swelling also proves an effective way to separate the mechanical contributions of nuclear elements. In unswollen nuclei, chromatin is a primary force-bearing element, whereas swollen nuclei are an order of magnitude softer, with the lamina sustaining much of the load. In both cases, nuclear deformability increases with time, scaling as a power law—thus lacking any characteristic timescale—when nuclei are either aspirated or indented by atomic force microscopy. The nucleus is stiff and resists distortion at short times, but it softens and deforms more readily at longer times. Such results indicate an essentially infinite spectrum of timescales for structural reorganization, with implications for regulating genome expression kinetics.},
	number = {4},
	urldate = {2017-01-03},
	journal = {Biophysical Journal},
	author = {Dahl, Kris Noel and Engler, Adam J. and Pajerowski, J. David and Discher, Dennis E.},
	month = oct,
	year = {2005},
	pmid = {16055543},
	pmcid = {PMC1366783},
	pages = {2855--2864}
}

@article{mathieu_cytoskeletal_2012,
	title = {Cytoskeletal and {Focal} {Adhesion} {Influences} on {Mesenchymal} {Stem} {Cell} {Shape}, {Mechanical} {Properties}, and {Differentiation} {Down} {Osteogenic}, {Adipogenic}, and {Chondrogenic} {Pathways}},
	volume = {18},
	issn = {1937-3368},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3495119/},
	doi = {10.1089/ten.teb.2012.0014},
	abstract = {Mesenchymal stem cells (MSCs) hold great potential for regenerative medicine and tissue-engineering applications. They have multipotent differentiation capabilities and have been shown to differentiate down various lineages, including osteoblasts, adipocytes, chondrocytes, myocytes, and possibly neurons. The majority of approaches to control the MSC fate have been via the use of chemical factors in the form of growth factors within the culture medium. More recently, it has been understood that mechanical forces play a significant role in regulating MSC fate. We and others have shown that mechanical stimuli can control MSC lineage specification. The cytoskeleton is known to play a large role in mechanotransduction, and a growing number of studies are showing that it can also contribute to MSC differentiation. This review analyzes the significant contribution of actin and integrin distribution, and the smaller role of microtubules, in regulating MSC fate. Osteogenic differentiation is more prevalent in MSCs with a stiff, spread actin cytoskeleton and greater numbers of focal adhesions. Both adipogenic differentiation and chondrogenic differentiation are encouraged when MSCs have a spherical morphology associated with a dispersed actin cytoskeleton with few focal adhesions. Different mechanical stimuli can be implemented to alter these cytoskeletal patterns and encourage MSC differentiation to the desired lineage.},
	number = {6},
	urldate = {2017-01-03},
	journal = {Tissue Engineering. Part B, Reviews},
	author = {Mathieu, Pattie S. and Loboa, Elizabeth G.},
	month = dec,
	year = {2012},
	pmid = {22741572},
	pmcid = {PMC3495119},
	pages = {436--444}
}

@article{taylor_tools_2011,
	title = {Tools for {Studying} {Biomechanical} {Interactions} in {Cells}},
	url = {http://link-1springer-1com-1springer.han.technikum-wien.at/chapter/10.1007/978-1-4419-8083-0_11},
	doi = {10.1007/978-1-4419-8083-0_11},
	language = {en},
	urldate = {2017-01-03},
	author = {Taylor, Rebecca E. and Mukundan, Vikram and Pruitt, Beth L.},
	year = {2011},
	pages = {233--265}
}

@article{guilak_viscoelastic_2000,
	title = {Viscoelastic properties of the cell nucleus},
	volume = {269},
	issn = {0006-291X},
	doi = {10.1006/bbrc.2000.2360},
	abstract = {Mechanical factors play an important role in the regulation of cell physiology. One pathway by which mechanical stress may influence gene expression is through a direct physical connection from the extracellular matrix across the plasma membrane and to the nucleus. However, little is known of the mechanical properties or deformation behavior of the nucleus. The goal of this study was to quantify the viscoelastic properties of mechanically and chemically isolated nuclei of articular chondrocytes using micropipet aspiration in conjunction theoretical viscoelastic model. Isolated nuclei behaved as viscoelastic solid materials similar to the cytoplasm, but were 3-4 times stiffer and nearly twice as viscous as the cytoplasm. Quantitative information of the biophysical properties and deformation behavior of the nucleus may provide further insight on the relationships between the stress-strain state of the nucleus and that of the extracellular matrix, as well as potential mechanisms of mechanical signal transduction.},
	language = {eng},
	number = {3},
	journal = {Biochemical and Biophysical Research Communications},
	author = {Guilak, F. and Tedrow, J. R. and Burgkart, R.},
	month = mar,
	year = {2000},
	pmid = {10720492},
	keywords = {Animals, Cartilage, Articular, Cell Fractionation, Cell Nucleus, Cells, Cultured, Elasticity, Multivariate Analysis, Swine, Viscosity},
	pages = {781--786}
}

@article{sear_cytoplasm_2005,
	title = {The cytoplasm of living cells: a functional mixture of thousands of components},
	volume = {17},
	issn = {0953-8984},
	shorttitle = {The cytoplasm of living cells},
	url = {http://stacks.iop.org/0953-8984/17/i=45/a=052},
	doi = {10.1088/0953-8984/17/45/052},
	abstract = {Inside every living cell is the cytoplasm: a fluid mixture of thousands of different macromolecules, predominantly proteins. This mixture is where most of the biochemistry occurs that enables living cells to function, and it is perhaps the most complex liquid on earth. Here we take an inventory of what is actually in this mixture. Recent genome-sequencing work has given us for the first time at least some information on all of these thousands of components. Having done so we consider two physical phenomena in the cytoplasm: diffusion and possible phase separation. Diffusion is slower in the highly crowded cytoplasm than in dilute solution. Reasonable estimates of this slow-down can be obtained and their consequences explored; for example, monomer–dimer equilibria are established approximately 20 times more slowly than in a dilute solution. Phase separation in all except exceptional cells appears not to be a problem, despite the high density and so strong protein–protein interactions present. We suggest that this may be partially a by-product of the evolution of other properties, and partially a result of the huge number of components present.},
	language = {en},
	number = {45},
	urldate = {2017-01-03},
	journal = {Journal of Physics: Condensed Matter},
	author = {Sear, Richard P.},
	year = {2005},
	pages = {S3587}
}

@article{luby-phelps_cytoarchitecture_2000,
	title = {Cytoarchitecture and physical properties of cytoplasm: volume, viscosity, diffusion, intracellular surface area},
	volume = {192},
	issn = {0074-7696},
	shorttitle = {Cytoarchitecture and physical properties of cytoplasm},
	abstract = {Classical biochemistry is founded on several assumptions valid in dilute aqueous solutions that are often extended without question to the interior milieu of intact cells. In the first section of this chapter, we present these assumptions and briefly examine the ways in which the cell interior may depart from the conditions of an ideal solution. In the second section, we summarize experimental evidence regarding the physical properties of the cell cytoplasm and their effect on the diffusion and binding of macromolecules and vesicles. While many details remain to be worked out, it is clear that the aqueous phase of the cytoplasm is crowded rather than dilute, and that the diffusion and partitioning of macromolecules and vesicles in cytoplasm is highly restricted by steric hindrance as well as by unexpected binding interactions. Furthermore, the enzymes of several metabolic pathways are now known to be organized into structural and functional units with specific localizations in the solid phase, and as much as half the cellular protein content may also be in the solid phase.},
	language = {eng},
	journal = {International Review of Cytology},
	author = {Luby-Phelps, K.},
	year = {2000},
	pmid = {10553280},
	keywords = {Animals, Cytoplasm, Diffusion, Humans, Macromolecular Substances, Models, Biological, Proteins, Solutions, Surface Properties, Viscosity, Water},
	pages = {189--221}
}

@article{ofek_situ_2009,
	title = {In situ {Mechanical} {Properties} of the {Chondrocyte} {Cytoplasm} and {Nucleus}},
	volume = {42},
	issn = {0021-9290},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2671568/},
	doi = {10.1016/j.jbiomech.2009.01.024},
	abstract = {The way in which the nucleus experiences mechanical forces has important implications for understanding mechanotransduction. Knowledge of nuclear material properties and, specifically, their relationship to the properties of the bulk cell can help determine if the nucleus directly experiences mechanical load, or if it is signal transduction secondary to cell membrane deformation that leads to altered gene expression. Prior work measuring nuclear material properties using micropipette aspiration suggests that the nucleus is substantially stiffer than the bulk cell (), whereas recent work with unconfined compression of single chondrocytes showed a nearly one-to-one correlation between cellular and nuclear strains (). In this study, a linearly elastic finite element model of the cell with a nuclear inclusion was used to simulate the unconfined compression data. Cytoplasmic and nuclear stiffnesses were varied from 1 to 7 kPa for several combinations of cytoplasmic and nuclear Poisson’s ratios. It was found that the experimental data were best fit when the ratio of cytoplasmic to nuclear stiffness was 1.4, and both cytoplasm and nucleus were modeled as incompressible. The cytoplasmic to nuclear stiffness ratio is significantly lower than prior reports for isolated nuclei. These results suggest the nucleus may behave mechanically different in situ than when isolated.},
	number = {7},
	urldate = {2017-01-03},
	journal = {Journal of biomechanics},
	author = {Ofek, Gidon and Natoli, Roman M. and Athanasiou, Kyriacos A.},
	month = may,
	year = {2009},
	pmid = {19261283},
	pmcid = {PMC2671568},
	pages = {873--877}
}

@article{mcgarry_three-dimensional_2004,
	title = {A three-dimensional finite element model of an adherent eukaryotic cell},
	volume = {7},
	issn = {1473-2262},
	url = {https://www.researchgate.net/publication/8608977_A_three-dimensional_finite_element_model_of_an_adherent_eukaryotic_cell},
	doi = {10.22203/eCM.v007a03},
	abstract = {Official Full-Text Publication: A three-dimensional finite element model of an adherent eukaryotic cell on ResearchGate, the professional network for scientists.},
	urldate = {2017-01-05},
	journal = {ResearchGate},
	author = {McGarry, J. G. and Prendergast, P. J.},
	month = may,
	year = {2004},
	pmid = {15095253},
	pages = {27--33; discussion 33--4}
}

@article{dokukina_model_2010,
	title = {A {Model} of {Fibroblast} {Motility} on {Substrates} with {Different} {Rigidities}},
	volume = {98},
	issn = {0006-3495},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2884250/},
	doi = {10.1016/j.bpj.2010.03.026},
	abstract = {To function efficiently in the body, the biological cells must have the ability to sense the external environment. Mechanosensitivity toward the extracellular matrix was identified as one of the sensing mechanisms affecting cell behavior. It was shown experimentally that a fibroblast cell prefers locomoting over the stiffer substrate when given a choice between a softer and a stiffer substrate. In this article, we develop a discrete model of fibroblast motility with substrate-rigidity sensing. Our model allows us to understand the interplay between the cell-substrate sensing and the cell biomechanics. The model cell exhibits experimentally observed substrate rigidity sensing, which allows us to gain additional insights into the cell mechanosensitivity.},
	number = {12},
	urldate = {2017-01-06},
	journal = {Biophysical Journal},
	author = {Dokukina, Irina V. and Gracheva, Maria E.},
	month = jun,
	year = {2010},
	pmid = {20550891},
	pmcid = {PMC2884250},
	pages = {2794--2803}
}

@article{paul_propagation_2008,
	title = {Propagation of {Mechanical} {Stress} through the {Actin} {Cytoskeleton} toward {Focal} {Adhesions}: {Model} and {Experiment}},
	volume = {94},
	issn = {0006-3495},
	shorttitle = {Propagation of {Mechanical} {Stress} through the {Actin} {Cytoskeleton} toward {Focal} {Adhesions}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2212708/},
	doi = {10.1529/biophysj.107.108688},
	abstract = {We investigate both theoretically and experimentally how stress is propagated through the actin cytoskeleton of adherent cells and consequentially distributed at sites of focal adhesions (FAs). The actin cytoskeleton is modeled as a two-dimensional cable network with different lattice geometries. Both prestrain, resulting from actomyosin contractility, and central application of external force, lead to finite forces at the FAs that are largely independent of the lattice geometry, but strongly depend on the exact spatial distribution of the FAs. The simulation results compare favorably with experiments with adherent fibroblasts onto which lateral force is exerted using a microfabricated pillar. For elliptical cells, central application of external force along the long axis leads to two large stress regions located obliquely opposite to the pulling direction. For elliptical cells pulled along the short axis as well as for circular cells, there is only one region of large stress opposite to the direction of pull. If in the computer simulations FAs are allowed to rupture under force for elliptically elongated and circular cell shapes, then morphologies arise which are typical for migrating fibroblasts and keratocytes, respectively. The same effect can be obtained also by internally generated force, suggesting a mechanism by which cells can control their migration morphologies.},
	number = {4},
	urldate = {2017-01-06},
	journal = {Biophysical Journal},
	author = {Paul, Raja and Heil, Patrick and Spatz, Joachim P. and Schwarz, Ulrich S.},
	month = feb,
	year = {2008},
	pmid = {17933882},
	pmcid = {PMC2212708},
	pages = {1470--1482}
}

@article{legant_measurement_2010,
	title = {Measurement of mechanical tractions exerted by cells in three-dimensional matrices},
	volume = {7},
	copyright = {© 2010 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1548-7091},
	url = {http://www.nature.com/nmeth/journal/v7/n12/abs/nmeth.1531.html},
	doi = {10.1038/nmeth.1531},
	abstract = {Quantitative measurements of cell-generated forces have heretofore required that cells be cultured on two-dimensional substrates. We describe a technique to quantitatively measure three-dimensional traction forces exerted by cells fully encapsulated in well-defined elastic hydrogel matrices. Using this approach we measured traction forces for several cell types in various contexts and revealed patterns of force generation attributable to morphologically distinct regions of cells as they extend into the surrounding matrix.},
	language = {en},
	number = {12},
	urldate = {2016-12-09},
	journal = {Nature Methods},
	author = {Legant, Wesley R. and Miller, Jordan S. and Blakely, Brandon L. and Cohen, Daniel M. and Genin, Guy M. and Chen, Christopher S.},
	month = dec,
	year = {2010},
	keywords = {Abaqus, Adhesion, Biophysical methods, Biophysics, Cell biology, FEM, Traction},
	pages = {969--971}
}

@article{maskarinec_quantifying_2009,
	title = {Quantifying cellular traction forces in three dimensions},
	volume = {106},
	issn = {0027-8424},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2799761/},
	doi = {10.1073/pnas.0904565106},
	abstract = {Cells engage in mechanical force exchange with their extracellular environment through tension generated by the cytoskeleton. A method combining laser scanning confocal microscopy (LSCM) and digital volume correlation (DVC) enables tracking and quantification of cell-mediated deformation of the extracellular matrix in all three spatial dimensions. Time-lapse confocal imaging of migrating 3T3 fibroblasts on fibronectin (FN)-modified polyacrylamide gels of varying thickness reveals significant in-plane (x, y) and normal (z) displacements, and illustrates the extent to which cells, even in nominally two-dimensional (2-D) environments, explore their surroundings in all three dimensions. The magnitudes of the measured displacements are independent of the elastic moduli of the gels. Analysis of the normal displacement profiles suggests that normal forces play important roles even in 2-D cell migration.},
	number = {52},
	urldate = {2017-01-09},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Maskarinec, Stacey A. and Franck, Christian and Tirrell, David A. and Ravichandran, Guruswami},
	month = dec,
	year = {2009},
	pmid = {20018765},
	pmcid = {PMC2799761},
	keywords = {Adhesion, Cell, Traction},
	pages = {22108--22113}
}

@article{del_alamo_three-dimensional_2013,
	title = {Three-{Dimensional} {Quantification} of {Cellular} {Traction} {Forces} and {Mechanosensing} of {Thin} {Substrata} by {Fourier} {Traction} {Force} {Microscopy}},
	volume = {8},
	issn = {1932-6203},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3762859/},
	doi = {10.1371/journal.pone.0069850},
	abstract = {We introduce a novel three-dimensional (3D) traction force microscopy (TFM) method motivated by the recent discovery that cells adhering on plane surfaces exert both in-plane and out-of-plane traction stresses. We measure the 3D deformation of the substratum on a thin layer near its surface, and input this information into an exact analytical solution of the elastic equilibrium equation. These operations are performed in the Fourier domain with high computational efficiency, allowing to obtain the 3D traction stresses from raw microscopy images virtually in real time. We also characterize the error of previous two-dimensional (2D) TFM methods that neglect the out-of-plane component of the traction stresses. This analysis reveals that, under certain combinations of experimental parameters (cell size, substratums' thickness and Poisson's ratio), the accuracy of 2D TFM methods is minimally affected by neglecting the out-of-plane component of the traction stresses. Finally, we consider the cell's mechanosensing of substratum thickness by 3D traction stresses, finding that, when cells adhere on thin substrata, their out-of-plane traction stresses can reach four times deeper into the substratum than their in-plane traction stresses. It is also found that the substratum stiffness sensed by applying out-of-plane traction stresses may be up to 10 times larger than the stiffness sensed by applying in-plane traction stresses.},
	number = {9},
	urldate = {2017-01-09},
	journal = {PLoS ONE},
	author = {del Álamo, Juan C. and Meili, Ruedi and Álvarez-González, Begoña and Alonso-Latorre, Baldomero and Bastounis, Effie and Firtel, Richard and Lasheras, Juan C.},
	month = sep,
	year = {2013},
	pmid = {24023712},
	pmcid = {PMC3762859}
}

@article{chan_equilibrium_1999,
	title = {An equilibrium model of endothelial cell adhesion via integrin-dependent and integrin-independent ligands},
	volume = {20},
	issn = {0142-9612},
	url = {http://www.sciencedirect.com/science/article/pii/S0142961299001672},
	doi = {10.1016/S0142-9612(99)00167-2},
	abstract = {Endothelial cell adhesion can be enhanced by supplementing integrin-mediated adhesion via fibronectin with the high-affinity avidin–biotin system in which biotin is covalently linked to membrane proteins and avidin binds to biotinylated surfaces (Bhat et al. J Biomed Mater Res 1998;41:377–85). An equilibrium model was extended to explain detachment of spreading cells following exposure to flow for this two ligand system. The two different receptor–ligand systems were treated as springs in parallel in which the equilibrium dissociation constant was a function of the separation distance of the cell from the surface. Flow experiments were performed to measure the endothelial cell adhesion strength as a function of the extent of biotinylation of the endothelium. Surfaces contained adsorbed fibronectin, avidin or both ligands. The contact area between the cell membrane and substrate was measured using total internal reflection fluorescence microscopy. Estimates of the unstressed dissociation constant for fibronectin and avidin were determined from data for adhesion strength and contact area of each ligand separately. Using these unstressed equilibrium constants, the model predicted, with reasonable accuracy, the strength of endothelial cell adhesion to surfaces containing fibronectin and avidin. The results indicate that as the extent of biotinylation increases, the avidin–biotin system contributes a larger fraction of the total adhesion strength but the maximum contribution of the avidin–biotin system is less than 50\%. The magnitude of the affinity constant and force per bond for the avidin–biotin system are consistent with detachment by extraction of receptors from the cell. The resulting increase in the adhesion strength on surfaces with both avidin–biotin and fibronectin is due to the increase in contact area and the larger number of bonds formed.},
	number = {23–24},
	urldate = {2017-01-09},
	journal = {Biomaterials},
	author = {Chan, Bernard P and Bhat, Vinayak D and Yegnasubramanian, Srinivasan and Reichert, William M and Truskey, George A},
	month = dec,
	year = {1999},
	keywords = {Adhesion strength, Cell adhesion, Total internal fluorescence},
	pages = {2395--2403}
}

@article{wang_cell_2002,
	title = {Cell prestress. {I}. {Stiffness} and prestress are closely associated in adherent contractile cells},
	volume = {282},
	issn = {0363-6143},
	doi = {10.1152/ajpcell.00269.2001},
	abstract = {The tensegrity hypothesis holds that the cytoskeleton is a structure whose shape is stabilized predominantly by the tensile stresses borne by filamentous structures. Accordingly, cell stiffness must increase in proportion with the level of the tensile stress, which is called the prestress. Here we have tested that prediction in adherent human airway smooth muscle (HASM) cells. Traction microscopy was used to measure the distribution of contractile stresses arising at the interface between each cell and its substrate; this distribution is called the traction field. Because the traction field must be balanced by tensile stresses within the cell body, the prestress could be computed. Cell stiffness (G) was measured by oscillatory magnetic twisting cytometry. As the contractile state of the cell was modulated with graded concentrations of relaxing or contracting agonists (isoproterenol or histamine, respectively), the mean prestress ((t)) ranged from 350 to 1,900 Pa. Over that range, cell stiffness increased linearly with the prestress: G (Pa) = 0.18(t) + 92. While this association does not necessarily preclude other interpretations, it is the hallmark of systems that secure shape stability mainly through the prestress. Regardless of mechanism, these data establish a strong association between stiffness of HASM cells and the level of tensile stress within the cytoskeleton.},
	language = {eng},
	number = {3},
	journal = {American Journal of Physiology. Cell Physiology},
	author = {Wang, Ning and Tolić-Nørrelykke, Iva Marija and Chen, Jianxin and Mijailovich, Srboljub M. and Butler, James P. and Fredberg, Jeffrey J. and Stamenović, Dimitrije},
	month = mar,
	year = {2002},
	pmid = {11832346},
	keywords = {Acrylic Resins, Actins, Cell adhesion, Cells, Cultured, Cytoskeleton, Histamine, Humans, Isoproterenol, Muscle Contraction, Muscle, Smooth, NASA Discipline Cell Biology, Non-NASA Center, Stress, Mechanical, Tensile Strength},
	pages = {C606--616}
}

@article{maskarinec_quantifying_2009-1,
	title = {Quantifying cellular traction forces in three dimensions},
	volume = {106},
	issn = {0027-8424},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2799761/},
	doi = {10.1073/pnas.0904565106},
	abstract = {Cells engage in mechanical force exchange with their extracellular environment through tension generated by the cytoskeleton. A method combining laser scanning confocal microscopy (LSCM) and digital volume correlation (DVC) enables tracking and quantification of cell-mediated deformation of the extracellular matrix in all three spatial dimensions. Time-lapse confocal imaging of migrating 3T3 fibroblasts on fibronectin (FN)-modified polyacrylamide gels of varying thickness reveals significant in-plane (x, y) and normal (z) displacements, and illustrates the extent to which cells, even in nominally two-dimensional (2-D) environments, explore their surroundings in all three dimensions. The magnitudes of the measured displacements are independent of the elastic moduli of the gels. Analysis of the normal displacement profiles suggests that normal forces play important roles even in 2-D cell migration.},
	number = {52},
	urldate = {2017-01-10},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Maskarinec, Stacey A. and Franck, Christian and Tirrell, David A. and Ravichandran, Guruswami},
	month = dec,
	year = {2009},
	pmid = {20018765},
	pmcid = {PMC2799761},
	pages = {22108--22113}
}

@article{wang_integrins_2016,
	title = {Integrins outside focal adhesions transmit tensions during stable cell adhesion},
	volume = {6},
	issn = {2045-2322},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5109487/},
	doi = {10.1038/srep36959},
	abstract = {Integrins coupled with other proteins form protein complexes named focal adhesions (FA) which are considered as the primary sites for cellular forces transduction during cell stable adhesion. Cell traction forces transmitted by FAs and integrin tensions inside FAs have been extensively studied. However, it remains unknown whether integrins outside FAs can transmit tension, and if so, what is the tension range. We previously developed a tension sensor named tension gauge tether (TGT). To calibrate integrin tensions outside FAs, here we applied multiplex TGT (mTGT) to simultaneously monitor integrin tensions at separate levels. mTGT unambiguously revealed that integrins outside FAs also transmit tension after FA formation. These tensions are mainly located in the range of 43 {\textasciitilde} 54 pN which is lower than integrin tensions inside FAs. Integrin tensions both inside and outside FAs substantially contribute to bulk cellular forces and they respond independently to actin and myosin II inhibition, serum deprivation and microtubule inhibition, indicating their different tension sources and independent dynamics. Our work identified integrin tensions outside FAs and calibrated the tension range for the first time. We also demonstrated that mTGT is a valuable tool to monitor integrin tension profile in a broad detection range of 10 {\textasciitilde} 60 pN.},
	urldate = {2017-01-10},
	journal = {Scientific Reports},
	author = {Wang, Yongliang and Wang, Xuefeng},
	month = nov,
	year = {2016},
	pmid = {27845380},
	pmcid = {PMC5109487}
}

@article{kim_three-dimensional_2016,
	title = {Three-{Dimensional} {Reflectance} {Traction} {Microscopy}},
	volume = {11},
	issn = {1932-6203},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4909212/},
	doi = {10.1371/journal.pone.0156797},
	abstract = {Cells in three-dimensional (3D) environments exhibit very different biochemical and biophysical phenotypes compared to the behavior of cells in two-dimensional (2D) environments. As an important biomechanical measurement, 2D traction force microscopy can not be directly extended into 3D cases. In order to quantitatively characterize the contraction field, we have developed 3D reflectance traction microscopy which combines confocal reflection imaging and partial volume correlation postprocessing. We have measured the deformation field of collagen gel under controlled mechanical stress. We have also characterized the deformation field generated by invasive breast cancer cells of different morphologies in 3D collagen matrix. In contrast to employ dispersed tracing particles or fluorescently-tagged matrix proteins, our methods provide a label-free, computationally effective strategy to study the cell mechanics in native 3D extracellular matrix.},
	number = {6},
	urldate = {2017-01-10},
	journal = {PLoS ONE},
	author = {Kim, Jihan and Jones, Christopher A. R. and Groves, Nicholas Scott and Sun, Bo},
	month = jun,
	year = {2016},
	pmid = {27304456},
	pmcid = {PMC4909212}
}

@article{ahmad_khalili_review_2015,
	title = {A {Review} of {Cell} {Adhesion} {Studies} for {Biomedical} and {Biological} {Applications}},
	volume = {16},
	issn = {1422-0067},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4581240/},
	doi = {10.3390/ijms160818149},
	abstract = {Cell adhesion is essential in cell communication and regulation, and is of fundamental importance in the development and maintenance of tissues. The mechanical interactions between a cell and its extracellular matrix (ECM) can influence and control cell behavior and function. The essential function of cell adhesion has created tremendous interests in developing methods for measuring and studying cell adhesion properties. The study of cell adhesion could be categorized into cell adhesion attachment and detachment events. The study of cell adhesion has been widely explored via both events for many important purposes in cellular biology, biomedical, and engineering fields. Cell adhesion attachment and detachment events could be further grouped into the cell population and single cell approach. Various techniques to measure cell adhesion have been applied to many fields of study in order to gain understanding of cell signaling pathways, biomaterial studies for implantable sensors, artificial bone and tooth replacement, the development of tissue-on-a-chip and organ-on-a-chip in tissue engineering, the effects of biochemical treatments and environmental stimuli to the cell adhesion, the potential of drug treatments, cancer metastasis study, and the determination of the adhesion properties of normal and cancerous cells. This review discussed the overview of the available methods to study cell adhesion through attachment and detachment events.},
	number = {8},
	urldate = {2017-01-10},
	journal = {International Journal of Molecular Sciences},
	author = {Ahmad Khalili, Amelia and Ahmad, Mohd Ridzuan},
	month = aug,
	year = {2015},
	pmid = {26251901},
	pmcid = {PMC4581240},
	pages = {18149--18184}
}
@article{wang_hidden_2016,
	title = {Hidden in the mist no more: physical force in cell biology},
	volume = {13},
	issn = {1548-7091},
	shorttitle = {Hidden in the mist no more},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4861038/},
	doi = {10.1038/nmeth.3744},
	abstract = {To drive its migration through a fibrillar matrix—and thus to spread, invade or metastasize—a cancer cell must exert physical forces. The first visualization of these forces in three dimensions reveals surprising migration dynamics.},
	number = {2},
	urldate = {2017-01-10},
	journal = {Nature methods},
	author = {Wang, Karin and Cai, Li-Heng and Lan, Bo and Fredberg, Jeffrey J},
	month = feb,
	year = {2016},
	pmid = {26820546},
	pmcid = {PMC4861038},
	pages = {124--125}
}

@article{kyburz_synthetic_2015,
	title = {Synthetic {Mimics} of the {Extracellular} {Matrix}: {How} {Simple} is {Complex} {Enough}?},
	volume = {43},
	issn = {0090-6964},
	shorttitle = {Synthetic {Mimics} of the {Extracellular} {Matrix}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4380864/},
	doi = {10.1007/s10439-015-1297-4},
	abstract = {Cells reside in a complex and dynamic extracellular matrix where they interact with a myriad of biophysical and biochemical cues that direct their function and regulate tissue homeostasis, wound repair, and even pathophysiological events. There is a desire in the biomaterials community to develop synthetic hydrogels to recapitulate facets of the ECM for in vitro culture platforms and tissue engineering applications. Advances in synthetic hydrogel design and chemistries, including user-tunable platforms, have broadened the field’s understanding of the role of matrix cues in directing cellular processes and enabled the design of improved tissue engineering scaffolds. This review focuses on recent advances in the development and fabrication of hydrogels and discusses what aspects of ECM signals can be incorporated to direct cell function in different contexts.},
	number = {3},
	urldate = {2017-01-10},
	journal = {Annals of biomedical engineering},
	author = {Kyburz, Kyle A. and Anseth, Kristi S.},
	month = mar,
	year = {2015},
	pmid = {25753017},
	pmcid = {PMC4380864},
	pages = {489--500}
}

@article{zhou_measurement_2015,
	title = {Measurement {Systems} for {Cell} {Adhesive} {Forces}},
	volume = {137},
	issn = {0148-0731},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4347357/},
	doi = {10.1115/1.4029210},
	abstract = {Cell adhesion to the extracellular matrix (ECM) involves integrin receptor–ligand binding and clustering to form focal adhesion (FA) complexes, which mechanically link the cell’s cytoskeleton to the ECM and regulate fundamental cell signaling pathways. Although elucidation of the biochemical events in cell-matrix adhesive interactions is rapidly advancing, recent studies show that the forces underlying cell-matrix adhesive interactions are also critical to cell responses. Therefore, multiple measurement systems have been developed to quantify the spatial and temporal dynamics of cell adhesive forces, and these systems have identified how mechanical events influence cell phenotype and FA structure–function relationships under physiological and pathological settings. This review focuses on the development, methodology, and applications of measurement systems for probing (a) cell adhesion strength and (b) 2D and 3D cell traction forces.},
	number = {2},
	urldate = {2017-01-10},
	journal = {Journal of Biomechanical Engineering},
	author = {Zhou, Dennis W. and García, Andrés J.},
	month = feb,
	year = {2015},
	pmid = {25416835},
	pmcid = {PMC4347357},
	pages = {0209081--0209088}
}

@article{moeendarbary_cell_2014,
	title = {Cell mechanics: principles, practices, and prospects},
	volume = {6},
	issn = {1939-5094},
	shorttitle = {Cell mechanics},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4309479/},
	doi = {10.1002/wsbm.1275},
	abstract = {Cells generate and sustain mechanical forces within their environment as part of their normal physiology. They are active materials that can detect mechanical stimulation by the activation of mechanosensitive signaling pathways, and respond to physical cues through cytoskeletal re-organization and force generation. Genetic mutations and pathogens that disrupt the cytoskeletal architecture can result in changes to cell mechanical properties such as elasticity, adhesiveness, and viscosity. On the other hand, perturbations to the mechanical environment can affect cell behavior. These transformations are often a hallmark and symptom of a variety of pathologies. Consequently, there are now a myriad of experimental techniques and theoretical models adapted from soft matter physics and mechanical engineering to characterize cell mechanical properties. Interdisciplinary research combining modern molecular biology with advanced cell mechanical characterization techniques now paves the way for furthering our fundamental understanding of cell mechanics and its role in development, physiology, and disease. We describe a generalized outline for measuring cell mechanical properties including loading protocols, tools, and data interpretation. We summarize recent advances in the field and explain how cell biomechanics research can be adopted by physicists, engineers, biologists, and clinicians alike.},
	number = {5},
	urldate = {2017-01-10},
	journal = {Wiley Interdisciplinary Reviews. Systems Biology and Medicine},
	author = {Moeendarbary, Emad and Harris, Andrew R},
	month = sep,
	year = {2014},
	pmid = {25269160},
	pmcid = {PMC4309479},
	pages = {371--388}
}

@article{chan_equilibrium_1999,
	title = {An equilibrium model of endothelial cell adhesion via integrin-dependent and integrin-independent ligands},
	volume = {20},
	issn = {0142-9612},
	url = {http://www.sciencedirect.com/science/article/pii/S0142961299001672},
	doi = {10.1016/S0142-9612(99)00167-2},
	abstract = {Endothelial cell adhesion can be enhanced by supplementing integrin-mediated adhesion via fibronectin with the high-affinity avidin–biotin system in which biotin is covalently linked to membrane proteins and avidin binds to biotinylated surfaces (Bhat et al. J Biomed Mater Res 1998;41:377–85). An equilibrium model was extended to explain detachment of spreading cells following exposure to flow for this two ligand system. The two different receptor–ligand systems were treated as springs in parallel in which the equilibrium dissociation constant was a function of the separation distance of the cell from the surface. Flow experiments were performed to measure the endothelial cell adhesion strength as a function of the extent of biotinylation of the endothelium. Surfaces contained adsorbed fibronectin, avidin or both ligands. The contact area between the cell membrane and substrate was measured using total internal reflection fluorescence microscopy. Estimates of the unstressed dissociation constant for fibronectin and avidin were determined from data for adhesion strength and contact area of each ligand separately. Using these unstressed equilibrium constants, the model predicted, with reasonable accuracy, the strength of endothelial cell adhesion to surfaces containing fibronectin and avidin. The results indicate that as the extent of biotinylation increases, the avidin–biotin system contributes a larger fraction of the total adhesion strength but the maximum contribution of the avidin–biotin system is less than 50\%. The magnitude of the affinity constant and force per bond for the avidin–biotin system are consistent with detachment by extraction of receptors from the cell. The resulting increase in the adhesion strength on surfaces with both avidin–biotin and fibronectin is due to the increase in contact area and the larger number of bonds formed.},
	number = {23–24},
	urldate = {2017-01-10},
	journal = {Biomaterials},
	author = {Chan, Bernard P and Bhat, Vinayak D and Yegnasubramanian, Srinivasan and Reichert, William M and Truskey, George A},
	month = dec,
	year = {1999},
	keywords = {Adhesion strength, Cell adhesion, Total internal fluorescence},
	pages = {2395--2403}
}

@article{robinson_extracellular_2005,
	title = {Extracellular {Matrix} {Scaffold} for {Cardiac} {Repair}},
	volume = {112},
	copyright = {© 2005},
	issn = {0009-7322, 1524-4539},
	url = {http://circ.ahajournals.org/content/112/9_suppl/I-135},
	doi = {10.1161/CIRCULATIONAHA.104.525436},
	abstract = {Background— Heart failure remains a significant problem. Tissue-engineered cardiac patches offer potential to treat severe heart failure. We studied an extracellular matrix scaffold for repairing the infarcted left ventricle.
Methods and Results— Pigs (n=42) underwent left ventricular (LV) infarction. At 6 to 8 weeks, either 4-layer multilaminate urinary bladder-derived extracellular matrix or expanded polytetrafluoroethlyene (ePTFE) was implanted as full-thickness LV wall patch replacement. At 1-week, 1-month, or 3-month intervals, pigs were terminated. After macroscopic examination, samples of tissue were prepared for histology, immunocytochemistry, and analysis of cell proportions by flow cytometry. One-week and 1-month patches were intact with thrombus and inflammation; at 1 month, there was also tissue with spindle-shaped cells in proteoglycan-rich and collagenous matrix. More α-smooth muscle actin-positive cells were present in urinary bladder matrix (UBM) than in ePTFE (22.2±3.3\% versus 8.4±2.7\%; P=0.04). At 3 months, UBM was bioresorbed, and a collagen-rich vascularized tissue with numerous myofibroblasts was present. Isolated regions of α-sarcomeric actin-positive, intensely α-smooth muscle actin-immunopositive, and striated cells were observed. ePTFE at 3 months had foreign-body response with necrosis and calcification. Flow cytometry showed similarities of cells from UBM to normal myocardium, whereas ePTFE had limited cardiomyocyte markers.
Conclusions— Appearance of a fibrocellular tissue that included contractile cells accompanied biodegradation of UBM when implanted as an LV-free wall infarction patch. UBM appears superior to synthetic material for cardiac patching and trends toward myocardial replacement at 3 months.},
	language = {en},
	number = {9 suppl},
	urldate = {2017-01-18},
	journal = {Circulation},
	author = {Robinson, Keith A. and Li, Jinshen and Mathison, Megumi and Redkar, Alka and Cui, Jianhua and Chronos, Nicolas A. F. and Matheny, Robert G. and Badylak, Stephen F.},
	month = aug,
	year = {2005},
	pmid = {16159805},
	keywords = {Tissue Engineering, heart failure, surgery},
	pages = {I--135--I--143}
}

@article{bellamy_long-term_2015,
	title = {Long-term functional benefits of human embryonic stem cell-derived cardiac progenitors embedded into a fibrin scaffold},
	volume = {34},
	issn = {1053-2498},
	url = {http://www.sciencedirect.com/science/article/pii/S1053249814014326},
	doi = {10.1016/j.healun.2014.10.008},
	abstract = {Background
Cardiac-committed cells and biomimetic scaffolds independently improve the therapeutic efficacy of stem cells. In this study we tested the long-term effects of their combination.
Methods
Eighty immune-deficient rats underwent permanent coronary artery ligation. Five to 7 weeks later, those with an echocardiographically measured ejection fraction (EF) ≤55\% were re-operated on and randomly allocated to receive a cell-free fibrin patch (n = 25), a fibrin patch loaded with 700,000 human embryonic stem cells (ESC) pre-treated to promote early cardiac differentiation (SSEA-1+ progenitors [n = 30]), or to serve as sham-operated animals (n = 25). Left ventricular function was assessed by echocardiography at baseline and every month thereafter until 4 months. Hearts were then processed for assessment of fibrosis and angiogenesis and a 5-component heart failure score was constructed by integrating the absolute change in left ventricular end-systolic volume (LVESV) between 4 months and baseline, and the quantitative polymerase chain reaction (qPCR)-based expression of natriuretic peptides A and B, myosin heavy chain 7 and periostin. All data were recorded and analyzed in a blinded manner.
Results
The cell-treated group consistently yielded better functional outcomes than the sham-operated group (p = 0.002 for EF; p = 0.01 for LVESV). Angiogenesis in the border zone was also significantly greater in the cell-fibrin group (p = 0.006), which yielded the lowest heart failure score (p = 0.04 vs sham). Engrafted progenitors were only detected shortly after transplantation; no grafted cells were identified after 4 months. There was no teratoma identified.
Conclusions
A fibrin scaffold loaded with ESC-derived cardiac progenitors resulted in sustained improvement in contractility and attenuation of remodeling without sustained donor cell engraftment. A paracrine effect, possibly on innate reparative responses, is a possible mechanism for this enduring effect.},
	number = {9},
	urldate = {2017-01-18},
	journal = {The Journal of Heart and Lung Transplantation},
	author = {Bellamy, Valérie and Vanneaux, Valérie and Bel, Alain and Nemetalla, Hany and Emmanuelle Boitard, Solène and Farouz, Yohan and Joanne, Pierre and Perier, Marie-Cécile and Robidel, Estelle and Mandet, Chantal and Hagège, Albert and Bruneval, Patrick and Larghero, Jérôme and Agbulut, Onnik and Menasché, Philippe},
	month = sep,
	year = {2015},
	keywords = {Stem cells, Tissue Engineering, cardiac patches, cardiac progenitors, cell transplantation, embryonic stem cells, heart failure},
	pages = {1198--1207}
}

@article{gao_myocardial_2017,
	title = {Myocardial {Tissue} {Engineering} {With} {Cells} {Derived} from {Human} {Induced}-{Pluripotent} {Stem} {Cells} and a {Native}-{Like}, {High}-{Resolution}, 3-{Dimensionally} {Printed} {Scaffold}},
	issn = {1524-4571},
	doi = {10.1161/CIRCRESAHA.116.310277},
	abstract = {RATIONALE: Conventional three-dimensional (3D) printing techniques cannot produce structures of the size at which individual cells interact.
OBJECTIVE: Here, we used multiphoton-excited, 3-dimensional printing (MPE-3DP) to generate a native-like, extracellular matrix (ECM) scaffold with submicron resolution, and then seeded the scaffold with cardiomyocytes (CMs), smooth-muscle cells (SMCs), and endothelial cells (ECs) that had been differentiated from human induced-pluripotent stem cells (iPSCs) to generate a human, iPSC-derived cardiac muscle patch (hCMP), which was subsequently evaluated in a murine model of myocardial infarction (MI).
METHODS AND RESULTS: The scaffold was seeded with {\textasciitilde}50,000 human, iPSC-derived CMs, SMCs, and ECs (in a 2:1:1 ratio) to generate the hCMP, which began generating calcium transients and beating synchronously within 1 day of seeding; the speeds of contraction and relaxation and the peak amplitudes of the calcium transients increased significantly over the next 7 days. When tested in mice with surgically induced MI, measurements of cardiac function, infarct size, apoptosis, both vascular and arteriole density, and cell proliferation at week 4 after treatment were significantly better in animals treated with the hCMPs than in animals treated with cell-free scaffolds, and the rate of cell engraftment in hCMP-treated animals was 24.5\% at week 1 and 11.2\% at week 4.
CONCLUSIONS: Thus, the novel MPE-3DP technique produces ECM-based scaffolds with exceptional resolution and fidelity, and hCMPs fabricated with these scaffolds may significantly improve recovery from ischemic myocardial injury.},
	language = {eng},
	journal = {Circulation Research},
	author = {Gao, Ling and Kupfer, Molly and Jung, Jangwook and Yang, Libang and Zhang, Patrick and Sie, Yong and Tran, Quyen and Ajeti, Visar and Freeman, Brian and Fast, Vladimir and Campagnola, Paul and Ogle, Brenda and Zhang, Jianyi},
	month = jan,
	year = {2017},
	pmid = {28069694},
	keywords = {Tissue Engineering, heart, myocardial infarction}
}

@article{tang_regenerative_2017,
	title = {A regenerative cardiac patch formed by spray painting of biomaterials onto the heart},
	issn = {1937-3392},
	doi = {10.1089/ten.TEC.2016.0492},
	abstract = {Layering a regenerative polymer scaffold on the surface of the heart, termed as a cardiac patch, has been proven to be effective in preserving cardiac function after myocardial infarction. However, the placement of such a patch on the heart usually needs open-chest surgery, which is traumatic therefore prevents the translation of this strategy into the clinic. We sought to device a novel method to apply a cardiac patch by spray painting in situ polymerizable biomaterials onto the heart with a minimally invasive procedure. To prove the concept, we used platelet fibrin gel as the "paint" material in a mouse model of myocardial infarction. The use of the spraying system allowed for placement of a uniform cardiac patch on the heart in a mini-invasive fashion without the need for sutures or glue. The spray treatment promoted cardiac repair and attenuated cardiac dysfunction after myocardial infarction.},
	language = {eng},
	journal = {Tissue Engineering. Part C, Methods},
	author = {Tang, Junnan and Vandergriff, Adam and Wang, Zegen and Hensley, Michael and Cores, Jhon and Allen, Tyler and Dinh, Phuong-Uyen and Zhang, Jinying and Caranasos, Thomas and Cheng, Ke},
	month = jan,
	year = {2017},
	pmid = {28068869}
}

@article{wan_human_2017,
	title = {Human heart valve-derived scaffold improves cardiac repair in a murine model of myocardial infarction},
	volume = {7},
	issn = {2045-2322},
	doi = {10.1038/srep39988},
	abstract = {Cardiac tissue engineering using biomaterials with or without combination of stem cell therapy offers a new option for repairing infarcted heart. However, the bioactivity of biomaterials remains to be optimized because currently available biomaterials do not mimic the biochemical components as well as the structural properties of native myocardial extracellular matrix. Here we hypothesized that human heart valve-derived scaffold (hHVS), as a clinically relevant novel biomaterial, may provide the proper microenvironment of native myocardial extracellular matrix for cardiac repair. In this study, human heart valve tissue was sliced into 100 μm tissue sheet by frozen-sectioning and then decellularized to form the hHVS. Upon anchoring onto the hHVS, post-infarct murine BM c-kit+ cells exhibited an increased capacity for proliferation and cardiomyogenic differentiation in vitro. When used to patch infarcted heart in a murine model of myocardial infarction, either implantation of the hHVS alone or c-kit+ cell-seeded hHVS significantly improved cardiac function and reduced infarct size; while c-kit+ cell-seeded hHVS was even superior to the hHVS alone. Thus, we have successfully developed a hHVS for cardiac repair. Our in vitro and in vivo observations provide the first clinically relevant evidence for translating the hHVS-based biomaterials into clinical strategies to treat myocardial infarction.},
	language = {eng},
	journal = {Scientific Reports},
	author = {Wan, Long and Chen, Yao and Wang, Zhenhua and Wang, Weijun and Schmull, Sebastian and Dong, Jun and Xue, Song and Imboden, Hans and Li, Jun},
	month = jan,
	year = {2017},
	pmid = {28051180},
	pmcid = {PMC5209673},
	pages = {39988}
}

@article{oneill_collagen_2016,
	title = {A {Collagen} {Cardiac} {Patch} {Incorporating} {Alginate} {Microparticles} {Permits} the {Controlled} {Release} of {HGF} and {IGF}-1 to {Enhance} {Cardiac} {Stem} {Cell} {Migration} and {Proliferation}},
	issn = {1932-7005},
	doi = {10.1002/term.2392},
	abstract = {Cardiac Stem Cells (CSCs) represent a logical cell type to exploit as a regenerative treatment option for tissue damage accrued as a result of a myocardial infarction (MI). However, the isolation and expansion of CSCs prior to cell transplantation is time-consuming, costly and invasive, and the reliability of cell expansion may also prove to be a major obstacle in the clinical application of CSC based transplantation therapy after a MI. In order to overcome this, we propose the incorporation of growth factor-eluting alginate microparticles (MPs) into collagen-based scaffolds as an implantable biomaterial to promote the recruitment and expansion of CSCs in the myocardium. In order to obtain scaffolds able to enhance the motogenic and proliferative potential of CSCs, the aim of this work was to achieve a sustained delivery of both Hepatocyte Growth Factor (HGF) and Insulin-Like Growth Factor 1 (IGF1). Both proteins were initially encapsulated in alginate MPs by spray-drying and subsequently incorporated into a collagen scaffold. MPs were seen to homogeneously distribute through the interconnected scaffold pore structure. The resulting scaffolds were capable of extending the release of both proteins up to 15 days, a 3-fold increase over non-encapsulated proteins embedded in the scaffolds. In vitro assays with isolated CSCs demonstrated that the sustained release of both bioactive proteins resulted in an increased motogenic and proliferative effect. As presently practiced, the isolation and expansion of CSCs for autologous cell transplantation is slow, expensive and difficult to attain. Thus, there is need for strategies to specifically activate in situ the intrinsic cardiac regenerative potential represented by the CSCs using combinations of growth factors obviating the need for cell transplantation. By favouring the natural regenerative capability of CSCs, it is hypothesised that the cardiac patch presented here will result in positive therapeutic outcomes in myocardial infarction and heart failure patients in the future.},
	language = {eng},
	journal = {Journal of Tissue Engineering and Regenerative Medicine},
	author = {O'Neill, Hugh S. and O'Sullivan, Janice and Porteous, Niamh and Ruiz Hernandez, Eduardo and Kelly, Helena M. and O'Brien, Fergal J. and Duffy, Garry P.},
	month = dec,
	year = {2016},
	pmid = {27943590},
	keywords = {Biomaterials, Cardiac Stem Cells, Controlled release, Growth factor delivery, Microparticles, Tissue engineered scaffolds}
}

@article{dobrilovic_early_2016,
	title = {Early complications of biologic extracellular matrix patch after use for femoral artery repair},
	issn = {1097-6809},
	doi = {10.1016/j.jvs.2016.07.131},
	abstract = {BACKGROUND: The CorMatrix (CorMatrix Cardiovascular, Roswell, Ga) biologic extracellular patch derived from porcine small intestinal mucosa provides a biologic scaffold for cellular ingrowth and eventual tissue regeneration. It has been used in a variety of applications, including cardiac and vascular repair procedures.
METHODS: CorMatrix was used as a patch arterioplasty for femoral artery repair in conjunction with endarterectomy for seven separate procedures in six patients (one patient underwent staged, bilateral femoral procedures).
RESULTS: Patients were a median age of 67 years (interquartile range, 3.6 years). Six of seven procedures (86\%) were performed on male patients. There were no operative deaths. Three of seven procedures (43\%) resulted in significant early complications. Two procedures (29\%) resulted in catastrophic biologic extracellular matrix patch disruption (11 and 19 days after initial procedure), requiring emergency exploration, patch removal, and definitive repair with vein patch arterioplasty. Both patches demonstrated an absence of growth on culture. One procedure (14\%) resulted in groin pseudoaneurysm formation. Use of the CorMatrix patch was suspended upon recognition of significant complications.
CONCLUSIONS: Use of CorMatrix patch in the femoral artery position demonstrates a high incidence of early postoperative complications, including catastrophic patch disruption and pseudoaneurysm formation.},
	language = {eng},
	journal = {Journal of Vascular Surgery},
	author = {Dobrilovic, Nikola and Soukas, Peter and Sadiq, Immad and Goldstein, Lisa and Raman, Jaishankar},
	month = oct,
	year = {2016},
	pmid = {27751739}
}

@article{boccardo_engineered_2016,
	title = {Engineered mesenchymal cell-based patches as controlled {VEGF} delivery systems to induce extrinsic angiogenesis},
	volume = {42},
	issn = {1878-7568},
	doi = {10.1016/j.actbio.2016.07.041},
	abstract = {Therapeutic over-expression of Vascular Endothelial Growth Factor (VEGF) by transduced progenitors is a promising strategy to efficiently induce angiogenesis in ischemic tissues (e.g. limb muscle and myocardium), but tight control over the micro-environmental distribution of the dose is required to avoid induction of angioma-like tumors. Therapeutic VEGF release was achieved by purified transduced adipose mesenchymal stromal cells (ASC) that homogeneously produce specific VEGF levels, inducing only normal angiogenesis after injection in non-ischemic tissues. However, the therapeutic potential of this approach mostly in the cardiac field is limited by the poor cell survival and the restricted area of effect confined to the cell-injection site. The implantation of cells previously organized in vitro in 3D engineered tissues could overcome these issues. Here we hypothesized that collagen sponge-based construct (patch), generated by ASC expressing controlled VEGF levels, can function as delivery device to induce angiogenesis in surrounding areas (extrinsic vascularization). A 7-mm-thick acellular collagen scaffold (empty), sutured beneath the patch, provided a controlled and reproducible model to clearly investigate the ongoing angiogenesis in subcutaneous mice pockets. VEGF-expressing ASC significantly increased the capillary in-growth inside both the patch itself and the empty scaffold compared to naïve cells, leading to significantly improved survival of implanted cells. These data suggest that this strategy confers control (i) on angiogenesis efficacy and safety by means of ASC expressing therapeutic VEGF levels and (ii) over the treated area through the specific localization in an engineered collagen sponge-based patch.
STATEMENT OF SIGNIFICANCE: Development of efficient pro-angiogenic therapies to restore the micro-vascularization in ischemic tissues is still an open issue. Although extensively investigated, the promising approach based on injections of progenitors transduced to over-express Vascular Endothelial Growth Factor (VEGF) has still several limitations: (i) need of a tight control over the microenvironmental VEGF dose to avoid angioma-like tumor growth; (ii) poor implanted cell survival; (iii) effect area restricted mainly to the injection sites. Here, we aimed to overcome these drawbacks by generating a novel cell-based controlled VEGF delivery device. In particular, transduced mesenchymal cells, purified to release a sustained, safe and efficient VEGF dose, were organized in three-dimensional engineered tissues to improve cell survival and provide a uniform vascularization throughout both the mm-thick implanted constructs themselves and the surrounding area.},
	language = {eng},
	journal = {Acta Biomaterialia},
	author = {Boccardo, Stefano and Gaudiello, Emanuele and Melly, Ludovic and Cerino, Giulia and Ricci, Davide and Martin, Ivan and Eckstein, Friedrich and Banfi, Andrea and Marsano, Anna},
	month = sep,
	year = {2016},
	pmid = {27469308},
	keywords = {Angiogenesis, Genetically modified cells, Tissue Engineering, VEGF},
	pages = {127--135}
}

@article{lakshmanan_engineering_2016,
	title = {Engineering a growth factor embedded nanofiber matrix niche to promote vascularization for functional cardiac regeneration},
	volume = {97},
	issn = {1878-5905},
	doi = {10.1016/j.biomaterials.2016.02.033},
	abstract = {The major loss of tissue extracellular matrix (ECM) after myocardial ischemia is a serious burden that gradually leads to heart failure. Due to lack of available treatment methods to restore the cardiac function, various research strategies have come up to treat the ischemic myocardium. However these have met with limited success due to the complexity of the cardiac tissue, which exhibits a nanofibrous collagenous matrix with spatio-temporal localization of a combination of growth factors. To mimic the topographical and chemical cues of the natural cardiac tissue, we have fabricated a growth factor embedded nanofibrous scaffold through electrospinning. In our previous work, we have reported a nanofibrous matrix made of PLCL and PEOz with an average diameter of 500 nm. The scaffold properties were specifically characterized in vitro for cardio-compatibility. In the present study, we have loaded dual growth factors VEGF and bFGF in the nanofiber matrix and investigated its suitability for cardiac tissue engineering. The encapsulation and release of dual growth factors from the matrix were studied using XPS and ELISA. Bioactivity of the loaded growth factors towards proliferation and migration of endothelial cells (HUVECs) was evaluated through MTS and Boyden chamber assays respectively. The efficiency of growth factors on the nanofibrous matrix to activate signaling molecules was studied in HUVECs through gene expression analysis. Preclinical evaluation of the growth factor embedded nanofibrous patch in a rabbit acute myocardial infarction (AMI) model was studied and cardiac function assessment was made through ECG and echocardiography. The evidence for angiogenesis in the patch secured regions was analyzed through histopathology and immunohistochemistry. Our results confirm the effectiveness of growth factor embedded nanofiber matrix in restoration of cardiac function after ischemia when compared to conventional patch material thereby exhibiting promise as a valuable therapeutic solution to treat ischemic disorders.},
	language = {eng},
	journal = {Biomaterials},
	author = {Lakshmanan, Rajesh and Kumaraswamy, Priyadharshini and Krishnan, Uma Maheswari and Sethuraman, Swaminathan},
	month = aug,
	year = {2016},
	pmid = {27177129},
	keywords = {Bioactive cardiac patch, Cardiac regeneration, Growth factors, Nanofibrous, Scaffolds},
	pages = {176--195}
}

@article{roura_fibrin_2016,
	title = {Fibrin, the preferred scaffold for cell transplantation after myocardial infarction? {An} old molecule with a new life},
	issn = {1932-7005},
	shorttitle = {Fibrin, the preferred scaffold for cell transplantation after myocardial infarction?},
	doi = {10.1002/term.2129},
	abstract = {Fibrin is a topical haemostat, sealant and tissue glue, which consists of concentrated fibrinogen and thrombin. It has broad medical and research uses. Recently, several studies have shown that engineered patches comprising mixtures of biological or synthetic materials and progenitor cells showed therapeutic promise for regenerating damaged tissues. In that context, fibrin maintains cell adherence at the site of injury, where cells are required for tissue repair, and offers a nurturing environment that protects implanted cells without interfering with their expected benefit. Here we review the past, present and future uses of fibrin, with a focus on its use as a scaffold material for cardiac repair. Fibrin patches filled with regenerative cells can be placed over the scarring myocardium; this methodology avoids many of the drawbacks of conventional cell-infusion systems. Advantages of using fibrin also include extraction from the patient's blood, an easy readjustment and implantation procedure, increase in viability and early proliferation of delivered cells, and benefits even with the patch alone. In line with this, we discuss the numerous preclinical studies that have used fibrin-cell patches, the practical issues inherent in their generation, and the necessary process of scaling-up from animal models to patients. In the light of the data presented, fibrin stands out as a valuable biomaterial for delivering cells to damaged tissue and for promoting beneficial effects. However, before the fibrin scaffold can be translated from bench to bedside, many issues must be explored further, including suboptimal survival and limited migration of the implanted cells to underlying ischaemic myocardium. Copyright © 2016 John Wiley \& Sons, Ltd.},
	language = {eng},
	journal = {Journal of Tissue Engineering and Regenerative Medicine},
	author = {Roura, Santiago and Gálvez-Montón, Carolina and Bayes-Genis, Antoni},
	month = apr,
	year = {2016},
	pmid = {27061269},
	keywords = {Cardiac regeneration, Tissue Engineering, cell therapy, fibrin, myocardial infarction, patch, scaffold}
}

@article{heydrick_pediatric_2016,
	title = {Pediatric cardiovascular grafts: historical perspective and future directions},
	volume = {40},
	issn = {1879-0429},
	shorttitle = {Pediatric cardiovascular grafts},
	doi = {10.1016/j.copbio.2016.03.013},
	abstract = {Tissue-engineered cardiovascular patches, cardiac valves, and great vessels are emerging solutions for the surgical treatment of congenital cardiovascular abnormalities due to their potential for adapting with the growing child. The ideal pediatric cardiovascular patch/graft is non-thrombogenic, phenotypically compatible, and matches the compliance and mechanical strength of the native tissue, both initially and throughout growth. Bottom-up tissue engineering approaches, in which three-dimensional tissue is built layer-by-layer from scaffold-less cell sheets in vitro, offer an exciting potential solution. Cell source variability, sheet patterning, and scaffold-less fabrication are promising advantages offered by this approach. Here we review the latest developments and next steps in bottom-up tissue engineering targeted at meeting the necessary design criteria for successful pediatric cardiac tissue-engineered grafts.},
	language = {eng},
	journal = {Current Opinion in Biotechnology},
	author = {Heydrick, Stanley and Roberts, Erin and Kim, Jaeyun and Emani, Sitaram and Wong, Joyce Y.},
	month = aug,
	year = {2016},
	pmid = {27046072},
	pages = {119--124}
}

@article{stoppel_anisotropic_2015,
	title = {Anisotropic silk biomaterials containing cardiac extracellular matrix for cardiac tissue engineering},
	volume = {10},
	issn = {1748-605X},
	doi = {10.1088/1748-6041/10/3/034105},
	abstract = {Cardiac malformations and disease are the leading causes of death in the United States in live-born infants and adults, respectively. In both of these cases, a decrease in the number of functional cardiomyocytes often results in improper growth of heart tissue, wound healing complications, and poor tissue repair. The field of cardiac tissue engineering seeks to address these concerns by developing cardiac patches created from a variety of biomaterial scaffolds to be used in surgical repair of the heart. These scaffolds should be fully degradable biomaterial systems with tunable properties such that the materials can be altered to meet the needs of both in vitro culture (e.g. disease modeling) and in vivo application (e.g. cardiac patch). Current platforms do not utilize both structural anisotropy and proper cell-matrix contacts to promote functional cardiac phenotypes and thus there is still a need for critically sized scaffolds that mimic both the structural and adhesive properties of native tissue. To address this need, we have developed a silk-based scaffold platform containing cardiac tissue-derived extracellular matrix (cECM). These silk-cECM composite scaffolds have tunable architectures, degradation rates, and mechanical properties. Subcutaneous implantation in rats demonstrated that addition of the cECM to aligned silk scaffold led to 99\% endogenous cell infiltration and promoted vascularization of a critically sized scaffold (10 × 5 × 2.5 mm) after 4 weeks in vivo. In vitro, silk-cECM scaffolds maintained the HL-1 atrial cardiomyocytes and human embryonic stem cell-derived cardiomyocytes and promoted a more functional phenotype in both cell types. This class of hybrid silk-cECM anisotropic scaffolds offers new opportunities for developing more physiologically relevant tissues for cardiac repair and disease modeling.},
	language = {eng},
	number = {3},
	journal = {Biomedical Materials (Bristol, England)},
	author = {Stoppel, Whitney L. and Hu, Dongjian and Domian, Ibrahim J. and Kaplan, David L. and Black, Lauren D.},
	month = mar,
	year = {2015},
	pmid = {25826196},
	pmcid = {PMC4417360},
	keywords = {Animals, Anisotropy, Biocompatible Materials, Cells, Cultured, Equipment Design, Equipment Failure Analysis, Extracellular Matrix, Materials Testing, Myocardium, Myocytes, Cardiac, Rats, Rats, Sprague-Dawley, Silk, Tissue Engineering, Tissue Scaffolds},
	pages = {034105}
}

@article{menasche_future_2016,
	title = {The future of stem cells: {Should} we keep the "stem" and skip the "cells"?},
	volume = {152},
	issn = {1097-685X},
	shorttitle = {The future of stem cells},
	doi = {10.1016/j.jtcvs.2016.02.058},
	abstract = {There is accumulating evidence that the cardioprotective effects of stem cells are predominantly mediated by the release of a blend of factors, possibly clustered into extracellular vesicles, which harness endogenous repair pathways. The clinical translation of this concept requires the identification of the cell-secreted signaling biomolecules and an appropriate transfer method. The study by Wei and colleagues has addressed these 2 requirements by showing that the epicardial delivery of a collagen patch loaded with the cardiokine follistatin-like 1 improved left ventricular function in animal models of myocardial infarction. Beyond the choice of the factor and its vehicle, these data may open a new therapeutic path whereby the functionalization of biomaterials by bioactive compounds could successfully substitute for the current cell transplantation-based strategy.},
	language = {eng},
	number = {2},
	journal = {The Journal of Thoracic and Cardiovascular Surgery},
	author = {Menasché, Philippe},
	month = aug,
	year = {2016},
	pmid = {27021156},
	keywords = {Biomaterials, Stem cells, heart failure, paracrine signaling effects by},
	pages = {345--349}
}

@article{barile_endogenous_2007,
	title = {Endogenous cardiac stem cells},
	volume = {50},
	issn = {0033-0620},
	doi = {10.1016/j.pcad.2007.03.005},
	abstract = {In the past few years it has been established that the heart contains a reservoir of stem and progenitor cells. These cells are positive for various stem/progenitor cell markers (Kit, Sca-1, Isl-1, and Side Population (SP) properties). The relationship between the various cardiac stem cells (CSC) and progenitor cells described awaits clarification. Furthermore, they may open a new therapeutic strategies of cardiac repair based on the regeneration potential of cardiac stem cells. Currently, cellular cardiomyoplasty is actively explored as means of regenerating damaged myocardium using several different cell types. CSCs seem a logical cell source to exploit for cardiac regeneration therapy. Their presence into the heart, the frequent co-expression of early cardiac progenitor transcription factors, and the capability for ex vivo and in vivo differentiation toward the cardiac lineages offer promise of enhanced cardiogenicity compared to other cell sources. CSCs, when isolated from various animal models by selection based on c-Kit, Sca-1, and/or MDR1, have shown cardiac regeneration potential in vivo following injection in the infracted myocardium. Recently, we have successfully isolated CSCs from small biopsies of human myocardium and expanded them ex vivo by many folds without losing differentiation potential into cardiomyocytes and vascular cells, bringing autologous transplantation of CSCs closer to clinical evaluation. These cells are spontaneously shed from human surgical specimens and murine heart samples in primary culture. This heterogeneous population of cells forms multi-cellular clusters, dubbed cardiospheres (CSs), in suspension culture. CSs are composed of clonally-derived cells, consist of proliferating c-Kit positive cells primarily in their core and differentiating cells expressing cardiac and endothelial cell markers on their periphery. Although the intracardiac origin of adult myocytes has been unequivocally documented, the potential of an extracardiac source of cells, able to repopulate the lost CSCs in pathological conditions (infarct) cannot be excluded and will be discussed in this review. The delivery of human CSs or of CSs-derived cells into the injured heart of the SCID mouse resulted in engraftment, migration, myocardial regeneration and improvement of left ventricular function. Our method for ex vivo expansion of resident CSCs for subsequent autologous transplantation back into the heart, may give these cell populations, the resident and the transplanted one, the combined ability to mediate myocardial regeneration to an appreciable degree, and may change the way in which cardiovascular disease will be approached in the future.},
	language = {eng},
	number = {1},
	journal = {Progress in Cardiovascular Diseases},
	author = {Barile, Lucio and Messina, Elisa and Giacomello, Alessandro and Marbán, Eduardo},
	month = aug,
	year = {2007},
	pmid = {17631436},
	keywords = {Animals, Cell Count, Cell Differentiation, Cell Lineage, Cell Proliferation, Cell Separation, Heart Diseases, Humans, Myocardium, Myocytes, Cardiac, Regeneration, Stem Cell Transplantation, Stem cells, Tissue Culture Techniques, cell transplantation},
	pages = {31--48}
}

@article{gunter_microtissues_2016,
	title = {Microtissues in {Cardiovascular} {Medicine}: {Regenerative} {Potential} {Based} on a {3D} {Microenvironment}},
	volume = {2016},
	issn = {1687-966X},
	shorttitle = {Microtissues in {Cardiovascular} {Medicine}},
	doi = {10.1155/2016/9098523},
	abstract = {More people die annually from cardiovascular diseases than from any other cause. In particular, patients who suffer from myocardial infarction may be affected by ongoing adverse remodeling processes of the heart that may ultimately lead to heart failure. The introduction of stem and progenitor cell-based applications has raised substantial hope for reversing these processes and inducing cardiac regeneration. However, current stem cell therapies using single-cell suspensions have failed to demonstrate long-lasting efficacy due to the overall low retention rate after cell delivery to the myocardium. To overcome this obstacle, the concept of 3D cell culture techniques has been proposed to enhance therapeutic efficacy and cell engraftment based on the simulation of an in vivo-like microenvironment. Of great interest is the use of so-called microtissues or spheroids, which have evolved from their traditional role as in vitro models to their novel role as therapeutic agents. This review will provide an overview of the therapeutic potential of microtissues by addressing primarily cardiovascular regeneration. It will accentuate their advantages compared to other regenerative approaches and summarize the methods for generating clinically applicable microtissues. In addition, this review will illustrate the unique properties of the microenvironment within microtissues that makes them a promising next-generation therapeutic approach.},
	language = {eng},
	journal = {Stem Cells International},
	author = {Günter, Julia and Wolint, Petra and Bopp, Annina and Steiger, Julia and Cambria, Elena and Hoerstrup, Simon P. and Emmert, Maximilian Y.},
	year = {2016},
	pmid = {27073399},
	pmcid = {PMC4814701},
	pages = {9098523}
}

@article{wen_local_2012,
	title = {Local activation of cardiac stem cells for post-myocardial infarction cardiac repair},
	volume = {16},
	issn = {1582-4934},
	doi = {10.1111/j.1582-4934.2012.01589.x},
	abstract = {The prognosis of patients with myocardial infarction (MI) and resultant chronic heart failure remains extremely poor despite continuous advancements in optimal medical therapy and interventional procedures. Animal experiments and clinical trials using adult stem cell therapy following MI have shown a global improvement of myocardial function. The emergence of stem cell transplantation approaches has recently represented promising alternatives to stimulate myocardial regeneration. Regarding their tissue-specific properties, cardiac stem cells (CSCs) residing within the heart have advantages over other stem cell types to be the best cell source for cell transplantation. However, time-consuming and costly procedures to expanse cells prior to cell transplantation and the reliability of cell culture and expansion may both be major obstacles in the clinical application of CSC-based transplantation therapy after MI. The recognition that the adult heart possesses endogenous CSCs that can regenerate cardiomyocytes and vascular cells has raised the unique therapeutic strategy to reconstitute dead myocardium via activating these cells post-MI. Several strategies, such as growth factors, mircoRNAs and drugs, may be implemented to potentiate endogenous CSCs to repair infarcted heart without cell transplantation. Most molecular and cellular mechanism involved in the process of CSC-based endogenous regeneration after MI is far from understanding. This article reviews current knowledge opening up the possibilities of cardiac repair through CSCs activation in situ in the setting of MI.},
	language = {eng},
	number = {11},
	journal = {Journal of Cellular and Molecular Medicine},
	author = {Wen, Zhuzhi and Mai, Zun and Zhang, Haifeng and Chen, Yangxin and Geng, Dengfeng and Zhou, Shuxian and Wang, Jingfeng},
	month = nov,
	year = {2012},
	pmid = {22613044},
	pmcid = {PMC4118225},
	keywords = {Adult, Animals, Cell Communication, Humans, Intercellular Signaling Peptides and Proteins, MicroRNAs, Myocardium, Regeneration, Stem Cell Transplantation, Stem cells, heart, myocardial infarction},
	pages = {2549--2563}
}

@article{emmert_cell_2014,
	series = {Innovative tissue models for drug discovery and development},
	title = {Cell therapy, {3D} culture systems and tissue engineering for cardiac regeneration},
	volume = {69–70},
	issn = {0169-409X},
	url = {http://www.sciencedirect.com/science/article/pii/S0169409X13002901},
	doi = {10.1016/j.addr.2013.12.004},
	abstract = {Ischemic Heart Disease (IHD) still represents the “Number One Killer” worldwide accounting for the death of numerous patients. However the capacity for self-regeneration of the adult heart is very limited and the loss of cardiomyocytes in the infarcted heart leads to continuous adverse cardiac-remodeling which often leads to heart-failure (HF). The concept of regenerative medicine comprising cell-based therapies, bio-engineering technologies and hybrid solutions has been proposed as a promising next-generation approach to address IHD and HF. Numerous strategies are under investigation evaluating the potential of regenerative medicine on the failing myocardium including classical cell-therapy concepts, three-dimensional culture techniques and tissue-engineering approaches. While most of these regenerative strategies have shown great potential in experimental studies, the translation into a clinical setting has either been limited or too rapid leaving many key questions unanswered. This review summarizes the current state-of-the-art, important challenges and future research directions as to regenerative approaches addressing IHD and resulting HF.},
	urldate = {2017-01-19},
	journal = {Advanced Drug Delivery Reviews},
	author = {Emmert, Maximilian Y. and Hitchcock, Robert W. and Hoerstrup, Simon P.},
	month = apr,
	year = {2014},
	keywords = {Bioreactors, Cardiac cell therapy, Cardiac tissue engineering, Myocardial regeneration, Stem cells, Three dimensional culture systems},
	pages = {254--269}
}

@article{behfar_cell_2014,
	title = {Cell therapy for cardiac repair—lessons from clinical trials},
	volume = {11},
	copyright = {© 2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1759-5002},
	url = {http://www.nature.com/nrcardio/journal/v11/n4/full/nrcardio.2014.9.html},
	doi = {10.1038/nrcardio.2014.9},
	abstract = {The global impetus to identify curative therapies has been fuelled by the unmet needs of patients in the context of a growing heart failure pandemic. To date, regeneration trials in patients with cardiovascular disease have used stem-cell-based therapy in the period immediately after myocardial injury, in an attempt to halt progression towards ischaemic cardiomyopathy, or in the setting of congestive heart failure, to target the disease process and prevent organ decompensation. Worldwide, several thousand patients have now been treated using autologous cell-based therapy; the safety and feasibility of this approach has been established, pitfalls have been identified, and optimization procedures envisioned. Furthermore, the initiation of phase III trials to further validate the therapeutic value of cell-based regenerative medicine and address the barriers to successful clinical implementation has led to resurgence in the enthusiasm for such treatments among patients and health-care providers. In particular, poor definition of cell types used, diversity in cell-handling procedures, and functional variability intrinsic to autologously-derived cells have been identified as the main factors limiting adoption of cell-based therapies. In this Review, we summarize the experience obtained from trials of 'first-generation' cell-based therapy, and emphasize the advances in the purification and lineage specification of stem cells that have enabled the development of 'next-generation' stem-cell-based therapies targeting cardiovascular disease.},
	language = {en},
	number = {4},
	urldate = {2017-01-19},
	journal = {Nature Reviews Cardiology},
	author = {Behfar, Atta and Crespo-Diaz, Ruben and Terzic, Andre and Gersh, Bernard J.},
	month = apr,
	year = {2014},
	keywords = {Stem-cell therapies, heart failure, myocardial infarction},
	pages = {232--246}
}

@article{kelm_scaffold-free_2010,
	series = {Therapeutic {Cell} {Delivery} for {In} {Situ} {Regenerative} {Medicine}},
	title = {Scaffold-free cell delivery for use in regenerative medicine},
	volume = {62},
	issn = {0169-409X},
	url = {http://www.sciencedirect.com/science/article/pii/S0169409X10000396},
	doi = {10.1016/j.addr.2010.02.003},
	abstract = {The development of cell-based therapies for diseased tissues is one of the most promising research directions in regenerative medicine. Cell-delivery methods are an essential part of cell therapy concepts. Therapies with the potential to become clinical routine will only be possible if these methods ensure efficient engraftment and therapeutically-relevant number of cells survive. Here we provide an overview of three different scaffold-free cell-delivery concepts: (i) single cell delivery, (ii) cell sheet engineering and (iii) microtissue technology.},
	number = {7–8},
	urldate = {2017-01-19},
	journal = {Advanced Drug Delivery Reviews},
	author = {Kelm, Jens M. and Fussenegger, Martin},
	month = jun,
	year = {2010},
	keywords = {Cell sheets, Microtissues, Stem cells, Tissue Engineering},
	pages = {753--764}
}

@article{capulli_fibrous_2016,
	title = {Fibrous {Scaffolds} for {Building} {Hearts} and {Heart} {Parts}},
	volume = {96},
	issn = {0169-409X},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4807693/},
	doi = {10.1016/j.addr.2015.11.020},
	abstract = {Extracellular matrix (ECM) structure and biochemistry provide cell-instructive cues that promote and regulate tissue growth, function, and repair. From a structural perspective, the ECM is a scaffold that guides the self-assembly of cells into distinct functional tissues. The ECM promotes the interaction between individual cells and between different cell types, and increases the strength and resilience of the tissue in mechanically dynamic environments. From a biochemical perspective, factors regulating cell-ECM adhesion have been described and diverse aspects of cell-ECM interactions in health and disease continue to be clarified. Natural ECMs therefore provide excellent design rules for tissue engineering scaffolds. The design of regenerative three-dimensional (3D) engineered scaffolds is informed by the target ECM structure, chemistry, and mechanics, to encourage cell infiltration and tissue genesis. This can be achieved using nanofibrous scaffolds composed of polymers that simultaneously recapitulate 3D ECM architecture, high-fidelity nanoscale topography, and bio-activity. Their high porosity, structural anisotropy, and bio-activity present unique advantages for engineering 3D anisotropic tissues. Here, we use the heart as a case study and examine the potential of ECM-inspired nanofibrous scaffolds for cardiac tissue engineering. We asked: Do we know enough to build a heart? To answer this question, we tabulated structural and functional properties of myocardial and valvular tissues for use as design criteria, reviewed nanofiber manufacturing platforms and assessed their capabilities to produce scaffolds that meet our design criteria. Our knowledge of the anatomy and physiology of the heart, as well as our ability to create synthetic ECM scaffolds have advanced to the point that valve replacement with nanofibrous scaffolds may be achieved in the short term, while myocardial repair requires further study in vitro and in vivo.,},
	urldate = {2017-01-19},
	journal = {Advanced drug delivery reviews},
	author = {Capulli, A. K. and MacQueen, L. A. and Sheehy, Sean P. and Parker, K. K.},
	month = jan,
	year = {2016},
	pmid = {26656602},
	pmcid = {PMC4807693},
	pages = {83--102}
}

@article{hinderer_generation_2015,
	title = {Generation and {Assessment} of {Functional} {Biomaterial} {Scaffolds} for {Applications} in {Cardiovascular} {Tissue} {Engineering} and {Regenerative} {Medicine}},
	volume = {4},
	issn = {2192-2640},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4745029/},
	doi = {10.1002/adhm.201400762},
	abstract = {Current clinically applicable tissue and organ replacement therapies are limited in the field of cardiovascular regenerative medicine. The available options do not regenerate damaged tissues and organs, and, in the majority of the cases, show insufficient restoration of tissue function. To date, anticoagulant drug‐free heart valve replacements or growing valves for pediatric patients, hemocompatible and thrombus‐free vascular substitutes that are smaller than 6 mm, and stem cell‐recruiting delivery systems that induce myocardial regeneration are still only visions of researchers and medical professionals worldwide and far from being the standard of clinical treatment. The design of functional off‐the‐shelf biomaterials as well as automatable and up‐scalable biomaterial processing methods are the focus of current research endeavors and of great interest for fields of tissue engineering and regenerative medicine. Here, various approaches that aim to overcome the current limitations are reviewed, focusing on biomaterials design and generation methods for myocardium, heart valves, and blood vessels. Furthermore, novel contact‐ and marker‐free biomaterial and extracellular matrix assessment methods are highlighted.},
	number = {16},
	urldate = {2017-01-19},
	journal = {Advanced Healthcare Materials},
	author = {Hinderer, Svenja and Brauchle, Eva and Schenke‐Layland, Katja},
	month = nov,
	year = {2015},
	pmid = {25778713},
	pmcid = {PMC4745029},
	pages = {2326--2341}
}

@article{castellano_comparison_2014,
	title = {A {Comparison} of {Electrospun} {Polymers} {Reveals} {Poly}(3-{Hydroxybutyrate}) {Fiber} as a {Superior} {Scaffold} for {Cardiac} {Repair}},
	volume = {23},
	issn = {1547-3287},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4066229/},
	doi = {10.1089/scd.2013.0578},
	abstract = {The development of biomaterials for myocardial tissue engineering requires a careful assessment of their performance with regards to functionality and biocompatibility, including the immune response. Poly(3-hydroxybutyrate) (PHB), poly(e-caprolactone) (PCL), silk, poly-lactic acid (PLA), and polyamide (PA) scaffolds were generated by electrospinning, and cell compatibility in vitro, and immune response and cardiac function in vitro and in vivo were compared with a noncrosslinked collagen membrane (Col) control material. Results showed that cell adhesion and growth of mesenchymal stem cells, cardiomyocytes, and cardiac fibroblasts in vitro was dependent on the polymer substrate, with PHB and PCL polymers permitting the greatest adhesion/growth of cells. Additionally, polymer substrates triggered unique expression profiles of anti- and pro-inflammatory cytokines in human peripheral blood mononuclear cells. Implantation of PCL, silk, PLA, and PA patches on the epicardial surface of healthy rats induced a classical foreign body reaction pattern, with encapsulation of polymer fibers and induction of the nonspecific immune response, whereas Col and PHB patches were progressively degraded. When implanted on infarcted rat heart, Col, PCL, and PHB reduced negative remodeling, but only PHB induced significant angiogenesis. Importantly, Col and PHB modified the inflammatory response to an M2 macrophage phenotype in cardiac tissue, indicating a more beneficial reparative process and remodeling. Collectively, these results identify PHB as a superior substrate for cardiac repair.},
	number = {13},
	urldate = {2017-01-19},
	journal = {Stem Cells and Development},
	author = {Castellano, Delia and Blanes, María and Marco, Bruno and Cerrada, Inmaculada and Ruiz-Saurí, Amparo and Pelacho, Beatriz and Araña, Miriam and Montero, Jose A. and Cambra, Vicente and Prosper, Felipe and Sepúlveda, Pilar},
	month = jul,
	year = {2014},
	pmid = {24564648},
	pmcid = {PMC4066229},
	pages = {1479--1490}
}

@article{lister_how_2016,
	title = {How {Biomaterials} {Can} {Influence} {Various} {Cell} {Types} in the {Repair} and {Regeneration} of the {Heart} after {Myocardial} {Infarction}},
	volume = {4},
	issn = {2296-4185},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4948030/},
	doi = {10.3389/fbioe.2016.00062},
	abstract = {The healthy heart comprises many different cell types that work together to preserve optimal function. However, in a diseased heart the function of one or more cell types is compromised which can lead to many adverse events, one of which is myocardial infarction (MI). Immediately after MI, the cardiac environment is characterized by excessive cardiomyocyte death and inflammatory signals leading to the recruitment of macrophages to clear the debris. Proliferating fibroblasts then invade, and a collagenous scar is formed to prevent rupture. Better functional restoration of the heart is not achieved due to the limited regenerative capacity of cardiac tissue. To address this, biomaterial therapy is being investigated as an approach to improve regeneration in the infarcted heart, as they can possess the potential to control cell function in the infarct environment and limit the adverse compensatory changes that occur post-MI. Over the past decade, there has been considerable research into the development of biomaterials for cardiac regeneration post-MI; and various effects have been observed on different cell types depending on the biomaterial that is applied. Biomaterial treatment has been shown to enhance survival, improve function, promote proliferation, and guide the mobilization and recruitment of different cells in the post-MI heart. This review will provide a summary on the biomaterials developed to enhance cardiac regeneration and remodeling post-MI with a focus on how they control macrophages, cardiomyocytes, fibroblasts, and endothelial cells. A better understanding of how a biomaterial interacts with the different cell types in the heart may lead to the development of a more optimized biomaterial therapy for cardiac regeneration.},
	urldate = {2017-01-19},
	journal = {Frontiers in Bioengineering and Biotechnology},
	author = {Lister, Zachary and Rayner, Katey J. and Suuronen, Erik J.},
	month = jul,
	year = {2016},
	pmid = {27486578},
	pmcid = {PMC4948030}
}

@article{ehler_cell_2014,
	title = {Cell electrospinning cardiac patches for tissue engineering the heart},
	volume = {139},
	url = {http://pubs.rsc.org/en/Content/ArticleLanding/2014/AN/C4AN00766B},
	doi = {10.1039/C4AN00766B},
	language = {en},
	number = {18},
	urldate = {2017-01-19},
	journal = {Analyst},
	author = {Ehler, Elisabeth and N. Jayasinghe, Suwan},
	year = {2014},
	pages = {4449--4452}
}

@article{prabhakaran_electrospun_2011,
	title = {Electrospun biocomposite nanofibrous patch for cardiac tissue engineering},
	volume = {6},
	issn = {1748-605X},
	url = {http://stacks.iop.org/1748-605X/6/i=5/a=055001},
	doi = {10.1088/1748-6041/6/5/055001},
	abstract = {A bioengineered construct that matches the chemical, mechanical, biological properties and extracellular matrix morphology of native tissue could be suitable as a cardiac patch for supporting the heart after myocardial infarction. The potential of utilizing a composite nanofibrous scaffold of poly(dl-lactide- co -glycolide)/gelatin (PLGA/Gel) as a biomimetic cardiac patch is studied by culturing a population of cardiomyocyte containing cells on the electrospun scaffolds. The chemical characterization and mechanical properties of the electrospun PLGA and PLGA/Gel nanofibers were studied by Fourier transform infrared spectroscopy, scanning electron microscopy and tensile measurements. The biocompatibility of the scaffolds was also studied and the cardiomyocytes seeded on PLGA/Gel nanofibers were found to express the typical functional cardiac proteins such as alpha-actinin and troponin I, showing the easy integration of cardiomyocytes on PLGA/Gel scaffolds. Our studies strengthen the application of electrospun PLGA/Gel nanofibers as a bio-mechanical support for injured myocardium and as a potential substrate for induction of endogenous cardiomyocyte proliferation, ultimately reducing the cardiac dysfunction and improving cardiac remodeling.},
	language = {en},
	number = {5},
	urldate = {2017-01-19},
	journal = {Biomedical Materials},
	author = {Prabhakaran, Molamma P. and Kai, Dan and Ghasemi-Mobarakeh, Laleh and Ramakrishna, Seeram},
	year = {2011},
	pages = {055001}
}

@article{kundanati_fabrication_2016,
	title = {Fabrication and {Mechanical} {Characterization} of {Hydrogel} {Infused} {Network} {Silk} {Scaffolds}},
	volume = {17},
	issn = {1422-0067},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5085664/},
	doi = {10.3390/ijms17101631},
	abstract = {Development and characterization of porous scaffolds for tissue engineering and regenerative medicine is of great importance. In recent times, silk scaffolds were developed and successfully tested in tissue engineering and drug release applications. We developed a novel composite scaffold by mechanical infusion of silk hydrogel matrix into a highly porous network silk scaffold. The mechanical behaviour of these scaffolds was thoroughly examined for their possible use in load bearing applications. Firstly, unconfined compression experiments show that the denser composite scaffolds displayed significant enhancement in the elastic modulus as compared to either of the components. This effect was examined and further explained with the help of foam mechanics principles. Secondly, results from confined compression experiments that resemble loading of cartilage in confinement, showed nonlinear material responses for all scaffolds. Finally, the confined creep experiments were performed to calculate the hydraulic permeability of the scaffolds using soil mechanics principles. Our results show that composite scaffolds with some modifications can be a potential candidate for use of cartilage like applications. We hope such approaches help in developing novel scaffolds for tissue engineering by providing an understanding of the mechanics and can further be used to develop graded scaffolds by targeted infusion in specific regions.},
	number = {10},
	urldate = {2017-01-20},
	journal = {International Journal of Molecular Sciences},
	author = {Kundanati, Lakshminath and Singh, Saket K. and Mandal, Biman B. and Murthy, Tejas G. and Gundiah, Namrata and Pugno, Nicola M.},
	month = sep,
	year = {2016},
	pmid = {27681725},
	pmcid = {PMC5085664}
}

@article{nguyen_combination_2014,
	title = {A {Combination} of {Biphasic} {Calcium} {Phosphate} {Scaffold} with {Hyaluronic} {Acid}-{Gelatin} {Hydrogel} as a {New} {Tool} for {Bone} {Regeneration}},
	volume = {20},
	issn = {1937-3341},
	url = {http://online.liebertpub.com/doi/abs/10.1089/ten.TEA.2013.0352},
	doi = {10.1089/ten.tea.2013.0352},
	abstract = {A novel bone substitute was fabricated to enhance bone healing by combining ceramic and polymer materials. In this study, Hyaluronic acid (HyA)–Gelatin (Gel) hydrogel was loaded into a biphasic calcium phosphate (BCP) ceramic, and the resulting scaffold, with unique micro- and macroporous orientation, was evaluated for bone regeneration applications. The fabricated scaffold showed high interconnected porosity, with an average compressive strength of 2.8±0.15 MPa, which is usually recommended for cancellous bone substitution. In vitro cytocompatibility studies were conducted using bone marrow mesenchymal stem cells. The HyA-Gel–loaded BCP scaffold resulted in a significant increase in cell proliferation at 3 (p{\textless}0.05) and 7 days (p{\textless}0.001) and high alkaline phosphatase activities at 14 and 21 days. Furthermore, the in vivo studies showed that the implanted HyA-Gel–loaded BCP scaffold begins to degrade within 3 months after implantation. Histological sections also confirmed a rapid new bone formation and a high rate of collagen mineralization. A bone matrix formation was confirmed by positive immunohistochemistry staining of osteopontin, osteocalcin, and collagen type I. In vivo expression of extracellular matrix proteins demonstrated that this novel bone substitute holds great promise for use in stimulating new bone regeneration.},
	number = {13-14},
	urldate = {2017-01-20},
	journal = {Tissue Engineering Part A},
	author = {Nguyen, Thuy Ba Linh and Lee, Byong-Taek},
	month = feb,
	year = {2014},
	pages = {1993--2004}
}

@article{griffin_evolution_2015,
	title = {Evolution of {Bone} {Grafting}: {Bone} {Grafts} and {Tissue} {Engineering} {Strategies} for {Vascularized} {Bone} {Regeneration}},
	volume = {13},
	issn = {1534-8644, 1559-0119},
	shorttitle = {Evolution of {Bone} {Grafting}},
	url = {http://link.springer.com/article/10.1007/s12018-015-9194-9},
	doi = {10.1007/s12018-015-9194-9},
	abstract = {The regeneration of bone in segmental defects has historically been a challenge in the orthopedic field. In particular, a lack of vascular supply often leads to nonunion and avascular necrosis. While the gold standard of clinical care remains the autograft, this approach is limited for large bone defects. Therefore, allograft bone is often required for defects of critical size though a high complication rate is directly attributable to their limited ability to revitalize, revascularize, and remodel resulting in necrosis and re-fracture. However, emerging insights into the mechanisms of bone healing continue to expand treatment options for bony defects to include synthetic materials, growth factors, and cells. The success of such strategies hinges on fabricating an environment that can mimic the body’s natural healing process, allowing for vascularization, bridging, and remodeling of bone. Biological, chemical, and engineering techniques have been explored to determine the appropriate materials and factors for potential use. This review will serve to highlight some of the historical and present uses of allografts and autografts and current strategies in bone tissue engineering for the treatment for bony defects, with particular emphasis on vascularization.},
	language = {en},
	number = {4},
	urldate = {2017-01-20},
	journal = {Clinical Reviews in Bone and Mineral Metabolism},
	author = {Griffin, Kaitlyn S. and Davis, Korbin M. and McKinley, Todd O. and Anglen, Jeffrey O. and Chu, Tien-Min G. and Boerckel, Joel D. and Kacena, Melissa A.},
	month = dec,
	year = {2015},
	pages = {232--244}
}

@article{qian_hemodynamic_2012,
	title = {Hemodynamic {Contribution} of {Stem} {Cell} {Scaffolding} in {Acute} {Injured} {Myocardium}},
	volume = {18},
	issn = {1937-3341},
	url = {http://online.liebertpub.com/doi/abs/10.1089/ten.tea.2011.0591},
	doi = {10.1089/ten.tea.2011.0591},
	abstract = {Tissue-engineered scaffolds may improve experimental outcomes in cardiac cell therapy by targeted delivery of stem cells and mechanically support an infarcted left ventricular (LV) wall. We transplanted cardiomyocyte-like cells (5×105) with scaffolding via epicardial patching (cell patch, n=17) or a low-dose intramyocardial hydrogel (LD hydrogel, n=18), a high-dose (5×106) intramyocardial hydrogel (HD hydrogel, n=18) or transplanting a serum-free medium control (control, n=13), a blank patch (n=14), and a blank gel (n=16) for targeted cardiomyoplasty in a myocardial infarcted rat model. LV real-time hemodynamics were assessed using a 1.9-F pressure–volume catheter 7 weeks after stem cell transplantation. All mode of scaffold transplantation protected diastolic function by preserving LV wall integrity that resulted in a lower end diastolic pressure–volume relationship (EDPVR) as compared to a control medium-injected group. Moreover, epicardial patching, but not hydrogel injection, reduced ventricular wall stress with a significantly better LV end diastolic pressure (EDP: 5.3±2.4 mmHg vs. 9.6±6.9 mmHg, p{\textless}0.05) as compared to control. Furthermore, epicardial patching additionally preserved systolic function by modulating negative remodeling through restricting dilatation of the LV chamber. In comparison to control, an improved ejection fraction in the cell patch group (80.1\%±5.9\% vs. 67.9\%±3.2\%, p{\textless}0.01) was corroborated by load-independent enhancement of the end systolic pressure–volume relationship (ESPVR: 0.88±0.61 mmHg/uL vs. 0.29±0.19 mmHg/uL, p{\textless}0.05) and preload recruitable stroke work (PRSW: 68.7±26.4 mmHg vs. 15.6±16.2 mmHg, p{\textless}0.05) in systolic function. Moreover, the cell patch group (14.2±1.7 cells/high-power field vs. 7.4±1.6 cells/high power field, p{\textless}0.05) was significantly better in myocardial retention of transplanted stem cells as compared to the LD hydrogel group. Collectively, myocardial transplantation of compliant scaffolding materials alone may physically improve wall mechanics, largely independent of stem cells. However, epicardially grafted cell patch conferred added systolic contractility by improving stem cell retention and cellular alignment leading to improved LV remodeling and geometric preservation postinfarction.},
	number = {15-16},
	urldate = {2017-01-20},
	journal = {Tissue Engineering Part A},
	author = {Qian, Ling and Shim, Winston and Gu, Yacui and Shirhan, Mohamed and Lim, Kee Pah and Tan, Lay Poh and Lim, Chong Hee and Sin, Yoong Kong and Wong, Philip},
	month = may,
	year = {2012},
	pages = {1652--1663}
}

@article{gaetani_epicardial_2015,
	title = {Epicardial application of cardiac progenitor cells in a {3D}-printed gelatin/hyaluronic acid patch preserves cardiac function after myocardial infarction},
	volume = {61},
	issn = {0142-9612},
	url = {//www.sciencedirect.com/science/article/pii/S0142961215004287},
	doi = {10.1016/j.biomaterials.2015.05.005},
	abstract = {Cardiac cell therapy suffers from limitations related to poor engraftment and significant cell death after transplantation. In this regard, ex vivo tissue engineering is a tool that has been demonstrated to increase cell retention and survival. The aim of our study was to evaluate the therapeutic potential of a 3D-printed patch composed of human cardiac-derived progenitor cells (hCMPCs) in a hyaluronic acid/gelatin (HA/gel) based matrix. hCMPCs were printed in the HA/gel matrix (30 × 106 cells/ml) to form a biocomplex made of six perpendicularly printed layers with a surface of 2 × 2 cm and thickness of 400 μm, in which they retained their viability, proliferation and differentiation capability. The printed biocomplex was transplanted in a mouse model of myocardial infarction (MI). The application of the patch led to a significant reduction in adverse remodeling and preservation of cardiac performance as was shown by both MRI and histology. Furthermore, the matrix supported the long-term in vivo survival and engraftment of hCMPCs, which exhibited a temporal increase in cardiac and vascular differentiation markers over the course of the 4 week follow-up period. Overall, we developed an effective and translational approach to enhance hCMPC delivery and action in the heart.},
	urldate = {2017-01-20},
	journal = {Biomaterials},
	author = {Gaetani, Roberto and Feyen, Dries A. M. and Verhage, Vera and Slaats, Rolf and Messina, Elisa and Christman, Karen L. and Giacomello, Alessandro and Doevendans, Pieter A. F. M. and Sluijter, Joost P. G.},
	month = aug,
	year = {2015},
	keywords = {Cardiac progenitor cells, Cardiac regeneration, Cardiac tissue engineering, Tissue printing, heart failure},
	pages = {339--348}
}

@article{roche_soft_2017,
	title = {Soft robotic sleeve supports heart function},
	volume = {9},
	copyright = {Copyright © 2017, American Association for the Advancement of Science},
	issn = {1946-6234, 1946-6242},
	url = {http://stm.sciencemag.org/content/9/373/eaaf3925},
	doi = {10.1126/scitranslmed.aaf3925},
	abstract = {Robots have a change of heart
Ventricular assist devices help failing hearts function by pumping blood but require monitoring and anticoagulant therapy to prevent blood clot formation. Roche et al. created a soft robotic device with material properties similar to those of native heart tissue that sits snugly around the heart and provides ventricular assistance without ever contacting blood. The robotic sleeve uses compressed air to power artificial silicone muscles that compress and twist, mimicking the movements of the normal human heart. The authors show that the artificial muscles could be selectively activated to twist, compress, or simultaneously perform both actions on one side or both sides of the heart. The device increased cardiac ejection volume in vitro and when implanted in adult pigs during drug-induced cardiac arrest.
There is much interest in form-fitting, low-modulus, implantable devices or soft robots that can mimic or assist in complex biological functions such as the contraction of heart muscle. We present a soft robotic sleeve that is implanted around the heart and actively compresses and twists to act as a cardiac ventricular assist device. The sleeve does not contact blood, obviating the need for anticoagulation therapy or blood thinners, and reduces complications with current ventricular assist devices, such as clotting and infection. Our approach used a biologically inspired design to orient individual contracting elements or actuators in a layered helical and circumferential fashion, mimicking the orientation of the outer two muscle layers of the mammalian heart. The resulting implantable soft robot mimicked the form and function of the native heart, with a stiffness value of the same order of magnitude as that of the heart tissue. We demonstrated feasibility of this soft sleeve device for supporting heart function in a porcine model of acute heart failure. The soft robotic sleeve can be customized to patient-specific needs and may have the potential to act as a bridge to transplant for patients with heart failure.
A soft robotic sleeve modeled on the structure of the human heart assists cardiovascular function in an ex vivo and in vivo porcine model of heart failure.
A soft robotic sleeve modeled on the structure of the human heart assists cardiovascular function in an ex vivo and in vivo porcine model of heart failure.},
	language = {en},
	number = {373},
	urldate = {2017-01-23},
	journal = {Science Translational Medicine},
	author = {Roche, Ellen T. and Horvath, Markus A. and Wamala, Isaac and Alazmani, Ali and Song, Sang-Eun and Whyte, William and Machaidze, Zurab and Payne, Christopher J. and Weaver, James C. and Fishbein, Gregory and Kuebler, Joseph and Vasilyev, Nikolay V. and Mooney, David J. and Pigula, Frank A. and Walsh, Conor J.},
	month = jan,
	year = {2017},
	pmid = {28100834},
	pages = {eaaf3925}
}

@article{hirt_cardiac_2014,
	title = {Cardiac {Tissue} {Engineering}},
	volume = {114},
	copyright = {© 2014 American Heart Association, Inc.},
	issn = {0009-7330, 1524-4571},
	url = {http://circres.ahajournals.org/content/114/2/354},
	doi = {10.1161/CIRCRESAHA.114.300522},
	abstract = {The engineering of 3-dimensional (3D) heart muscles has undergone exciting progress for the past decade. Profound advances in human stem cell biology and technology, tissue engineering and material sciences, as well as prevascularization and in vitro assay technologies make the first clinical application of engineered cardiac tissues a realistic option and predict that cardiac tissue engineering techniques will find widespread use in the preclinical research and drug development in the near future. Tasks that need to be solved for this purpose include standardization of human myocyte production protocols, establishment of simple methods for the in vitro vascularization of 3D constructs and better maturation of myocytes, and, finally, thorough definition of the predictive value of these methods for preclinical safety pharmacology. The present article gives an overview of the present state of the art, bottlenecks, and perspectives of cardiac tissue engineering for cardiac repair and in vitro testing.},
	language = {en},
	number = {2},
	urldate = {2017-01-24},
	journal = {Circulation Research},
	author = {Hirt, Marc N. and Hansen, Arne and Eschenhagen, Thomas},
	month = jan,
	year = {2014},
	pmid = {24436431},
	keywords = {Myocardium, drug toxicity, guided tissue regeneration, heart disease, organ culture techniques, organoids, pluripotent stem cells},
	pages = {354--367}
}

@article{holladay_recovery_2012,
	title = {Recovery of cardiac function mediated by {MSC} and interleukin-10 plasmid functionalised scaffold},
	volume = {33},
	issn = {0142-9612},
	url = {//www.sciencedirect.com/science/article/pii/S0142961211012221},
	doi = {10.1016/j.biomaterials.2011.10.019},
	abstract = {Stem cell transplantation has been suggested as a treatment for myocardial infarction, but clinical studies have yet to demonstrate conclusive, positive effects. This may be related to poor survival of the transplanted stem cells due to the inflammatory response following myocardial infarction. To address this, a scaffold-based stem cell delivery system was functionalised with anti-inflammatory plasmids (interleukin-10) to improve stem cell retention and recovery of cardiac function. Myocardial infarction was induced and these functionalised scaffolds were applied over the infarcted myocardium. Four weeks later, stem cell retention, cardiac function, remodelling and inflammation were quantified. Interleukin-10 gene transfer improved stem cell retention by more than five-fold and the hearts treated with scaffold, stem cells and interleukin-10 had significant functional recovery compared to the scaffold control (scaffold: −10 ± 7\%, scaffold, interleukin-10 and stem cells: +7 ± 6\%). This improved function was associated with increased infarcted wall thickness and increased ratios of collagen type III/type I, decreased cell death, and a change in macrophage markers from mainly cytotoxic in the scaffold group to mainly regulatory in scaffold, stem cells and interleukin-10 group. Thus, treatment of myocardial infarction with stem cells and interleukin-10 gene transfer significantly improved stem cell retention and ultimately improved overall cardiac function.},
	number = {5},
	urldate = {2017-01-24},
	journal = {Biomaterials},
	author = {Holladay, Carolyn A. and Duffy, Aoife M. and Chen, Xizhe and Sefton, Michael V. and O’Brien, Timothy D. and Pandit, Abhay S.},
	month = feb,
	year = {2012},
	keywords = {Anti-inflammatory gene transfer, Cardiac tissue engineering, Interleukin-10, Mesenchymal stem cells, scaffold},
	pages = {1303--1314}
}

@article{savi_enhanced_2015,
	title = {Enhanced engraftment and repairing ability of human adipose-derived stem cells, conveyed by pharmacologically active microcarriers continuously releasing {HGF} and {IGF}-1, in healing myocardial infarction in rats},
	volume = {103},
	issn = {1552-4965},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/jbm.a.35442/abstract},
	doi = {10.1002/jbm.a.35442},
	abstract = {One of the main cause of ineffective cell therapy in repairing the damaged heart is the poor yield of grafted cells. To overcome this drawback, rats with 4-week-old myocardial infarction (MI) were injected in the border zone with human adipose-derived stem cells (ADSCs) conveyed by poly(lactic-co-glycolic acid) microcarriers (PAMs) releasing hepatocyte growth factor (HGF) and insulin-like growth factor-1 (IGF-1) (GFsPAMs). According to treatments, animals were subdivided into different groups: MI\_ADSC, MI\_ADSC/PAM, MI\_GFsPAM, MI\_ADSC/GFsPAM, and untreated MI\_V. Two weeks after injection, a 31\% increase in ADSC engraftment was observed in MI\_ADSC/PAM compared with MI\_ADSC (p {\textless} 0.05). A further ADSC retention was obtained in MI\_ADSC/GFsPAM with respect to MI\_ADSC (106\%, p {\textless} 0.05) and MI\_ADSC/PAM (57\%, p {\textless} 0.05). A 130\% higher density of blood vessels of medium size was present in MI\_ADSC/GFsPAM compared with MI\_ADSC (p {\textless} 0.01). MI\_ADSC/GFsPAM also improved, albeit slightly, left ventricular remodeling and hemodynamics with respect to the other groups. Notably, ADSCs and/or PAMs, with or without HGF/IGF-1, trended to induce arrhythmias in electrically driven, Langendorff-perfused, hearts of all groups. Thus, PAMs releasing HGF/IGF-1 markedly increase ADSC engraftment 2 weeks after injection and stimulate healing in chronically infarcted myocardium, but attention should be paid to potentially negative electrophysiological consequences. © 2015 Wiley Periodicals, Inc. J Biomed Mater Res Part A: 103A: 3012–3025, 2015.},
	language = {en},
	number = {9},
	urldate = {2017-01-24},
	journal = {Journal of Biomedical Materials Research Part A},
	author = {Savi, Monia and Bocchi, Leonardo and Fiumana, Emanuela and Karam, Jean-Pierre and Frati, Caterina and Bonafé, Francesca and Cavalli, Stefano and Morselli, Paolo G. and Guarnieri, Carlo and Caldarera, Claudio M. and Muscari, Claudio and Montero-Menei, Claudia N. and Stilli, Donatella and Quaini, Federico and Musso, Ezio},
	month = sep,
	year = {2015},
	keywords = {adipose-derived stem cell, arrhythmia, hepatocyte growth factor, insulin-like growth factor 1, myocardial infarction, pharmacologically active microcarrier},
	pages = {3012--3025}
}

@article{song_3d-printed_2015,
	title = {{3D}-{Printed} {Drug}/{Cell} {Carrier} {Enabling} {Effective} {Release} of {Cyclosporin} {A} for {Xenogeneic} {Cell}-{Based} {Therapy}},
	volume = {24},
	doi = {10.3727/096368915X686779},
	abstract = {Systemic administration of the immunosuppressive drug cyclosporin A (CsA) is frequently associated with a number of side effects; therefore, sometimes it cannot be applied in sufficient dosage after allogeneic or xenogeneic cell transplantation. Local delivery is a possible solution to this problem. We used 3D printing to develop a CsA-loaded 3D drug carrier for the purpose of local and sustained delivery of CsA. The carrier is a hybrid of CsA-poly(lactic-co-glycolic acid) (PLGA) microsphere-loaded hydrogel and a polymeric framework so that external force can be endured under physiological conditions. The expression of cytokines, which are secreted by spleen cells activated by Con A, and which are related to immune rejection, was significantly decreased in vitro by the released CsA from the drug carrier. Drug carriers seeded with xenogeneic cells (human lung fibroblast) were subcutaneously implanted into the BALB/c mouse. As a result, T-cell-mediated rejection was also significantly suppressed for 4 weeks. These results show that the developed 3D drug carrier can be used as an effective xenogeneic cell delivery system with controllable immunosuppressive drugs for cell-based therapy.},
	number = {12},
	journal = {Cell Transplantation},
	author = {Song, Tae-Ha and Jang, Jinah and Choi, Yeong-Jin and Shim, Jin-Hyung and Cho, Dong-Woo},
	month = dec,
	year = {2015},
	keywords = {3D Printing, Cell-Based Therapy, Cyclosporin A, Drug Delivery System, T-Cell-Mediated Rejection},
	pages = {2513--2525}
}

@incollection{roland_interpenetrating_2013,
	title = {Interpenetrating {Polymer} {Networks} ({IPN}): {Structure} and {Mechanical} {Behavior}},
	copyright = {©2014 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-36199-9},
	shorttitle = {Interpenetrating {Polymer} {Networks} ({IPN})},
	url = {http://link.springer.com/referenceworkentry/10.1007/978-3-642-36199-9_91-1},
	abstract = {SynonymsCo-continuous networks; Macrocyclic catenanes; Polymer blend networkDefinitionInterpenetrating polymer network (IPN) refers to a type of elastomer in which two chemically distinct networks coexist, ideally having a structure that is homogeneous down to the segmental level [1]. The two components are present as co-continuous, interlocking networks (catenanes). This co-continuity can be achieved by kinetic retention of an initially miscible mixture of the monomers used to form the network chains, with phase segregation inhibited by the network structure, or be the result of thermodynamic compatibility of the constituent polymers. A specific type of IPN relies on solvent to promote miscibility of the two polymers. Hydrogel IPNs, which use water as the solvent, are not included in this review (see related entry Double Network Hydrogels:​ Soft and Tough IPN).IntroductionThe defining characteristic of polymers is the enormous size of the constituent molecules (“macromolecules”), consi ...},
	language = {en},
	urldate = {2017-01-25},
	booktitle = {Encyclopedia of {Polymeric} {Nanomaterials}},
	publisher = {Springer Berlin Heidelberg},
	author = {Roland, C. M.},
	editor = {Kobayashi, Shiro and Müllen, Klaus},
	year = {2013},
	doi = {10.1007/978-3-642-36199-9_91-1},
	keywords = {Condensed Matter Physics, Nanochemistry, Nanotechnology, Polymer Sciences},
	pages = {1--9}
}

@article{haq_mechanical_2017,
	title = {Mechanical properties of {PNIPAM} based hydrogels: {A} review},
	volume = {70, Part 1},
	issn = {0928-4931},
	shorttitle = {Mechanical properties of {PNIPAM} based hydrogels},
	url = {//www.sciencedirect.com/science/article/pii/S0928493116315466},
	doi = {10.1016/j.msec.2016.09.081},
	abstract = {Materials which adjust their properties in response to environmental factors such as temperature, pH and ionic strength are rapidly evolving and known as smart materials. Hydrogels formed by smart polymers have various applications. Among the smart polymers, thermoresponsive polymer poly(N-isopropylacrylamide)(PNIPAM) is very important because of its well defined structure and property specially its temperature response is closed to human body and can be finetuned as well. Mechanical properties are critical for the performance of stimuli responsive hydrogels in diverse applications. However, native PNIPAM hydrogels are very fragile and hardly useful for any practical purpose. Intense researches have been done in recent decade to enhance the mechanical features of PNIPAM hydrogel. In this review, several strategies including interpenetrating polymer network (IPN), double network (DN), nanocomposite (NC) and slide ring (SR) hydrogels are discussed in the context of PNIPAM hydrogel.},
	urldate = {2017-01-25},
	journal = {Materials Science and Engineering: C},
	author = {Haq, Muhammad Abdul and Su, Yunlan and Wang, Dujin},
	month = jan,
	year = {2017},
	keywords = {Hydrogel, Mechanical properties, Poly(N-isopropylacrylamide), Smart material},
	pages = {842--855}
}

@article{haque_super_2012,
	title = {Super tough double network hydrogels and their application as biomaterials},
	volume = {53},
	issn = {0032-3861},
	url = {//www.sciencedirect.com/science/article/pii/S0032386112002212},
	doi = {10.1016/j.polymer.2012.03.013},
	abstract = {The double network (DN) technique, developed by authors’ group, provides an innovative and universal pass way to fabricate hydrogels with super high toughness comparable to rubbers. The excellent mechanical performances of DN hydrogels originate from the specific combination of two networks with contrasting structures. The first brittle network serves as sacrificial bonds, which breaks into small clusters to efficiently disperse the stress around the crack tip into the surrounding damage zone, while the second ductile polymer chains act as hidden length, which extends extensively to sustain large deformation. Based on the principle of DN hydrogel, the author’s group recently has developed several novel systems and techniques, which has greatly expanded the practical accessibility of DN technique for practical use. The DN principle and the DN gel have already attracted much attention in the soft matter community. Inspired by the DN principle, many research groups have also designed and developed some innovative hydrogels with large enhancement in their mechanical strength and toughness. Some tough hydrogels fabricated by the DN technique also exhibit good biocompatibility and low friction resistance with promising prospective in industrial and medicine fields, especially for load-bearing artificial soft tissues such as artificial cartilage. In this feature article, we address the major concept and toughening mechanism of DN gel, then we describe some recent novel hydrogel systems based on the DN concept, and finally the applicability of DN gel as soft biomaterials is discussed.},
	number = {9},
	urldate = {2017-01-25},
	journal = {Polymer},
	author = {Haque, Md. Anamul and Kurokawa, Takayuki and Gong, Jian Ping},
	month = apr,
	year = {2012},
	keywords = {Artificial cartilage, Bacterial cellulose, Damage zone, Double network principle, Microgel, Voids structure},
	pages = {1805--1822}
}

@article{haq_mechanical_2017-1,
	title = {Mechanical properties of {PNIPAM} based hydrogels: {A} review},
	volume = {70, Part 1},
	issn = {0928-4931},
	shorttitle = {Mechanical properties of {PNIPAM} based hydrogels},
	url = {//www.sciencedirect.com/science/article/pii/S0928493116315466},
	doi = {10.1016/j.msec.2016.09.081},
	abstract = {Materials which adjust their properties in response to environmental factors such as temperature, pH and ionic strength are rapidly evolving and known as smart materials. Hydrogels formed by smart polymers have various applications. Among the smart polymers, thermoresponsive polymer poly(N-isopropylacrylamide)(PNIPAM) is very important because of its well defined structure and property specially its temperature response is closed to human body and can be finetuned as well. Mechanical properties are critical for the performance of stimuli responsive hydrogels in diverse applications. However, native PNIPAM hydrogels are very fragile and hardly useful for any practical purpose. Intense researches have been done in recent decade to enhance the mechanical features of PNIPAM hydrogel. In this review, several strategies including interpenetrating polymer network (IPN), double network (DN), nanocomposite (NC) and slide ring (SR) hydrogels are discussed in the context of PNIPAM hydrogel.},
	urldate = {2017-01-25},
	journal = {Materials Science and Engineering: C},
	author = {Haq, Muhammad Abdul and Su, Yunlan and Wang, Dujin},
	month = jan,
	year = {2017},
	keywords = {Hydrogel, Mechanical properties, Poly(N-isopropylacrylamide), Smart material},
	pages = {842--855}
}

@article{du_toit_polymeric_2016,
	title = {Polymeric networks for controlled release of drugs: a patent review},
	volume = {26},
	issn = {1744-7674},
	shorttitle = {Polymeric networks for controlled release of drugs},
	doi = {10.1080/13543776.2016.1178720},
	abstract = {INTRODUCTION: Polymeric networks for controlled drug delivery possess wide pharmaceutical and biomedical applications.
AREAS COVERED: In this review, we explore the diversity of polymeric networks that exist, from simple to highly complex and 'smart' embodiments. The patented delivery systems reviewed reflect this, based on both conventional polymeric networks and stimulus-responsive networks where engineering of a controlled molecular architecture of polymeric networks enables a defined response to external or internal stimuli. Future trends in terms of nano-sized polymeric network patents are also highlighted.
EXPERT OPINION: A critical analysis of challenges potentially facing extended propulsion of the research and development of polymeric networks is provided. The significant therapeutic potential of polymer networks for controlled drug delivery is highlighted in the patented drug delivery systems examined; however, there needs to be enhanced representation of such systems in the market and thus available to patients. Concerted efforts are therefore necessary to propel these systems from the experimental setting to pilot scale production, and preclinical and clinical testing, for extension of their practicality.},
	language = {eng},
	number = {6},
	journal = {Expert Opinion on Therapeutic Patents},
	author = {du Toit, Lisa C. and Choonara, Yahya E. and Kumar, Pradeep and Pillay, Viness},
	month = jun,
	year = {2016},
	pmid = {27079971},
	keywords = {Controlled drug delivery, crosslinking, drug delivery systems, hydrogels, interpenetrating polymer networks, patents, polymer network, stimulus-responsive drug delivery systems},
	pages = {703--717}
}

@incollection{lakes_elastic_1998,
	series = {The {IMA} {Volumes} in {Mathematics} and its {Applications}},
	title = {Elastic {Freedom} in {Cellular} {Solids} and {Composite} {Materials}},
	copyright = {©1998 Springer Science+Business Media New York},
	isbn = {978-1-4612-7256-4 978-1-4612-1728-2},
	url = {http://link.springer.com/chapter/10.1007/978-1-4612-1728-2_9},
	abstract = {The question of how much freedom is to be incorporated in a continuum theory must ultimately be decided by experiment. There are several theories which describe behavior of materials. An early uniconstant theory was proposed based on atomic interaction theory; it was abandoned since it predicted a Poisson’s ratio of 1/4 for all materials. The elasticity theory currently accepted as classical allows Poisson’s ratios in isotropic materials in the range -1 to 1/2. Common materials exhibit a Poisson’s ratio from 1/4 to nearly 1/2. We have prepared materials with a Poisson’s ratio as small as -0.8. Deformation mechanisms in these materials include relative rotation of micro-elements, and non-affine micro-deformation. The relation between properties and structure is exploited to prepare viscoelastic composites with high stiffness combined with high damping. Generalized continuum theories exist with more freedom than classical theory. For example, in Cosserat elasticity there are characteristic lengths as additional engineering elastic constants. Recent experimental work discloses a variety of cellular and fibrous materials to exhibit such freedom, and the characteristic lengths have been measured. In hierarchical solids structural elements themselves have structure. Several examples of natural structural hierarchy are considered, with consequences related to optimality of material properties.},
	language = {en},
	number = {99},
	urldate = {2017-01-27},
	booktitle = {Mathematics of {Multiscale} {Materials}},
	publisher = {Springer New York},
	author = {Lakes, Roderic},
	editor = {Golden, Kenneth M. and Grimmett, Geoffrey R. and James, Richard D. and Milton, Graeme W. and Sen, Pabitra N.},
	year = {1998},
	doi = {10.1007/978-1-4612-1728-2_9},
	keywords = {Computational Intelligence, Math. Applications in Chemistry, Statistics, general},
	pages = {129--153}
}

@article{liu_hydrogel_2009,
	title = {Hydrogel based on interpenetrating polymer networks of dextran and gelatin for vascular tissue engineering},
	volume = {30},
	issn = {1878-5905},
	doi = {10.1016/j.biomaterials.2008.09.041},
	abstract = {Hydrogel networks are highly desirable as three-dimensional (3-D) tissue engineering scaffolds for cell encapsulation due to the high water content and ability to mimick the native extracellular matrix. However, their application is limited by their nanometer-scale mesh size, which restricts the spreading and proliferation of encapsulated cells, and their poor mechanical properties. This study seeks to address both limitations through application of a novel cell-encapsulating hydrogel family based on the interpenetrating polymer network (IPN) of gelatin and dextran bifunctionalized with methacrylate (MA) and aldehyde (AD) (Dex-MA-AD). The chemical structure of the synthesized Dex-MA-AD was verified by (1)H-NMR and the degrees of substitution of MA and AD were found to be 14 and 13.9+/-1.3 respectively. The water contents in all these hydrogels were approximately 80\%. Addition of 40 mg/ml to 60 mg/ml gelatin to neat Dex-MA-AD increased the compressive modulus from 15.4+/-3.0 kPa to around 51.9+/-0.1 kPa (about 3.4-fold). Further, our IPN hydrogels have higher dynamic storage moduli (i.e. on the order of 10(4)Pa) than polyethylene glycol-based hydrogels (around 10(2)-10(3)Pa) commonly used for smooth muscle cells (SMCs) encapsulation. Our dextran-based IPN hydrogels not only supported endothelial cells (ECs) adhesion and spreading on the surface, but also allowed encapsulated SMCs to proliferate and spread in the bulk interior of the hydrogel. These IPN hydrogels appear promising as 3-D scaffolds for vascular tissue engineering.},
	language = {eng},
	number = {2},
	journal = {Biomaterials},
	author = {Liu, Yunxiao and Chan-Park, Mary B.},
	month = jan,
	year = {2009},
	pmid = {18922573},
	keywords = {Aldehydes, Biocompatible Materials, Cell Proliferation, Cell adhesion, Cells, Cultured, Dextrans, Endothelial Cells, Gelatin, Humans, Hydrogel, Methacrylates, Polymers, Tissue Engineering},
	pages = {196--207}
}

@article{gibson_biomechanics_2005,
	title = {Biomechanics of cellular solids},
	volume = {38},
	issn = {0021-9290},
	url = {https://www.sciencedirect.com/science/article/pii/S0021929004004919},
	doi = {10.1016/j.jbiomech.2004.09.027},
	abstract = {Materials with a cellular structure are widespread in nature and include wood, cork, plant parenchyma and trabecular bone. Natural cellular materials are often mechanically efficient: the honeycomb-like microstructure of wood, for instance, gives it an exceptionally high performance index for resisting bending and buckling. Here we review the mechanics of a wide range of natural cellular materials and examine their role in lightweight natural sandwich structures (e.g. iris leaves) and natural tubular structures (e.g. plant stems or animal quills). We also describe two examples of engineered biomaterials with a cellular structure, designed to replace or regenerate tissue in the body.},
	number = {3},
	urldate = {2017-01-27},
	journal = {Journal of Biomechanics},
	author = {Gibson, Lorna J.},
	month = mar,
	year = {2005},
	keywords = {Cellular solids, Mechanical behavior, Plant stems, Scaffolds, Titanium foams, Trabecular bone, Wood},
	pages = {377--399}
}

@book{gibson_cellular_1999,
	title = {Cellular {Solids}: {Structure} and {Properties}},
	isbn = {978-0-521-49911-8},
	shorttitle = {Cellular {Solids}},
	abstract = {Cellular solids include engineering honeycombs and foams (which can now be made from polymers, metals, ceramics, and composites) as well as natural materials, such as wood, cork, and cancellous bone. This new edition of a classic work details current understanding of the structure and mechanical behavior of cellular materials, and the ways in which they can be exploited in engineering design. Gibson and Ashby have brought the book completely up to date, including new work on processing of metallic and ceramic foams and on the mechanical, electrical and acoustic properties of cellular solids. Data for commercially available foams are presented on material property charts; two new case studies show how the charts are used for selection of foams in engineering design. Over 150 references appearing in the literature since the publication of the first edition are cited. It will be of interest to graduate students and researchers in materials science and engineering.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Gibson, Lorna J. and Ashby, Michael F.},
	month = jul,
	year = {1999},
	note = {Google-Books-ID: IySUr5sn4N8C},
	keywords = {Technology \& Engineering / Materials Science}
}

@article{guessasma_relating_2008,
	title = {Relating cellular structure of open solid food foams to their {Young}’s modulus: {Finite} element calculation},
	volume = {45},
	issn = {0020-7683},
	shorttitle = {Relating cellular structure of open solid food foams to their {Young}’s modulus},
	url = {https://www.sciencedirect.com/science/article/pii/S0020768308000036},
	doi = {10.1016/j.ijsolstr.2008.01.007},
	abstract = {This paper investigates the role of structure on Young’s modulus of open cell materials of relative densities between 0.1 and 0.3. The cellular solid is obtained by generating mixture size of spherical voids using the Random Sequential Addition – RSA algorithm. The relative density of the material is controlled by increasing void number and overlap. Structural effects consider mainly a Gaussian distribution of spherical void size of varying width, distribution centre and void overlap distance. Finite element method is used to calculate effective Young’s modulus using a regular meshing scheme of 3D typical cellular solids and Conjugate Gradient solver. It is found that sphere overlap has the largest effect compared to sphere distribution width for a given density. A large scatter in the wall thickness distribution is predicted when overlapping is increased or when the width of sphere size distribution is decreased. Increased rigidity is found to be correlated to particular arrangement of mixture size spheres which is pointed out using the Pair Correlation Function. Experimental evidence of the role of void overlapping is treated in the case of bread crumbs structures determined using X-ray tomography. The scatter of effective Young’s modulus for a given relative density is sensitive to void overlapping.},
	number = {10},
	urldate = {2017-01-27},
	journal = {International Journal of Solids and Structures},
	author = {Guessasma, S. and Babin, P. and Valle, G. Della and Dendievel, R.},
	month = may,
	year = {2008},
	keywords = {Finite element method, Low relative density material, Overlapping, Random sequential addition, Young’s modulus},
	pages = {2881--2896}
}
@article{damore_bi-layered_2016,
	title = {Bi-layered polyurethane - {Extracellular} matrix cardiac patch improves ischemic ventricular wall remodeling in a rat model},
	volume = {107},
	issn = {1878-5905},
	doi = {10.1016/j.biomaterials.2016.07.039},
	abstract = {As an intervention to abrogate ischemic cardiomyopathy, the concept of applying a temporary, local patch to the surface of the recently infarcted ventricle has been explored from a number of design perspectives. Two important features considered for such a cardiac patch include the provision of appropriate mechanical support and the capacity to influence the remodeling pathway by providing cellular or biomolecule delivery. The objective of this report was to focus on these two features by first evaluating the incorporation of a cardiac extracellular matrix (ECM) component, and second by evaluating the impact of patch anisotropy on the pathological remodeling process initiated by myocardial infarction. The functional outcomes of microfibrous, elastomeric, biodegradable cardiac patches have been evaluated in a rat chronic infarction model. Ten weeks after infarction and 8 wk after patch epicardial placement, echocardiographic function, tissue-level structural remodeling (e.g., biaxial mechanical response and microstructural analysis), and cellular level remodeling were assessed. The results showed that the incorporation of a cardiac ECM altered the progression of several keys aspects of maladaptive remodeling following myocardial infarction. This included decreasing LV global mechanical compliance, inhibiting echocardiographically-measured functional deterioration, mitigating scar formation and LV wall thinning, and promoting angiogenesis. In evaluating the impact of patch anisotropy, no effects from the altered patch mechanics were detected after 8 wk, possibly due to patch fibrous encapsulation. Overall, this study demonstrates the benefit of a cardiac patch design that combines both ventricle mechanical support, through a biodegradable, fibrillary elastomeric component, and the incorporation of ECM-based hydrogel components.},
	language = {eng},
	journal = {Biomaterials},
	author = {D'Amore, Antonio and Yoshizumi, Tomo and Luketich, Samuel K. and Wolf, Matthew T. and Gu, Xinzhu and Cammarata, Marcello and Hoff, Richard and Badylak, Stephen F. and Wagner, William R.},
	month = nov,
	year = {2016},
	pmid = {27579776},
	keywords = {Cardiac ECM, Cardiac patch, Electrospun scaffold, Structure - function},
	pages = {1--14}
}

@article{breitbach_potential_2007,
	title = {Potential risks of bone marrow cell transplantation into infarcted hearts},
	volume = {110},
	issn = {0006-4971},
	doi = {10.1182/blood-2006-12-063412},
	abstract = {Cellular replacement therapy has emerged as a novel strategy for the treatment of heart failure. The aim of our study was to determine the fate of injected mesenchymal stem cells (MSCs) and whole bone marrow (BM) cells in the infarcted heart. MSCs were purified from BM of transgenic mice and characterized using flow cytometry and in vitro differentiation assays. Myocardial infarctions were generated in mice and different cell populations including transgenic MSCs, unfractionated BM cells, or purified hematopoietic progenitors were injected. Encapsulated structures were found in the infarcted areas of a large fraction of hearts after injecting MSCs (22 of 43, 51.2\%) and unfractionated BM cells (6 of 46, 13.0\%). These formations contained calcifications and/or ossifications. In contrast, no pathological abnormalities were found after injection of purified hematopoietic progenitors (0 of 5, 0.0\%), fibroblasts (0 of 5, 0.0\%), vehicle only (0 of 30, 0.0\%), or cytokine-induced mobilization of BM cells (0 of 35, 0.0\%). We conclude that the developmental fate of BM-derived cells is not restricted by the surrounding tissue after myocardial infarction and that the MSC fraction underlies the extended bone formation in the infarcted myocardium. These findings seriously question the biologic basis and clinical safety of using whole BM and in particular MSCs to treat nonhematopoietic disorders.},
	language = {eng},
	number = {4},
	journal = {Blood},
	author = {Breitbach, Martin and Bostani, Toktam and Roell, Wilhelm and Xia, Ying and Dewald, Oliver and Nygren, Jens M. and Fries, Jochen W. U. and Tiemann, Klaus and Bohlen, Heribert and Hescheler, Juergen and Welz, Armin and Bloch, Wilhelm and Jacobsen, Sten Eirik W. and Fleischmann, Bernd K.},
	month = aug,
	year = {2007},
	pmid = {17483296},
	keywords = {Animals, Bone Marrow Transplantation, Cell Differentiation, Cells, Cultured, Flow Cytometry, Green Fluorescent Proteins, Mesenchymal Stem Cell Transplantation, Mice, Mice, Inbred C57BL, Mice, Transgenic, Treatment Outcome, myocardial infarction, risk factors},
	pages = {1362--1369}
}

@misc{noauthor_elastic_2017,
	title = {Elastic moduli of model random three-dimensional closed-cell cellular solids - {Introduction}},
	url = {http://ciks.cbt.nist.gov/garbocz/closedcell/node1.html},
	urldate = {2017-01-31},
	month = jan,
	year = {2017}
}

@book{noauthor_materials_2003,
	title = {Materials {Data} {Book}},
	publisher = {Cambridge University Engineering Department},
	year = {2003}
}

@article{mathur_endothelial_2001,
	title = {Endothelial, cardiac muscle and skeletal muscle exhibit different viscous and elastic properties as determined by atomic force microscopy},
	volume = {34},
	issn = {0021-9290},
	url = {https://www.sciencedirect.com/science/article/pii/S002192900100149X},
	doi = {10.1016/S0021-9290(01)00149-X},
	abstract = {This study evaluated the hypothesis that, due to functional and structural differences, the apparent elastic modulus and viscous behavior of cardiac and skeletal muscle and vascular endothelium would differ. To accurately determine the elastic modulus, the contribution of probe velocity, indentation depth, and the assumed shape of the probe were examined. Hysteresis was observed at high indentation velocities arising from viscous effects. Irreversible deformation was not observed for endothelial cells and hysteresis was negligible below 1 μm/s. For skeletal muscle and cardiac muscle cells, hysteresis was negligible below 0.25 μm/s. Viscous dissipation for endothelial and cardiac muscle cells was higher than for skeletal muscle cells. The calculated elastic modulus was most sensitive to the assumed probe geometry for the first 60 nm of indentation for the three cell types. Modeling the probe as a blunt cone–spherical cap resulted in variation in elastic modulus with indentation depth that was less than that calculated by treating the probe as a conical tip. Substrate contributions were negligible since the elastic modulus reached a steady value for indentations above 60 nm and the probe never indented more than 10\% of the cell thickness. Cardiac cells were the stiffest (100.3±10.7 kPa), the skeletal muscle cells were intermediate (24.7±3.5 kPa), and the endothelial cells were the softest with a range of elastic moduli (1.4±0.1 to 6.8±0.4 kPa) depending on the location of the cell surface tested. Cardiac and skeletal muscle exhibited nonlinear elastic behavior. These passive mechanical properties are generally consistent with the function of these different cell types.},
	number = {12},
	urldate = {2017-02-08},
	journal = {Journal of Biomechanics},
	author = {Mathur, Anshu B. and Collinsworth, Amy M. and Reichert, William M. and Kraus, William E. and Truskey, George A.},
	month = dec,
	year = {2001},
	keywords = {Elastic Modulus, Hysteresis, Indenter geometry, Mechanical properties, Probe velocity},
	pages = {1545--1553}
}

@article{kohles_cytoskeletal_2012,
	title = {Cytoskeletal {Strains} in {Modeled} {Optohydrodynamically} {Stressed} {Healthy} and {Diseased} {Biological} {Cells}},
	volume = {2012},
	issn = {1687-8000},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3523158/},
	doi = {10.1155/2012/830741},
	abstract = {Controlled external chemomechanical stimuli have been shown to influence cellular and tissue regeneration/degeneration, especially with regards to distinct disease sequelae or health maintenance. Recently, a unique three-dimensional stress state was mathematically derived to describe the experimental stresses applied to isolated living cells suspended in an optohydrodynamic trap (optical tweezers combined with microfluidics). These formulae were previously developed in two and three dimensions from the fundamental equations describing creeping flows past a suspended sphere. The objective of the current study is to determine the full-field cellular strain response due to the applied three-dimensional stress environment through a multiphysics computational simulation. In this investigation, the multiscale cytoskeletal structures are modeled as homogeneous, isotropic, and linearly elastic. The resulting computational biophysics can be directly compared with experimental strain measurements, other modeling interpretations of cellular mechanics including the liquid drop theory, and biokinetic models of biomolecule dynamics. The described multiphysics computational framework will facilitate more realistic cytoskeletal model interpretations, whose intracellular structures can be distinctly defined, including the cellular membrane substructures, nucleus, and organelles.},
	urldate = {2017-02-09},
	journal = {Journal of Biophysics},
	author = {Kohles, Sean S. and Liang, Yu and Saha, Asit K.},
	year = {2012},
	pmid = {23304139},
	pmcid = {PMC3523158}
}

@article{chang_structure_2011,
	title = {Structure - {Function} {Relationships} in the {Stem} {Cell}’s {Mechanical} {World} {B}: {Emergent} {Anisotropy} of the {Cytoskeleton} {Correlates} to {Volume} and {Shape} {Changing} {Stress} {Exposure}},
	volume = {8},
	issn = {1556-5297},
	shorttitle = {Structure - {Function} {Relationships} in the {Stem} {Cell}’s {Mechanical} {World} {B}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3428039/},
	abstract = {In the preceding study (Part A), we showed that prescribed seeding conditions as well as seeding density can be used to subject multipotent stem cells (MSCs) to volume changing stresses and that changes in volume of the cell are associated with changes in shape, but not volume, of the cell nucleus. In the current study, we aim to control the mechanical milieu of live cells using these prescribed seeding conditions concomitant to delivery of shape changing stresses via fluid flow, while observing adaptation of the cytoskeleton, a major cellular transducer that modulates cell shape, stiffness and remodeling. We hypothesize that the spatiotemporal organization of tubulin and actin elements of the cytoskeleton changes in response to volume and shape changing stresses emulating those during development, prior to the first beating of the heart or twitching of muscle. Our approach was to quantify the change over baseline in spatiotemporal distribution of actin and tubulin in live C3H/10T1/2 model stem cells subjected to volume changing stresses induced by seeding at density as well as low magnitude, short duration, shape changing (shear) stresses induced by fluid flow (0.5 or 1.0 dyne/cm2 for 30/60/90 minutes). Upon exposure to fluid flow, both tubulin thickness (height) and concentration (fluorescence intensity) change significantly over baseline, as a function of proximity to neighboring cells (density) and the substrate (apical-basal height). Given our recently published studies showing amplification of stress gradients (flow velocity) with increasing distance to nearest neighbors and the substrate, i.e. with decreasing density and toward the apical side of the cell, tubulin adaptation appears to depend significantly on the magnitude of the stress to which the cell is exposed locally. In contrast, adaptation of actin to the changing mechanical milieu is more global, exhibiting less significant differences attributable to nearest neighbors or boundaries than differences attributable to magnitude of the stress to which the cell is exposed globally (0.5 versus 1.0 dyne/cm2). Furthermore, changes in the actin cytoskeletal distribution correlate positively with one pre-mesenchymal condensation marker (Msx2) and negatively with early markers of chondrogenesis (ColIIaI alone, indicative of pre-hypertrophic chondrogenesis) and osteogenesis (Runx2). Changes in the tubulin cytoskeletal distribution correlate positively with a marker of pericondensation (Sox9 alone), negatively with chondrogenesis (ColIIaI) and positively with adipogenesis (Ppar-γ2). Taken as a whole, exposure of MSCs to volume and shape changing stresses results in emergent anisotropy of cytoskeletal architecture (structure), which relate to emergent cell fate (function).},
	number = {4},
	urldate = {2017-02-09},
	journal = {Molecular \& cellular biomechanics : MCB},
	author = {Chang, Hana and Knothe Tate, Melissa L.},
	month = dec,
	year = {2011},
	pmid = {22338708},
	pmcid = {PMC3428039},
	pages = {297--318}
}

@article{gladilin_3d_2007,
	title = {{3D} finite element analysis of uniaxial cell stretching: from image to insight},
	volume = {4},
	issn = {1478-3975},
	shorttitle = {{3D} finite element analysis of uniaxial cell stretching},
	url = {http://stacks.iop.org/1478-3975/4/i=2/a=004},
	doi = {10.1088/1478-3975/4/2/004},
	abstract = {Mechanical forces play an important role in many microbiological phenomena such as embryogenesis, regeneration, cell proliferation and differentiation. Micromanipulation of cells in a controlled environment is a widely used approach for understanding cellular responses with respect to external mechanical forces. While modern micromanipulation and imaging techniques provide useful optical information about the change of overall cell contours under the impact of external loads, the intrinsic mechanisms of energy and signal propagation throughout the cell structure are usually not accessible by direct observation. This work deals with the computational modelling and simulation of intracellular strain state of uniaxially stretched cells captured in a series of images. A nonlinear elastic finite element method on tetrahedral grids was applied for numerical analysis of inhomogeneous stretching of a rat embryonic fibroblast 52 (REF 52) using a simplified two-component model of a eukaryotic cell consisting of a stiffer nucleus surrounded by a softer cytoplasm. The difference between simulated and experimentally observed cell contours is used as a feedback criterion for iterative estimation of canonical material parameters of the two-component model such as stiffness and compressibility. Analysis of comparative simulations with varying material parameters shows that (i) the ratio between the stiffness of cell nucleus and cytoplasm determines intracellular strain distribution and (ii) large deformations result in increased stiffness and decreased compressibility of the cell cytoplasm. The proposed model is able to reproduce the evolution of the cellular shape over a sequence of observed deformations and provides complementary information for a better understanding of mechanical cell response.},
	language = {en},
	number = {2},
	urldate = {2017-02-10},
	journal = {Physical Biology},
	author = {Gladilin, E. and Micoulet, A. and Hosseini, B. and Rohr, K. and Spatz, J. and Eils, R.},
	year = {2007},
	pages = {104}
}

@article{strange_mechanical_2014,
	title = {Mechanical behaviour of electrospun fibre-reinforced hydrogels},
	volume = {25},
	issn = {0957-4530, 1573-4838},
	url = {http://link.springer.com/article/10.1007/s10856-013-5123-y},
	doi = {10.1007/s10856-013-5123-y},
	abstract = {Mechanically robust and biomimicking scaffolds are needed for structural engineering of tissues such as the intervertebral disc, which are prone to failure and incapable of natural healing. Here, the formation of thick, randomly aligned polycaprolactone electrospun fibre structures infiltrated with alginate is reported. The composites are characterised using both indentation and tensile testing and demonstrate substantially different tensile and compressive moduli. The composites are mechanically robust and exhibit large strains-to-failure, exhibiting toughening mechanisms observed in other composite material systems. The method presented here provides a way to create large-scale biomimetic scaffolds that more closely mimic the composite structure of natural tissue, with tuneable tensile and compressive properties via the fibre and matrix phases, respectively.},
	language = {en},
	number = {3},
	urldate = {2017-02-13},
	journal = {Journal of Materials Science: Materials in Medicine},
	author = {Strange, Daniel G. T. and Tonsomboon, Khaow and Oyen, Michelle L.},
	month = mar,
	year = {2014},
	pages = {681--690}
}

@article{bosworth_state_2013,
	title = {State of the art composites comprising electrospun fibres coupled with hydrogels: a review},
	volume = {9},
	issn = {1549-9634},
	shorttitle = {State of the art composites comprising electrospun fibres coupled with hydrogels},
	url = {http://www.sciencedirect.com/science/article/pii/S1549963412006053},
	doi = {10.1016/j.nano.2012.10.008},
	abstract = {Research into scaffolds tailored for specific tissue engineering and biomaterial applications continues to develop as these structures are commonly impeded by their limitations. For example, electrospun fibres and hydrogels are commonly exploited because of their ability to mimic natural tissues; however, their clinical use remains restricted due to negligible cellular infiltration and poor mechanical properties, respectively. A small number of research groups are beginning to investigate composite scaffolds based on electrospun fibres and hydrogels in an attempt to overcome their individual shortcomings. This review paper discusses the various methodologies and approaches currently undertaken to create these novel composite structures and their intended applications. The combination of these two commonly used scaffold architectures to create synergistically superior structures is showing potential with regards to therapeutic use within the tissue engineering community.
From the Clinical Editor
This review discusses methodologies to create novel electrospun nanofibers and hydrogels, and their intended applications. The combination of these two scaffold architectures has important future clinical applications, although their use is currently limited to the experimental tissue engineering community.},
	number = {3},
	urldate = {2017-02-13},
	journal = {Nanomedicine: Nanotechnology, Biology and Medicine},
	author = {Bosworth, Lucy A. and Turner, Lesley-Anne and Cartmell, Sarah H.},
	month = apr,
	year = {2013},
	keywords = {Composites, Electrospinning, Nanofibres, Tissue Engineering, hydrogels},
	pages = {322--335}
}

@article{balguid_tailoring_2009,
	title = {Tailoring fiber diameter in electrospun poly(epsilon-caprolactone) scaffolds for optimal cellular infiltration in cardiovascular tissue engineering},
	volume = {15},
	issn = {1937-3341},
	doi = {10.1089/ten.tea.2007.0294},
	abstract = {Despite the attractive features of nanofibrous scaffolds for cell attachment in tissue-engineering (TE) applications, impeded cell ingrowth has been reported in electrospun scaffolds. Previous findings have shown that the scaffold can function as a sieve, keeping cells on the scaffold surface, and that cell migration into the scaffold does not occur in time. Because fiber diameter is directly related to the pore size of an electrospun scaffold, the objective of this study was to systematically evaluate how cell delivery can be optimized by tailoring the fiber diameter of electrospun poly(epsilon-caprolactone) (PCL) scaffolds. Five groups of electrospun PCL scaffolds with increasing average fiber diameters (3.4-12.1 microm) were seeded with human venous myofibroblasts. Cell distribution was analyzed after 3 days of culture. Cell penetration increased proportionally with increasing fiber diameter. Unobstructed delivery of cells was observed exclusively in the scaffold with the largest fiber diameter (12.1 microm). This scaffold was subsequently evaluated in a 4-week TE experiment and compared with a poly(glycolic acid)-poly(4-hydroxybutyrate) scaffold, a standard scaffold used successfully in cardiovascular tissue engineering applications. The PCL constructs showed homogeneous tissue formation and sufficient matrix deposition. In conclusion, fiber diameter is a crucial parameter to allow for homogeneous cell delivery in electrospun scaffolds. The optimal electrospun scaffold geometry, however, is not generic and should be adjusted to cell size.},
	language = {eng},
	number = {2},
	journal = {Tissue Engineering. Part A},
	author = {Balguid, Angelique and Mol, Anita and van Marion, Mieke H. and Bank, Ruud A. and Bouten, Carlijn V. C. and Baaijens, Frank P. T.},
	month = feb,
	year = {2009},
	pmid = {18694294},
	keywords = {Cardiovascular System, Cell Count, Humans, Mechanical Phenomena, Nanofibers, Polyesters, Polyglycolic Acid, Staining and Labeling, Tissue Engineering, Tissue Scaffolds, Tolonium Chloride},
	pages = {437--444}
}

@misc{noauthor_crcnetbase_2017,
	title = {{CRCnetBASE} - {Encyclopedia} of {Biomedical} {Polymers} and {Polymeric} {Biomaterials}},
	url = {http://www.crcnetbase.com/doi/pdfplus/10.1081/E-EBPP-120052312},
	urldate = {2017-02-14},
	month = feb,
	year = {2017}
}

@article{pham_electrospun_2006,
	title = {Electrospun poly(epsilon-caprolactone) microfiber and multilayer nanofiber/microfiber scaffolds: characterization of scaffolds and measurement of cellular infiltration},
	volume = {7},
	issn = {1525-7797},
	shorttitle = {Electrospun poly(epsilon-caprolactone) microfiber and multilayer nanofiber/microfiber scaffolds},
	doi = {10.1021/bm060680j},
	abstract = {The physical and spatial architectural geometries of electrospun scaffolds are important to their application in tissue engineering strategies. In this work, poly(epsilon-caprolactone) microfiber scaffolds with average fiber diameters ranging from 2 to 10 microm were individually electrospun to determine the parameters required for reproducibly fabricating scaffolds. As fiber diameter increased, the average pore size of the scaffolds, as measured by mercury porosimetry, increased (values ranging from 20 to 45 microm), while a constant porosity was observed. To capitalize on both the larger pore sizes of the microfiber layers and the nanoscale dimensions of the nanofiber layers, layered scaffolds were fabricated by sequential electrospinning. These scaffolds consisted of alternating layers of poly(epsilon-caprolactone) microfibers and poly(epsilon-caprolactone) nanofibers. By electrospinning the nanofiber layers for different lengths of time, the thickness of the nanofiber layers could be modulated. Bilayered constructs consisting of microfiber scaffolds with varying thicknesses of nanofibers on top were generated and evaluated for their potential to affect rat marrow stromal cell attachment, spreading, and infiltration. Cell attachment after 24 h did not increase with increasing number of nanofibers, but the presence of nanofibers enhanced cell spreading as evidenced by stronger F-actin staining. Additionally, increasing the thickness of the nanofiber layer reduced the infiltration of cells into the scaffolds under both static and flow perfusion culture for the specific conditions tested. The scaffold design presented in this study allows for cellular infiltration into the scaffolds while at the same time providing nanofibers as a physical mimicry of extracellular matrix.},
	language = {eng},
	number = {10},
	journal = {Biomacromolecules},
	author = {Pham, Quynh P. and Sharma, Upma and Mikos, Antonios G.},
	month = oct,
	year = {2006},
	pmid = {17025355},
	keywords = {Actins, Animals, Biochemistry, Biocompatible Materials, Cell Culture Techniques, Electrochemistry, Extracellular Matrix, Microscopy, Confocal, Models, Chemical, Models, Statistical, Nanotechnology, Polyesters, Porosity, Rats, Stem cells},
	pages = {2796--2805}
}

@article{moutos_biomimetic_2007,
	title = {A biomimetic three-dimensional woven composite scaffold for functional tissue engineering of cartilage},
	volume = {6},
	issn = {1476-1122},
	doi = {10.1038/nmat1822},
	abstract = {Tissue engineering seeks to repair or regenerate tissues through combinations of implanted cells, biomaterial scaffolds and biologically active molecules. The rapid restoration of tissue biomechanical function remains an important challenge, emphasizing the need to replicate structural and mechanical properties using novel scaffold designs. Here we present a microscale 3D weaving technique to generate anisotropic 3D woven structures as the basis for novel composite scaffolds that are consolidated with a chondrocyte-hydrogel mixture into cartilage tissue constructs. Composite scaffolds show mechanical properties of the same order of magnitude as values for native articular cartilage, as measured by compressive, tensile and shear testing. Moreover, our findings showed that porous composite scaffolds could be engineered with initial properties that reproduce the anisotropy, viscoelasticity and tension-compression nonlinearity of native articular cartilage. Such scaffolds uniquely combine the potential for load-bearing immediately after implantation in vivo with biological support for cell-based tissue regeneration without requiring cultivation in vitro.},
	language = {eng},
	number = {2},
	journal = {Nature Materials},
	author = {Moutos, Franklin T. and Freed, Lisa E. and Guilak, Farshid},
	month = feb,
	year = {2007},
	pmid = {17237789},
	keywords = {Biocompatible Materials, Cartilage, Tissue Engineering},
	pages = {162--167}
}

@article{agrawal_strong_2013,
	title = {Strong fiber-reinforced hydrogel},
	volume = {9},
	issn = {1742-7061},
	url = {http://www.sciencedirect.com/science/article/pii/S1742706112004886},
	doi = {10.1016/j.actbio.2012.10.011},
	abstract = {In biological hydrogels, the gel matrix is usually reinforced with micro- or nanofibers, and the resulting composite is tough and strong. In contrast, synthetic hydrogels are weak and brittle, although they are highly elastic. The are many potential applications for strong synthetic hydrogels in medical devices, including as scaffolds for tissue growth. This work describes a new class of hydrogel composites reinforced with elastic fibers, giving them a cartilage-like structure. A three-dimensional rapid prototyping technique was used to form crossed “log-piles” of elastic fibers that are then impregnated with an epoxy-based hydrogel in order to form the fiber-reinforced gel. The fibrous construct improves the strength, modulus and toughness of the hydrogel, and also constrains the swelling. By altering the construct geometry and studying the effect on mechanical properties, we will develop the understanding needed to design strong hydrogels for biomedical devices and soft machines.},
	number = {2},
	urldate = {2017-02-15},
	journal = {Acta Biomaterialia},
	author = {Agrawal, Animesh and Rahbar, Nima and Calvert, Paul D.},
	month = feb,
	year = {2013},
	keywords = {Biomimicking, Rapid prototyping, Reinforced hydrogels, Toughness},
	pages = {5313--5318}
}

@article{strange_electrospun_2012,
	title = {Electrospun {Fiber} - {Hydrogel} {Composites} for {Nucleus} {Pulposus} {Tissue} {Engineering}},
	volume = {1417},
	issn = {1946-4274, 0272-9172},
	url = {https://www.cambridge.org/core/journals/mrs-online-proceedings-library-archive/article/div-classtitleelectrospun-fiber-hydrogel-composites-for-nucleus-pulposus-tissue-engineeringdiv/34F9377F548E44748A66C19CCDA369BD},
	doi = {10.1557/opl.2012.742},
	abstract = {ABSTRACTNew materials are needed to replace degenerated intervertebral disc tissue and to provide longer-term solutions for chronic back-pain. Replacement tissue potentially could be engineered by seeding cells into a scaffold that mimics the architecture of natural tissue. Many natural tissues, including the nucleus pulposus (the central region of the intervertebral disc) consist of collagen nanofibers embedded in a gel-like matrix. Recently it was shown that electrospun micro- or nano-fiber structures of considerable thickness can be produced by collecting fibers in an ethanol bath. Here, randomly aligned polycaprolactone electrospun fiber structures up to 50 mm thick are backfilled with alginate hydrogels to form novel composite materials that mimic the fiber-reinforced structure of the nucleus pulposus. The composites are characterized using both indentation and tensile testing. The composites are mechanically robust, exhibiting substantial strain-to-failure. The method presented here provides a way to create large biomimetic scaffolds that more closely mimic the composite structure of natural tissue.},
	urldate = {2017-02-15},
	journal = {MRS Online Proceedings Library Archive},
	author = {Strange, Daniel G. T. and Tonsomboon, Khaow and Oyen, Michelle L.},
	month = jan,
	year = {2012},
	keywords = {biomaterial, biomimetic (assembly), composite}
}

@book{ghosh_micromechanical_2011,
	title = {Micromechanical {Analysis} and {Multi}-{Scale} {Modeling} {Using} the {Voronoi} {Cell} {Finite} {Element} {Method}},
	isbn = {978-1-4200-9438-1},
	abstract = {As multi-phase metal/alloy systems and polymer, ceramic, or metal matrix composite materials are increasingly being used in industry, the science and technology for these heterogeneous materials has advanced rapidly. By extending analytical and numerical models, engineers can analyze failure characteristics of the materials before they are integrated into the design process. Micromechanical Analysis and Multi-Scale Modeling Using the Voronoi Cell Finite Element Method addresses the key problem of multi-scale failure and deformation of materials that have complex microstructures. The book presents a comprehensive computational mechanics and materials science–based framework for multi-scale analysis.   The focus is on micromechanical analysis using the Voronoi cell finite element method (VCFEM) developed by the author and his research group for the efficient and accurate modeling of materials with non-uniform heterogeneous microstructures. While the topics covered in the book encompass the macroscopic scale of structural components and the microscopic scale of constituent heterogeneities like inclusions or voids, the general framework may be extended to other scales as well.   The book presents the major components of the multi-scale analysis framework in three parts. Dealing with multi-scale image analysis and characterization, the first part of the book covers 2D and 3D image-based microstructure generation and tessellation into Voronoi cells. The second part develops VCFEM for micromechanical stress and failure analysis, as well as thermal analysis, of extended microstructural regions. It examines a range of problems solved by VCFEM, from heat transfer and stress-strain analysis of elastic, elastic-plastic, and viscoplastic material microstructures to microstructural damage models including interfacial debonding and ductile failure. Establishing the multi-scale framework for heterogeneous materials with and without damage, the third part of the book discusses adaptive concurrent multi-scale analysis incorporating bottom-up and top-down modeling.  Including numerical examples and a CD-ROM with VCFEM source codes and input/output files, this book is a valuable reference for researchers, engineers, and professionals involved with predicting the performance and failure of materials in structure-materials interactions.},
	language = {en},
	publisher = {CRC Press},
	author = {Ghosh, Somnath},
	month = jun,
	year = {2011},
	note = {Google-Books-ID: 14wsSHcVy48C},
	keywords = {Technology \& Engineering / Automotive, Technology \& Engineering / Electronics / Microelectronics, Technology \& Engineering / Materials Science, Technology \& Engineering / Mechanical}
}

@article{butler_functional_2000,
	title = {Functional {Tissue} {Engineering}: {The} {Role} of {Biomechanics}},
	volume = {122},
	issn = {0148-0731},
	shorttitle = {Functional {Tissue} {Engineering}},
	url = {http://dx.doi.org/10.1115/1.1318906},
	doi = {10.1115/1.1318906},
	abstract = {“Tissue engineering” uses implanted cells, scaffolds, DNA, protein, and/or protein fragments to replace or repair injured or diseased tissues and organs. Despite its early success, tissue engineers have faced challenges in repairing or replacing tissues that serve a predominantly biomechanical function. An evolving discipline called “functional tissue engineering” (FTE) seeks to address these challenges. In this paper, the authors present principles of functional tissue engineering that should be addressed when engineering repairs and replacements for load-bearing structures. First, in vivo stress/strain histories need to be measured for a variety of activities. These in vivo data provide mechanical thresholds that tissue repairs/replacements will likely encounter after surgery. Second, the mechanical properties of the native tissues must be established for subfailure and failure conditions. These “baseline data” provide parameters within the expected thresholds for different in vivo activities and beyond these levels if safety factors are to be incorporated. Third, a subset of these mechanical properties must be selected and prioritized. This subset is important, given that the mechanical properties of the designs are not expected to completely duplicate the properties of the native tissues. Fourth, standards must be set when evaluating the repairs/replacements after surgery so as to determine, “how good is good enough?” Some aspects of the repair outcome may be inferior, but other mechanical characteristics of the repairs and replacements might be suitable. New and improved methods must also be developed for assessing the function of engineered tissues. Fifth, the effects of physical factors on cellular activity must be determined in engineered tissues. Knowing these signals may shorten the iterations required to replace a tissue successfully and direct cellular activity and phenotype toward a desired end goal. Finally, to effect a better repair outcome, cell-matrix implants may benefit from being mechanically stimulated using in vitro “bioreactors” prior to implantation. Increasing evidence suggests that mechanical stress, as well as other physical factors, may significantly increase the biosynthetic activity of cells in bioartificial matrices. Incorporating each of these principles of functional tissue engineering should result in safer and more efficacious repairs and replacements for the surgeon and patient.  [S0148-0731(00)00206-5]},
	number = {6},
	urldate = {2017-02-07},
	journal = {Journal of Biomechanical Engineering},
	author = {Butler, David L. and Goldstein, Steven A. and Guilak, Farshid},
	month = jul,
	year = {2000},
	pages = {570--575}
}

@article{mcgarry_three-dimensional_2004,
	title = {A three-dimensional finite element model of an adherent eukaryotic cell},
	volume = {7},
	issn = {1473-2262},
	abstract = {Mechanical stimulation is known to cause alterations in the behaviour of cells adhering to a substrate. The mechanisms by which forces are transduced into biological responses within the cell remain largely unknown. Since cellular deformation is likely involved, further understanding of the biomechanical origins of alterations in cellular response can be aided by the use of computational models in describing cellular structural behaviour and in determining cellular deformation due to imposed loads of various magnitudes. In this paper, a finite element modelling approach that can describe the biomechanical behaviour of adherent eukaryotic cells is presented. It fuses two previous modelling approaches by incorporating, in an idealised geometry, all cellular components considered structurally significant, i.e. prestressed cytoskeleton, cytoplasm, nucleus and membrane components. The aim is to determine if we can use this model to describe the non-linear structural behaviour of an adherent cell and to determine the contribution of the various cellular components to cellular stability. Results obtained by applying forces (in the picoNewton range) to the model membrane nodes suggest a key role for the cytoskeleton in determining cellular stiffness. The model captures non-linear structural behaviours such as strain hardening and prestress effects (in the region of receptor sites), and variable compliance along the cell surface. The role of the cytoskeleton in stiffening a cell during the process of cell spreading is investigated by applying forces to five increasingly spread cell geometries. Parameter studies reveal that material properties of the cytoplasm (elasticity and compressibility) also have a large influence on cellular stiffness. The computational model of a single cell developed here is proposed as one that is sufficiently complex to capture the non-linear behaviours of the cell response to forces whilst not being so complex that the parameters cannot be specified. The model could be very useful in computing cellular structural behaviour in response to various in vitro mechanical stimuli (e.g. fluid flow, substrate strain), or for use in algorithms that attempt to simulate mechanobiological processes.},
	language = {eng},
	journal = {European Cells \& Materials},
	author = {McGarry, J. G. and Prendergast, P. J.},
	month = apr,
	year = {2004},
	pmid = {15095253},
	keywords = {Actin Cytoskeleton, Animals, Cell Membrane, Cell Nucleus, Cell Shape, Cell adhesion, Chick Embryo, Cytoplasm, Elasticity, Eukaryotic Cells, Fibroblasts, Finite Element Analysis, Microtubules, Models, Biological},
	pages = {27--33; discussion 33--34}
}

@inproceedings{walters_illustrated_2016,
	address = {Tampere, Finnland},
	title = {An illustrated review of mechanotransduction and its impact on stem cell fate},
	url = {https://www.researchgate.net/publication/311191086_An_illustrated_review_of_mechanotransduction_and_its_impact_on_stem_cell_fate},
	abstract = {OUTLINE

This illustrated review introduces some of the effects of extracellular matrix (ECM) properties on stem cell fate via integrin-mediated mechanotransduction, with particular regard to...},
	urldate = {2016-12-16},
	publisher = {Tampere University of Technology},
	author = {Walters, Nick J. and Miettinen, Susanna and Gentleman, Eileen},
	month = nov,
	year = {2016},
	keywords = {3d, Focal Adhesion, mechanotransudction, stem cells}
}

@article{ghaemi_fluid-structure_2016,
	title = {Fluid-{Structure} {Interactions} {Analysis} of {Shear}-{Induced} {Modulation} of a {Mesenchymal} {Stem} {Cell}: {An} {Image}-{Based} {Study}},
	volume = {40},
	issn = {1525-1594},
	shorttitle = {Fluid-{Structure} {Interactions} {Analysis} of {Shear}-{Induced} {Modulation} of a {Mesenchymal} {Stem} {Cell}},
	doi = {10.1111/aor.12547},
	abstract = {Although effects of biochemical modulation of stem cells have been widely investigated, only recent advances have been made in the identification of mechanical conditioning on cell signaling pathways. Experimental investigations quantifying the micromechanical environment of mesenchymal stem cells (MSCs) are challenging while computational approaches can predict their behavior due to in vitro stimulations. This study introduces a 3D cell-specific finite element model simulating large deformations of MSCs. Here emphasizing cell mechanical modulation which represents the most challenging multiphysics phenomena in sub-cellular level, we focused on an approach attempting to elicit unique responses of a cell under fluid flow. Fluorescent staining of MSCs was performed in order to visualize the MSC morphology and develop a geometrically accurate model of it based on a confocal 3D image. We developed a 3D model of a cell fixed in a microchannel under fluid flow and then solved the numerical model by fluid-structure interactions method. By imposing flow characteristics representative of vigorous in vitro conditions, the model predicts that the employed external flow induces significant localized effective stress in the nucleo-cytoplasmic interface and average cell deformation of about 40\%. Moreover, it can be concluded that a lower strain level is made in the cell by the oscillatory flow as compared with steady flow, while same ranges of effective stress are recorded inside the cell in both conditions. The deeper understanding provided by this study is beneficial for better design of single cell in vitro studies.},
	language = {eng},
	number = {3},
	journal = {Artificial Organs},
	author = {Ghaemi, Roza Vaez and Vahidi, Bahman and Sabour, Mohammad Hossein and Haghighipour, Nooshin and Alihemmati, Zakieh},
	month = mar,
	year = {2016},
	pmid = {26333040},
	keywords = {Atomic force microscopy, Biomechanical Phenomena, Cell Differentiation, Cell Line, Cell-specific simulation, Confocal microscopy, Fluid-structure interactions, Humans, Hydrodynamics, Mechanical modulation, Mechanobiology, Mechanotransduction, Cellular, Mesenchymal Stromal Cells, Microscopy, Confocal, Models, Anatomic, Models, Biological, Optical Imaging, Stress, Mechanical},
	pages = {278--287}
}

@article{milner_finite-element_2012,
	title = {Finite-{Element} {Modeling} of {Viscoelastic} {Cells} {During} {High}-{Frequency} {Cyclic} {Strain}},
	volume = {3},
	issn = {2079-4983},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4031015/},
	doi = {10.3390/jfb3010209},
	abstract = {Mechanotransduction refers to the mechanisms by which cells sense and respond to local loads and forces. The process of mechanotransduction plays an important role both in maintaining tissue viability and in remodeling to repair damage; moreover, it may be involved in the initiation and progression of diseases such as osteoarthritis and osteoporosis. An understanding of the mechanisms by which cells respond to surrounding tissue matrices or artificial biomaterials is crucial in regenerative medicine and in influencing cellular differentiation. Recent studies have shown that some cells may be most sensitive to low-amplitude, high-frequency (i.e., 1–100 Hz) mechanical stimulation. Advances in finite-element modeling have made it possible to simulate high-frequency mechanical loading of cells. We have developed a viscoelastic finite-element model of an osteoblastic cell (including cytoskeletal actin stress fibers), attached to an elastomeric membrane undergoing cyclic isotropic radial strain with a peak value of 1,000 µstrain. The results indicate that cells experience significant stress and strain amplification when undergoing high-frequency strain, with peak values of cytoplasmic strain five times higher at 45 Hz than at 1 Hz, and peak Von Mises stress in the nucleus increased by a factor of two. Focal stress and strain amplification in cells undergoing high-frequency mechanical stimulation may play an important role in mechanotransduction.},
	number = {1},
	urldate = {2017-02-27},
	journal = {Journal of Functional Biomaterials},
	author = {Milner, Jaques S. and Grol, Matthew W. and Beaucage, Kim L. and Dixon, S. Jeffrey and Holdsworth, David W.},
	month = mar,
	year = {2012},
	pmid = {24956525},
	pmcid = {PMC4031015},
	pages = {209--224}
}

@inproceedings{ghaemi_cfd_2013,
	title = {{CFD} study of mesenchymal stem cells in fluid flow},
	doi = {10.1109/ICBME.2013.6782201},
	abstract = {Several biological effects have been reported for mechanical forces on individual cells including: signal transduction, gene expression, growth, and differentiation. In this paper, a novel model for studying the cell behavior under the effect of stresses is developed. A well-defined fluid flow passing over a single cell fixed inside a microchannel is considered in this model. By multi-scale modeling and fluid-structure interaction (FSI) method (which are strong tools in the field of cell mechanics)a single cell inside a microchannel (using its specific mechanical properties) have been simulated. For this purpose, at first, a 3D model of mesenchymal stem cells is created in a finite element software; by extracting the dimensions include surface area and volume of the nucleus and plasma membrane from literature. Then, the mechanical properties (Young's modulus) of the cell are determined using an atomic force microscopy (AFM) in Hetrz model. The results of simulation results using computational fluid dynamics, arbitrary Lagrangian-Eulerian method and adaptive mesh procedure, beside providing a framework for characterizing cytoskeletal structure affecting the cellular responses, can substantially enrich studies in the field of cellular biomechanics. Comparison between the two cellular model have shown that the presence of cellular components widely affect its response to external mechanical forces.},
	booktitle = {2013 20th {Iranian} {Conference} on {Biomedical} {Engineering} ({ICBME})},
	author = {Ghaemi, R. Vaez and Vahidi, B. and Sabour, M. H. and Haghighipour, N.},
	month = dec,
	year = {2013},
	keywords = {AFM, Atomic force microscopy, Biological system modeling, Biomechanics, CFD study, Cell Differentiation, Cell-Scale Simulation, Cells (biology), FSI, Fluid Structure Interaction, Fluids, Hetrz model, Mesenchymal stem cells, Multiscale modeling, Solid modeling, Solids, Strain, Stress, Young's modulus, adaptive mesh procedure, arbitrary Lagrangian-Eulerian method, bioMEMS, biomembranes, cell growth, cell mechanics, cellular biomechanics, cellular biophysics, computational fluid dynamics, cytoskeletal structure, finite element software, fluid flow, fluid-structure interaction, gene expression, genetics, mechanical forces, mesh generation, microchannel, microchannel flow, nucleus, plasma membrane, signal transduction, stress effect, surface area},
	pages = {103--108}
}

@article{guyot_immersed_2016,
	title = {Immersed {Boundary} {Models} for {Quantifying} {Flow}-{Induced} {Mechanical} {Stimuli} on {Stem} {Cells} {Seeded} on {3D} {Scaffolds} in {Perfusion} {Bioreactors}},
	volume = {12},
	issn = {1553-734X},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5033382/},
	doi = {10.1371/journal.pcbi.1005108},
	abstract = {Perfusion bioreactors regulate flow conditions in order to provide cells with oxygen, nutrients and flow-associated mechanical stimuli. Locally, these flow conditions can vary depending on the scaffold geometry, cellular confluency and amount of extra cellular matrix deposition. In this study, a novel application of the immersed boundary method was introduced in order to represent a detailed deformable cell attached to a 3D scaffold inside a perfusion bioreactor and exposed to microscopic flow. The immersed boundary model permits the prediction of mechanical effects of the local flow conditions on the cell. Incorporating stiffness values measured with atomic force microscopy and micro-flow boundary conditions obtained from computational fluid dynamics simulations on the entire scaffold, we compared cell deformation, cortical tension, normal and shear pressure between different cell shapes and locations. We observed a large effect of the precise cell location on the local shear stress and we predicted flow-induced cortical tensions in the order of 5 pN/μm, at the lower end of the range reported in literature. The proposed method provides an interesting tool to study perfusion bioreactors processes down to the level of the individual cell’s micro-environment, which can further aid in the achievement of robust bioprocess control for regenerative medicine applications., Tissue Engineering involves the combination of cells, growth factors and biomaterials into artificial constructs which, upon implantation, can improve the healing capacity of the human body. A remaining challenge involves providing physical stimuli to individual cells, thereby guiding them towards the properties of the desired tissue type. Perfusion bioreactors try to control the local concentration of oxygen, nutrients and growth factors and mechanical stresses by varying the fluid flow. In this work, we predict the shear stress that individual cells experience at the microscopic scale, as a function of the bioreactor inlet flow velocity, by making use of the immersed boundary method. This method combines an Eulerian grid (fixed in space) with a Lagrangian grid (moving with the flow) to model the deformation of cells due to flow inside a scaffold pore. Our simulations show that the local shear stress levels on specific, realistic cell geometries are different from the shear stress levels on empty scaffolds, which are often still used as a reference. Finally, we predict and discuss the additional effect of realistic flow on other mechanical cell properties, such as its deformation and its cortical tension.},
	number = {9},
	urldate = {2017-02-27},
	journal = {PLoS Computational Biology},
	author = {Guyot, Yann and Smeets, Bart and Odenthal, Tim and Subramani, Ramesh and Luyten, Frank P. and Ramon, Herman and Papantoniou, Ioannis and Geris, Liesbet},
	month = sep,
	year = {2016},
	pmid = {27658116},
	pmcid = {PMC5033382}
}

@article{ruiz_effect_2012,
	title = {The effect of nicotine on the mechanical properties of mesenchymal stem cells},
	volume = {4},
	issn = {1179-1330},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3467115/},
	doi = {10.2147/CHC.S24381},
	abstract = {Purpose
To measure the elasticity of the nucleus and cytoplasm of human mesenchymal stem cells (MSCs) as well as changes brought about by exposure to nicotine in vitro.

Methods
MSCs were synchronized to the G0 stage of the cell cycle through serum deprivation techniques. The cells were then treated with medium containing nicotine (0.1 µM, 0.5 µM, and 1 µM). Atomic force microscopy was then used to measure the Young’s modulus of both the nucleus and cytoplasm of these cells.

Results
For both unsynchronized and synchronized cells, the nucleus was softer than the cytoplasm, although this difference was not found to be statistically significant. The nucleus of cells treated with nicotine was significantly stiffer than the control for all concentrations. The cytoplasm was significantly stiffer in nicotine-treated cells than in control cells for the 0.5 µM and 1.0 µM concentrations only.

Conclusions
The results of this study could suggest that nicotine affects the biophysical properties of human MSCs in a dose-dependent manner, which may render the cells less responsive to mechanoinduction and other physical stimuli.},
	urldate = {2017-02-27},
	journal = {Cell health and cytoskeleton},
	author = {Ruiz, Juan P and Pelaez, Daniel and Dias, Janice and Ziebarth, Noël M and Cheung, Herman S},
	month = mar,
	year = {2012},
	pmid = {23060733},
	pmcid = {PMC3467115},
	pages = {29--35}
}

@misc{noauthor_focal_2016,
	title = {Focal {Adhesion} {Assembly}},
	url = {https://www.mechanobio.info/topics/mechanosignaling/cell-matrix-adhesion/focal-adhesion/focal-adhesion-assembly/},
	urldate = {2016-12-20},
	journal = {Mechanobiology Info},
	month = dec,
	year = {2016}
}

@misc{noauthor_focal_2016-1,
	title = {Focal {Adhesion} {Assembly}},
	url = {https://www.mechanobio.info/topics/mechanosignaling/cell-matrix-adhesion/focal-adhesion/focal-adhesion-assembly/},
	urldate = {2016-12-13},
	journal = {Mechanobiology Info},
	month = dec,
	year = {2016},
	keywords = {Adhesion, Basic functionality, Cell, ECM, Focal Adhesion, Mechanic}
}

@article{zhu_ventricular_2017,
	title = {Ventricular wall biomaterial injection therapy after myocardial infarction: {Advances} in material design, mechanistic insight and early clinical experiences},
	issn = {0142-9612},
	shorttitle = {Ventricular wall biomaterial injection therapy after myocardial infarction},
	url = {http://www.sciencedirect.com/science/article/pii/S0142961217301151},
	doi = {10.1016/j.biomaterials.2017.02.032},
	abstract = {Intramyocardial biomaterial injection therapy for myocardial infarction has made significant progress since concept initiation more than 10 years ago. The interim successes and progress in the first 5 years have been extensively reviewed. During the last 5 years, two phase II clinical trials have reported their long term follow up results and many additional biomaterial candidates have reached preclinical and clinical testing. Also in recent years deeper investigations into the mechanisms behind the beneficial effects associated with biomaterial injection therapy have been pursued, and a variety of process and material parameters have been evaluated for their impact on therapeutic outcomes. This review explores the advances made in this biomaterial-centered approach to ischemic cardiomyopathy and discusses potential future research directions as this therapy seeks to positively impact patients suffering from one of the world's most common sources of mortality.},
	urldate = {2017-03-03},
	journal = {Biomaterials},
	author = {Zhu, Yang and Matsumura, Yasumoto and Wagner, William R.},
	month = mar,
	year = {2017},
	keywords = {Clinical trials, Finite element modeling, Injectable materials, Mechanical support, Ventricular remodeling, myocardial infarction}
}

@article{dorsey_mri_2015,
	title = {{MRI} {Evaluation} of {Injectable} {Hyaluronic} {Acid}-{Based} {Hydrogel} {Therapy} to {Limit} {Ventricular} {Remodeling} after {Myocardial} {Infarction}},
	volume = {69},
	issn = {0142-9612},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4556569/},
	doi = {10.1016/j.biomaterials.2015.08.011},
	abstract = {Injectable biomaterials are an attractive therapy to attenuate left ventricular (LV) remodeling after myocardial infarction (MI). Although studies have shown that injectable hydrogels improve cardiac structure and function in vivo, temporal changes in infarct material properties after treatment have not been assessed. Emerging imaging and modeling techniques now allow for serial, non-invasive estimation of infarct material properties. Specifically, cine MRI assesses global LV structure and function, late-gadolinium enhancement (LGE) MRI enables visualization of infarcted tissue to quantify infarct expansion, and spatial modulation of magnetization (SPAMM) tagging provides passive wall motion assessment as a measure of tissue strain, which can all be used to evaluate infarct properties when combined with finite element (FE) models. In this work, we investigated the temporal effects of degradable hyaluronic acid (HA) hydrogels on global LV remodeling, infarct thinning and expansion, and infarct stiffness in a porcine infarct model for 12 weeks post-MI using MRI and FE modeling. Hydrogel treatment led to decreased LV volumes, improved ejection fraction, and increased wall thickness when compared to controls. FE model simulations demonstrated that hydrogel therapy increased infarct stiffness for 12 weeks post-MI. Thus, evaluation of myocardial tissue properties through MRI and FE modeling provides insight into the influence of injectable hydrogel therapies on myocardial structure and function post-MI.},
	urldate = {2017-03-06},
	journal = {Biomaterials},
	author = {Dorsey, Shauna M. and McGarvey, Jeremy R. and Wang, Hua and Nikou, Amir and Arama, Leron and Koomalsingh, Kevin J. and Kondo, Norihiro and Gorman, Joseph H. and Pilla, James J. and Gorman, Robert C. and Wenk, Jonathan F. and Burdick, Jason A.},
	month = nov,
	year = {2015},
	pmid = {26280951},
	pmcid = {PMC4556569},
	pages = {65--75}
}

@article{carlescu_fem_2014,
	title = {{FEM} {Simulation} on {Uniaxial} {Tension} of {Hyperelastic} {Elastomers}},
	volume = {659},
	issn = {1662-7482},
	url = {https://www.scientific.net/AMM.659.57},
	doi = {10.4028/www.scientific.net/AMM.659.57},
	abstract = {Advanced Concepts in Mechanical Engineering II: FEM Simulation on Uniaxial Tension of Hyperelastic Elastomers},
	language = {EN},
	urldate = {2017-03-08},
	journal = {Applied Mechanics and Materials},
	author = {Carlescu, Vlad and Prisacaru, Gheorghe and Olaru, Dumitru},
	year = {2014},
	pages = {57--62}
}

@article{damore_characterization_2010,
	title = {Characterization of the complete fiber network topology of planar fibrous tissues and scaffolds},
	volume = {31},
	issn = {0142-9612},
	url = {http://www.sciencedirect.com/science/article/pii/S0142961210004230},
	doi = {10.1016/j.biomaterials.2010.03.052},
	abstract = {Understanding how engineered tissue scaffold architecture affects cell morphology, metabolism, phenotypic expression, as well as predicting material mechanical behavior has recently received increased attention. In the present study, an image-based analysis approach that provides an automated tool to characterize engineered tissue fiber network topology is presented. Micro-architectural features that fully defined fiber network topology were detected and quantified, which include fiber orientation, connectivity, intersection spatial density, and diameter. Algorithm performance was tested using scanning electron microscopy (SEM) images of electrospun poly(ester urethane)urea (ES-PEUU) scaffolds. SEM images of rabbit mesenchymal stem cell (MSC) seeded collagen gel scaffolds and decellularized rat carotid arteries were also analyzed to further evaluate the ability of the algorithm to capture fiber network morphology regardless of scaffold type and the evaluated size scale. The image analysis procedure was validated qualitatively and quantitatively, comparing fiber network topology manually detected by human operators (n = 5) with that automatically detected by the algorithm. Correlation values between manual detected and algorithm detected results for the fiber angle distribution and for the fiber connectivity distribution were 0.86 and 0.93 respectively. Algorithm detected fiber intersections and fiber diameter values were comparable (within the mean ± standard deviation) with those detected by human operators. This automated approach identifies and quantifies fiber network morphology as demonstrated for three relevant scaffold types and provides a means to: (1) guarantee objectivity, (2) significantly reduce analysis time, and (3) potentiate broader analysis of scaffold architecture effects on cell behavior and tissue development both in vitro and in vivo.},
	number = {20},
	urldate = {2017-03-09},
	journal = {Biomaterials},
	author = {D’Amore, Antonio and Stella, John A. and Wagner, William R. and Sacks, Michael S.},
	month = jul,
	year = {2010},
	keywords = {Decellularized tissue, Electrospinning, Image analysis, Microstructure, Scaffold morphology, collagen gel},
	pages = {5345--5354}
}

@article{eichhorn_statistical_2005,
	title = {Statistical geometry of pores and statistics of porous nanofibrous assemblies},
	volume = {2},
	issn = {1742-5689},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1578270/},
	doi = {10.1098/rsif.2005.0039},
	abstract = {The application of theoretical models to describe the structure of the types of fibrous network produced by the electrospinning of polymers for use in tissue engineering and a number of other applications is presented. Emphasis is placed on formal analyses of the pore size distribution and porosities that one would encounter with such structures and the nature of their relationships with other structural characteristics likely to be important for the performance of nanofibrous materials. The theoretical structures considered result from interactions between randomly placed straight rods that represent fibres with nanoscale dimensions. The dominant role of fibre diameter in controlling the pore diameter of the networks is shown and we discuss the perhaps counter-intuitive finding that at a given network mass per unit area and porosity, increasing fibre diameter results in an increase in mean pore radius. Larger pores may be required for ingrowth of cells to nanofibrous networks, hence this study clarifies that simply making the diameters of the fibres smaller might not be the way to improve cell proliferation on such substrates. An extensive review of structural features of the network such as the distribution of mass, inter-fibre contacts and available surface for cell attachment, fibre contact distributions for integrity of the networks and the porosity and pore size distributions is given, with emphasis placed on nanofibre dimensions for the first time.},
	number = {4},
	urldate = {2017-03-09},
	journal = {Journal of the Royal Society Interface},
	author = {Eichhorn, Stephen J and Sampson, William W},
	month = sep,
	year = {2005},
	pmid = {16849188},
	pmcid = {PMC1578270},
	pages = {309--318}
}

@article{demarchez_role_1992,
	title = {The role of fibroblasts in dermal vascularization and remodeling of reconstructed human skin after transplantation onto the nude mouse},
	volume = {54},
	issn = {0041-1337},
	abstract = {The vascularization and the dermal remodeling of two different types of human skin reconstructed "in vitro" and grafted onto the nude mouse were studied. They were composed of human keratinocytes grown either on a human acellular deepidermized dermis (DED), or on a lattice composed of human fibroblasts embedded in bovine type I collagen, a living dermal equivalent (LDE). At different stages after grafting, the transplants were harvested and processed for an immunohistological study with species-specific and non-species-specific antibodies. At one month after grafting, the two types of grafted dermis contained blood vessels whose vascular basement membranes were labeled with a mouse-specific anti-type IV collagen antibody. With an antibody specific for human type IV collagen, a constant labeling of the vascular basement membrane was only observed in the LDE containing fibroblasts. In the DED, a constant association of the mouse endothelial cells with human type IV collagen was observed at early stages after grafting. At later stages, the human type IV collagen progressively disappeared. On the other hand, the dermal-epidermal junction underneath the human epidermis contained human type IV collagen in the two types of reconstructed skin. Labeling with the species-specific antibodies directed against human or murine type I collagen showed that the ratio murine type I collagen versus human type I collagen increased with time, suggesting that the DED is progressively invaded by mouse fibroblasts that produce the mouse collagen. On the other hand, in the LDE, the preexisting bovine type I collagen became progressively undetectable while both human type I collagen and elastic fibers were deposited by numerous human fibroblasts. Mouse type I collagen was not detected. Altogether, these observations made by grafting human skin reconstructed "in vitro" onto the nude mouse should be interesting for evaluating the usefulness of grafting a dermal substrate together with the epidermal sheet in the treatment of burns.},
	language = {eng},
	number = {2},
	journal = {Transplantation},
	author = {Demarchez, M. and Hartmann, D. J. and Regnier, M. and Asselineau, D.},
	month = aug,
	year = {1992},
	pmid = {1496543},
	keywords = {Animals, Collagen, Extracellular Matrix, Factor VIII, Fibroblasts, Fluorescent Antibody Technique, Humans, Keratinocytes, Mice, Mice, Nude, Skin, Skin Transplantation, Time Factors, Transplantation, Heterologous},
	pages = {317--326}
}

@article{lamme_higher_2000,
	title = {Higher numbers of autologous fibroblasts in an artificial dermal substitute improve tissue regeneration and modulate scar tissue formation},
	volume = {190},
	issn = {0022-3417},
	doi = {10.1002/(SICI)1096-9896(200004)190:5<595::AID-PATH572>3.0.CO;2-V},
	abstract = {Cultured skin substitutes are increasingly important for the treatment of burns and chronic wounds. The role of fibroblast numbers present in a living-skin equivalent is at present unknown. The quality of dermal tissue regeneration was therefore investigated in relation to the number of autologous fibroblasts seeded in dermal substitutes, transplanted instantaneously or precultured for 10 days in the substitute. A full-thickness porcine wound model was used to compare acellular dermal substitutes (ADS) with dermal substitutes seeded with fibroblasts at two densities, 1x10(5) (0-DS10) and 5x10(5) cells/cm(2) (0-DS50), and with dermal substitutes seeded 10 days before operation at the same densities (10-DS10 and 10-DS50) (n=7 for each group, five pigs). After transplantation of the dermal substitutes, split-skin mesh grafts were applied on top. Wound healing was evaluated blind for 6 weeks. Cosmetic appearance was evaluated and wound contraction was measured by planimetry. The wound biopsies taken after 3 weeks were stained for myofibroblasts (alpha-smooth muscle actin), and after 6 weeks for scar tissue formation (collagen bundles organized in parallel and the absence of elastin staining). Collagen maturation was investigated with polarized light. For wound cosmetic parameters, the 10-DS50 and 0-DS50 treatments scored significantly better than the ADS treatment, as did the 10-DS50 treatment for wound contraction (p{\textless}0.05, paired t-test). Three weeks after wounding, the area with myofibroblasts in the granulation tissue, determined by image analysis, was significantly smaller for 0-DS50, 10-DS10, and 10-DS50 than for the ADS treatment (p{\textless}0.04, paired t-test). After 6 weeks, the wounds treated with 0-DS50, 0-DS10, and 10-DS50 had significantly less scar tissue and significantly more mature collagen bundles in the regenerated dermis. This improvement of wound healing was correlated with the higher numbers of fibroblasts present in the dermal substitute at the moment of transplantation. In conclusion, dermal regeneration of experimental full-skin defects was significantly improved by treatment with dermal substitutes containing high numbers of (precultured) autologous fibroblasts.},
	language = {eng},
	number = {5},
	journal = {The Journal of Pathology},
	author = {Lamme, E. N. and Van Leeuwen, R. T. and Brandsma, K. and Van Marle, J. and Middelkoop, E.},
	month = apr,
	year = {2000},
	pmid = {10727986},
	keywords = {Animals, Cell Count, Cell Culture Techniques, Cicatrix, Female, Fibroblasts, Regeneration, Skin, Skin Physiological Phenomena, Skin, Artificial, Swine, Wound Healing},
	pages = {595--603}
}

@article{tuan_dermal_1994,
	title = {Dermal fibroblasts activate keratinocyte outgrowth on collagen gels},
	volume = {107 ( Pt 8)},
	issn = {0021-9533},
	abstract = {The effects of dermal fibroblasts on keratinocyte outgrowth on collagen substrata was studied using an in vitro keratinocyte-collagen gel composite model. Skin fibroblasts were seeded inside collagen gels, which remained attached to the cell culture plastic substratum. Fibroblasts incorporated in collagen gels were either kept viable throughout the study, or were lysed hypotonically with water at different time intervals (2 hours and 5 days). Results show that very little keratinocyte outgrowth occurred on either plain collagen gels or gels that had previously contained viable fibroblasts for 2 hours. A 3- to 4-fold increase in keratinocyte outgrowth occurred on collagen gels that had previously contained viable fibroblasts for 5 days. A striking increase (20-fold) in keratinocyte outgrowth was observed on collagen gels that contain viable fibroblasts. The effect of fibroblast diffusible factors on keratinocyte outgrowth was further studied with a co-culture system using Millicell inserts. It was found that the co-culture of fibroblasts with the composite enhanced keratinocyte outgrowth on collagen gels that had previously contained viable fibroblasts for 5 days. Among all, however, the keratinocyte outgrowth was far better on gels containing viable fibroblasts. Addition of keratinocyte growth factor or its neutralizing antibody did not affect keratinocyte outgrowth. These results suggest that dermal fibroblasts can activate keratinocyte outgrowth on collagen matrices through some diffusible factors other than keratinocyte growth factor, and epithelial-mesenchymal interactions exert some special effects on keratinocyte outgrowth on collagen gels.},
	language = {eng},
	journal = {Journal of Cell Science},
	author = {Tuan, T. L. and Keller, L. C. and Sun, D. and Nimni, M. E. and Cheung, D.},
	month = aug,
	year = {1994},
	pmid = {7983187},
	keywords = {Cell Communication, Cell Division, Cells, Cultured, Collagen, Culture Media, Culture Techniques, Fibroblasts, Gels, Humans, Keratinocytes, Skin},
	pages = {2285--2289}
}

@article{lowery_effect_2010,
	title = {Effect of fiber diameter, pore size and seeding method on growth of human dermal fibroblasts in electrospun poly(epsilon-caprolactone) fibrous mats},
	volume = {31},
	issn = {1878-5905},
	doi = {10.1016/j.biomaterials.2009.09.072},
	abstract = {Nonwoven fiber mats of poly(epsilon-caprolactone) (PCL) and PCL blended with poly(ethylene oxide) (PEO) were generated by electrospinning. Differential scanning calorimetry, scanning electron microscopy, and gravimetric measurement confirm the removal of PEO after immersion in water, as well as an increase in the PCL crystallinity. The reorganization of PCL resulted in the macroscopic alteration of the electrospun mat, decreasing the peak pore diameter up to a factor of 3 while only minimally affecting the fiber diameter. This technique was used to create electrospun PCL scaffolds with similar fiber diameters but different pore diameters to examine the effect of pore diameter on cell growth. Human Dermal Fibroblasts (HDF) were seeded into multiple samples using a perfusion seeding technique to guarantee successful cell deposition. Fluorescence analysis at 7, 14, and 21 days found that cells proliferated at a faster rate on scaffolds with peak pore diameters greater than 6 microm, as determined by mercury porosimetry. Cell conformation was also found to change as the peak pore diameter grew from 12 to 23 microm; cells began aligning along single fibers instead of attaching to multiple fibers. Knowledge of the effect of void architecture on cell proliferation and conformation could lead to the development of more effective scaffolds for tissue engineering.},
	language = {eng},
	number = {3},
	journal = {Biomaterials},
	author = {Lowery, Joseph L. and Datta, Néha and Rutledge, Gregory C.},
	month = jan,
	year = {2010},
	pmid = {19822363},
	keywords = {Biocompatible Materials, Calorimetry, Differential Scanning, Caproates, Cell Culture Techniques, Cells, Cultured, Electrochemical Techniques, Fibroblasts, Humans, Lactones, Materials Testing, Microscopy, Electron, Scanning, Porosity, Skin, Surface Properties, Tissue Scaffolds},
	pages = {491--504}
}

@article{bagherzadeh_theoretical_2013,
	title = {A theoretical analysis and prediction of pore size and pore size distribution in electrospun multilayer nanofibrous materials},
	volume = {101A},
	issn = {1552-4965},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/jbm.a.34487/abstract},
	doi = {10.1002/jbm.a.34487},
	abstract = {Electrospinning process can fabricate nanomaterials with unique nanostructures for potential biomedical and environmental applications. However, the prediction and, consequently, the control of the porous structure of these materials has been impractical due to the complexity of the electrospinning process. In this research, a theoretical model for characterizing the porous structure of the electrospun nanofibrous network has been developed by combining the stochastic and stereological probability approaches. From consideration of number of fiber-to-fiber contacts in an electrospun nanofibrous assembly, geometrical and statistical theory relating morphological and structural parameters of the network to the characteristic dimensions of interfibers pores is provided. It has been shown that these properties are strongly influenced by the fiber diameter, porosity, and thickness of assembly. It is also demonstrated that at a given network porosity, increasing fiber diameter and thickness of the network reduces the characteristic dimensions of pores. It is also discussed that the role of fiber diameter and number of the layer in the assembly is dominant in controlling the pore size distribution of the networks. The theory has been validated experimentally and results compared with the existing theory to predict the pore size distribution of nanofiber mats. It is believed that the presented theory for estimation of pore size distribution is more realistic and useful for further studies of multilayer random nanofibrous assemblies. © 2013 Wiley Periodicals, Inc. J Biomed Mater Res Part A, 2013.},
	language = {en},
	number = {7},
	urldate = {2017-03-09},
	journal = {Journal of Biomedical Materials Research Part A},
	author = {Bagherzadeh, Roohollah and Najar, Saeed Shaikhzadeh and Latifi, Masoud and Tehran, Mohammad Amani and Kong, Lingxue},
	month = jul,
	year = {2013},
	keywords = {fiber to fiber contact, nanofiber, nanofibrous structures, pore size, pore size distribution},
	pages = {2107--2117}
}

@article{stricker_mechanics_2010,
	title = {Mechanics of the {F}-actin {Cytoskeleton}},
	volume = {43},
	issn = {0021-9290},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2813332/},
	doi = {10.1016/j.jbiomech.2009.09.003},
	number = {1},
	urldate = {2017-03-09},
	journal = {Journal of biomechanics},
	author = {Stricker, Jonathan and Falzone, Tobias and Gardel, Margaret},
	month = jan,
	year = {2010},
	pmid = {19913792},
	pmcid = {PMC2813332},
	pages = {9}
}

@article{xu_strain_2000,
	title = {Strain hardening of actin filament networks. {Regulation} by the dynamic cross-linking protein alpha-actinin},
	volume = {275},
	issn = {0021-9258},
	doi = {10.1074/jbc.M002377200},
	abstract = {Mechanical stresses applied to the plasma membrane of an adherent cell induces strain hardening of the cytoskeleton, i.e. the elasticity of the cytoskeleton increases with its deformation. Strain hardening is thought to mediate the transduction of mechanical signals across the plasma membrane through the cytoskeleton. Here, we describe the strain dependence of a model system consisting of actin filaments (F-actin), a major component of the cytoskeleton, and the F-actin cross-linking protein alpha-actinin, which localizes along contractile stress fibers and at focal adhesions. We show that the amplitude and rate of shear deformations regulate the resilience of F-actin networks. At low temperatures, for which the lifetime of binding of alpha-actinin to F-actin is long, F-actin/alpha-actinin networks exhibit strong strain hardening at short time scales and soften at long time scales. For F-actin networks in the absence of alpha-actinin or for F-actin/alpha-actinin networks at high temperatures, strain hardening appears only at very short time scales. We propose a model of strain hardening for F-actin networks, based on both the intrinsic rigidity of F-actin and dynamic topological constraints formed by the cross-linkers located at filaments entanglements. This model offers an explanation for the origin of strain hardening observed when shear stresses are applied against the cellular membrane.},
	language = {eng},
	number = {46},
	journal = {The Journal of Biological Chemistry},
	author = {Xu, J. and Tseng, Y. and Wirtz, D.},
	month = nov,
	year = {2000},
	pmid = {10954703},
	keywords = {Actin Cytoskeleton, Actinin, Actins, Animals, Chickens, Dimerization, Models, Chemical, Protein Binding, Rabbits, Rheology, Stress, Mechanical, Temperature},
	pages = {35886--35892}
}

@article{kanyanta_mechanical_2010,
	title = {Mechanical characterisation of polyurethane elastomer for biomedical applications},
	volume = {3},
	issn = {1751-6161},
	url = {http://www.sciencedirect.com/science/article/pii/S1751616109000460},
	doi = {10.1016/j.jmbbm.2009.03.005},
	abstract = {Mechanical testing and modelling of a material for biomedical applications have to be based on conditions representative of the application of interest. In this work, an ether-based polyurethane elastomer is used to build mock arteries. The aim is to study the behaviour of arteries under pulsatile loading conditions and how that behaviour changes with the development and progression of atherosclerosis. Polyurethane elastomers are widely used as biomaterials, e.g. in tube form for bypasses and catheters. However, their mechanical behaviour has not been extensively characterised. This work establishes the variations in the behaviour of polyurethane elastomer with temperature, humidity and strain rate and also reports planar and equibiaxial tension, relaxation, creep and cyclic test results, providing a comprehensive characterisation of the material. Test results are used to determine the properties of the polyurethane elastomer and in the selection of a representative material model for future simulations of arterial behaviour and the development of atherosclerosis. The results show that the behaviour of the elastomer is significantly dependent on both humidity and temperature, with Young’s modulus of 7.4 MPa, 5.3 MPa and 4.7 MPa under dry-room temperature, wet-room temperature and wet at 37 ∘C conditions, respectively. The elastomer also exhibits rate-dependent viscoelastic behaviour. Yeoh’s hyperelastic material model provided the best fit to the entire range of experimental data. The Neo-Hookean model provides a good fit at small strain but significantly diverges at large strains. Nevertheless, in applications where deformations are relatively small, i.e. below 15\%, the Neo-Hookean model can be used.},
	number = {1},
	urldate = {2017-03-09},
	journal = {Journal of the Mechanical Behavior of Biomedical Materials},
	author = {Kanyanta, Valentine and Ivankovic, Alojz},
	month = jan,
	year = {2010},
	pages = {51--62}
}

@article{ananthakrishnan_quantifying_2006,
	title = {Quantifying the contribution of actin networks to the elastic strength of fibroblasts},
	volume = {242},
	issn = {0022-5193},
	doi = {10.1016/j.jtbi.2006.03.021},
	abstract = {The structural models created to understand the cytoskeletal mechanics of cells in suspension are described here. Suspended cells can be deformed by well-defined surface stresses in an Optical Stretcher [Guck, J., Ananthakrishnan, R., Mahmood, H., Moon, T.J., Cunningham, C.C., Käs, J., 2001. The optical stretcher: a novel laser tool to micromanipulate cells. Biophys. J. 81(2), 767-784], a two-beam optical trap designed for the contact-free deformation of cells. Suspended cells have a well-defined cytoskeleton, displaying a radially symmetric actin cortical network underlying the cell membrane with no actin stress fibers, and microtubules and intermediate filaments in the interior. Based on experimental data using suspended fibroblasts, we create two structural models: a thick shell actin cortex model that describes cell deformation for a localized stress distribution on these cells and a three-layered model that considers the entire cytoskeleton when a broad stress distribution is applied. Applying the models to data, we obtain a (actin) cortical shear moduli G of approximately 220 Pa for normal fibroblasts and approximately 185 Pa for malignantly transformed fibroblasts. Additionally, modeling the cortex as a transiently crosslinked isotropic actin network, we show that actin and its crosslinkers must be co-localized into a tight shell to achieve these cortical strengths. The similar moduli values and cortical actin and crosslinker densities but different deformabilities of the normal and cancerous cells suggest that a cell's structural strength is not solely determined by cytoskeletal composition but equally importantly by (actin) cytoskeletal architecture via differing cortical thicknesses. We also find that although the interior structural elements (microtubules, nucleus) contribute to the deformed cell's exact shape via their loose coupling to the cortex, it is the outer actin cortical shell (and its thickness) that mainly determines the cell's structural response.},
	language = {eng},
	number = {2},
	journal = {Journal of Theoretical Biology},
	author = {Ananthakrishnan, Revathi and Guck, Jochen and Wottawah, Falk and Schinkinger, Stefan and Lincoln, Bryan and Romeyke, Maren and Moon, Tess and Käs, Josef},
	month = sep,
	year = {2006},
	pmid = {16720032},
	keywords = {Actins, Animals, Cell Nucleus, Cell Shape, Cytoskeleton, Elasticity, Fibroblasts, Finite Element Analysis, Microtubules, Models, Biological, Stress, Mechanical},
	pages = {502--516}
}

@article{salbreux_actin_2012,
	title = {Actin cortex mechanics and cellular morphogenesis},
	volume = {22},
	issn = {0962-8924, 1879-3088},
	url = {http://www.cell.com/trends/cell-biology/abstract/S0962-8924(12)00111-0},
	doi = {10.1016/j.tcb.2012.07.001},
	language = {English},
	number = {10},
	urldate = {2017-03-09},
	journal = {Trends in Cell Biology},
	author = {Salbreux, Guillaume and Charras, Guillaume and Paluch, Ewa},
	month = oct,
	year = {2012},
	pmid = {22871642},
	keywords = {Actin cortex, Cell Shape, actin dynamics, actomyosin contractility, cell mechanics, intracellular pressure},
	pages = {536--545}
}

@article{schwarz_physics_2013,
	title = {Physics of adherent cells},
	volume = {85},
	url = {http://link.aps.org/doi/10.1103/RevModPhys.85.1327},
	doi = {10.1103/RevModPhys.85.1327},
	abstract = {One of the most unique physical features of cell adhesion to external surfaces is the active generation of mechanical force at the cell-material interface. This includes pulling forces generated by contractile polymer bundles and networks, and pushing forces generated by the polymerization of polymer networks. These forces are transmitted to the substrate mainly by focal adhesions, which are large, yet highly dynamic adhesion clusters. Tissue cells use these forces to sense the physical properties of their environment and to communicate with each other. The effect of forces is intricately linked to the material properties of cells and their physical environment. Here a review is given of recent progress in our understanding of the role of forces in cell adhesion from the viewpoint of theoretical soft matter physics and in close relation to the relevant experiments.},
	number = {3},
	urldate = {2017-03-09},
	journal = {Reviews of Modern Physics},
	author = {Schwarz, Ulrich S. and Safran, Samuel A.},
	month = aug,
	year = {2013},
	pages = {1327--1381}
}

@article{tseng_functional_2002,
	title = {Functional {Synergy} of {Actin} {Filament} {Cross}-linking {Proteins}},
	volume = {277},
	issn = {0021-9258, 1083-351X},
	url = {http://www.jbc.org/content/277/28/25609},
	doi = {10.1074/jbc.M202609200},
	abstract = {The organization of filamentous actin (F-actin) in resilient networks is coordinated by various F-actin cross-linking proteins. The relative tolerance of cells to null mutations of genes that code for a single actin cross-linking protein suggests that the functions of those proteins are highly redundant. This apparent functional redundancy may, however, reflect the limited resolution of available assays in assessing the mechanical role of F-actin cross-linking/bundling proteins. Using reconstituted F-actin networks and rheological methods, we demonstrate how α-actinin and fascin, two F-actin cross-linking/bundling proteins that co-localize along stress fibers and in lamellipodia, could synergistically enhance the resilience of F-actin networks in vitro. These two proteins can generate microfilament arrays that “yield” at a strain amplitude that is much larger than each one of the proteins separately. F-actin/α-actinin/fascin networks display strain-induced hardening, whereby the network “stiffens” under shear deformations, a phenomenon that is non-existent in F-actin/fascin networks and much weaker in F-actin/α-actinin networks. Strain-hardening is further enhanced at high rates of deformation and high concentrations of actin cross-linking proteins. A simplified model suggests that the optimum results of the competition between the increased stiffness of bundles and their decreased density of cross-links. Our studies support a re-evaluation of the notion of functional redundancy among cytoskeletal regulatory proteins.},
	language = {en},
	number = {28},
	urldate = {2017-03-09},
	journal = {Journal of Biological Chemistry},
	author = {Tseng, Yiider and Schafer, Benjamin W. and Almo, Steven C. and Wirtz, Denis},
	month = jul,
	year = {2002},
	pmid = {12006593},
	pages = {25609--25616}
}

@inproceedings{yogesh_d._bansod_world_2015,
	title = {World {Academy} of {Science}, {Engineering} and {Technology}},
	url = {https://waset.org/Publication/continuum-based-modelling-approaches-for-cell-mechanics/10002070},
	urldate = {2017-03-09},
	booktitle = {Continuum-{Based} {Modelling} {Approaches} for {Cell} {Mechanics}},
	author = {{Yogesh D. Bansod} and {Jiri Bursa}},
	year = {2015}
}

@phdthesis{yogesh_deepak_bansod_computational_2016,
	address = {Brno},
	title = {Computational {Simulation} of {Mechanical} {Tests} of {Isolated} {Animal} {Cells}},
	language = {English},
	school = {Technical University of Brno},
	author = {{Yogesh Deepak Bansod} and {Jiri Bursa}},
	year = {2016}
}

@book{bhatia_engineering_2011,
	title = {Engineering {Biomaterials} for {Regenerative} {Medicine}: {Novel} {Technologies} for {Clinical} {Applications}},
	isbn = {978-1-4614-1080-5},
	shorttitle = {Engineering {Biomaterials} for {Regenerative} {Medicine}},
	abstract = {Regeneration of tissues and organs remains one of the great challenges of clinical medicine, and physicians are constantly seeking better methods for tissue repair and replacement. Tissue engineering and regenerative medicine have been investigated for virtually every organ system in the human body, and progress is made possible by advances in materials science, polymer chemistry, and molecular biology. This book reviews the current status of biomaterials for regenerative medicine, and highlights advances in both basic science and clinical practice. The latest methods for regulating the biological and chemical composition of biomaterials are described, together with techniques for modulating mechanical properties of engineered constructs. Contributors delineate methods for guiding the host response to implantable materials, and explain the use of biologically-inspired materials for optimal biological functionality and compatibility. The book culminates in a discussion of the clinical applications of regenerative medicine. By integrating engineering and clinical medicine, Engineering Biomaterials for Regenerative Medicine examines how tissue engineering and regenerative medicine can be translated into successful therapies to bridge the gap between laboratory and clinic. The book will aid materials scientists and engineers in identifying research priorities to fulfill clinical needs, and will also enable physicians to understand novel biomaterials that are emerging in the clinic. This integrated approach also gives engineering students a sense of the excitement and relevance of materials science in the development of novel therapeutic strategies.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Bhatia, Sujata K.},
	month = nov,
	year = {2011},
	keywords = {Medical / Microbiology, Science / Chemistry / Organic, Science / Life Sciences / Cell Biology, Science / Life Sciences / Molecular Biology, Technology \& Engineering / Biomedical, Technology \& Engineering / Chemical \& Biochemical, Technology \& Engineering / Engineering (General), Technology \& Engineering / Manufacturing, Technology \& Engineering / Materials Science, Technology \& Engineering / Textiles \& Polymers}
}

@article{yuk_skin-inspired_2016,
	title = {Skin-inspired hydrogel–elastomer hybrids with robust interfaces and functional microstructures},
	volume = {7},
	copyright = {© 2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
	issn = {2041-1723},
	url = {http://www.nature.com/ncomms/2016/160627/ncomms12028/full/ncomms12028.html},
	doi = {10.1038/ncomms12028},
	abstract = {Soft hybrids that integrate hydrogels and elastomers can be used in applications, such as stretchable electronics and soft robotics, but usually have shortcomings.},
	language = {en},
	urldate = {2017-03-14},
	journal = {Nature Communications},
	author = {Yuk, Hyunwoo and Zhang, Teng and Parada, German Alberto and Liu, Xinyue and Zhao, Xuanhe},
	month = jun,
	year = {2016},
	pages = {12028}
}

@article{balberg_computer_1983,
	title = {Computer study of the percolation threshold in a two-dimensional anisotropic system of conducting sticks},
	volume = {28},
	url = {http://link.aps.org/doi/10.1103/PhysRevB.28.3799},
	doi = {10.1103/PhysRevB.28.3799},
	abstract = {We report here a Monte Carlo study of the percolation threshold in two-dimensional systems of conducting sticks. This is an extension of the work of Pike and Seager, who have considered only the isotropic sample of randomly-oriented—, equal-length—sticks system. Our study is concerned with the dependence of the percolation threshold on the macroscopic anisotropy of systems in which there is a preferred orientation of the sticks ensemble, as well as on the distribution of the sticks' lengths. In particular, we studied systems in which the orientation is determined by random alignments within a given interval or in which the alignments are normally distributed around a given direction. Similarly, for the sticks' lengths we have studied systems of equal lengths, of normally distributed lengths, and of log-normally distributed lengths. The results have shown that the percolation threshold always increases with the macroscopic anisotropy. Extrapolation of the results, from those of the finite sticks ensembles used to the infinite ensemble case, has indicated that in the infinite ensemble the percolation threshold is isotropic. It is found that the broader the stick-length distribution, the lower the mean of the distribution needed for the onset of percolation. Application of the present results for the evaluation of the conductivity indicates that the anisotropy dependence of the conductivity in systems of conducting fibers is determined by both the anisotropy dependence of the percolation threshold and the anisotropy dependence of the critical exponent. If (as found experimentally) a practically infinite two-dimensional system has a conductivity anisotropy, it must be attributed to the anisotropy in the latter parameter.},
	number = {7},
	urldate = {2017-03-24},
	journal = {Physical Review B},
	author = {Balberg, I. and Binenbaum, N.},
	month = oct,
	year = {1983},
	pages = {3799--3812}
}

@article{schmitt_classification_2016,
	title = {Classification and quantification of pore shapes in sandstone reservoir rocks with 3-{D} {X}-ray micro-computed tomography},
	volume = {7},
	issn = {1869-9510},
	url = {http://www.solid-earth.net/7/285/2016/},
	doi = {10.5194/se-7-285-2016},
	language = {English},
	number = {1},
	urldate = {2017-03-28},
	journal = {Solid Earth},
	author = {Schmitt, Mayka and Halisch, Matthias and Müller, Cornelia and Fernandes, Celso Peres},
	month = feb,
	year = {2016},
	pages = {285--300}
}

@article{jones_assessment_2007,
	series = {Imaging {Techniques} for {Biomaterials} {Characterization}},
	title = {Assessment of bone ingrowth into porous biomaterials using {MICRO}-{CT}},
	volume = {28},
	issn = {0142-9612},
	url = {http://www.sciencedirect.com/science/article/pii/S0142961207001287},
	doi = {10.1016/j.biomaterials.2007.01.046},
	abstract = {The three-dimensional (3D) structure and architecture of biomaterial scaffolds play a critical role in bone formation as they affect the functionality of the tissue-engineered constructs. Assessment techniques for scaffold design and their efficacy in bone ingrowth studies require an ability to accurately quantify the 3D structure of the scaffold and an ability to visualize the bone regenerative processes within the scaffold structure. In this paper, a 3D micro-CT imaging and analysis study of bone ingrowth into tissue-engineered scaffold materials is described. Seven specimens are studied in this paper; a set of three specimens with a cellular structure, varying pore size and implant material, and a set of four scaffolds with two different scaffold designs investigated at early (4 weeks) and late (12 weeks) explantation times. The difficulty in accurately phase separating the multiple phases within a scaffold undergoing bone regeneration is first highlighted. A sophisticated three-phase segmentation approach is implemented to develop high-quality phase separation with minimal artifacts. A number of structural characteristics and bone ingrowth characteristics of the scaffolds are quantitatively measured on the phase separated images. Porosity, pore size distributions, pore constriction sizes, and pore topology are measured on the original pore phase of the scaffold volumes. The distribution of bone ingrowth into the scaffold pore volume is also measured. For early explanted specimens we observe that bone ingrowth occurs primarily at the periphery of the scaffold with a constant decrease in bone mineralization into the scaffold volume. Pore size distributions defined by both the local pore geometry and by the largest accessible pore show distinctly different behavior. The accessible pore size is strongly correlated to bone ingrowth. In the specimens studied a strong enhancement of bone ingrowth is observed for pore diameters\&gt;100 μm. Little difference in bone ingrowth is measured with different scaffold design. This result illustrates the benefits of microtomography for analyzing the 3D structure of scaffolds and the resultant bone ingrowth.},
	number = {15},
	urldate = {2017-03-28},
	journal = {Biomaterials},
	author = {Jones, Anthony C. and Arns, Christoph H. and Sheppard, Adrian P. and Hutmacher, Dietmar W. and Milthorpe, Bruce K. and Knackstedt, Mark A.},
	month = may,
	year = {2007},
	keywords = {Bone ingrowth, Hydroxyapatite, Micro-CT, Pore structure, Scaffolds},
	pages = {2491--2504}
}
@article{xiong_review_2016,
	title = {Review of pore network modelling of porous media: {Experimental} characterisations, network constructions and applications to reactive transport},
	volume = {192},
	issn = {0169-7722},
	shorttitle = {Review of pore network modelling of porous media},
	url = {http://www.sciencedirect.com/science/article/pii/S016977221630122X},
	doi = {10.1016/j.jconhyd.2016.07.002},
	abstract = {Pore network models have been applied widely for simulating a variety of different physical and chemical processes, including phase exchange, non-Newtonian displacement, non-Darcy flow, reactive transport and thermodynamically consistent oil layers. The realism of such modelling, i.e. the credibility of their predictions, depends to a large extent on the quality of the correspondence between the pore space of a given medium and the pore network constructed as its representation. The main experimental techniques for pore space characterisation, including direct imaging, mercury intrusion porosimetry and gas adsorption, are firstly summarised. A review of the main pore network construction techniques is then presented. Particular focus is given on how such constructions are adapted to the data from experimentally characterised pore systems. Current applications of pore network models are considered, with special emphasis on the effects of adsorption, dissolution and precipitation, as well as biomass growth, on transport coefficients. Pore network models are found to be a valuable tool for understanding and predicting meso-scale phenomena, linking single pore processes, where other techniques are more accurate, and the homogenised continuum porous media, used by engineering community.},
	urldate = {2017-03-28},
	journal = {Journal of Contaminant Hydrology},
	author = {Xiong, Qingrong and Baychev, Todor G. and Jivkov, Andrey P.},
	month = sep,
	year = {2016},
	keywords = {Pore network model, Porous media, Reactive transport},
	pages = {101--117}
}

@inproceedings{dong_pore_2007,
	title = {Pore {Network} {Modeling}: {Analysis} of {Pore} {Size} {Distribution} of {Arabian} {Core} {Samples}},
	isbn = {978-1-55563-187-1},
	shorttitle = {Pore {Network} {Modeling}},
	url = {https://www.onepetro.org/conference-paper/SPE-105156-MS},
	doi = {10.2118/105156-MS},
	abstract = {Abstract We use X-ray microtomography (micro-CT) to image rock cuttings of poorly consolidated sandstone and vuggy carbonate from Saudi Arabian oil and gas fields.\&\#160; The cuttings are a few mm across and are imaged to a resolution between 3 and 1},
	language = {english},
	urldate = {2017-03-28},
	publisher = {Society of Petroleum Engineers},
	author = {Dong, Hu and Touati, Mustafa and Blunt, Martin Julian},
	month = jan,
	year = {2007}
}

@article{dong_pore-network_2009,
	title = {Pore-network extraction from micro-computerized-tomography images},
	volume = {80},
	url = {http://link.aps.org/doi/10.1103/PhysRevE.80.036307},
	doi = {10.1103/PhysRevE.80.036307},
	abstract = {Network models that represent the void space of a rock by a lattice of pores connected by throats can predict relative permeability once the pore geometry and wettability are known. Micro-computerized-tomography scanning provides a three-dimensional image of the pore space. However, these images cannot be directly input into network models. In this paper a modified maximal ball algorithm, extending the work of Silin and Patzek [D. Silin and T. Patzek, Physica A 371, 336 (2006)], is developed to extract simplified networks of pores and throats with parametrized geometry and interconnectivity from images of the pore space. The parameters of the pore networks, such as coordination number, and pore and throat size distributions are computed and compared to benchmark data from networks extracted by other methods, experimental data, and direct computation of permeability and formation factor on the underlying images. Good agreement is reached in most cases allowing networks derived from a wide variety of rock types to be used for predictive modeling.},
	number = {3},
	urldate = {2017-03-28},
	journal = {Physical Review E},
	author = {Dong, Hu and Blunt, Martin J.},
	month = sep,
	year = {2009},
	pages = {036307}
}

@article{boever_quantification_2012,
	title = {Quantification and {Prediction} of the {3D} {Pore} {Network} {Evolution} in {Carbonate} {Reservoir} {Rocks}},
	volume = {67},
	copyright = {© 2012, IFP Energies nouvelles},
	issn = {1294-4475, 1953-8189},
	url = {http://dx.doi.org/10.2516/ogst/2011170},
	doi = {10.2516/ogst/2011170},
	abstract = {Oil \& Gas Science and Technology - Revue d'IFP Energies nouvelles},
	language = {en},
	number = {1},
	urldate = {2017-03-28},
	journal = {Oil \& Gas Science and Technology – Revue d’IFP Energies nouvelles},
	author = {Boever, E. De and Varloteaux, C. and Nader, F. H. and Foubert, A. and Békri, S. and Youssef, S. and Rosenberg, E.},
	month = jan,
	year = {2012},
	pages = {161--178}
}

@article{olivares_simulation_2012,
	title = {Simulation of {Cell} {Seeding} {Within} a {Three}-{Dimensional} {Porous} {Scaffold}: {A} {Fluid}-{Particle} {Analysis}},
	volume = {18},
	issn = {1937-3384},
	shorttitle = {Simulation of {Cell} {Seeding} {Within} a {Three}-{Dimensional} {Porous} {Scaffold}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3401387/},
	doi = {10.1089/ten.tec.2011.0660},
	abstract = {Cell seeding is a critical step in tissue engineering. A high number of cells evenly distributed in scaffolds after seeding are associated with a more functional tissue culture. Furthermore, high cell densities have shown the possibility to reduce culture time or increase the formation of tissue. Experimentally, it is difficult to predict the cell-seeding process. In this study, a new methodology to simulate the cell-seeding process under perfusion conditions is proposed. The cells are treated as spherical particles dragged by the fluid media, where the physical parameters are computed through a Lagrangian formulation. The methodology proposed enables to define the kinetics of cell seeding continuously over time. An exponential relationship was found to optimize the seeding time and the number of cells seeded in the scaffold. The cell distribution and cell efficiency predicted using this methodology were similar to the experimental results of Melchels et al. One of the main advantages of this method is to be able to determine the three-dimensional position of all the seeded cells and to, therefore, better know the initial conditions for further cell proliferation and differentiation studies. This study opens up the field of numerical predictions related to the interactions between biomaterials, cells, and dynamics media.},
	number = {8},
	urldate = {2017-03-28},
	journal = {Tissue Engineering. Part C, Methods},
	author = {Olivares, Andy L. and Lacroix, Damien},
	month = aug,
	year = {2012},
	pmid = {22372887},
	pmcid = {PMC3401387},
	pages = {624--631}
}

@article{guz_if_2014,
	title = {If {Cell} {Mechanics} {Can} {Be} {Described} by {Elastic} {Modulus}: {Study} of {Different} {Models} and {Probes} {Used} in {Indentation} {Experiments}},
	volume = {107},
	issn = {0006-3495},
	shorttitle = {If {Cell} {Mechanics} {Can} {Be} {Described} by {Elastic} {Modulus}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4129501/},
	doi = {10.1016/j.bpj.2014.06.033},
	abstract = {Here we investigated the question whether cells, being highly heterogeneous objects, could be described with the elastic modulus (effective Young’s modulus) in a self-consistent way. We performed a comparative analysis of the elastic modulus derived from the indentation data obtained with atomic force microscopy (AFM) on human cervical epithelial cells (both normal and cancerous). Both sharp (cone) and dull (2500-nm radius sphere) AFM probes were used. The indentation data were processed through different elastic models. The cell was approximated as a homogeneous elastic medium that had either 1), smooth hemispherical boundary (Hertz/Sneddon models) or 2), the boundary covered with a layer of glycocalyx and membrane protrusions (“brush” models). Consistency of these approximations was investigated. Specifically, we tested the independence of the elastic modulus of the indentation depth, which is assumed in these models. We demonstrated that only one model showed consistency in treating cells as a homogeneous elastic medium, namely, the brush model, when processing the indentation data collected with the dull AFM probe. The elastic modulus demonstrated strong depth dependence in all models: Hertz/Sneddon models (no brush taken into account), and when the brush model was applied to the data collected with sharp conical probes. We conclude that it is possible to describe the elastic properties of the cell body by means of an effective elastic modulus, used in a self-consistent way, when using the brush model to analyze data collected with a dull AFM probe. The nature of these results is discussed.},
	number = {3},
	urldate = {2017-03-28},
	journal = {Biophysical Journal},
	author = {Guz, Nataliia and Dokukin, Maxim and Kalaparthi, Vivekanand and Sokolov, Igor},
	month = aug,
	year = {2014},
	pmid = {25099796},
	pmcid = {PMC4129501},
	pages = {564--575}
}

@article{yao_effects_2016,
	title = {Effects of oxidative stress-induced changes in the actin cytoskeletal structure on myoblast damage under compressive stress: confocal-based cell-specific finite element analysis},
	volume = {15},
	issn = {1617-7940},
	shorttitle = {Effects of oxidative stress-induced changes in the actin cytoskeletal structure on myoblast damage under compressive stress},
	doi = {10.1007/s10237-016-0779-0},
	abstract = {Muscle cells are frequently subjected to both mechanical and oxidative stresses in various physiological and pathological situations. To explore the mechanical mechanism of muscle cell damage under loading and oxidative stresses, we experimentally studied the effects of extrinsic hydrogen peroxides on the actin cytoskeletal structure in C2C12 myoblasts and presented a finite element (FE) analysis of how such changes in the actin cytoskeletal structure affected a myoblast's capability to resist damage under compression. A confocal-based cell-specific FE model was built to parametrically study the effects of stress fiber density, fiber cross-sectional area, fiber tensile prestrain, as well as the elastic moduli of the stress fibers, actin cortex, nucleus and cytoplasm. The results showed that a decrease in the elastic moduli of both the stress fibers and actin cortex could increase the average tensile strain on the actin cortex-membrane structure and reduce the apparent cell elastic modulus. Assuming the cell would die when a certain percentage of membrane elements were strained beyond a threshold, a lower elastic modulus of actin cytoskeleton would compromise the compressive resistance of a myoblast and lead to cell death more readily. This model was used with a Weibull distribution function to successfully describe the extent of myoblasts damaged in a monolayer under compression.},
	language = {eng},
	number = {6},
	journal = {Biomechanics and Modeling in Mechanobiology},
	author = {Yao, Yifei and Lacroix, Damien and Mak, Arthur F. T.},
	month = dec,
	year = {2016},
	pmid = {26994918},
	keywords = {Actin Cytoskeleton, Finite element modeling, Myoblast, Oxidative stress, Weibull distribution},
	pages = {1495--1508}
}

@article{barreto_structural_2014,
	title = {Structural finite element analysis to explain cell mechanics variability},
	volume = {38},
	issn = {1878-0180},
	doi = {10.1016/j.jmbbm.2013.11.022},
	abstract = {The ability to model the mechanical responses of different cell types presents many opportunities to tissue engineering research to further identify changes from physiological conditions to disease. Using a previously validated finite element cell model we aim to show how variation of the material properties of the intracellular components affects cell response after compression and shearing. A parametric study was performed to understand the key mechanical features from different cell types, focussing on specific cytoskeleton components and prestress. Results show that actin cortex does not have a mechanical role in resisting shearing loading conditions. The sensitivity analysis predicted that cell force to compression and shearing is highly affected by changes in cortex thickness, cortex Young's modulus and rigidity of the remaining cytoplasm. Variation of prestress affects mainly the response of cells under shear loads and the model defines a relationship between cell force and prestress depending on the specific loading conditions, which is in good agreement with in vitro experiments. The results are used to make predictions that can relate mechanical properties with cell phenotype to be used as guidelines for individual cytoskeletal structures for future modelling efforts of the structure-function relationships of living cells.},
	language = {eng},
	journal = {Journal of the Mechanical Behavior of Biomedical Materials},
	author = {Barreto, Sara and Perrault, Cecile M. and Lacroix, Damien},
	month = oct,
	year = {2014},
	pmid = {24389336},
	keywords = {Actin cortex, Biomechanical Phenomena, Cell adhesion, Cell model, Cells, Cytoskeleton, Finite Element Analysis, Material properties, Mechanical Phenomena, Phenotype},
	pages = {219--231}
}

@book{birkfellner_applied_2014,
	address = {Boca Raton, Fla. [u.a.]},
	edition = {2. ed.},
	title = {Applied medical image processing: a basic course},
	isbn = {978-1-4665-5557-0},
	shorttitle = {Applied medical image processing},
	url = {http://media.obvsg.at/p-AC10672695-1001},
	abstract = {Enthalten: Literaturangaben},
	language = {eng},
	urldate = {2017-04-06},
	publisher = {CRC Pr},
	author = {Birkfellner, Wolfgang},
	year = {2014},
	keywords = {(DE-588)4006617-4, (DE-588)4006684-8, (DE-588)4038243-6, Automatische Bildverarbeitung, Bildbearbeitung, Bilddatenverarbeitung, Bilddiagnostik, Bildgebende Diagnostik, Bildgebende Methode, Bildgebendes Diagnoseverfahren, Bildgebendes Verfahren, Bildverarbeitung, Diagnostic imaging--Digital techniques., Diagnostik Bildgebendes Verfahren, Digitale Bildverarbeitung, Elektronische Bildverarbeitung, Heilkunst, Humanmedizin, Image processing, Image processing--Digital techniques., Imageprocessing, Imaging, Medical Imaging, Medicine, Medizin, Medizinische Bildgebung, Picture processing}
}

@misc{lindquist_3dma-rock_2017,
	title = {{3DMA}-{Rock}},
	url = {http://www.ams.sunysb.edu/~lindquis/3dma/3dma_rock/3dma_rock.html},
	urldate = {2017-04-06},
	journal = {A Softeware Package for Automated Analysis of Rock Pore Structure in 3-D Computed Microtomography Images},
	author = {Lindquist, W.B. and Lee, S.-M. and Oh, W. and Venkatarangan, A.B. and Shin, H. and Prodanovic, M.},
	month = apr,
	year = {2017}
}

@article{danoviz_rat_2010,
	title = {Rat adipose tissue-derived stem cells transplantation attenuates cardiac dysfunction post infarction and biopolymers enhance cell retention},
	volume = {5},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0012077},
	abstract = {BACKGROUND: Cardiac cell transplantation is compromised by low cell retention and poor graft viability. Here, the effects of co-injecting adipose tissue-derived stem cells (ASCs) with biopolymers on cell cardiac retention, ventricular morphometry and performance were evaluated in a rat model of myocardial infarction (MI).
METHODOLOGY/PRINCIPAL FINDINGS: 99mTc-labeled ASCs (1x10(6) cells) isolated from isogenic Lewis rats were injected 24 hours post-MI using fibrin a, collagen (ASC/C), or culture medium (ASC/M) as vehicle, and cell body distribution was assessed 24 hours later by gamma-emission counting of harvested organs. ASC/F and ASC/C groups retained significantly more cells in the myocardium than ASC/M (13.8+/-2.0 and 26.8+/-2.4\% vs. 4.8+/-0.7\%, respectively). Then, morphometric and direct cardiac functional parameters were evaluated 4 weeks post-MI cell injection. Left ventricle (LV) perimeter and percentage of interstitial collagen in the spare myocardium were significantly attenuated in all ASC-treated groups compared to the non-treated (NT) and control groups (culture medium, fibrin, or collagen alone). Direct hemodynamic assessment under pharmacological stress showed that stroke volume (SV) and left ventricle end-diastolic pressure were preserved in ASC-treated groups regardless of the vehicle used to deliver ASCs. Stroke work (SW), a global index of cardiac function, improved in ASC/M while it normalized when biopolymers were co-injected with ASCs. A positive correlation was observed between cardiac ASCs retention and preservation of SV and improvement in SW post-MI under hemodynamic stress.
CONCLUSIONS: We provided direct evidence that intramyocardial injection of ASCs mitigates the negative cardiac remodeling and preserves ventricular function post-MI in rats and these beneficial effects can be further enhanced by administering co-injection of ASCs with biopolymers.},
	language = {eng},
	number = {8},
	journal = {PloS One},
	author = {Danoviz, Maria E. and Nakamuta, Juliana S. and Marques, Fabio L. N. and dos Santos, Leonardo and Alvarenga, Erica C. and dos Santos, Alexandra A. and Antonio, Ednei L. and Schettert, Isolmar T. and Tucci, Paulo J. and Krieger, Jose E.},
	month = aug,
	year = {2010},
	pmid = {20711471},
	pmcid = {PMC2919414},
	keywords = {Adipose Tissue, Animals, Biopolymers, Cell Survival, Cells, Cultured, Collagen, Female, Injections, Myocardium, Rats, Rats, Inbred Lew, Stem Cell Transplantation, Stem cells, fibrin, heart, myocardial infarction},
	pages = {e12077}
}

@article{christman_injectable_2004,
	title = {Injectable fibrin scaffold improves cell transplant survival, reduces infarct expansion, and induces neovasculature formation in ischemic myocardium},
	volume = {44},
	issn = {0735-1097},
	doi = {10.1016/j.jacc.2004.04.040},
	abstract = {OBJECTIVES: In this study, we determined whether fibrin glue improves cell transplant retention and survival, reduces infarct expansion, and induces neovasculature formation.
BACKGROUND: Current efforts in restoring the myocardium after myocardial infarction (MI) include the delivery of viable cells to replace necrotic cardiomyocytes. Cellular transplantation techniques are, however, limited by transplanted cell retention and survival within the ischemic tissue.
METHODS: The left coronary artery of rats was occluded for 17 min followed by reperfusion. One week later, bovine serum albumin (BSA), fibrin glue, skeletal myoblasts in BSA, or skeletal myoblasts in fibrin glue were injected into the infarcted area of the left ventricle. The animals were euthanized five weeks after injection, and their hearts were excised, fresh frozen, and sectioned for histology and immunohistochemistry.
RESULTS: After five weeks, the mean area covered by skeletal myoblasts in fibrin glue was significantly greater than the area covered by myoblasts injected in BSA. Myoblasts within the infarct were often concentrated around arterioles. The infarct scar size and myoblasts in the fibrin group were significantly smaller than those in the control and BSA groups. Fibrin glue also significantly increased the arteriole density in the infarct scar as compared with the control group.
CONCLUSIONS: This study indicates that fibrin glue increases cell transplant survival, decreases infarct size, and increases blood flow to ischemic myocardium. Therefore, fibrin glue may have potential as a biomaterial scaffold to improve cellular cardiomyoplasty treat and MIs.},
	language = {eng},
	number = {3},
	journal = {Journal of the American College of Cardiology},
	author = {Christman, Karen L. and Vardanian, Andrew J. and Fang, Qizhi and Sievers, Richard E. and Fok, Hubert H. and Lee, Randall J.},
	month = aug,
	year = {2004},
	pmid = {15358036},
	keywords = {Animals, Cell Culture Techniques, Cell Survival, Disease Models, Animal, Female, Fibrin Tissue Adhesive, Graft Survival, Heart Ventricles, Immunohistochemistry, Injections, Intralesional, Myoblasts, Skeletal, Rats, Rats, Sprague-Dawley, Tissue Adhesives, Transplantation, Autologous, myocardial infarction},
	pages = {654--660}
}

@article{morrill_validated_2016,
	title = {A validated software application to measure fiber organization in soft tissue},
	volume = {15},
	issn = {1617-7959, 1617-7940},
	url = {https://link.springer.com/article/10.1007/s10237-016-0776-3},
	doi = {10.1007/s10237-016-0776-3},
	abstract = {The mechanical behavior of soft connective tissue is governed by a dense network of fibrillar proteins in the extracellular matrix. Characterization of this fibrous network requires the accurate extraction of descriptive structural parameters from imaging data, including fiber dispersion and mean fiber orientation. Common methods to quantify fiber parameters include fast Fourier transforms (FFT) and structure tensors; however, information is limited on the accuracy of these methods. In this study, we compared these two methods using test images of fiber networks with varying topology. The FFT method with a band-pass filter was the most accurate, with an error of 0.7∘±0.4∘0.7∘±0.4∘0.7{\textasciicircum}\{{\textbackslash}circ \} {\textbackslash}pm 0.4{\textasciicircum}\{{\textbackslash}circ \} in measuring mean fiber orientation and an error of 7.4±3.0\%7.4±3.0\%7.4 {\textbackslash}pm 3.0{\textbackslash},{\textbackslash}\% in measuring fiber dispersion in the test images. The accuracy of the structure tensor method was approximately five times worse than the FFT band-pass method when measuring fiber dispersion. A free software application, FiberFit, was then developed that utilizes an FFT band-pass filter to fit fiber orientations to a semicircular von Mises distribution. FiberFit was used to measure collagen fibril organization in confocal images of bovine ligament at magnifications of 63×63×63\{{\textbackslash}times \} and 20×20×20\{{\textbackslash}times \}. Grayscale conversion prior to FFT analysis gave the most accurate results, with errors of 3.3∘±3.1∘3.3∘±3.1∘3.3{\textasciicircum}\{{\textbackslash}circ \} {\textbackslash}pm 3.1{\textasciicircum}\{{\textbackslash}circ \} for mean fiber orientation and 13.3±8.2\%13.3±8.2\%13.3 {\textbackslash}pm 8.2{\textbackslash},{\textbackslash}\% for fiber dispersion when measuring confocal images at 63×63×63\{{\textbackslash}times \}. By developing and validating a software application that facilitates the automated analysis of fiber organization, this study can help advance a mechanistic understanding of collagen networks and help clarify the mechanobiology of soft tissue remodeling and repair.},
	language = {en},
	number = {6},
	urldate = {2017-03-09},
	journal = {Biomechanics and Modeling in Mechanobiology},
	author = {Morrill, Erica E. and Tulepbergenov, Azamat N. and Stender, Christina J. and Lamichhane, Roshani and Brown, Raquel J. and Lujan, Trevor J.},
	month = dec,
	year = {2016},
	pages = {1467--1478}
}

@article{chen_-plane_2012,
	title = {In-plane elastic buckling of hierarchical honeycomb materials},
	volume = {34},
	issn = {0997-7538},
	url = {http://www.sciencedirect.com/science/article/pii/S0997753811001781},
	doi = {10.1016/j.euromechsol.2011.12.003},
	abstract = {In this paper, we study the elastic buckling of a new class of honeycomb materials with hierarchical architecture, which is often observed in nature. Employing the top–down approach, the virtual buckling stresses and corresponding strains for each cell wall at level n − 1 are calculated from those at level n; then, comparing these virtual buckling stresses of all cell walls, the real local buckling stress is deduced; also, the progressive failure of the hierarchical structure is studied. Finally, parametric analyses reveal influences of some key parameters on the local buckling stress and strength-to-density ratio; meanwhile the constitutive behaviors and energy-absorption properties, with increasing hierarchy n, are calculated. The results show the possibility to tailor the elastic buckling properties at each hierarchical level, and could thus have interesting applications, e.g., in the design of multiscale energy-absorption honeycomb light materials.},
	urldate = {2017-05-02},
	journal = {European Journal of Mechanics - A/Solids},
	author = {Chen, Qiang and Pugno, Nicola M.},
	month = jul,
	year = {2012},
	keywords = {Energy absorption, Hierarchical honeycomb, Local buckling stress, Progressive failure},
	pages = {120--129}
}

@article{camci-unal_hydrogels_2014,
	title = {Hydrogels for cardiac tissue engineering},
	volume = {6},
	copyright = {© 2014 Nature Publishing Group},
	url = {http://www.nature.com/am/journal/v6/n5/full/am201419a.html},
	doi = {10.1038/am.2014.19},
	abstract = {Cardiac failure is a critical condition that results in life-threatening consequences. Due to a limited number of organ donors, tissue engineering has emerged to generate functional tissue constructs and provide an alternative mean to repair and regenerate damaged heart tissues. In this paper, we review the emerging directions associated with cardiac tissue engineering approaches. In particular, we discuss the use of hydrogels in repair and regeneration of damaged hearts. Because of their tissue-like biological, chemical and mechanical properties, hydrogels represent a potentially powerful material for directing cells into functional cardiac tissues. Herein, we will summarize both traditional and next-generation hydrogels with conductive, elastomeric and oxygen-releasing capabilities that can promote vascularization and stem cell differentiation to form properly functioning cardiac tissues.},
	language = {en},
	number = {5},
	urldate = {2017-05-04},
	journal = {NPG Asia Materials},
	author = {Camci-Unal, Gulden and Annabi, Nasim and Dokmeci, Mehmet R. and Liao, Ronglih and Khademhosseini, Ali},
	month = may,
	year = {2014},
	keywords = {Biomaterials, Cardiac tissue engineering, Stem cells, hydrogels, regenerative medicine},
	pages = {e99}
}

@article{geckil_engineering_2010,
	title = {Engineering hydrogels as extracellular matrix mimics},
	volume = {5},
	issn = {1743-5889},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2892416/},
	doi = {10.2217/nnm.10.12},
	abstract = {Extracellular matrix (ECM) is a complex cellular environment consisting of proteins, proteoglycans, and other soluble molecules. ECM provides structural support to mammalian cells and a regulatory milieu with a variety of important cell functions, including assembling cells into various tissues and organs, regulating growth and cell–cell communication. Developing a tailored in vitro cell culture environment that mimics the intricate and organized nanoscale meshwork of native ECM is desirable. Recent studies have shown the potential of hydrogels to mimic native ECM. Such an engineered native-like ECM is more likely to provide cells with rational cues for diagnostic and therapeutic studies. The research for novel biomaterials has led to an extension of the scope and techniques used to fabricate biomimetic hydrogel scaffolds for tissue engineering and regenerative medicine applications. In this article, we detail the progress of the current state-of-the-art engineering methods to create cell-encapsulating hydrogel tissue constructs as well as their applications in in vitro models in biomedicine.},
	number = {3},
	urldate = {2017-05-04},
	journal = {Nanomedicine (London, England)},
	author = {Geckil, Hikmet and Xu, Feng and Zhang, Xiaohui and Moon, SangJun and Demirci, Utkan},
	month = apr,
	year = {2010},
	pmid = {20394538},
	pmcid = {PMC2892416},
	pages = {469--484}
}

@article{radisic_materials_2013,
	title = {Materials {Science} and {Tissue} {Engineering}: {Repairing} the {Heart}},
	volume = {88},
	issn = {0025-6196},
	shorttitle = {Materials {Science} and {Tissue} {Engineering}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3786696/},
	doi = {10.1016/j.mayocp.2013.05.003},
	abstract = {Heart failure following a myocardial infarction continues to be a leading killer in the western world. Currently there are no therapies that effectively prevent or reverse the cardiac damage and negative left ventricular remodeling process that follows a myocardial infarction. Since the heart has limited regenerative capacity, there has been significant effort to develop new therapies that could repair and regenerate the myocardium. While cell transplantation alone was initially studied, more recently tissue engineering strategies using biomaterial scaffolds have been explored. In this review, we cover the different approaches to engineer the myocardium. These include cardiac patches, which are in vitro engineered constructs of functional myocardium, as well as injectable scaffolds that can either encourage endogenous repair and regeneration, or act as vehicles to support delivery of cells and other therapeutics.},
	number = {8},
	urldate = {2017-05-04},
	journal = {Mayo Clinic proceedings. Mayo Clinic},
	author = {Radisic, Milica and Christman, Karen L.},
	month = aug,
	year = {2013},
	pmid = {23910415},
	pmcid = {PMC3786696},
	pages = {884--898}
}

@article{grigore_hydrogels_2017,
	title = {Hydrogels for {Cardiac} {Tissue} {Repair} and {Regeneration}},
	volume = {1},
	abstract = {The main cause of death in the world continues to be cardiovascular disease, which affects annually
over 900,000 people and in the entire word approximately 50\% of the people suffering myocardial
infarction (MI) die within 5 years. MI causes a number of cardiac pathologies like hypertension, blocked
coronary arteries and valvular heart diseases resulting ischemic cardiac injury. In the last years, cardiac
tissue engineering has made considerable progress, because this progress have been made towards
developing injectable hydrogels for the purpose of cardiac repair and/or regeneration. This study aims
to provide an updated survey of the major progress in the fl ied of injectable cardiac tissue engineering,
including biomaterials (natural, synthetic or hybrid hydrogels), their advantages or disadvantages and the
main seeding cell sources. Also, this review focuses on the progress made in the fi eld of hydrogels for
cardiac tissue repair and/or regeneration for MI over the last years},
	number = {1},
	urldate = {2017-04-05},
	journal = {Open Journal of Materials Science},
	author = {Grigore, Madalina},
	month = jan,
	year = {2017},
	pages = {1--9}
}

@article{venugopal_biomaterial_2012,
	title = {Biomaterial strategies for alleviation of myocardial infarction},
	volume = {9},
	issn = {1742-5662},
	doi = {10.1098/rsif.2011.0301},
	abstract = {World Health Organization estimated that heart failure initiated by coronary artery disease and myocardial infarction (MI) leads to 29 per cent of deaths worldwide. Heart failure is one of the leading causes of death in industrialized countries and is expected to become a global epidemic within the twenty-first century. MI, the main cause of heart failure, leads to a loss of cardiac tissue impairment of left ventricular function. The damaged left ventricle undergoes progressive 'remodelling' and chamber dilation, with myocyte slippage and fibroblast proliferation. Repair of diseased myocardium with in vitro-engineered cardiac muscle patch/injectable biopolymers with cells may become a viable option for heart failure patients. These events reflect an apparent lack of effective intrinsic mechanism for myocardial repair and regeneration. Motivated by the desire to develop minimally invasive procedures, the last 10 years observed growing efforts to develop injectable biomaterials with and without cells to treat cardiac failure. Biomaterials evaluated include alginate, fibrin, collagen, chitosan, self-assembling peptides, biopolymers and a range of synthetic hydrogels. The ultimate goal in therapeutic cardiac tissue engineering is to generate biocompatible, non-immunogenic heart muscle with morphological and functional properties similar to natural myocardium to repair MI. This review summarizes the properties of biomaterial substrates having sufficient mechanical stability, which stimulates the native collagen fibril structure for differentiating pluripotent stem cells and mesenchymal stem cells into cardiomyocytes for cardiac tissue engineering.},
	language = {eng},
	number = {66},
	journal = {Journal of the Royal Society, Interface},
	author = {Venugopal, Jayarama Reddy and Prabhakaran, Molamma P. and Mukherjee, Shayanti and Ravichandran, Rajeswari and Dan, Kai and Ramakrishna, Seeram},
	month = jan,
	year = {2012},
	pmid = {21900319},
	pmcid = {PMC3223634},
	keywords = {Adipose Tissue, Animals, Biocompatible Materials, Biomechanical Phenomena, Cell Differentiation, Cord Blood Stem Cell Transplantation, Extracellular Matrix, Mesenchymal Stromal Cells, Myocardium, Rats, Tissue Engineering, Tissue Scaffolds, myocardial infarction, pluripotent stem cells},
	pages = {1--19}
}

@article{engler_matrix_2006,
	title = {Matrix {Elasticity} {Directs} {Stem} {Cell} {Lineage} {Specification}},
	volume = {126},
	issn = {0092-8674},
	url = {http://www.sciencedirect.com/science/article/pii/S0092867406009615},
	doi = {10.1016/j.cell.2006.06.044},
	abstract = {Summary
Microenvironments appear important in stem cell lineage specification but can be difficult to adequately characterize or control with soft tissues. Naive mesenchymal stem cells (MSCs) are shown here to specify lineage and commit to phenotypes with extreme sensitivity to tissue-level elasticity. Soft matrices that mimic brain are neurogenic, stiffer matrices that mimic muscle are myogenic, and comparatively rigid matrices that mimic collagenous bone prove osteogenic. During the initial week in culture, reprogramming of these lineages is possible with addition of soluble induction factors, but after several weeks in culture, the cells commit to the lineage specified by matrix elasticity, consistent with the elasticity-insensitive commitment of differentiated cell types. Inhibition of nonmuscle myosin II blocks all elasticity-directed lineage specification–without strongly perturbing many other aspects of cell function and shape. The results have significant implications for understanding physical effects of the in vivo microenvironment and also for therapeutic uses of stem cells.},
	number = {4},
	urldate = {2017-05-04},
	journal = {Cell},
	author = {Engler, Adam J. and Sen, Shamik and Sweeney, H. Lee and Discher, Dennis E.},
	month = aug,
	year = {2006},
	pages = {677--689}
}

@article{lee_alginate:_2012,
	title = {Alginate: properties and biomedical applications},
	volume = {37},
	issn = {0079-6700},
	shorttitle = {Alginate},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3223967/},
	doi = {10.1016/j.progpolymsci.2011.06.003},
	abstract = {Alginate is a biomaterial that has found numerous applications in biomedical science and engineering due to its favorable properties, including biocompatibility and ease of gelation. Alginate hydrogels have been particularly attractive in wound healing, drug delivery, and tissue engineering applications to date, as these gels retain structural similarity to the extracellular matrices in tissues and can be manipulated to play several critical roles. This review will provide a comprehensive overview of general properties of alginate and its hydrogels, their biomedical applications, and suggest new perspectives for future studies with these polymers.},
	number = {1},
	urldate = {2017-05-16},
	journal = {Progress in polymer science},
	author = {Lee, Kuen Yong and Mooney, David J.},
	month = jan,
	year = {2012},
	pmid = {22125349},
	pmcid = {PMC3223967},
	pages = {106--126}
}

@article{ungerleider_concise_2014,
	title = {Concise {Review}: {Injectable} {Biomaterials} for the {Treatment} of {Myocardial} {Infarction} and {Peripheral} {Artery} {Disease}: {Translational} {Challenges} and {Progress}},
	volume = {3},
	issn = {2157-6564},
	shorttitle = {Concise {Review}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4149304/},
	doi = {10.5966/sctm.2014-0049},
	abstract = {This report summarizes the latest preclinical and clinical studies on injectable biomaterial therapies for myocardial infarction (MI) and peripheral artery disease (PAD). The study highlights the major challenges facing translation of these therapies to the clinic (e.g., regulatory, manufacturing, and delivery), with the purpose of increasing awareness of the barriers for translating novel biomaterial therapies for MI and PAD and facilitating more rapid translation of new biomaterial technologies., Recently, injectable biomaterial-based therapies for cardiovascular disease have been gaining attention, because they have shown therapeutic potential in preclinical models for myocardial infarction (MI) and peripheral artery disease (PAD). Naturally derived (e.g., alginate, hyaluronic acid, collagen, or extracellular matrix-based) or synthetic (e.g., peptide or polymer-based) materials can enhance stem cell survival and retention in vivo, prolong growth factor release from bulk hydrogel or particle constructs, and even stimulate endogenous tissue regeneration as a standalone therapy. Although there are many promising preclinical examples, the therapeutic potential of biomaterial-based products for cardiovascular disease has yet to be proved on a clinical and commercial scale. This review aims to briefly summarize the latest preclinical and clinical studies on injectable biomaterial therapies for MI and PAD. Furthermore, our overall goal is to highlight the major challenges facing translation of these therapies to the clinic (e.g., regulatory, manufacturing, and delivery), with the purpose of increasing awareness of the barriers for translating novel biomaterial therapies for MI and PAD and facilitating more rapid translation of new biomaterial technologies.},
	number = {9},
	urldate = {2017-05-16},
	journal = {Stem Cells Translational Medicine},
	author = {Ungerleider, Jessica L. and Christman, Karen L.},
	month = sep,
	year = {2014},
	pmid = {25015641},
	pmcid = {PMC4149304},
	pages = {1090--1099}
}

@phdthesis{sargus-patino_alginate_2013,
	address = {Lincoln, Nebraska},
	title = {Alginate {Hydrogel} as a {Three}-dimensional {Extracellular} {Matrix} for {In} {Vitro} {Models} of {Development}},
	url = {http://digitalcommons.unl.edu/biosysengdiss/37},
	abstract = {Tissue engineering, involving the use of three-dimensional (3-D) scaffolds for cell and tissue culture, is a promising technique for establishing in vitro culture models that mimic in vivo environments. In vitro models present ethical and cost advantages over in vivo models, and allow for controlled, mechanistic studies on factors that regulate normal and abnormal tissue development. Alginate, a linear polysaccharide derived from brown algae, has properties that make it a favorable material as a 3-D extracellular matrix for in vitro cell and tissue models. After demonstrating alginate’s tunable physical and chemical properties with respect to gel formation, stiffness, and cellular interactions, alginate hydrogel was employed in two separate culture systems that share in common the ultimate goal of serving as in vitro models of tissue development and function: 1) an in vitro model of pig embryo elongation to develop strategies for improving pregnancy outcomes, and 2) an in vitro model of growth plate cartilage to discover factors necessary for inducing native cartilage architecture for tissue engineering applications. In regards to pig embryo culture, embryos encapsulated within alginate hydrogels exhibited greater survival and morphological changes than non-encapsulated control embryos, along with increased expression of steroidogenic transcripts and estrogen production, consistent with in vivo elongation. For the growth plate model, alginate hydrogels were used for the encapsulation of mouse growth plate chondrocytes in vitro to study the effects of soluble parathyroid hormone (PTH), a signaling factor that regulates growth plate structure and function in vivo, along with the effects of an arginine-glycine-aspartic acid (RGD) peptide conjugated to the alginate. PTH and RGD peptide treatment resulted in decreased collagen X and Indian hedgehog transcript expression in encapsulated chondrocytes, demonstrating the role of these factors on the regulation of chondrocyte hypertrophy in vitro. Overall, information gained from utilizing these in vitro models as research tools can be used to advance the field of developmental biology and enhance tissue engineering therapies for the treatment of degenerative diseases.},
	urldate = {2017-05-16},
	school = {University of Nebraska},
	author = {Sargus-Patino, Catherine},
	month = nov,
	year = {2013}
}

@article{sack_partial_2016,
	title = {Partial {LVAD} restores ventricular outputs and normalizes {LV} but not {RV} stress distributions in the acutely failing heart in silico},
	volume = {39},
	issn = {1724-6040},
	doi = {10.5301/ijao.5000520},
	abstract = {PURPOSE: Heart failure is a worldwide epidemic that is unlikely to change as the population ages and life expectancy increases. We sought to detail significant recent improvements to the Dassault Systèmes Living Heart Model (LHM) and use the LHM to compute left ventricular (LV) and right ventricular (RV) myofiber stress distributions under the following 4 conditions: (1) normal cardiac function; (2) acute left heart failure (ALHF); (3) ALHF treated using an LV assist device (LVAD) flow rate of 2 L/min; and (4) ALHF treated using an LVAD flow rate of 4.5 L/min.
METHODS AND RESULTS: Incorporating improved systolic myocardial material properties in the LHM resulted in its ability to simulate the Frank-Starling law of the heart. We decreased myocardial contractility in the LV myocardium so that LV ejection fraction decreased from 56\% to 28\%. This caused mean LV end diastolic (ED) stress to increase to 508\% of normal, mean LV end systolic (ES) stress to increase to 113\% of normal, mean RV ED stress to decrease to 94\% of normal and RV ES to increase to 570\% of normal. When ALHF in the model was treated with an LVAD flow rate of 4.5 L/min, most stress results normalized. Mean LV ED stress became 85\% of normal, mean LV ES stress became 109\% of normal and mean RV ED stress became 95\% of normal. However, mean RV ES stress improved less dramatically (to 342\% of normal values).
CONCLUSIONS: These simulations strongly suggest that an LVAD is effective in normalizing LV stresses but not RV stresses that become elevated as a result of ALHF.},
	language = {eng},
	number = {8},
	journal = {The International Journal of Artificial Organs},
	author = {Sack, Kevin L. and Baillargeon, Brian and Acevedo-Bolton, Gabriel and Genet, Martin and Rebelo, Nuno and Kuhl, Ellen and Klein, Liviu and Weiselthaler, Georg M. and Burkhoff, Daniel and Franz, Thomas and Guccione, Julius M.},
	month = oct,
	year = {2016},
	pmid = {27646633},
	pmcid = {PMC5067236},
	pages = {421--430}
}

@article{loh_three-dimensional_2013,
	title = {Three-{Dimensional} {Scaffolds} for {Tissue} {Engineering} {Applications}: {Role} of {Porosity} and {Pore} {Size}},
	volume = {19},
	issn = {1937-3368},
	shorttitle = {Three-{Dimensional} {Scaffolds} for {Tissue} {Engineering} {Applications}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3826579/},
	doi = {10.1089/ten.teb.2012.0437},
	abstract = {Tissue engineering applications commonly encompass the use of three-dimensional (3D) scaffolds to provide a suitable microenvironment for the incorporation of cells or growth factors to regenerate damaged tissues or organs. These scaffolds serve to mimic the actual in vivo microenvironment where cells interact and behave according to the mechanical cues obtained from the surrounding 3D environment. Hence, the material properties of the scaffolds are vital in determining cellular response and fate. These 3D scaffolds are generally highly porous with interconnected pore networks to facilitate nutrient and oxygen diffusion and waste removal. This review focuses on the various fabrication techniques (e.g., conventional and rapid prototyping methods) that have been employed to fabricate 3D scaffolds of different pore sizes and porosity. The different pore size and porosity measurement methods will also be discussed. Scaffolds with graded porosity have also been studied for their ability to better represent the actual in vivo situation where cells are exposed to layers of different tissues with varying properties. In addition, the ability of pore size and porosity of scaffolds to direct cellular responses and alter the mechanical properties of scaffolds will be reviewed, followed by a look at nature's own scaffold, the extracellular matrix. Overall, the limitations of current scaffold fabrication approaches for tissue engineering applications and some novel and promising alternatives will be highlighted.},
	number = {6},
	journal = {Tissue Engineering. Part B, Reviews},
	author = {Loh, Qiu Li and Choong, Cleo},
	month = dec,
	year = {2013},
	pmid = {23672709},
	pmcid = {PMC3826579},
	pages = {485--502}
}

@article{al-riyami_how_2008,
	title = {How to prepare a {Research} {Proposal}},
	volume = {23},
	issn = {1999-768X},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3282423/},
	abstract = {Health research, medical education and clinical practice form the three pillars of modern day medical practice. As one authority rightly put it: ‘Health research is not a luxury, but an essential need that no nation can afford to ignore’. Health research can and should be pursued by a broad range of people. Even if they do not conduct research themselves, they need to grasp the principles of the scientific method to understand the value and limitations of science and to be able to assess and evaluate results of research before applying them. This review paper aims to highlight the essential concepts to the students and beginning researchers and sensitize and motivate the readers to access the vast literature available on research methodologies.},
	number = {2},
	journal = {Oman Medical Journal},
	author = {Al-Riyami, Asya},
	month = apr,
	year = {2008},
	pmid = {22379539},
	pmcid = {PMC3282423},
	pages = {66--69}
}

@article{an_design_2015,
	series = {Special {Section}: {Advanced} {Materials} and {Materials} {GenomeMembers}},
	title = {Design and {3D} {Printing} of {Scaffolds} and {Tissues}},
	volume = {1},
	issn = {2095-8099},
	url = {http://www.sciencedirect.com/science/article/pii/S2095809916300716},
	doi = {10.15302/J-ENG-2015061},
	abstract = {A growing number of three-dimensional (3D)-printing processes have been applied to tissue engineering. This paper presents a state-of-the-art study of 3D-printing technologies for tissue-engineering applications, with particular focus on the development of a computer-aided scaffold design system; the direct 3D printing of functionally graded scaffolds; the modeling of selective laser sintering (SLS) and fused deposition modeling (FDM) processes; the indirect additive manufacturing of scaffolds, with both micro and macro features; the development of a bioreactor; and 3D/4D bioprinting. Technological limitations will be discussed so as to highlight the possibility of future improvements for new 3D-printing methodologies for tissue engineering.},
	number = {2},
	journal = {Engineering},
	author = {An, Jia and Teoh, Joanne Ee Mei and Suntornnond, Ratima and Chua, Chee Kai},
	month = jun,
	year = {2015},
	pages = {261--268}
}

@article{wang_evaluating_2015,
	title = {Evaluating {3D}-{Printed} {Biomaterials} as {Scaffolds} for {Vascularized} {Bone} {Tissue} {Engineering}},
	volume = {27},
	issn = {1521-4095},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/adma.201403943/abstract},
	doi = {10.1002/adma.201403943},
	language = {en},
	number = {1},
	journal = {Advanced Materials},
	author = {Wang, Martha O. and Vorwald, Charlotte E. and Dreher, Maureen L. and Mott, Eric J. and Cheng, Ming-Huei and Cinar, Ali and Mehdizadeh, Hamidreza and Somo, Sami and Dean, David and Brey, Eric M. and Fisher, John P.},
	month = jan,
	year = {2015},
	pages = {138--144}
}

@misc{co-ordination_of_notified_bodies_medical_devices_recommendation_2001,
	type = {Recommendation pdf},
	title = {Recommendation {NB}-{MED}/2.2/{Rec4}},
	url = {http://www.team-nb.org//wp-content/uploads/2015/05/nbmeddocuments/Recommendation-NB-MED-2_2-4_rev5_Software_and_Medical_Devices.pdf},
	language = {English},
	urldate = {2016-03-31},
	journal = {Software and Medical Devices - Essential Requirements},
	author = {{Co-ordination of Notified Bodies Medical Devices}},
	month = jun,
	year = {2001}
}

@misc{european_commission_medical_2016,
	title = {Medical devices - {European} {Commission}},
	url = {http://ec.europa.eu/growth/single-market/european-standards/harmonised-standards/medical-devices/index_en.htm},
	language = {English},
	urldate = {2016-03-31},
	journal = {Harmonsied Standards for Medical Devices},
	author = {{European Commission}},
	month = mar,
	year = {2016}
}

@article{noauthor_medical_2007,
	title = {Medical {Device} {Directive} 93\_42\_EEC.pdf},
	volume = {L},
	number = {247},
	urldate = {2016-03-16},
	journal = {Official Journal of the EU},
	month = nov,
	year = {2007},
	pages = {21ff.}
}

@article{european_commission_machinery_2006,
	title = {Machinery {Directive} 2006.pdf},
	volume = {L 157},
	url = {http://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32006L0042&from=EN},
	urldate = {2016-03-31},
	journal = {Official Journal of the EU},
	author = {{European Commission}},
	month = sep,
	year = {2006},
	pages = {24ff.}
}

@misc{cei/iec_iec_2006,
	title = {{IEC} 62304:2006 {Medical} {Device} {Software} - {Software} {Life} {Cycle} {Processes}},
	author = {{CEI/IEC}},
	month = may,
	year = {2006}
}

@misc{iso_iso_2007,
	title = {{ISO} 13485:2007 {Medical} {Devices} - {Quality} {Management} {Systems}},
	author = {{ISO}},
	year = {2007}
}

@misc{working_group_on_borderline_and_classification_manual_2011,
	title = {Manual on {Borderline} and {Classification} in the {Community} {Regulatory} {Framework} for {Medical} {Devices}},
	url = {http://ec.europa.eu/consumers/sectors/medical-devices/files/wg_minutes_member_lists/version1_9_borderline_manual_en.pdf},
	language = {English},
	urldate = {2016-03-31},
	journal = {MANUAL ON BORDERLINE AND CLASSIFICATION IN THE COMMUNITY REGULATORY FRAMEWORK FOR MEDICAL DEVICES},
	author = {{Working Group on Borderline And Classification}},
	month = mar,
	year = {2011}
}

@misc{noauthor_mobile_2016,
	title = {Mobile {Health} {Apps} {Interactive} {Tool} {\textbar} {Federal} {Trade} {Commission}},
	url = {https://www.ftc.gov/tips-advice/business-center/guidance/mobile-health-apps-interactive-tool#which},
	urldate = {2016-04-19},
	month = apr,
	year = {2016}
}

@article{bers_donald_cardiac_2002,
	title = {Cardiac excitation–contraction coupling},
	number = {415},
	journal = {NATURE},
	author = {{Bers, Donald}},
	month = jan,
	year = {2002},
	keywords = {Calcium, Cardiac, Cell, Excitation, Myocardium},
	pages = {198--205}
}

@misc{daniel_burkhoff_md_phd_mechanical_2011,
	title = {{MECHANICAL} {PROPERTIES} {OF} {THE} {HEART} {AND} {ITS} {INTERACTION} {WITH} {THE} {VASCULAR} {SYSTEM}},
	shorttitle = {Mechanical {Properties} of the {Heart}},
	language = {English},
	author = {{Daniel Burkhoff MD PhD}},
	month = jan,
	year = {2011},
	keywords = {Basic functionality, Cardiac, Cell, Excitation, Mechanics, Myocardium}
}

@misc{stefano_piccolo_tugs_2016,
	title = {Tugs and {Prods} on a {Cell}, {Not} {Just} {Its} {Genes}, {Determine} {Its} {Fate} in the {Human} {Body}},
	url = {https://www.scientificamerican.com/article/tugs-and-prods-on-a-cell-not-just-its-genes-determine-its-fate-in-the-human-body/},
	abstract = {Physical pushes and pulls on a cell, not just genes, determine whether it will become part of a bone, a brain\&mdash;or a deadly tumor},
	urldate = {2016-10-20},
	journal = {Scientific American},
	author = {{Stefano Piccolo}},
	month = oct,
	year = {2016},
	keywords = {Cellular, Growth, Mechanical, Molecules, Proteins, Signalling, Stress, Stretch, Taz, Yap}
}

@article{zhao_notch_2014,
	title = {Notch signaling regulates cardiomyocyte proliferation during zebrafish heart regeneration},
	volume = {111},
	issn = {1091-6490},
	doi = {10.1073/pnas.1311705111},
	abstract = {The human heart's failure to replace ischemia-damaged myocardium with regenerated muscle contributes significantly to the worldwide morbidity and mortality associated with coronary artery disease. Remarkably, certain vertebrate species, including the zebrafish, achieve complete regeneration of amputated or injured myocardium through the proliferation of spared cardiomyocytes. Nonetheless, the genetic and cellular determinants of natural cardiac regeneration remain incompletely characterized. Here, we report that cardiac regeneration in zebrafish relies on Notch signaling. Following amputation of the zebrafish ventricular apex, Notch receptor expression becomes activated specifically in the endocardium and epicardium, but not the myocardium. Using a dominant negative approach, we discovered that suppression of Notch signaling profoundly impairs cardiac regeneration and induces scar formation at the amputation site. We ruled out defects in endocardial activation, epicardial activation, and dedifferentiation of compact myocardial cells as causative for the regenerative failure. Furthermore, coronary endothelial tubes, which we lineage traced from preexisting endothelium in wild-type hearts, formed in the wound despite the myocardial regenerative failure. Quantification of myocardial proliferation in Notch-suppressed hearts revealed a significant decrease in cycling cardiomyocytes, an observation consistent with a noncell autonomous requirement for Notch signaling in cardiomyocyte proliferation. Unexpectedly, hyperactivation of Notch signaling also suppressed cardiomyocyte proliferation and heart regeneration. Taken together, our data uncover the exquisite sensitivity of regenerative cardiomyocyte proliferation to perturbations in Notch signaling.},
	language = {ENG},
	number = {4},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Zhao, Long and Borikova, Asya L. and Ben-Yair, Raz and Guner-Ataman, Burcu and MacRae, Calum A. and Lee, Richard T. and Burns, C. Geoffrey and Burns, Caroline E.},
	month = jan,
	year = {2014},
	pmid = {24474765},
	pmcid = {PMC3910613},
	keywords = {Cardiac, Notch, Pathway, Remodelling, Signalling},
	pages = {1403--1408}
}

@article{tzahor_wnt/beta-catenin_2007,
	title = {Wnt/beta-catenin signaling and cardiogenesis: timing does matter},
	volume = {13},
	issn = {1534-5807},
	shorttitle = {Wnt/beta-catenin signaling and cardiogenesis},
	doi = {10.1016/j.devcel.2007.06.006},
	abstract = {Recent findings in mouse and zebrafish embryos, as well as in embryonic stem cells, emphasize the critical importance of the Wnt/beta-catenin pathway in the regulation of cardiogenesis, and highlight the exquisite timing and specific cellular responses by which this signaling pathway exerts its influence. These studies clearly demonstrate that the Wnt/beta-catenin pathway plays distinct, even opposing, roles during various stages of cardiac development.},
	language = {ENG},
	number = {1},
	journal = {Developmental Cell},
	author = {Tzahor, Eldad},
	month = jul,
	year = {2007},
	pmid = {17609106},
	pages = {10--13}
}

@misc{noauthor_how_2015,
	title = {How to avoid {FDA} regulation for your medical app},
	url = {http://www.imedicalapps.com/2015/07/avoid-fda-regulation-medical-app/},
	abstract = {Determine if your medical app will require FDA regulation.},
	urldate = {2016-10-22},
	journal = {iMedicalApps},
	month = jul,
	year = {2015}
}

@article{y.x._gan_three-dimensional_2005,
	title = {Three-dimensional modeling of the mechanical property of linearly elastic open cell foams},
	volume = {42},
	issn = {00207683},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0020768305001137},
	doi = {10.1016/j.ijsolstr.2005.03.002},
	language = {en},
	number = {26},
	urldate = {2016-12-05},
	journal = {International Journal of Solids and Structures},
	author = {{Y.X. Gan} and Chen, C. and Shen, Y.P.},
	month = dec,
	year = {2005},
	pages = {6628--6642}
}

@misc{noauthor_more_2015,
	title = {More than 165,000 mobile health apps now available},
	url = {http://www.imedicalapps.com/2015/09/ims-health-apps-report/},
	abstract = {A report from the IMS Institute finds the market is still growing fast, with some surprising insights of characteristics \& use of health apps.},
	urldate = {2016-11-19},
	journal = {iMedicalApps},
	month = sep,
	year = {2015}
}

@article{boyle_computational_2010,
	title = {Computational simulation methodologies for mechanobiological modelling: a cell-centred approach to neointima development in stents},
	volume = {368},
	issn = {1364-503X},
	shorttitle = {Computational simulation methodologies for mechanobiological modelling},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2944394/},
	doi = {10.1098/rsta.2010.0071},
	abstract = {The design of medical devices could be very much improved if robust tools were available for computational simulation of tissue response to the presence of the implant. Such tools require algorithms to simulate the response of tissues to mechanical and chemical stimuli. Available methodologies include those based on the principle of mechanical homeostasis, those which use continuum models to simulate biological constituents, and the cell-centred approach, which models cells as autonomous agents. In the latter approach, cell behaviour is governed by rules based on the state of the local environment around the cell; and informed by experiment. Tissue growth and differentiation requires simulating many of these cells together. In this paper, the methodology and applications of cell-centred techniques—with particular application to mechanobiology—are reviewed, and a cell-centred model of tissue formation in the lumen of an artery in response to the deployment of a stent is presented. The method is capable of capturing some of the most important aspects of restenosis, including nonlinear lesion growth with time. The approach taken in this paper provides a framework for simulating restenosis; the next step will be to couple it with more patient-specific geometries and quantitative parameter data.},
	number = {1921},
	urldate = {2016-12-05},
	journal = {Philosophical transactions. Series A, Mathematical, physical, and engineering sciences},
	author = {Boyle, C. J. and Lennon, A. B. and Early, M. and Kelly, D. J. and Lally, C. and Prendergast, P. J.},
	month = jun,
	year = {2010},
	pmid = {20478914},
	pmcid = {PMC2944394},
	keywords = {Cellular, History, Links, Mechanic, Modelling, Sources},
	pages = {2919--2935}
}

@phdthesis{bruce_h._modelling_2013,
	address = {Lund},
	title = {{MODELLING} {ADHESION} {IN} {PACKAGING} {MATERIALS} {Physical} {Tests} and {Virtual} {Tests} in {Abaqus}},
	url = {http://www.byggmek.lth.se/fileadmin/byggnadsmekanik/publications/tvsm5000/web5188.pdf},
	language = {English},
	urldate = {2016-07-12},
	school = {Lund University},
	author = {{Bruce, H.} and {Holmqvist, C.}},
	month = oct,
	year = {2013},
	keywords = {Abaqus, Adhesion}
}

@book{noauthor_computational_2008,
	title = {Computational {Models} for the {Bio}-chemo-mechanical {Behavior} of {Cells} in {Diverse} {Extra}-cellular {Settings}},
	isbn = {978-0-549-98793-2},
	abstract = {Computational models for simulating the bio-chemo-mechanical response of the cells in diverse extra-cellular settings are developed in this research. First, we consider the viability of a cytoskeletal model composed of cable-like fibrils as a statically determinate structure. We find that the discrete model of stress fibers lacks the features essential for capturing various aspect of cell behavior. We develop a finite element model based on a continuum mechanics grounded bio-chemo-mechanical model for cytoskeletal contractility and focal adhesion formation. We extend this model to two-dimensional situations and simulate the behavior of cells adhered to flat substrates as well as micro-posts. This modeling scheme is shown to capture a variety of key experimental observations including: (i) high concentrations of stress-fibers and focal adhesions at the periphery of ligand patterns; (ii) high focal adhesion concentrations along the edges of the V, T, Y and U-shaped concave ligand patterns; and (iii) highly aligned stress-fibers along the non-adhered edges of cells. We also use this model to simulate the cell response to varying substrate stiffness, substrate architecture and cell size. Both for flat gel substrates and micro-posts, cell contractility and focal adhesion concentration are shown to be higher for stiffer adhered substrate, which matches with experimental results in the literature. Lastly, we devise a new signaling model for the pathway where a Ca2+ signal originates from focal adhesions growth and activates the intracellular acto-myosin contractile machinery. A one dimensional cell attached to a rigid ligand patch and pulled at one end is utilized to demonstrate the response of a cell having the signaling, stress fiber and focal adhesion models.},
	language = {en},
	publisher = {ProQuest},
	year = {2008},
	note = {Google-Books-ID: 2oX311OcS44C},
	keywords = {Abaqus, Cell Adhesion, Focal Adhesion}
}

@misc{center_for_history_and_new_media_zotero_nodate,
	title = {Zotero {Quick} {Start} {Guide}},
	url = {http://zotero.org/support/quick_start_guide},
	author = {{Center for History and New Media}}
}

@article{he_basic_2014,
	title = {Some basic questions on mechanosensing in cell–substrate interaction},
	volume = {70},
	issn = {0022-5096},
	url = {http://www.sciencedirect.com/science/article/pii/S0022509614001070},
	doi = {10.1016/j.jmps.2014.05.016},
	abstract = {Cells constantly probe their surrounding microenvironment by pushing and pulling on the extracellular matrix (ECM). While it is widely accepted that cell induced traction forces at the cell–matrix interface play essential roles in cell signaling, cell migration and tissue morphogenesis, a number of puzzling questions remain with respect to mechanosensing in cell–substrate interactions. Here we show that these open questions can be addressed by modeling the cell–substrate system as a pre-strained elastic disk attached to an elastic substrate via molecular bonds at the interface. Based on this model, we establish analytical and numerical solutions for the displacement and stress fields in both cell and substrate, as well as traction forces at the cell–substrate interface. We show that the cell traction generally increases with distance away from the cell center and that the traction-distance relationship changes from linear on soft substrates to exponential on stiff substrates. These results indicate that cell adhesion and migration behaviors can be regulated by cell shape and substrate stiffness. Our analysis also reveals that the cell traction increases linearly with substrate stiffness on soft substrates but then levels off to a constant value on stiff substrates. This biphasic behavior in the dependence of cell traction on substrate stiffness immediately sheds light on an existing debate on whether cells sense mechanical force or deformation when interacting with their surroundings. Finally, it is shown that the cell induced deformation field decays exponentially with distance away from the cell. The characteristic length of this decay is comparable to the cell size and provides a quantitative measure of how far cells feel into the ECM.},
	urldate = {2016-12-09},
	journal = {Journal of the Mechanics and Physics of Solids},
	author = {He, Shijie and Su, Yewang and Ji, Baohua and Gao, Huajian},
	month = oct,
	year = {2014},
	keywords = {Cell adhesion, Cell migration, Cell traction, Cells, Cell–matrix interaction, ECM},
	pages = {116--135}
}

@article{gardel_cellsubstrate_2010,
	title = {Cell–substrate interactions},
	volume = {22},
	issn = {0953-8984},
	url = {http://stacks.iop.org/0953-8984/22/i=19/a=190301},
	doi = {10.1088/0953-8984/22/19/190301},
	abstract = {One of the most striking achievements of evolution is the ability to build cellular systems that are both robust and dynamic. Taken by themselves, both properties are obvious requirements: robustness reflects the fact that cells are there to survive, and dynamics is required to adapt to changing environments. However, it is by no means trivial to understand how these two requirements can be implemented simultaneously in a physical system. The long and difficult quest to build adaptive materials is testimony to the inherent difficulty of this goal. Here materials science can learn a lot from nature, because cellular systems show that robustness and dynamics can be achieved in a synergetic fashion. For example, the capabilities of tissues to repair and regenerate are still unsurpassed in the world of synthetic materials. One of the most important aspects of the way biological cells adapt to their environment is their adhesive interaction with the substrate. Numerous aspects of the physiology of metazoan cells, including survival, proliferation, differentiation and migration, require the formation of adhesions to the cell substrate, typically an extracellular matrix protein. Adhesions guide these diverse processes both by mediating force transmission from the cell to the substrate and by controlling biochemical signaling pathways. While the study of cell–substrate adhesions is a mature field in cell biology, a quantitative biophysical understanding of how the interactions of the individual molecular components give rise to the rich dynamics and mechanical behaviors observed for cell–substrate adhesions has started to emerge only over the last decade or so. The recent growth of research activities on cell–substrate interactions was strongly driven by the introduction of new physical techniques for surface engineering into traditional cell biological work with cell culture. For example, microcontact printing of adhesive patterns was used to show that cell fate depends not on the amount of ligand for adhesion receptors, but on its spatial distribution [ 1 [\#ref1] ]. New protocols for the preparation of soft elastic substrates were essential to show that adhesion structures and cytoskeleton of adherent cells strongly adapt to substrate stiffness [ 2 [\#ref2] ], with dramatic effects for cellular decision making. For example, it has been shown recently that differentiation of mesenchymal stem cells is strongly influenced by substrate stiffness [ 3 [\#ref3] ]. Thus, physical factors appear to be equally important as biochemical ones in determining the cellular response to its substrate [ 4 [\#ref4] ]. The introduction of novel physical techniques not only opened up completely new perspectives regarding biological function, it also introduced a new quantitative element into this field. For example, the availability of soft elastic substrates with controlled stiffness allows us to reconstruct cellular traction forces and to correlate them with other cellular features. This development enables modeling approaches to work in close contact with experimental data, thus opening up the perspective that the field of cell–substrate interactions will become a quantitative and predictive science in the future. Because physical research into cell–substrate interactions has become one of the fastest growing research areas in cellular biophysics and materials science, we believe that it is very timely that this special issue gathers some of the on-going research effort in this field. In contrast to the non-living world, cellular systems usually interact with their environment through specific adhesion, mainly based on adhesion receptors from the integrin family. During recent years, force spectroscopy has emerged as one of the main methods to study the physics of specific adhesion. In this special issue, single cell force spectroscopy is used by Boettiger and Wehrle-Haller to characterize the strength of cell-matrix adhesion and how it is modulated by the glycocalyx [ 5 [\#ref5] ], while Chirasatitsin and Engler use force spectroscopy mapping to characterize the spatial distribution of adhesive sites on the substrate [ 6 [\#ref6] ]. Scrimgeour et al describe a new method to adhesively pattern self-assembled monolayers for cell adhesion by a simple photobleaching setup [ 7 [\#ref7] ] and Stricker et al demonstrate how elastic substrates can be combined with microcontact printing to improve the reconstruction of traction forces [ 8 [\#ref8] ]. The work by Metzner et al shows that meaningful results on the cell–substrate interactions can be extracted also from experiments in which cells interact with biofunctionalized beads [ 9 [\#ref9] ]. If cells start to adhere to a substrate, the main rate-limiting step is establishment of close contact between the plasma membrane and the substrate. This process can be followed with high spatial and temporal resolution with reflection interference microscopy, as demonstrated by Ryzhkov et al for mouse embryonic fibroblasts [ 10 [\#ref10] ] and by Cretel et al for T lymphocytes [ 11 [\#ref11] ]. Once mature adhesion has been achieved, the integrin-based focal adhesions providing anchorage to the substrate are strongly connected to the actin cytoskeleton, the main determinant of cell shape and structure. Heil and Spatz use microfabricated pillars to perturb the mechanical balance and quantitatively characterize the fast response of the focal adhesions [ 12 [\#ref12] ]. A similar approach is used by Kirchenbüchler et al , who use deformation of an elastic substrate to demonstrate that the weak link in the mechanical system of substrate, adhesions and actin cytoskeleton is most likely located at the adhesion-cytoskeleton interface [ 13 [\#ref13] ]. Rather than using external perturbations, Zemel et al quantify and model how cells spontaneously polarize their cytoskeleton in response to the physical properties of the substrate [ 14 [\#ref14] ]. Quantitative analysis of cellular data has become standard in the field of cell–substrate interactions. Moreover, theoretical models for cell–substrate interactions help us to identify and understand the mechanisms underlying the observed phenomena in these complex systems. Recently, a large effort has been invested into understanding how force transmitted by the actin cytoskeleton changes the state of focal adhesions. In the contribution by Biton and Safran, this issue is addressed for the case that force arises from shear flow over an adhering cell [ 15 [\#ref15] ]. Another important source for force on focal adhesions is actin retrograde flow, which has been demonstrated before to show variable coupling to the underlying layer of adhesion receptors. Two contributions discuss how stochastic bond dynamics at the cell–substrate interface is modulated by physical factors. The model by Sabass and Schwarz suggests that dissipation in the actin cytoskeleton stabilizes bond dynamics [ 16 [\#ref16] ] and the model by Li et al suggests that catch bonding and multiple layers are important elements of the way focal adhesions function [ 17 [\#ref17] ]. If interacting with an elastic environment, the combined system of focal adhesions and actin cytoskeleton can be used by cells to sense its rigidity and to make decisions on its response. Moshayedi et al show that great care has to be taken when preparing soft elastic substrates for cell culture studies and then use their protocols to quantitatively evaluate the mechanosensitive response of astrocytes from the brain [ 18 [\#ref18] ]. The cellular system used by Lee et al is pericytes from the microvasculature, for which the authors show that they exert sufficient forces to stimulate vascular endothelial cells [ 19 [\#ref19] ]. Buxboim et al use the technology of soft elastic substrates to measure how far mesenchymal stem cells can mechanically sense into their substrate [ 20 [\#ref20] ]. The mechanical activity of cells observed in two-dimensional cell culture has significant consequences for both physiological and disease-related situations, including cell migration, tissue maintenance and tumor growth. Jannat et al show that chemotaxis of neutrophils, that is the first line of the immune system, is strongly modulated by mechanosensing on substrates of varying stiffness [ 21 [\#ref21] ]. Mogilner and Rubinstein present a theoretical systems analysis for the shape of rapidly migrating keratocytes [ 22 [\#ref22] ]. Saez et al show, with microfabricated pillar assays, how force is distributed within a layer of epithelial cells [ 23 [\#ref23] ]. For three-dimensional tissue models, new techniques have to be developed to characterize the complex mechanics of hydrogels. Levental et al [ 24 [\#ref24] ] and Kotlarchyk et al [ 25 [\#ref25] ] approach this challenge with mechanical and optical methods, respectively. Narayanan et al combine experiments and continuum models to explore how chemo-mechanical interactions influence tumor growth [ 26 [\#ref26] ]. References [1] Chen C S, Mrksich M, Huang S, Whitesides G M and Ingber D E 1997 Geometric control of cell life and death Science 276 [http://dx.doi.org/10.1126/science.276.5317.1425] 1425 [2] Pelham R J Jr and Wang Y-L 1997 Cell locomotion and focal adhesions are regulated by substrate flexibility Proc. Natl. Acad. Sci. USA 94 [http://www.pnas.org/content/94/25/13661.abstract?sid=2588ef69-ccb8-46a2-92f3-b0abfdc5e41f] 13661 [3] Engler A J, Sen S, Sweeney H L and Discher D E 2006 Matrix elasticity directs stem cell lineage specification Cell 126 [http://dx.doi.org/10.1016/j.cell.2006.06.044] 677–89 [4] Geiger B, Spatz J P and Bershadsky A D 2009 Environmental sensing through focal adhesions Nat. Rev. Mol. Cell Biol. 10 [http://dx.doi.org/10.1038/nrm25934] 21 [5] Boettiger D and Wehrle-Haller B 2010 Integrin and glycocalyx mediated contributions to cell adhesion identified by single cell force spectroscopy J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194101] 194101 [6] Chirasatitsin S and Engler A J 2010 Detecting cell-adhesive sites in extracellular matrix using force spectroscopy mapping J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194102] 194102 [7] Scrimgeour J, Kodali V K, Kovari D T and Curtis J E 2010 Photobleaching-activated micropatterning on self-assembled monolayers J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194103] 194103 [8] Stricker J, Sabass B, Schwarz U S and Gardel M L 2010 Optimization of traction force microscopy for micron-sized focal adhesions J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194104] 194104 [9] Metzner C, Raupach C, Mierke C T and Fabry B 2010 Fluctuations of cytoskeleton-bound microbeads—the effect of bead–receptor binding dynamics J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194105] 194105 [10] Ryzhkov P, Prass M, Gummich M, Kühn J-S, Oettmeier C and Döbereiner H-G 2010 Adhesion patterns in early cell spreading J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194106] 194106 [11] Cretel E, Touchard D, Benoliel A M, Bongrand P and Pierres A 2010 Early contacts between T lymphocytes and activating surfaces J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194107] 194107 [12] Heil P and Spatz J P 2010 Lateral shear forces applied to cells with single elastic micropillars to influence focal adhesion dynamics J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194108] 194108 [13] Kirchenbüchler D, Born S, Kirchgeßner N, Houben S, Hoffmann B and Merkel R 2010 Substrate, focal adhesions, and actin filaments: a mechanical unit with a weak spot for mechanosensitive proteins J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194109] 194109 [14] Zemel A, Rehfeldt F, Brown A E X, Discher D E and Safran S A 2010 Cell shape, spreading symmetry, and the polarization of stress-fibers in cells J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194110] 194110 [15] Biton Y Y and Safran S A 2010 Theory of the mechanical response of focal adhesions to shear flow J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194111] 194111 [16] Sabass B and Schwarz U S 2010 Modeling cytoskeletal flow over adhesion sites: competition between stochastic bond dynamics and intracellular relaxation J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194112] 194112 [17] Li Y, Bhimalapuram P and Dinner A R 2010 Model for how retrograde actin flow regulates adhesion traction stresses J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194113] 194113 [18] Moshayedi P, da F Costa L, Christ A, Lacour S P, Fawcett J, Guck J and Franze K 2010 Mechanosensitivity of astrocytes on optimized polyacrylamide gels analyzed by quantitative morphometry J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194114] 194114 [19] Lee S, Zeiger A, Maloney J M, Kotecki M, Van Vliet K J and Herman I M 2010 Pericyte contraction at the cell-material interface can modulate the microvascular niche J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194115] 194115 [20] Buxboim A, Rajagopal K, Brown A E X and Discher D E 2010 How deeply cells feel: methods for thin gels J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194116] 194116 [21] Jannat R A, Robbins G P, Ricart B G, Dembo M and Hammer D A 2010 Neutrophil adhesion and chemotaxis depend on substrate mechanics J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194117] 194117 [22] Mogilner A and Rubinstein B 2010 Actin disassembly 'clock' and membrane tension determine cell shape and turning: a mathematical method J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194118] 194118 [23] Saez A, Anon E, Ghibaudo M, du Roure O, Di Meglio J-M, Hersen P, Silberzan P, Buguin A, Ladoux B 2010 Traction forces exerted by epithelial cell sheets J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194119] 194119 [24] Levental I, Levental K R, Klein E A, Assoian R, Miller R T, Wells R G and Janmey P A 2010 A simple indentation device for measuring micrometer-scale tissue stiffness J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194120] 194120 [25] Kotlarchyk M A, Botvinick E L and Putnam A J 2010 Characterization of hydrogel microstructure using laser tweezers particle tracking and confocal reflection imaging J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194121] 194121 [26] Narayanan H, Verner S N, Mills K L, Kemkemer R and Garikipati K 2010 In silico estimates of the free energy rates in growing tumor spheroids J. Phys.: Condens. Matter 22 [http://dx.doi.org/10.1088/0953-8984/22/19/194122] 194122},
	language = {en},
	number = {19},
	urldate = {2016-12-09},
	journal = {Journal of Physics: Condensed Matter},
	author = {Gardel, Margaret and Schwarz, Ulrich},
	year = {2010},
	pages = {190301}
}

@article{engler_matrix_2006-1,
	title = {Matrix {Elasticity} {Directs} {Stem} {Cell} {Lineage} {Specification}},
	volume = {126},
	issn = {0092-8674},
	url = {http://www.sciencedirect.com/science/article/pii/S0092867406009615},
	doi = {10.1016/j.cell.2006.06.044},
	abstract = {Summary
Microenvironments appear important in stem cell lineage specification but can be difficult to adequately characterize or control with soft tissues. Naive mesenchymal stem cells (MSCs) are shown here to specify lineage and commit to phenotypes with extreme sensitivity to tissue-level elasticity. Soft matrices that mimic brain are neurogenic, stiffer matrices that mimic muscle are myogenic, and comparatively rigid matrices that mimic collagenous bone prove osteogenic. During the initial week in culture, reprogramming of these lineages is possible with addition of soluble induction factors, but after several weeks in culture, the cells commit to the lineage specified by matrix elasticity, consistent with the elasticity-insensitive commitment of differentiated cell types. Inhibition of nonmuscle myosin II blocks all elasticity-directed lineage specification–without strongly perturbing many other aspects of cell function and shape. The results have significant implications for understanding physical effects of the in vivo microenvironment and also for therapeutic uses of stem cells.},
	number = {4},
	urldate = {2016-12-09},
	journal = {Cell},
	author = {Engler, Adam J. and Sen, Shamik and Sweeney, H. Lee and Discher, Dennis E.},
	month = aug,
	year = {2006},
	pages = {677--689}
}

@article{he_basic_2014-1,
	title = {Some basic questions on mechanosensing in cell–substrate interaction},
	volume = {70},
	issn = {0022-5096},
	url = {http://www.sciencedirect.com/science/article/pii/S0022509614001070},
	doi = {10.1016/j.jmps.2014.05.016},
	abstract = {Cells constantly probe their surrounding microenvironment by pushing and pulling on the extracellular matrix (ECM). While it is widely accepted that cell induced traction forces at the cell–matrix interface play essential roles in cell signaling, cell migration and tissue morphogenesis, a number of puzzling questions remain with respect to mechanosensing in cell–substrate interactions. Here we show that these open questions can be addressed by modeling the cell–substrate system as a pre-strained elastic disk attached to an elastic substrate via molecular bonds at the interface. Based on this model, we establish analytical and numerical solutions for the displacement and stress fields in both cell and substrate, as well as traction forces at the cell–substrate interface. We show that the cell traction generally increases with distance away from the cell center and that the traction-distance relationship changes from linear on soft substrates to exponential on stiff substrates. These results indicate that cell adhesion and migration behaviors can be regulated by cell shape and substrate stiffness. Our analysis also reveals that the cell traction increases linearly with substrate stiffness on soft substrates but then levels off to a constant value on stiff substrates. This biphasic behavior in the dependence of cell traction on substrate stiffness immediately sheds light on an existing debate on whether cells sense mechanical force or deformation when interacting with their surroundings. Finally, it is shown that the cell induced deformation field decays exponentially with distance away from the cell. The characteristic length of this decay is comparable to the cell size and provides a quantitative measure of how far cells feel into the ECM.},
	urldate = {2016-12-09},
	journal = {Journal of the Mechanics and Physics of Solids},
	author = {He, Shijie and Su, Yewang and Ji, Baohua and Gao, Huajian},
	month = oct,
	year = {2014},
	keywords = {Cell adhesion, Cell migration, Cell traction, Cell–matrix interaction},
	pages = {116--135}
}

@article{ahmed_hydrogel:_2015,
	title = {Hydrogel: {Preparation}, characterization, and applications: {A} review},
	volume = {6},
	issn = {2090-1232},
	shorttitle = {Hydrogel},
	url = {http://www.sciencedirect.com/science/article/pii/S2090123213000969},
	doi = {10.1016/j.jare.2013.07.006},
	abstract = {Hydrogel products constitute a group of polymeric materials, the hydrophilic structure of which renders them capable of holding large amounts of water in their three-dimensional networks. Extensive employment of these products in a number of industrial and environmental areas of application is considered to be of prime importance. As expected, natural hydrogels were gradually replaced by synthetic types due to their higher water absorption capacity, long service life, and wide varieties of raw chemical resources. Literature on this subject was found to be expanding, especially in the scientific areas of research. However, a number of publications and technical reports dealing with hydrogel products from the engineering points of view were examined to overview technological aspects covering this growing multidisciplinary field of research. The primary objective of this article is to review the literature concerning classification of hydrogels on different bases, physical and chemical characteristics of these products, and technical feasibility of their utilization. It also involved technologies adopted for hydrogel production together with process design implications, block diagrams, and optimized conditions of the preparation process. An innovated category of recent generations of hydrogel materials was also presented in some details.},
	number = {2},
	urldate = {2016-12-09},
	journal = {Journal of Advanced Research},
	author = {Ahmed, Enas M.},
	month = mar,
	year = {2015},
	keywords = {Hydrogel, Innovation, Optimization, Preparation, Processing},
	pages = {105--121}
}

@article{manzano_structural_2015,
	title = {Structural biology response of a collagen hydrogel synthetic extracellular matrix with embedded human fibroblast: computational and experimental analysis},
	volume = {53},
	issn = {0140-0118, 1741-0444},
	shorttitle = {Structural biology response of a collagen hydrogel synthetic extracellular matrix with embedded human fibroblast},
	url = {http://link.springer.com/article/10.1007/s11517-015-1277-8},
	doi = {10.1007/s11517-015-1277-8},
	abstract = {Adherent cells exert contractile forces which play an important role in the spatial organization of the extracellular matrix (ECM). Due to these forces, the substrate experiments a volume reduction leading to a characteristic shape. ECM contraction is a key process in many biological processes such as embryogenesis, morphogenesis and wound healing. However, little is known about the specific parameters that control this process. With this aim, we present a 3D computational model able to predict the contraction process of a hydrogel matrix due to cell–substrate mechanical interaction. It considers cell-generated forces, substrate deformation, ECM density, cellular migration and proliferation. The model also predicts the cellular spatial distribution and concentration needed to reproduce the contraction process and confirms the minimum value of cellular concentration necessary to initiate the process observed experimentally. The obtained continuum formulation has been implemented in a finite element framework. In parallel, in vitro experiments have been performed to obtain the main model parameters and to validate it. The results demonstrate that cellular forces, migration and proliferation are acting simultaneously to display the ECM contraction.},
	language = {en},
	number = {8},
	urldate = {2016-12-09},
	journal = {Medical \& Biological Engineering \& Computing},
	author = {Manzano, Sara and Moreno-Loshuertos, Raquel and Doblaré, Manuel and Ochoa, Ignacio and Doweidar, Mohamed Hamdy},
	month = aug,
	year = {2015},
	pages = {721--735}
}